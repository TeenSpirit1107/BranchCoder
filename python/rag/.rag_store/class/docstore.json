{"docstore/metadata": {"class::0": {"doc_hash": "7ee8c57becdd7507a5ba717c297add00f7d21c3d2d8021ff4cf0ac7fcfb65eda"}, "class::1": {"doc_hash": "a37811d48eafdcda063528dd74a7dd4b711d0f62693844561110b35f4ba0d55c"}, "class::2": {"doc_hash": "233fd563b37ceee70e898eef869de303bab73294b3145318fcd07613aff0afbc"}, "fe5c7dd6-1f8f-49ab-9691-ef56210c1b3e": {"doc_hash": "a298f11138b8e3ccf64118cb3ab54cdb1370136b6e4ca4860d3698c3f52a31e0", "ref_doc_id": "class::0"}, "94dd7c5f-f394-44cb-b237-2d4f6a0f3c13": {"doc_hash": "d72fd2534163b1eff8b37207e008e484efdbd3d569956f02b5a14b24185dd342", "ref_doc_id": "class::1"}, "e2387403-f6a2-47fb-928f-18f0358d9536": {"doc_hash": "8be741579710470d3e32ea86d4dfcde41e1c1dd6360a63cee5454b3aff1f651a", "ref_doc_id": "class::2"}}, "docstore/ref_doc_info": {"class::0": {"node_ids": ["fe5c7dd6-1f8f-49ab-9691-ef56210c1b3e"], "metadata": {"type": "class", "idx": 0, "file": "/home/yf/Workspace/deep_learning/assignment1/models/softmax_regression.py", "name": "SoftmaxRegression", "qualname": "<module>.SoftmaxRegression"}}, "class::1": {"node_ids": ["94dd7c5f-f394-44cb-b237-2d4f6a0f3c13"], "metadata": {"type": "class", "idx": 1, "file": "/home/yf/Workspace/deep_learning/assignment1/models/_base_network.py", "name": "_baseNetwork", "qualname": "<module>._baseNetwork"}}, "class::2": {"node_ids": ["e2387403-f6a2-47fb-928f-18f0358d9536"], "metadata": {"type": "class", "idx": 2, "file": "/home/yf/Workspace/deep_learning/assignment1/models/two_layer_nn.py", "name": "TwoLayerNet", "qualname": "<module>.TwoLayerNet"}}}, "docstore/data": {"fe5c7dd6-1f8f-49ab-9691-ef56210c1b3e": {"__data__": {"id_": "fe5c7dd6-1f8f-49ab-9691-ef56210c1b3e", "embedding": null, "metadata": {"type": "class", "idx": 0, "file": "/home/yf/Workspace/deep_learning/assignment1/models/softmax_regression.py", "name": "SoftmaxRegression", "qualname": "<module>.SoftmaxRegression"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "class::0", "node_type": "4", "metadata": {"type": "class", "idx": 0, "file": "/home/yf/Workspace/deep_learning/assignment1/models/softmax_regression.py", "name": "SoftmaxRegression", "qualname": "<module>.SoftmaxRegression"}, "hash": "7ee8c57becdd7507a5ba717c297add00f7d21c3d2d8021ff4cf0ac7fcfb65eda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A single-layer softmax regression neural network extended from _baseNetwork; responsible for weight management (W1), forward computation of loss/accuracy, and gradient computation for training via backpropagation through a ReLU-activated linear layer before softmax.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 266, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "94dd7c5f-f394-44cb-b237-2d4f6a0f3c13": {"__data__": {"id_": "94dd7c5f-f394-44cb-b237-2d4f6a0f3c13", "embedding": null, "metadata": {"type": "class", "idx": 1, "file": "/home/yf/Workspace/deep_learning/assignment1/models/_base_network.py", "name": "_baseNetwork", "qualname": "<module>._baseNetwork"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "class::1", "node_type": "4", "metadata": {"type": "class", "idx": 1, "file": "/home/yf/Workspace/deep_learning/assignment1/models/_base_network.py", "name": "_baseNetwork", "qualname": "<module>._baseNetwork"}, "hash": "a37811d48eafdcda063528dd74a7dd4b711d0f62693844561110b35f4ba0d55c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A foundational base class that stores configuration (input_size, num_classes) and parameter containers (weights, gradients), and provides common neural-network utilities (softmax, cross-entropy loss, accuracy, and simple activations with derivatives). It is designed to be subclassed to implement concrete architectures and forward/backward passes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 348, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2387403-f6a2-47fb-928f-18f0358d9536": {"__data__": {"id_": "e2387403-f6a2-47fb-928f-18f0358d9536", "embedding": null, "metadata": {"type": "class", "idx": 2, "file": "/home/yf/Workspace/deep_learning/assignment1/models/two_layer_nn.py", "name": "TwoLayerNet", "qualname": "<module>.TwoLayerNet"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "class::2", "node_type": "4", "metadata": {"type": "class", "idx": 2, "file": "/home/yf/Workspace/deep_learning/assignment1/models/two_layer_nn.py", "name": "TwoLayerNet", "qualname": "<module>.TwoLayerNet"}, "hash": "233fd563b37ceee70e898eef869de303bab73294b3145318fcd07613aff0afbc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A simple feedforward neural network with one hidden layer (hidden_size), using sigmoid activation between layers and softmax cross-entropy loss for classification; it initializes parameters in _weight_init, and exposes a forward method that also computes and stores gradients for optimization via backpropagation; it inherits common behaviors (activations, loss, metrics) from the _baseNetwork base class.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 405, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}