{"docstore/metadata": {"file::0": {"doc_hash": "5605d5bc58f306303daba49d7b477915e478bc50d92b136059f849b611371177"}, "file::1": {"doc_hash": "b6a4434b0a77d0437e9d13dff4be3d77f76c9b7882cd020cce235b8923d0f5e2"}, "file::2": {"doc_hash": "b70dcb164797fb875aaf4483f241d0a326654348f22e74d5784c1c8a65cf43c6"}, "3af61f7a-fc95-43e0-ba8e-3d415f7cbb63": {"doc_hash": "9f4888791b9da94c4f990f49df0e70d9692221d5740b6a920cc99f55f9c4f596", "ref_doc_id": "file::0"}, "e29aaab4-6e88-474d-bf48-a5b7a851f657": {"doc_hash": "ed37f945c2c32eacab5cada96e9cda05264bbc2e9066abbee57d336dd4f83275", "ref_doc_id": "file::1"}, "64abe6c4-14a7-438f-9381-3c7a6e96511c": {"doc_hash": "6cdb4c9ef018cfbfabf0cb0fe11cb4845bcbe2946b6d033b1668e20fb59681a3", "ref_doc_id": "file::2"}, "a82d70f4-16bf-4335-882a-221c10b8c9cb": {"doc_hash": "3fc221516d6a74119a11e1746e3e991606ffc3a5a588707a502272377927ae08", "ref_doc_id": "file::0"}, "b02d1fd5-36f7-42b8-9738-7da52d0650d6": {"doc_hash": "e59eb52f2a96a765afafd605f21ff805a99345387128c86074dcdcaeb932021b", "ref_doc_id": "file::0"}, "468a3a23-afec-43b9-960e-3fd1b6ff4b13": {"doc_hash": "0d4018486a5f7f6b942960556fc78b5f9ba014291eb51aedaeb3fa4f5b0837f9", "ref_doc_id": "file::0"}, "120bb69f-6d57-4e96-b192-221b87d55b5e": {"doc_hash": "58d46aae3b63a21aec2c17db47a2f1c417274f0380cf51243e2643081519b4ae", "ref_doc_id": "file::0"}, "8dd01f08-9697-4a37-b9fa-a4d668922398": {"doc_hash": "7a0b1e72cddac8510d0ee943fb1663f4310c56df54ea323b0dbecabacfd95fb8", "ref_doc_id": "file::0"}, "790265b5-ab7f-444c-af28-6082f26b344f": {"doc_hash": "f636ef75885a9a3353d704d8a1b84384d6cb08cc7be8330c71c7c927f869b36e", "ref_doc_id": "file::0"}, "82952809-d15b-4c2b-850b-c5d9435fabbf": {"doc_hash": "4a94153c166551b073a2ff6d6ad5d690be0a3af709f855cdf592edb0df989896", "ref_doc_id": "file::0"}, "dec3b867-cb63-429c-980c-8b7e9be9146f": {"doc_hash": "5585d8c1bb21de3daec20f4e3e424504807f88119ca3e23c12f05d5a33651a09", "ref_doc_id": "file::0"}, "f3dab468-6b0a-4db8-a0ee-7654625bacdb": {"doc_hash": "256f21258453ff73b442fd2e67d5d9a60b595f4dd63724aa843006029cd84a89", "ref_doc_id": "file::0"}, "b7af01f6-e21b-4a5f-a17e-c43788cff166": {"doc_hash": "8fa64d5b09a9dcacb4580fbf3d26e98beb22ab072b07ada842d502d291f74cf2", "ref_doc_id": "file::0"}, "8b6bb0d8-e890-4e0d-942b-1c4c42080305": {"doc_hash": "743f9f6344393c3a6857db14f49bd81fef366abb19d19fc683eb2aa48ab6eca3", "ref_doc_id": "file::0"}, "a1211432-f10f-4b5b-8cd4-5d8f9a29e24d": {"doc_hash": "29ee7e60e3d65d1017d33a5ce8a3db25cd22715e5db7c7e74a682ebaa2431dfb", "ref_doc_id": "file::0"}, "7df94a5d-8f02-4c51-90ac-ef8d470b4fb1": {"doc_hash": "b18540473136104907d924cd6c8876342ab873a8e032623cd3507a3e8cc1cc33", "ref_doc_id": "file::0"}, "62f4b61a-237e-4da6-8113-aa115245584d": {"doc_hash": "52e2b25551446b97a33d774a2a0ce6a7b364ec48793528bfe6a0db87ec8ebb0d", "ref_doc_id": "file::0"}, "9097f7f8-005f-4429-bc64-9b5748140e40": {"doc_hash": "1df3585f3b0195b818f866dc3f04363b68467c74eaa3820d719e67ed9566d817", "ref_doc_id": "file::0"}}, "docstore/ref_doc_info": {"file::0": {"node_ids": ["3af61f7a-fc95-43e0-ba8e-3d415f7cbb63", "a82d70f4-16bf-4335-882a-221c10b8c9cb", "b02d1fd5-36f7-42b8-9738-7da52d0650d6", "468a3a23-afec-43b9-960e-3fd1b6ff4b13", "120bb69f-6d57-4e96-b192-221b87d55b5e", "8dd01f08-9697-4a37-b9fa-a4d668922398", "790265b5-ab7f-444c-af28-6082f26b344f", "82952809-d15b-4c2b-850b-c5d9435fabbf", "dec3b867-cb63-429c-980c-8b7e9be9146f", "f3dab468-6b0a-4db8-a0ee-7654625bacdb", "b7af01f6-e21b-4a5f-a17e-c43788cff166", "8b6bb0d8-e890-4e0d-942b-1c4c42080305", "a1211432-f10f-4b5b-8cd4-5d8f9a29e24d", "7df94a5d-8f02-4c51-90ac-ef8d470b4fb1", "62f4b61a-237e-4da6-8113-aa115245584d", "9097f7f8-005f-4429-bc64-9b5748140e40"], "metadata": {"type": "file", "idx": 0, "file": "softmax_regression.py"}}, "file::1": {"node_ids": ["e29aaab4-6e88-474d-bf48-a5b7a851f657"], "metadata": {"type": "file", "idx": 1, "file": "_base_network.py"}}, "file::2": {"node_ids": ["64abe6c4-14a7-438f-9381-3c7a6e96511c"], "metadata": {"type": "file", "idx": 2, "file": "two_layer_nn.py"}}}, "docstore/data": {"3af61f7a-fc95-43e0-ba8e-3d415f7cbb63": {"__data__": {"id_": "3af61f7a-fc95-43e0-ba8e-3d415f7cbb63", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "softmax_regression.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "softmax_regression.py"}, "hash": "2f4ea4ac5f041d7b141e9e31fa60a3b2c96c80ebcc41ac0ed6a3ebdc3babdccb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SoftmaxRegression: Defines a single-layer softmax regression classifier with no bias. It inherits from _baseNetwork to reuse common utilities for activations, loss calculation, accuracy, and gradient storage. The class initializes a weight matrix W1 and corresponding gradient buffers, seeding NumPy for reproducibility. The forward method supports both training and evaluation: it computes a linear projection, applies ReLU, then softmax, and derives cross-entropy loss and accuracy; in training mode it also backpropagates to compute and store gradients w.r.t. W1. It relies on NumPy and the base network module in the same package for core operations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e29aaab4-6e88-474d-bf48-a5b7a851f657": {"__data__": {"id_": "e29aaab4-6e88-474d-bf48-a5b7a851f657", "embedding": null, "metadata": {"type": "file", "idx": 1, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::1", "node_type": "4", "metadata": {"type": "file", "idx": 1, "file": "_base_network.py"}, "hash": "b6a4434b0a77d0437e9d13dff4be3d77f76c9b7882cd020cce235b8923d0f5e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "File-level summary This module defines a base neural network class using NumPy, intended to be extended by concrete models. It stores weights and gradients in dictionaries and provides a set of common utilities for neural networks, including softmax, cross-entropy loss, accuracy computation, and basic activation functions (sigmoid and ReLU) with their derivatives. The forward pass and weight initialization are left as placeholders for subclasses to implement. The implementation is self-contained, with no external dependencies beyond NumPy, and emphasizes numerical stability (e.g., softmax) and safe loss computation. The class interacts with training loops and layer-specific components via standardized interfaces and shared data structures (weights and gradients).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 773, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "64abe6c4-14a7-438f-9381-3c7a6e96511c": {"__data__": {"id_": "64abe6c4-14a7-438f-9381-3c7a6e96511c", "embedding": null, "metadata": {"type": "file", "idx": 2, "file": "two_layer_nn.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::2", "node_type": "4", "metadata": {"type": "file", "idx": 2, "file": "two_layer_nn.py"}, "hash": "b70dcb164797fb875aaf4483f241d0a326654348f22e74d5784c1c8a65cf43c6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TwoLayerNet module implementing a simple two-layer neural network for classification. It extends a base network (_baseNetwork) to reuse utilities for activations, loss calculation, and accuracy metrics. The file handles deterministic weight initialization, forward computation (including loss, accuracy, and gradient generation), and backpropagation to populate gradients for W1, b1, W2, and b2. It relies on numpy for numeric operations and on methods provided by the base class such as sigmoid, sigmoid_dev, softmax, cross_entropy_loss, and compute_accuracy. This structure is designed to be used by training loops that update parameters via the stored gradients.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 665, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a82d70f4-16bf-4335-882a-221c10b8c9cb": {"__data__": {"id_": "a82d70f4-16bf-4335-882a-221c10b8c9cb", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "a81757543e92ef44c40ae4afbb53307cd73f07b2660c6e9ced137a48cfa70182", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A minimal base neural network module intended to be subclassed by concrete models. It defines configuration attributes like input_size and num_classes, and stores weights and gradients in dictionaries for easy extension. It provides common utility functions used in neural nets, including a numerically stable softmax, cross-entropy loss, and accuracy calculation, as well as basic activations (sigmoid and ReLU) with their derivatives. The file includes placeholder methods for weight initialization and forward pass to be implemented by subclasses. A small top-level greeting function is included to facilitate imports in tests. The module depends on NumPy and is designed to be extended by specific network implementations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 726, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b02d1fd5-36f7-42b8-9738-7da52d0650d6": {"__data__": {"id_": "b02d1fd5-36f7-42b8-9738-7da52d0650d6", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "0c2fef7a8ab4c6a29dbb5f15525f9fdc6fd358206d9626e0b7f62ba0e3053a21", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The module defines a minimal base neural network class intended to be extended by concrete models. It stores core configuration like input_size and num_classes, and maintains dictionaries for weights and gradients. It provides utility implementations for common operations such as softmax, cross-entropy loss, accuracy measurement, and basic activation functions (sigmoid and ReLU) along with their derivatives. There are placeholder methods for weight initialization and the forward pass, signaling where subclasses should implement model-specific behavior. The code relies on NumPy and includes a small greeting helper for testing.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 633, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "468a3a23-afec-43b9-960e-3fd1b6ff4b13": {"__data__": {"id_": "468a3a23-afec-43b9-960e-3fd1b6ff4b13", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "18ccd29b09b34a764cc8e4632423d9e10b5ab80fb52e999cb1610b95e6990ef0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The file defines a base neural network class, _baseNetwork, intended to be extended by specific architectures. It uses NumPy for numerical operations and maintains dictionaries for weights and gradients. It provides common utility methods such as softmax, cross-entropy loss, accuracy computation, and common activation functions (sigmoid and ReLU) along with their derivatives. Some core methods like weight initialization and the forward pass are left as placeholders for subclasses to implement. The class tracks input size and number of classes, and includes a simple greeting helper for testing.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 600, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "120bb69f-6d57-4e96-b192-221b87d55b5e": {"__data__": {"id_": "120bb69f-6d57-4e96-b192-221b87d55b5e", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "8196f6e074f15c383c3c3635bf6d219a25b50054d27dc2f8b404e47dc0ff910f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The _base_network.py module defines a minimal base neural network class, primarily serving as a collection of common utilities and a lightweight scaffolding for more specialized networks. It imports numpy and exposes configuration (input_size, num_classes) along with dictionaries to hold weights and gradients. The class provides implementations for several standard activations (sigmoid, ReLU and their derivatives) and evaluation utilities (softmax, cross-entropy loss, accuracy) that can be reused by subclasses. Two placeholder methods (_weight_init and forward) are included for subclasses to implement concrete weight initialization and forward-pass logic. The module is designed to be extended by concrete network implementations and to support training workflows via numpy-based computations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 801, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8dd01f08-9697-4a37-b9fa-a4d668922398": {"__data__": {"id_": "8dd01f08-9697-4a37-b9fa-a4d668922398", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "8fc23698c1bb652fbc7b70c320e34b8eeb4c31bc26f75b920545e537339cb376", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The _baseNetwork module defines a minimal base class intended as a scaffold for neural network models. It initializes core configuration like input_size and number of classes, and maintains dictionaries for weights and gradients to be managed by subclasses. It provides placeholder methods for weight initialization and forward propagation, signaling that concrete models should override these. It implements common utilities including a numerically stable softmax, cross-entropy loss, and accuracy computation, along with a sigmoid activation. The module imports NumPy and includes a small testing helper function greeting, plus additional activation helpers whose placement in the file appears to be nested inside the greeting function, which is a formatting or scoping issue in the source.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 792, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "790265b5-ab7f-444c-af28-6082f26b344f": {"__data__": {"id_": "790265b5-ab7f-444c-af28-6082f26b344f", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "3cacf061f603ffffec65bda063e35a008aea42e90f30206664eddf94d801cfb8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The _baseNetwork.py module defines a lightweight base class for simple neural networks. It initializes with an input size and a number of classes, and maintains dictionaries for weights and gradients to be used by derived models. The file provides common utilities such as softmax, cross-entropy loss, and accuracy calculation, along with basic activation functions (sigmoid and ReLU) and their derivatives. There are two placeholder methods (_weight_init and forward) intended to be implemented by subclasses, indicating this class is meant to be extended for specific architectures. The code relies on numpy for numerical operations and includes standard numerical-stability practices (e.g., in softmax and cross-entropy). Note: there is a stray \"@@\" fragment in the sigmoid method that may cause a syntax issue if executed as-is.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 832, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82952809-d15b-4c2b-850b-c5d9435fabbf": {"__data__": {"id_": "82952809-d15b-4c2b-850b-c5d9435fabbf", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "93b08f04da5688c2f5f0337556934f72b5d32992204460e2b3a682d6444942a3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "File-level summary The module defines a base neural network class, _baseNetwork, that holds basic configuration such as input size and number of classes, along with dictionaries for weights and gradients to be populated by concrete implementations. It provides placeholder methods for weight initialization and the forward pass, signaling that subclasses should implement these steps. It also offers a collection of common utilities used in neural networks: softmax for converting scores to probabilities, cross-entropy loss, accuracy computation, and basic activation functions (sigmoid and ReLU) with their derivatives. A small greeting function is included to verify module import in testing environments. The code relies on NumPy and is intended to be extended by concrete architectures that fill in model-specific logic and parameter updates.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 847, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dec3b867-cb63-429c-980c-8b7e9be9146f": {"__data__": {"id_": "dec3b867-cb63-429c-980c-8b7e9be9146f", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "3911ee67333f912b5a79cf5c33fda5ed8923bd7ffaf057f7ab9ad0ca0a15c814", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "File-level summary This file defines a base class for neural networks, focusing on common utilities rather than a complete model. It exposes basic configuration (input_size and number of classes) and stores parameter and gradient dictionaries for potential subclasses. The class provides implementations for several activation functions (sigmoid, ReLU) and their derivatives, as well as core learning utilities like softmax, cross-entropy loss, and accuracy computation. It is designed to be extended by concrete network implementations, and relies solely on NumPy (no external non-standard dependencies). The methods operate on standard (N, D) shaped inputs and (N,) labels, and include numerical stabilization where appropriate.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 730, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f3dab468-6b0a-4db8-a0ee-7654625bacdb": {"__data__": {"id_": "f3dab468-6b0a-4db8-a0ee-7654625bacdb", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "512c337cad490e3b201c517bfb835072ddc547c67335245dbdfe8e8aca5b4cb6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The file `_base_network.py` defines a base class for a neural network, focusing on fundamental operations such as initialization, forward propagation, and activation functions. It relies on the `numpy` library for numerical operations. The class encapsulates methods for computing softmax probabilities, cross-entropy loss, accuracy, and various activation functions like sigmoid and ReLU, along with their derivatives. This file serves as a foundational component for building more complex neural network architectures.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7af01f6-e21b-4a5f-a17e-c43788cff166": {"__data__": {"id_": "b7af01f6-e21b-4a5f-a17e-c43788cff166", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "8cb5550daf26a4c1adb3e184da27c7019ed99694f8b4f15b7834a4a8519a4bbf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The `_base_network.py` file defines a foundational class for a neural network, focusing on basic operations such as initialization, forward propagation, and activation functions. It includes methods for computing softmax probabilities, cross-entropy loss, and accuracy, as well as activation functions like sigmoid and ReLU. The file relies on the `numpy` library for numerical operations and does not have any external dependencies beyond the standard Python distribution. The class is designed to be extended or used as a base for more complex network architectures.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 568, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b6bb0d8-e890-4e0d-942b-1c4c42080305": {"__data__": {"id_": "8b6bb0d8-e890-4e0d-942b-1c4c42080305", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "4084f984af0dc049ba413f744760be1ee9a8edd0c5fd5eb1197f21785ca5f144", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The file `_base_network.py` defines a base class for a neural network, focusing on initialization and basic operations such as activation functions and loss calculations. It relies on the `numpy` library for numerical operations. The class `_baseNetwork` is responsible for setting up the network's structure, including input size and number of classes, and provides methods for forward propagation, activation functions, and performance metrics like accuracy and loss. The file includes a simple greeting function for testing purposes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 536, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a1211432-f10f-4b5b-8cd4-5d8f9a29e24d": {"__data__": {"id_": "a1211432-f10f-4b5b-8cd4-5d8f9a29e24d", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "54259afc7365829fcd2c46ec77efb1414d67b36b66edb48fa218627ec4e0eb13", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This file, `_base_network.py`, defines a base class for a neural network model, focusing on fundamental operations such as initialization, forward propagation, and activation functions. It relies on the `numpy` library for numerical operations. The class `_baseNetwork` encapsulates the network's parameters and provides methods for computing softmax probabilities, cross-entropy loss, accuracy, and various activation functions. The file does not directly interact with other modules but provides essential building blocks for more complex neural network implementations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 572, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7df94a5d-8f02-4c51-90ac-ef8d470b4fb1": {"__data__": {"id_": "7df94a5d-8f02-4c51-90ac-ef8d470b4fb1", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "61698437cea41be1e8bb0b248ab7a0ec14085362af374e84e54b6bce1dada84f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This file, `_base_network.py`, defines a base class for a neural network, `_baseNetwork`, which is responsible for initializing network parameters, computing activations, and evaluating model performance. It includes methods for softmax, cross-entropy loss, accuracy computation, and activation functions like sigmoid and ReLU. The file relies on the `numpy` library for numerical operations and does not have any external dependencies beyond the standard Python distribution. The class is designed to be a foundational component for building more complex neural network models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 578, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "62f4b61a-237e-4da6-8113-aa115245584d": {"__data__": {"id_": "62f4b61a-237e-4da6-8113-aa115245584d", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "338bb3bae4d2f4ed6b4e6367676720c680bfc9d16c63c055ccf732c4412e6ced", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The file `_base_network.py` is responsible for defining a base neural network class, `_baseNetwork`, which includes methods for initializing network parameters, computing activations, and evaluating model performance. It relies on the `numpy` library for numerical operations. The class provides foundational methods such as `softmax`, `cross_entropy_loss`, and `compute_accuracy`, which are essential for training and evaluating neural networks. Additionally, it includes activation functions like `sigmoid` and `ReLU`, along with their derivatives.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 550, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9097f7f8-005f-4429-bc64-9b5748140e40": {"__data__": {"id_": "9097f7f8-005f-4429-bc64-9b5748140e40", "embedding": null, "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "file::0", "node_type": "4", "metadata": {"type": "file", "idx": 0, "file": "_base_network.py"}, "hash": "5605d5bc58f306303daba49d7b477915e478bc50d92b136059f849b611371177", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The file `_base_network.py` defines a base class for a neural network, focusing on core functionalities such as initialization, forward propagation, and activation functions. It relies on the `numpy` library for numerical operations. The class `_baseNetwork` encapsulates methods for computing softmax, cross-entropy loss, accuracy, and various activation functions, which are essential for training and evaluating neural networks. Additionally, a standalone function `greeting` is included for testing purposes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 512, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}