{
  "root": "/home/yf/Workspace/coding_agent",
  "classes": [
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/plan.py",
      "name": "ExecutionStatus",
      "qualname": "<module>.ExecutionStatus",
      "source": "class ExecutionStatus(str, Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    PAUSED = \"paused\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/plan.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(Enum):\n    CODE = \"code\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n    REASONING = \"reasoning\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/plan.py",
      "name": "Step",
      "qualname": "<module>.Step",
      "source": "class Step(BaseModel):\n    id: str\n\n    # superplanner modification\n    sub_plan_step: Optional[str] = None\n    sub_flow_type: Optional[SubPlannerType] = None\n    \n    description: str\n    status: ExecutionStatus = ExecutionStatus.PENDING\n    result: Optional[str] = None\n    error: Optional[str] = None\n\n    file: Optional[List[Dict[str, Any]]] = None\n    web: Optional[List[Dict[str, Any]]] = None\n\n    def is_done(self) -> bool:\n        return self.status == ExecutionStatus.COMPLETED or self.status == ExecutionStatus.FAILED\n",
      "methods": [
        "<module>.Step.is_done"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/plan.py",
      "name": "Plan",
      "qualname": "<module>.Plan",
      "source": "class Plan(BaseModel):\n    id: str\n    title: str\n    goal: str\n    steps: List[Step]\n    message: Optional[str] = None\n    status: ExecutionStatus = ExecutionStatus.PENDING\n    result: Optional[Dict[str, Any]] = None\n    error: Optional[str] = None\n\n    def is_done(self) -> bool:\n        return self.status == ExecutionStatus.COMPLETED or self.status == ExecutionStatus.FAILED\n    \n    def get_next_step(self) -> Optional[Step]:\n        for step in self.steps:\n            if not step.is_done():\n                return step\n        return None\n",
      "methods": [
        "<module>.Plan.is_done",
        "<module>.Plan.get_next_step"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/conversation.py",
      "name": "ConversationEvent",
      "qualname": "<module>.ConversationEvent",
      "source": "class ConversationEvent(BaseModel):\n    \"\"\"会话事件记录\"\"\"\n    \n    id: str = Field(default_factory=lambda: uuid.uuid4().hex)\n    agent_id: str  # 使用agent_id作为会话标识\n    event_type: str  # 事件类型：message, tool, step, plan, error, done等\n    event_data: Dict[str, Any]  # 事件数据\n    timestamp: datetime = Field(default_factory=datetime.now)\n    sequence: int  # 事件在会话中的序号\n    \n    class Config:\n        json_encoders = {\n            datetime: lambda v: v.isoformat()\n        }\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/conversation.py",
      "name": "Config",
      "qualname": "<module>.ConversationEvent.Config",
      "source": "    class Config:\n        json_encoders = {\n            datetime: lambda v: v.isoformat()\n        }\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/conversation.py",
      "name": "ConversationHistory",
      "qualname": "<module>.ConversationHistory",
      "source": "class ConversationHistory(BaseModel):\n    \"\"\"会话历史记录\"\"\"\n    \n    agent_id: str  # 使用agent_id作为会话标识\n    user_id: Optional[str] = None\n    flow_id: str = \"plan_act\"\n    title: Optional[str] = None  # 会话标题\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n    events: List[ConversationEvent] = Field(default_factory=list)\n    \n    def add_event(self, event_type: str, event_data: Dict[str, Any]) -> ConversationEvent:\n        \"\"\"添加事件到会话历史\"\"\"\n        event = ConversationEvent(\n            agent_id=self.agent_id,\n            event_type=event_type,\n            event_data=event_data,\n            sequence=len(self.events) + 1\n        )\n        self.events.append(event)\n        self.updated_at = datetime.now()\n        return event\n    \n    def get_events_from_sequence(self, from_sequence: int = 1) -> List[ConversationEvent]:\n        \"\"\"获取从指定序号开始的事件\"\"\"\n        return [event for event in self.events if event.sequence >= from_sequence]\n    \n    def get_latest_events(self, count: int = 10) -> List[ConversationEvent]:\n        \"\"\"获取最新的N个事件\"\"\"\n        return self.events[-count:] if len(self.events) > count else self.events\n    \n    class Config:\n        json_encoders = {\n            datetime: lambda v: v.isoformat()\n        } ",
      "methods": [
        "<module>.ConversationHistory.add_event",
        "<module>.ConversationHistory.get_events_from_sequence",
        "<module>.ConversationHistory.get_latest_events"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/conversation.py",
      "name": "Config",
      "qualname": "<module>.ConversationHistory.Config",
      "source": "    class Config:\n        json_encoders = {\n            datetime: lambda v: v.isoformat()\n        } ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/agent_context.py",
      "name": "AgentContext",
      "qualname": "<module>.AgentContext",
      "source": "class AgentContext:\n    \"\"\"Agent上下文领域模型\n    \n    包含Agent运行时的核心信息，但不包含运行时资源（如队列、任务等）\n    \"\"\"\n    agent_id: str\n    agent: Agent\n    flow_id: str\n    sandbox_id: Optional[str] = None\n    status: str = \"created\"  # created, running, stopped, error\n    last_message: Optional[str] = None\n    last_message_time: Optional[int] = None\n    created_at: datetime = None\n    updated_at: datetime = None\n    meta_data: Dict[str, Any] = None\n    \n    def __post_init__(self):\n        if self.created_at is None:\n            self.created_at = datetime.now()\n        if self.updated_at is None:\n            self.updated_at = datetime.now()\n        if self.meta_data is None:\n            self.meta_data = {}\n    \n    def update_status(self, status: str) -> None:\n        \"\"\"更新状态\"\"\"\n        self.status = status\n        self.updated_at = datetime.now()\n    \n    def update_last_message(self, message: str, timestamp: Optional[int] = None) -> None:\n        \"\"\"更新最后消息\"\"\"\n        self.last_message = message\n        self.last_message_time = timestamp\n        self.updated_at = datetime.now()\n    \n    def set_sandbox_id(self, sandbox_id: str) -> None:\n        \"\"\"设置沙盒ID\"\"\"\n        self.sandbox_id = sandbox_id\n        self.updated_at = datetime.now() ",
      "methods": [
        "<module>.AgentContext.__post_init__",
        "<module>.AgentContext.update_status",
        "<module>.AgentContext.update_last_message",
        "<module>.AgentContext.set_sandbox_id"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/memory.py",
      "name": "Memory",
      "qualname": "<module>.Memory",
      "source": "class Memory(BaseModel):\n    \"\"\"\n    Memory class, defining the basic behavior of memory\n    \"\"\"\n\n    messages: List[Union[Dict[str, Any], ChatCompletionMessage]] = []\n    file: List[Dict[str, Any]] = []\n    web: List[Dict[str, Any]] = []\n    # 工具使用历史\n    tool_usage_history: List[Dict[str, Any]] = []\n    # 上下文管理配置\n    auto_optimize: bool = True  # 是否自动优化上下文长度\n    max_total_tokens: int = 1000000  # 最大总token数\n    preserve_recent_messages: int = 10  # 保留最近消息数量\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"将Memory对象序列化为字典\"\"\"\n        # 将所有消息转换为字典格式\n        serialized_messages = []\n        for message in self.messages:\n            if isinstance(message, ChatCompletionMessage):\n                # 将ChatCompletionMessage转换为字典\n                msg_dict = {\n                    \"role\": message.role,\n                    \"content\": message.content\n                }\n                # 添加其他可能的字段\n                if hasattr(message, 'name') and message.name:\n                    msg_dict[\"name\"] = message.name\n                if hasattr(message, 'function_call') and message.function_call:\n                    msg_dict[\"function_call\"] = message.function_call\n                if hasattr(message, 'tool_calls') and message.tool_calls:\n                    msg_dict[\"tool_calls\"] = message.tool_calls\n                serialized_messages.append(msg_dict)\n            else:\n                # 已经是字典格式\n                serialized_messages.append(message)\n        \n        return {\n            \"messages\": serialized_messages,\n            \"auto_optimize\": self.auto_optimize,\n            \"max_total_tokens\": self.max_total_tokens,\n            \"preserve_recent_messages\": self.preserve_recent_messages\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"Memory\":\n        \"\"\"从字典反序列化Memory对象\"\"\"\n        if not data:\n            return cls()\n        \n        return cls(\n            messages=data.get(\"messages\", []),\n            auto_optimize=data.get(\"auto_optimize\", True),\n            max_total_tokens=data.get(\"max_total_tokens\", 1000000),\n            preserve_recent_messages=data.get(\"preserve_recent_messages\", 10)\n        )\n\n    def get_message_role(self, message: Union[Dict[str, Any], ChatCompletionMessage]) -> str:\n        \"\"\"Get the role of the message\"\"\"\n        if isinstance(message, dict):\n            return message.get(\"role\")\n        elif isinstance(message, ChatCompletionMessage):\n            return message.role\n        return None\n\n    def add_message(self, message: Union[Dict[str, Any], str]) -> None:\n        \"\"\"Add message to memory\"\"\"\n        # 添加调试日志\n        import logging\n        logger = logging.getLogger(__name__)\n        \n        original_type = type(message).__name__\n        logger.info(f\"[DEBUG 1] 添加消息到内存，原始类型: {original_type}, 消息预览: {str(message)[:200]}\")\n        \n        # 类型检查和自动转换\n        if isinstance(message, str):\n            # 如果传入的是字符串，自动转换为字典格式\n            logger.debug(f\"自动转换字符串消息: {message[:100]}...\")\n            message = {\n                \"role\": \"assistant\",\n                \"content\": message\n            }\n        elif not isinstance(message, dict):\n            # 如果不是字符串也不是字典，尝试转换\n            logger.warning(f\"[DEBUG 1] 收到非标准消息类型: {original_type}，尝试转换\")\n            try:\n                if hasattr(message, 'model_dump'):\n                    # 处理Pydantic模型\n                    message = message.model_dump()\n                    logger.debug(\"使用model_dump转换成功\")\n                elif hasattr(message, '__dict__'):\n                    # 处理普通对象\n                    message = message.__dict__\n                    logger.debug(\"使用__dict__转换成功\")\n                else:\n                    # 最后的兜底转换\n                    message = {\n                        \"role\": \"assistant\",\n                        \"content\": str(message)\n                    }\n                    logger.debug(\"使用str()兜底转换\")\n            except Exception as e:\n                # 如果所有转换都失败，使用字符串表示\n                logger.error(f\"[DEBUG 1] 消息转换失败: {e}，使用兜底方案\")\n                message = {\n                    \"role\": \"assistant\", \n                    \"content\": str(message)\n                }\n        \n        # 检查最终消息的content是否为null\n        content = message.get('content')\n        if content is None:\n            logger.error(f\"[DEBUG 1] 检测到content为None! 消息: {message}\")\n            message['content'] = \"\"  # 设置为空字符串而不是None\n        elif not isinstance(content, str):\n            logger.warning(f\"[DEBUG 1] content不是字符串类型: {type(content)}, 值: {content}\")\n            message['content'] = str(content)\n        \n        logger.info(f\"[DEBUG 1] 最终消息格式: role={message.get('role')}, content_type={type(message.get('content'))}, content_length={len(str(message.get('content', '')))}\")\n        self.messages.append(message)\n        \n        # 自动优化上下文长度\n        if self.auto_optimize:\n            self._optimize_context_if_needed()\n    \n    def add_messages(self, messages: List[Dict[str, Any]]) -> None:\n        \"\"\"Add messages to memory\"\"\"\n        self.messages.extend(messages)\n        \n        # 自动优化上下文长度\n        if self.auto_optimize:\n            self._optimize_context_if_needed()\n\n    def add_tool_usage(self, event: Any) -> None:\n        \"\"\"Add tool usage event to history\"\"\"\n        try:\n            # 处理 ToolCallingEvent 和 ToolCalledEvent\n            if hasattr(event, 'type') and event.type in ['tool_calling', 'tool_called']:\n                tool_usage = {\n                    'type': event.type,\n                    'tool_name': getattr(event, 'tool_name', ''),\n                    'function_name': getattr(event, 'function_name', ''),\n                    'function_args': getattr(event, 'function_args', {}),\n                }\n                \n                if event.type == 'tool_called':\n                    tool_usage['function_result'] = getattr(event, 'function_result', None)\n                \n                self.tool_usage_history.append(tool_usage)\n        except Exception:\n            # 如果出错，静默忽略\n            pass\n\n    def get_tool_history(self) -> str:\n        \"\"\"Get formatted tool usage history\"\"\"\n        if not self.tool_usage_history:\n            return \"No tool usage history available.\"\n        \n        history_lines = []\n        for usage in self.tool_usage_history:\n            if usage['type'] == 'tool_calling':\n                history_lines.append(\n                    f\"Tool Call: {usage['tool_name']}.{usage['function_name']}({usage['function_args']})\"\n                )\n            elif usage['type'] == 'tool_called':\n                history_lines.append(\n                    f\"Tool Result: {usage['tool_name']}.{usage['function_name']} -> {usage.get('function_result', 'No result')}\"\n                )\n        \n        return \"\\n\".join(history_lines)\n\n    def _optimize_context_if_needed(self) -> None:\n        \"\"\"如果需要，优化上下文长度\"\"\"\n        import logging\n        logger = logging.getLogger(__name__)\n        logger.info(f\"[DEBUG 4] 开始上下文优化，当前消息数量: {len(self.messages)}\")\n        \n        try:\n            # 在压缩前确保所有消息都是字典格式\n            cleaned_messages = []\n            for i, msg in enumerate(self.messages):\n                logger.debug(f\"[DEBUG 4] 处理消息 {i}: type={type(msg)}, preview={str(msg)[:100]}\")\n                if isinstance(msg, dict):\n                    # 检查字典消息的content字段\n                    if 'content' in msg and msg['content'] is None:\n                        logger.error(f\"[DEBUG 4] 在消息 {i} 中发现content为None: {msg}\")\n                        msg['content'] = \"\"\n                    cleaned_messages.append(msg)\n                elif isinstance(msg, str):\n                    # 自动转换字符串消息\n                    cleaned_messages.append({\n                        \"role\": \"assistant\",\n                        \"content\": msg\n                    })\n                else:\n                    # 处理其他类型的消息\n                    try:\n                        if hasattr(msg, 'model_dump'):\n                            converted = msg.model_dump()\n                            logger.debug(f\"[DEBUG 4] 使用model_dump转换消息 {i}\")\n                        elif hasattr(msg, '__dict__'):\n                            converted = msg.__dict__\n                            logger.debug(f\"[DEBUG 4] 使用__dict__转换消息 {i}\")\n                        else:\n                            converted = {\n                                \"role\": \"assistant\",\n                                \"content\": str(msg)\n                            }\n                            logger.debug(f\"[DEBUG 4] 使用str()转换消息 {i}\")\n                        \n                        # 检查转换后的content\n                        if 'content' in converted and converted['content'] is None:\n                            logger.error(f\"[DEBUG 4] 转换后的消息 {i} content为None: {converted}\")\n                            converted['content'] = \"\"\n                        \n                        cleaned_messages.append(converted)\n                    except Exception as e:\n                        # 最后的兜底处理\n                        logger.error(f\"[DEBUG 4] 消息 {i} 转换失败: {e}\")\n                        cleaned_messages.append({\n                            \"role\": \"assistant\",\n                            \"content\": str(msg)\n                        })\n            \n            # 更新消息列表\n            logger.info(f\"[DEBUG 4] 消息清理完成，清理前: {len(self.messages)}, 清理后: {len(cleaned_messages)}\")\n            self.messages = cleaned_messages\n            \n            # 进行压缩\n            manager = ContextManager(\n                max_tokens=self.max_total_tokens,\n                model_name=\"gpt-4.1\",\n                strategy=\"first\",\n                preserve_system=True\n            )\n            logger.info(f\"[DEBUG 4] 开始压缩，压缩前消息数量: {len(self.messages)}\")\n            self.messages = manager.compress(self.messages)\n            logger.info(f\"[DEBUG 4] 压缩完成，压缩后消息数量: {len(self.messages)}\")\n            \n            # 最终验证所有消息的content字段\n            for i, msg in enumerate(self.messages):\n                if isinstance(msg, dict) and 'content' in msg and msg['content'] is None:\n                    logger.error(f\"[DEBUG 4] 压缩后消息 {i} content仍为None: {msg}\")\n                    msg['content'] = \"\"\n            \n        except Exception as e:\n            # 如果压缩失败，记录错误但不中断程序\n            import logging\n            logger = logging.getLogger(__name__)\n            logger.warning(f\"上下文优化失败，跳过压缩: {e}\")\n            logger.warning(f\"[DEBUG 4] 上下文优化失败，跳过压缩: {e}\")\n            # 确保消息格式正确\n            cleaned_messages = []\n            for msg in self.messages:\n                if isinstance(msg, dict):\n                    if 'content' in msg and msg['content'] is None:\n                        logger.error(f\"[DEBUG 4] 兜底处理中发现content为None: {msg}\")\n                        msg['content'] = \"\"\n                    cleaned_messages.append(msg)\n                else:\n                    cleaned_messages.append({\n                        \"role\": \"assistant\",\n                        \"content\": str(msg)\n                    })\n            self.messages = cleaned_messages\n            logger.info(f\"[DEBUG 4] 兜底处理完成，最终消息数量: {len(self.messages)}\")\n\n    def get_messages(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all message history\"\"\"\n        import logging\n        logger = logging.getLogger(__name__)\n        \n        # [DEBUG 3] 最终验证所有消息\n        logger.info(f\"[DEBUG 3] get_messages调用，消息总数: {len(self.messages)}\")\n        validated_messages = []\n        \n        for i, msg in enumerate(self.messages):\n            if isinstance(msg, dict):\n                content = msg.get('content')\n                if content is None:\n                    logger.error(f\"[DEBUG 3] get_messages中检测到消息 {i} content为None: {msg}\")\n                    # 修复None content\n                    msg = msg.copy()  # 避免修改原始消息\n                    msg['content'] = \"\"\n                elif not isinstance(content, str):\n                    logger.warning(f\"[DEBUG 3] get_messages中消息 {i} content不是字符串: {type(content)}\")\n                    msg = msg.copy()\n                    msg['content'] = str(content)\n                validated_messages.append(msg)\n            else:\n                logger.error(f\"[DEBUG 3] get_messages中检测到非字典消息 {i}: {type(msg)}, 内容: {msg}\")\n                # 转换为标准格式\n                validated_messages.append({\n                    \"role\": \"assistant\",\n                    \"content\": str(msg)\n                })\n        \n        logger.info(f\"[DEBUG 3] get_messages完成验证，返回 {len(validated_messages)} 条消息\")\n        return validated_messages\n\n    def get_latest_system_message(self) -> Dict[str, Any]:\n        \"\"\"Get the latest system message\"\"\"\n        for message in reversed(self.messages):\n            if self.get_message_role(message) == \"system\":\n                return message\n        return {}\n\n    def get_non_system_messages(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all non-system messages\"\"\"\n        return [message for message in self.messages if self.get_message_role(message) != \"system\"]\n\n    def get_messages_with_latest_system(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all non-system messages plus the latest system message\"\"\"\n        latest_system = self.get_latest_system_message()\n        non_system_messages = self.get_non_system_messages()\n        if latest_system:\n            return [latest_system] + non_system_messages\n        return non_system_messages\n    \n    def clear_messages(self) -> None:\n        \"\"\"Clear memory\"\"\"\n        self.messages = []\n    \n    def get_filtered_messages(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all non-system and non-tool response messages, plus the latest system message\"\"\"\n        latest_system = self.get_latest_system_message()\n        messages = [message for message in self.messages \n                  if self.get_message_role(message) != \"system\"]\n                  #and self.get_message_role(message) != \"tool\"]\n        if latest_system:\n            return [latest_system] + messages\n        return messages\n\n    def roll_back(self) -> None:\n        \"\"\"Roll back memory\"\"\"\n        if len(self.messages) > 1 and \\\n                self.get_message_role(self.messages[-1]) == \"tool\" and \\\n                self.get_message_role(self.messages[-2]) != \"tool\":\n            self.messages.pop()\n        elif len(self.messages) > 0 and self.get_message_role(self.messages[-1]) == \"user\":\n            self.messages.pop()\n    \n    def set_context_config(self, \n                          auto_optimize: Optional[bool] = None,\n                          max_total_tokens: Optional[int] = None,\n                          preserve_recent_messages: Optional[int] = None) -> None:\n        \"\"\"\n        设置上下文管理配置\n        \n        Args:\n            auto_optimize: 是否自动优化上下文长度\n            max_total_tokens: 最大总token数\n            preserve_recent_messages: 保留最近消息数量\n        \"\"\"\n        if auto_optimize is not None:\n            self.auto_optimize = auto_optimize\n        if max_total_tokens is not None:\n            self.max_total_tokens = max_total_tokens\n        if preserve_recent_messages is not None:\n            self.preserve_recent_messages = preserve_recent_messages\n\n    def add_file(self, file_info: Optional[List[Dict[str, Any]]]) -> None:\n        \"\"\"Add file information to memory\"\"\"\n        if file_info is None:\n            return\n        self.file.extend(file_info)\n\n    def add_web(self, web_info: Optional[List[Dict[str, Any]]]) -> None:\n        \"\"\"Add web information to memory\"\"\"\n        if web_info is None:\n            return\n        self.web.extend(web_info)",
      "methods": [
        "<module>.Memory.to_dict",
        "<module>.Memory.from_dict",
        "<module>.Memory.get_message_role",
        "<module>.Memory.add_message",
        "<module>.Memory.add_messages",
        "<module>.Memory.add_tool_usage",
        "<module>.Memory.get_tool_history",
        "<module>.Memory._optimize_context_if_needed",
        "<module>.Memory.get_messages",
        "<module>.Memory.get_latest_system_message",
        "<module>.Memory.get_non_system_messages",
        "<module>.Memory.get_messages_with_latest_system",
        "<module>.Memory.clear_messages",
        "<module>.Memory.get_filtered_messages",
        "<module>.Memory.roll_back",
        "<module>.Memory.set_context_config",
        "<module>.Memory.add_file",
        "<module>.Memory.add_web"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/environment.py",
      "name": "Environment",
      "qualname": "<module>.Environment",
      "source": "class Environment(BaseModel):\n    \"\"\"Environment variables domain model.\"\"\"\n    \n    variables: Dict[str, str] = Field(default_factory=dict, description=\"环境变量键值对\")\n    user_id: Optional[str] = None\n    agent_id: Optional[str] = None\n    \n    def to_dict(self) -> Dict[str, str]:\n        \"\"\"\n        Convert environment variables to dictionary.\n        \n        Returns:\n            Dictionary of environment variables\n        \"\"\"\n        return self.variables.copy()\n    \n    @classmethod\n    def from_dict(cls, variables: Dict[str, str], user_id: Optional[str] = None, agent_id: Optional[str] = None) -> \"Environment\":\n        \"\"\"\n        Create Environment instance from dictionary.\n        \n        Args:\n            variables: Dictionary of environment variables\n            user_id: Optional user ID associated with these environment variables\n            agent_id: Optional agent ID associated with these environment variables\n            \n        Returns:\n            Environment instance\n        \"\"\"\n        return cls(variables=variables, user_id=user_id, agent_id=agent_id) ",
      "methods": [
        "<module>.Environment.to_dict",
        "<module>.Environment.from_dict"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/tool_result.py",
      "name": "ToolResult",
      "qualname": "<module>.ToolResult",
      "source": "class ToolResult(BaseModel):\n    success: bool\n    message: Optional[str] = None\n    data: Optional[Any] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "AgentEvent",
      "qualname": "<module>.AgentEvent",
      "source": "class AgentEvent(BaseModel):\n    \"\"\"Base class for agent events\"\"\"\n    type: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "ErrorEvent",
      "qualname": "<module>.ErrorEvent",
      "source": "class ErrorEvent(AgentEvent):\n    \"\"\"Error event\"\"\"\n    type: Literal[\"error\"] = \"error\"\n    error: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "PauseEvent",
      "qualname": "<module>.PauseEvent",
      "source": "class PauseEvent(AgentEvent):\n    \"\"\"Pause event\"\"\"\n    type: Literal[\"pause\"] = \"pause\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "PlanCreatedEvent",
      "qualname": "<module>.PlanCreatedEvent",
      "source": "class PlanCreatedEvent(AgentEvent):\n    \"\"\"Plan creation completed event\"\"\"\n    type: Literal[\"plan_created\"] = \"plan_created\"\n    plan: Plan\n    issuperplan: bool = False\n    issubplan: bool = False\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "PlanUpdatedEvent",
      "qualname": "<module>.PlanUpdatedEvent",
      "source": "class PlanUpdatedEvent(AgentEvent):\n    \"\"\"Plan update completed event\"\"\"\n    type: Literal[\"plan_updated\"] = \"plan_updated\"\n    plan: Plan\n    issuperplan: bool = False\n    issubplan: bool = False\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "ToolCallingEvent",
      "qualname": "<module>.ToolCallingEvent",
      "source": "class ToolCallingEvent(AgentEvent):\n    \"\"\"Tool calling event (before execution)\"\"\"\n    type: Literal[\"tool_calling\"] = \"tool_calling\"\n    tool_name: str\n    function_name: str\n    function_args: Dict[str, Any]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "ToolCalledEvent",
      "qualname": "<module>.ToolCalledEvent",
      "source": "class ToolCalledEvent(AgentEvent):\n    \"\"\"Tool called event (after execution)\"\"\"\n    type: Literal[\"tool_called\"] = \"tool_called\"\n    tool_name: str\n    function_name: str\n    function_args: Dict[str, Any]\n    function_result: Any\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "StepStartedEvent",
      "qualname": "<module>.StepStartedEvent",
      "source": "class StepStartedEvent(AgentEvent):\n    \"\"\"Step started event\"\"\"\n    type: Literal[\"step_started\"] = \"step_started\"\n    step: Step\n    plan: Plan\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "StepFailedEvent",
      "qualname": "<module>.StepFailedEvent",
      "source": "class StepFailedEvent(AgentEvent):\n    \"\"\"Step execution failed event\"\"\"\n    type: Literal[\"step_failed\"] = \"step_failed\"\n    step: Step\n    plan: Plan\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "StepCompletedEvent",
      "qualname": "<module>.StepCompletedEvent",
      "source": "class StepCompletedEvent(AgentEvent):\n    \"\"\"Step execution completed event\"\"\"\n    type: Literal[\"step_completed\"] = \"step_completed\"\n    step: Step\n    plan: Plan\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "PlanCompletedEvent",
      "qualname": "<module>.PlanCompletedEvent",
      "source": "class PlanCompletedEvent(AgentEvent):\n    \"\"\"Plan execution completed event\"\"\"\n    type: Literal[\"plan_completed\"] = \"plan_completed\"\n    plan: Plan\n    issuperplan: bool = False\n    issubplan: bool = False\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "MessageEvent",
      "qualname": "<module>.MessageEvent",
      "source": "class MessageEvent(AgentEvent):\n    \"\"\"Message event\"\"\"\n    type: Literal[\"message\"] = \"message\"\n    message: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "ReportEvent",
      "qualname": "<module>.ReportEvent",
      "source": "class ReportEvent(AgentEvent):\n    \"\"\"Report event\"\"\"\n    type: Literal[\"report\"] = \"report\"\n    message: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "UserInputEvent",
      "qualname": "<module>.UserInputEvent",
      "source": "class UserInputEvent(AgentEvent):\n    \"\"\"User input event\"\"\"\n    type: Literal[\"user_input\"] = \"user_input\"\n    message: str\n    file_ids: list[str]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event.py",
      "name": "DoneEvent",
      "qualname": "<module>.DoneEvent",
      "source": "class DoneEvent(AgentEvent):\n    \"\"\"Done event\"\"\"\n    type: Literal[\"done\"] = \"done\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/agent.py",
      "name": "Agent",
      "qualname": "<module>.Agent",
      "source": "class Agent(BaseModel):\n    \"\"\"Agent domain model.\"\"\"\n    \n    id: str = Field(default_factory=lambda: uuid.uuid4().hex[:16])\n    planner_memory: Memory\n    execution_memory: Memory\n    model_name: str\n    temperature: float = 0.7\n    max_tokens: Optional[int] = None\n    user_id: Optional[str] = None\n    environment: Optional[Environment] = None\n    \n    def __init__(self, id: Optional[str] = None, **data):\n        \"\"\"初始化Agent，支持传入自定义ID\n        \n        Args:\n            id: 可选的自定义ID，如果不提供则自动生成\n            **data: 其他Agent属性\n        \"\"\"\n        if id is not None:\n            data['id'] = id\n        super().__init__(**data)\n",
      "methods": [
        "<module>.Agent.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/user.py",
      "name": "UserFile",
      "qualname": "<module>.UserFile",
      "source": "class UserFile:\n    \"\"\"User file model.\"\"\"\n    \n    id: str\n    user_id: str\n    filename: str\n    path: str\n    created_at: datetime = field(default_factory=datetime.now)\n    updated_at: datetime = field(default_factory=datetime.now)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/user.py",
      "name": "UserTask",
      "qualname": "<module>.UserTask",
      "source": "class UserTask:\n    \"\"\"User task history model.\"\"\"\n    \n    id: str\n    user_id: str\n    agent_id: str\n    title: str\n    status: str\n    created_at: datetime = field(default_factory=datetime.now)\n    completed_at: Optional[datetime] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    \n    def complete(self) -> None:\n        \"\"\"Mark the task as completed.\"\"\"\n        self.status = \"completed\"\n        self.completed_at = datetime.now()\n",
      "methods": [
        "<module>.UserTask.complete"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/user.py",
      "name": "User",
      "qualname": "<module>.User",
      "source": "class User:\n    \"\"\"User domain model.\"\"\"\n    \n    id: str\n    email: str\n    name: Optional[str] = None\n    groups: List[str] = field(default_factory=list)\n    created_at: datetime = field(default_factory=datetime.now)\n    last_login: datetime = field(default_factory=datetime.now)\n    tasks: List[UserTask] = field(default_factory=list)\n    files: List[UserFile] = field(default_factory=list)\n    \n    @classmethod\n    def from_oauth(cls, user_info: Dict[str, Any]) -> \"User\":\n        \"\"\"Create a User from OAuth user information.\"\"\"\n        return cls(\n            id=user_info.get(\"user_id\", \"\"),\n            email=user_info.get(\"email\", \"\"),\n            name=user_info.get(\"name\"),\n            groups=user_info.get(\"groups\", []),\n        )\n    \n    def add_task(self, task: UserTask) -> None:\n        \"\"\"Add a task to the user's history.\"\"\"\n        self.tasks.append(task)\n    \n    def add_file(self, file: UserFile) -> None:\n        \"\"\"Add a file to the user's files.\"\"\"\n        self.files.append(file) ",
      "methods": [
        "<module>.User.from_oauth",
        "<module>.User.add_task",
        "<module>.User.add_file"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event_subscription.py",
      "name": "EventBuffer",
      "qualname": "<module>.EventBuffer",
      "source": "class EventBuffer(Protocol):\n    \"\"\"事件缓冲抽象接口\"\"\"\n    DEFAULT_MAX_SIZE = 1000  # 最大缓冲事件数量\n\n    def __init__(self, agent_id: str, max_size: int = DEFAULT_MAX_SIZE):\n        self.agent_id = agent_id\n        self.max_size = max_size\n\n    @abstractmethod\n    def add_event(self, event: AgentEvent) -> int:\n        \"\"\"添加事件到缓冲区，返回序号\"\"\"\n        pass\n\n    @abstractmethod\n    def get_events_from_sequence(self, from_sequence: int) -> List[AgentEvent]:\n        \"\"\"获取指定序号之后的事件\"\"\"\n        pass\n\n    @abstractmethod\n    def has_done_event_as_last(self) -> bool:\n        \"\"\"检查最后一个事件是否是DoneEvent\"\"\"\n        pass\n\n    @abstractmethod\n    def clear(self) -> None:\n        \"\"\"清空缓冲区\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def current_sequence(self) -> int:\n        \"\"\"获取当前序号\"\"\"\n        pass\n",
      "methods": [
        "<module>.EventBuffer.__init__",
        "<module>.EventBuffer.add_event",
        "<module>.EventBuffer.get_events_from_sequence",
        "<module>.EventBuffer.has_done_event_as_last",
        "<module>.EventBuffer.clear",
        "<module>.EventBuffer.current_sequence"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event_subscription.py",
      "name": "EventSubscriber",
      "qualname": "<module>.EventSubscriber",
      "source": "class EventSubscriber:\n    \"\"\"事件订阅者模型\"\"\"\n    subscriber_id: str\n    agent_id: str\n    event_queue: asyncio.Queue\n    created_at: datetime = field(default_factory=datetime.now)\n    last_activity: datetime = field(default_factory=datetime.now)\n    is_active: bool = True\n    \n    @classmethod\n    def create(cls, agent_id: str) -> \"EventSubscriber\":\n        \"\"\"创建新的事件订阅者\"\"\"\n        return cls(\n            subscriber_id=str(uuid.uuid4()),\n            agent_id=agent_id,\n            event_queue=asyncio.Queue(maxsize=100)  # 限制队列大小防止内存泄漏\n        )\n    \n    def update_activity(self) -> None:\n        \"\"\"更新活动时间\"\"\"\n        self.last_activity = datetime.now()\n    \n    def deactivate(self) -> None:\n        \"\"\"停用订阅者\"\"\"\n        self.is_active = False\n",
      "methods": [
        "<module>.EventSubscriber.create",
        "<module>.EventSubscriber.update_activity",
        "<module>.EventSubscriber.deactivate"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/event_subscription.py",
      "name": "AgentEventBroadcaster",
      "qualname": "<module>.AgentEventBroadcaster",
      "source": "class AgentEventBroadcaster:\n    \"\"\"Agent事件广播器领域模型\"\"\"\n    agent_id: str\n    subscribers: Dict[str, EventSubscriber] = field(default_factory=dict)  # subscriber_id -> subscriber\n    event_buffer: EventBuffer = None\n\n    def __post_init__(self):\n        \"\"\"初始化后检查事件缓冲区\"\"\"\n        if self.event_buffer is None:\n            raise ValueError(\"Event buffer must be provided\")\n        if self.event_buffer.agent_id != self.agent_id:\n            raise ValueError(f\"Event buffer agent_id {self.event_buffer.agent_id} does not match broadcaster agent_id {self.agent_id}\")\n\n    def add_subscriber(self, subscriber: EventSubscriber) -> None:\n        \"\"\"添加订阅者\"\"\"\n        if subscriber.agent_id != self.agent_id:\n            raise ValueError(f\"Subscriber agent_id {subscriber.agent_id} does not match broadcaster agent_id {self.agent_id}\")\n        self.subscribers[subscriber.subscriber_id] = subscriber\n        logger.debug(f\"Added subscriber {subscriber.subscriber_id} for agent {self.agent_id}\")\n    \n    def remove_subscriber(self, subscriber_id: str) -> bool:\n        \"\"\"移除订阅者\"\"\"\n        subscriber = self.subscribers.pop(subscriber_id, None)\n        if subscriber:\n            logger.debug(f\"Removed subscriber {subscriber_id} for agent {self.agent_id}\")\n            return True\n        return False\n\n    def broadcast_event(self, event: AgentEvent) -> int:\n        \"\"\"广播事件给所有活跃订阅者，返回事件序号\"\"\"\n        # 添加事件到缓冲区\n        sequence = self.event_buffer.add_event(event)\n        \n        # 广播给所有活跃订阅者\n        inactive_subscribers = []\n        for subscriber_id, subscriber in self.subscribers.items():\n            if not subscriber.is_active:\n                inactive_subscribers.append(subscriber_id)\n                continue\n                \n            try:\n                # 非阻塞方式放入订阅者队列\n                subscriber.event_queue.put_nowait(event)\n                subscriber.update_activity()\n                logger.debug(f\"Broadcasted event to subscriber {subscriber_id}\")\n            except asyncio.QueueFull:\n                logger.warning(f\"Subscriber {subscriber_id} queue full, dropping event\")\n                # 标记为不活跃，稍后清理\n                subscriber.deactivate()\n                inactive_subscribers.append(subscriber_id)\n        \n        # 清理不活跃的订阅者\n        for subscriber_id in inactive_subscribers:\n            self.remove_subscriber(subscriber_id)\n        \n        logger.debug(f\"Broadcasted event with sequence {sequence} to {len(self.subscribers)} subscribers for agent {self.agent_id}\")\n        return sequence\n\n    def get_active_subscriber_count(self) -> int:\n        \"\"\"获取活跃订阅者数量\"\"\"\n        return len([s for s in self.subscribers.values() if s.is_active])\n\n    def cleanup_inactive_subscribers(self, timeout_minutes: int = 30) -> int:\n        \"\"\"清理不活跃的订阅者，返回清理数量\"\"\"\n        cutoff_time = datetime.now() - timedelta(minutes=timeout_minutes)\n        inactive_subscriber_ids = []\n        \n        for subscriber_id, subscriber in self.subscribers.items():\n            if not subscriber.is_active or subscriber.last_activity < cutoff_time:\n                inactive_subscriber_ids.append(subscriber_id)\n        \n        # 清理不活跃的订阅者\n        for subscriber_id in inactive_subscriber_ids:\n            self.remove_subscriber(subscriber_id)\n        \n        logger.info(f\"Cleaned up {len(inactive_subscriber_ids)} inactive subscribers for agent {self.agent_id}\")\n        return len(inactive_subscriber_ids)\n",
      "methods": [
        "<module>.AgentEventBroadcaster.__post_init__",
        "<module>.AgentEventBroadcaster.add_subscriber",
        "<module>.AgentEventBroadcaster.remove_subscriber",
        "<module>.AgentEventBroadcaster.broadcast_event",
        "<module>.AgentEventBroadcaster.get_active_subscriber_count",
        "<module>.AgentEventBroadcaster.cleanup_inactive_subscribers"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/models/exceptions.py",
      "name": "AgentNotRunningError",
      "qualname": "<module>.AgentNotRunningError",
      "source": "class AgentNotRunningError(Exception):\n    \"\"\"Agent未运行异常\"\"\"\n    pass\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/sandbox.py",
      "name": "Sandbox",
      "qualname": "<module>.Sandbox",
      "source": "class Sandbox(Protocol):\n    \"\"\"Sandbox service gateway interface\"\"\"\n    \n    async def exec_command(\n        self,\n        session_id: str,\n        exec_dir: str,\n        command: str\n    ) -> ToolResult:\n        \"\"\"Execute command\n        \n        Args:\n            session_id: Session ID\n            exec_dir: Execution directory\n            command: Command to execute\n            \n        Returns:\n            Command execution result\n        \"\"\"\n        ...\n    \n    async def view_shell(self, session_id: str) -> ToolResult:\n        \"\"\"View shell status\n        \n        Args:\n            session_id: Session ID\n            \n        Returns:\n            Shell status information\n        \"\"\"\n        ...\n    \n    async def wait_for_process(\n        self,\n        session_id: str,\n        seconds: Optional[int] = None\n    ) -> ToolResult:\n        \"\"\"Wait for process\n        \n        Args:\n            session_id: Session ID\n            seconds: Wait seconds\n            \n        Returns:\n            Wait result\n        \"\"\"\n        ...\n    \n    async def write_to_process(\n        self,\n        session_id: str,\n        input_text: str,\n        press_enter: bool = True\n    ) -> ToolResult:\n        \"\"\"Write input to process\n        \n        Args:\n            session_id: Session ID\n            input_text: Input text\n            press_enter: Whether to press enter\n            \n        Returns:\n            Write result\n        \"\"\"\n        ...\n    \n    async def kill_process(self, session_id: str) -> ToolResult:\n        \"\"\"Terminate process\n        \n        Args:\n            session_id: Session ID\n            \n        Returns:\n            Termination result\n        \"\"\"\n        ...\n    \n    async def file_write(\n        self, \n        file: str, \n        content: str, \n        append: bool = False, \n        leading_newline: bool = False, \n        trailing_newline: bool = False, \n        sudo: bool = False\n    ) -> ToolResult:\n        \"\"\"Write content to file\n        \n        Args:\n            file: File path\n            content: Content to write\n            append: Whether to append content\n            leading_newline: Whether to add newline before content\n            trailing_newline: Whether to add newline after content\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            Write operation result\n        \"\"\"\n        ...\n    \n    async def file_read(\n        self, \n        file: str, \n        start_line: int = None, \n        end_line: int = None, \n        sudo: bool = False\n    ) -> ToolResult:\n        \"\"\"Read file content\n        \n        Args:\n            file: File path\n            start_line: Start line number\n            end_line: End line number\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            File content\n        \"\"\"\n        ...\n    \n    async def file_exists(self, path: str) -> ToolResult:\n        \"\"\"Check if file exists\n        \n        Args:\n            path: File path\n            \n        Returns:\n            Whether file exists\n        \"\"\"\n        ...\n    \n    async def file_delete(self, path: str) -> ToolResult:\n        \"\"\"Delete file\n        \n        Args:\n            path: File path\n            \n        Returns:\n            Delete operation result\n        \"\"\"\n        ...\n    \n    async def file_list(self, path: str) -> ToolResult:\n        \"\"\"List directory contents\n        \n        Args:\n            path: Directory path\n            \n        Returns:\n            Directory content list\n        \"\"\"\n        ...\n    \n    async def file_replace(\n        self, \n        file: str, \n        old_str: str, \n        new_str: str, \n        sudo: bool = False\n    ) -> ToolResult:\n        \"\"\"Replace string in file\n        \n        Args:\n            file: File path\n            old_str: String to replace\n            new_str: Replacement string\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            Replace operation result\n        \"\"\"\n        ...\n    \n    async def file_search(\n        self, \n        file: str, \n        regex: str, \n        sudo: bool = False\n    ) -> ToolResult:\n        \"\"\"Search in file content\n        \n        Args:\n            file: File path\n            regex: Regular expression\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            Search result\n        \"\"\"\n        ...\n    \n    async def file_find(\n        self, \n        path: str, \n        glob_pattern: str\n    ) -> ToolResult:\n        \"\"\"Find files by name pattern\n        \n        Args:\n            path: Search directory path\n            glob_pattern: Glob matching pattern\n            \n        Returns:\n            Found file list\n        \"\"\"\n        ...\n    \n    async def file_upload(\n        self, \n        file_path: str, \n        content: bytes, \n        make_executable: bool = False\n    ) -> ToolResult:\n        \"\"\"Upload file\n        \n        Args:\n            file_path: Target file path in sandbox\n            content: Binary file content\n            make_executable: Whether to make file executable\n            \n        Returns:\n            Upload result\n        \"\"\"\n        ...\n\n    async def file_download(self, file_path: str) -> bytes:\n        \"\"\"Download file\n        \n        Args:\n            file_path: File path in sandbox\n            \n        Returns:\n            Binary file content\n            \n        Raises:\n            FileNotFoundError: When file does not exist\n            PermissionError: When permission is denied\n            Exception: Other errors\n        \"\"\"\n        ...\n\n    async def get_status(self) -> ToolResult:\n        \"\"\"Get sandbox status, check if all services are running properly\n        \n        Returns:\n            Sandbox status information\n        \"\"\"\n        ...\n\n    async def ensure_status(self) -> ToolResult:\n        \"\"\"Ensure sandbox status is normal\n        \n        Returns:\n            Sandbox status\n        \"\"\"\n        ...\n    \n    def get_cdp_url(self) -> str:\n        \"\"\"Get Chrome DevTools Protocol URL\n        \n        Returns:\n            CDP URL string\n        \"\"\"\n        ...\n    \n    def get_vnc_url(self) -> str:\n        \"\"\"Get VNC URL\n        \n        Returns:\n            VNC URL string\n        \"\"\"\n        ...\n\n    def get_code_server_url(self) -> str:\n        \"\"\"Get Code Server URL\n        \n        Returns:\n            Code Server URL string\n        \"\"\"\n        ...\n    \n    # MCP Service Management Methods\n    async def mcp_install(\n        self, \n        pkg: str, \n        lang: str, \n        args: Optional[list] = None\n    ) -> ToolResult:\n        \"\"\"Install and start MCP server\n        \n        Args:\n            pkg: MCP package name\n            lang: Programming language type (\"python\" or \"node\")\n            args: Optional startup arguments list\n            \n        Returns:\n            Installation result\n        \"\"\"\n        ...\n    \n    async def mcp_uninstall(self, pkg: str) -> ToolResult:\n        \"\"\"Stop and uninstall MCP server\n        \n        Args:\n            pkg: MCP package name\n            \n        Returns:\n            Uninstallation result\n        \"\"\"\n        ...\n    \n    async def mcp_list_servers(self) -> ToolResult:\n        \"\"\"List all installed MCP servers\n        \n        Returns:\n            Server list result with status information for each server\n        \"\"\"\n        ...\n    \n    async def mcp_health_check(self, pkg: str) -> ToolResult:\n        \"\"\"Check MCP server health status\n        \n        Args:\n            pkg: MCP package name\n            \n        Returns:\n            Health status result\n        \"\"\"\n        ...\n    \n    async def mcp_proxy_request(\n        self, \n        pkg: str, \n        request: Dict\n    ) -> ToolResult:\n        \"\"\"Proxy JSON-RPC request to MCP server\n        \n        Args:\n            pkg: Target MCP server package name\n            request: JSON-RPC request data\n            \n        Returns:\n            Server response result\n        \"\"\"\n        ...\n    \n    async def mcp_get_capabilities(self, pkg: str) -> ToolResult:\n        \"\"\"Get MCP server capability information\n        \n        Args:\n            pkg: MCP package name\n            \n        Returns:\n            Server capability information result\n        \"\"\"\n        ...\n    \n    async def mcp_shutdown_all(self) -> ToolResult:\n        \"\"\"Shutdown all MCP servers\n        \n        Returns:\n            Shutdown operation result\n        \"\"\"\n        ...\n    \n    async def close(self):\n        \"\"\"Close gateway connection and clean up resources\"\"\"\n        ... ",
      "methods": [
        "<module>.Sandbox.exec_command",
        "<module>.Sandbox.view_shell",
        "<module>.Sandbox.wait_for_process",
        "<module>.Sandbox.write_to_process",
        "<module>.Sandbox.kill_process",
        "<module>.Sandbox.file_write",
        "<module>.Sandbox.file_read",
        "<module>.Sandbox.file_exists",
        "<module>.Sandbox.file_delete",
        "<module>.Sandbox.file_list",
        "<module>.Sandbox.file_replace",
        "<module>.Sandbox.file_search",
        "<module>.Sandbox.file_find",
        "<module>.Sandbox.file_upload",
        "<module>.Sandbox.file_download",
        "<module>.Sandbox.get_status",
        "<module>.Sandbox.ensure_status",
        "<module>.Sandbox.get_cdp_url",
        "<module>.Sandbox.get_vnc_url",
        "<module>.Sandbox.get_code_server_url",
        "<module>.Sandbox.mcp_install",
        "<module>.Sandbox.mcp_uninstall",
        "<module>.Sandbox.mcp_list_servers",
        "<module>.Sandbox.mcp_health_check",
        "<module>.Sandbox.mcp_proxy_request",
        "<module>.Sandbox.mcp_get_capabilities",
        "<module>.Sandbox.mcp_shutdown_all",
        "<module>.Sandbox.close"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/conversation_repository.py",
      "name": "ConversationRepository",
      "qualname": "<module>.ConversationRepository",
      "source": "class ConversationRepository(Protocol):\n    \"\"\"会话仓储接口\"\"\"\n    \n    @abstractmethod\n    async def save_history(self, history: ConversationHistory) -> None:\n        \"\"\"保存会话历史\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_history(self, agent_id: str) -> Optional[ConversationHistory]:\n        \"\"\"获取会话历史\"\"\"\n        pass\n    \n    @abstractmethod\n    async def add_event(self, agent_id: str, event_type: str, event_data: dict) -> ConversationEvent:\n        \"\"\"添加事件到会话历史\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_events_from_sequence(self, agent_id: str, from_sequence: int = 1) -> List[ConversationEvent]:\n        \"\"\"获取从指定序号开始的事件\"\"\"\n        pass\n    \n    @abstractmethod\n    async def delete_history(self, agent_id: str) -> bool:\n        \"\"\"删除会话历史\"\"\"\n        pass\n    \n    @abstractmethod\n    async def list_histories(self, user_id: str, limit: int = 50, offset: int = 0) -> List[ConversationHistory]:\n        \"\"\"列出会话历史（支持按用户过滤）\"\"\"\n        pass ",
      "methods": [
        "<module>.ConversationRepository.save_history",
        "<module>.ConversationRepository.get_history",
        "<module>.ConversationRepository.add_event",
        "<module>.ConversationRepository.get_events_from_sequence",
        "<module>.ConversationRepository.delete_history",
        "<module>.ConversationRepository.list_histories"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/search.py",
      "name": "SearchEngine",
      "qualname": "<module>.SearchEngine",
      "source": "class SearchEngine(Protocol):\n    \"\"\"Search engine service gateway interface\"\"\"\n    \n    async def search(\n        self, \n        query: str, \n        date_range: Optional[str] = None\n    ) -> ToolResult:\n        \"\"\"Search webpages using search engine\n        \n        Args:\n            query: Search query, Google search style, using 3-5 keywords\n            date_range: (Optional) Time range filter for search results\n            \n        Returns:\n            Search results\n        \"\"\"\n        ... ",
      "methods": [
        "<module>.SearchEngine.search"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/user_repository.py",
      "name": "UserRepository",
      "qualname": "<module>.UserRepository",
      "source": "class UserRepository(Protocol):\n    \"\"\"用户仓储接口\"\"\"\n    \n    @abstractmethod\n    async def save_user(self, user: User) -> None:\n        \"\"\"保存用户\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_user(self, user_id: str) -> Optional[User]:\n        \"\"\"通过ID获取用户\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_user_by_email(self, email: str) -> Optional[User]:\n        \"\"\"通过邮箱获取用户\"\"\"\n        pass\n    \n    @abstractmethod\n    async def save_task(self, task: UserTask) -> None:\n        \"\"\"保存用户任务\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_task(self, task_id: str) -> Optional[UserTask]:\n        \"\"\"通过ID获取任务\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_user_tasks(self, user_id: str) -> List[UserTask]:\n        \"\"\"获取用户所有任务\"\"\"\n        pass\n    \n    @abstractmethod\n    async def save_file(self, file: UserFile) -> None:\n        \"\"\"保存用户文件\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_file(self, file_id: str) -> Optional[UserFile]:\n        \"\"\"通过ID获取文件\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_user_files(self, user_id: str) -> List[UserFile]:\n        \"\"\"获取用户所有文件\"\"\"\n        pass ",
      "methods": [
        "<module>.UserRepository.save_user",
        "<module>.UserRepository.get_user",
        "<module>.UserRepository.get_user_by_email",
        "<module>.UserRepository.save_task",
        "<module>.UserRepository.get_task",
        "<module>.UserRepository.get_user_tasks",
        "<module>.UserRepository.save_file",
        "<module>.UserRepository.get_file",
        "<module>.UserRepository.get_user_files"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/agent_context_repository.py",
      "name": "AgentContextRepository",
      "qualname": "<module>.AgentContextRepository",
      "source": "class AgentContextRepository(Protocol):\n    \"\"\"Agent上下文仓储接口\"\"\"\n    \n    @abstractmethod\n    async def save_context(self, context: AgentContext) -> None:\n        \"\"\"保存Agent上下文\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_context(self, agent_id: str) -> Optional[AgentContext]:\n        \"\"\"通过agent_id获取Agent上下文\"\"\"\n        pass\n    \n    @abstractmethod\n    async def update_context(self, context: AgentContext) -> None:\n        \"\"\"更新Agent上下文\"\"\"\n        pass\n    \n    @abstractmethod\n    async def delete_context(self, agent_id: str) -> bool:\n        \"\"\"删除Agent上下文\"\"\"\n        pass\n    \n    @abstractmethod\n    async def list_contexts(self, user_id: Optional[str] = None, status: Optional[str] = None, \n                           limit: int = 50, offset: int = 0) -> List[AgentContext]:\n        \"\"\"列出Agent上下文（支持按用户和状态过滤）\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_contexts_by_user(self, user_id: str) -> List[AgentContext]:\n        \"\"\"获取指定用户的所有Agent上下文\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_contexts_by_status(self, status: str) -> List[AgentContext]:\n        \"\"\"获取指定状态的所有Agent上下文\"\"\"\n        pass\n    \n    @abstractmethod\n    async def update_status(self, agent_id: str, status: str) -> bool:\n        \"\"\"更新Agent状态\"\"\"\n        pass\n    \n    @abstractmethod\n    async def update_last_message(self, agent_id: str, message: str, timestamp: Optional[int] = None) -> bool:\n        \"\"\"更新最后消息\"\"\"\n        pass\n    \n    @abstractmethod\n    async def set_sandbox_id(self, agent_id: str, sandbox_id: str) -> bool:\n        \"\"\"设置沙盒ID\"\"\"\n        pass\n    \n    @abstractmethod\n    async def context_exists(self, agent_id: str) -> bool:\n        \"\"\"检查Agent上下文是否存在\"\"\"\n        pass ",
      "methods": [
        "<module>.AgentContextRepository.save_context",
        "<module>.AgentContextRepository.get_context",
        "<module>.AgentContextRepository.update_context",
        "<module>.AgentContextRepository.delete_context",
        "<module>.AgentContextRepository.list_contexts",
        "<module>.AgentContextRepository.get_contexts_by_user",
        "<module>.AgentContextRepository.get_contexts_by_status",
        "<module>.AgentContextRepository.update_status",
        "<module>.AgentContextRepository.update_last_message",
        "<module>.AgentContextRepository.set_sandbox_id",
        "<module>.AgentContextRepository.context_exists"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/browser.py",
      "name": "Browser",
      "qualname": "<module>.Browser",
      "source": "class Browser(Protocol):\n    \"\"\"Browser service gateway interface\"\"\"\n    \n    async def view_page(self) -> ToolResult:\n        \"\"\"View current page content\"\"\"\n        ...\n    \n    async def navigate(self, url: str) -> ToolResult:\n        \"\"\"Navigate to specified URL\"\"\"\n        ...\n    \n    async def restart(self, url: str) -> ToolResult:\n        \"\"\"Restart browser and navigate to specified URL\"\"\"\n        ...\n    \n    async def click(\n        self,\n        index: Optional[int] = None,\n        coordinate_x: Optional[float] = None,\n        coordinate_y: Optional[float] = None\n    ) -> ToolResult:\n        \"\"\"Click element\"\"\"\n        ...\n    \n    async def input(\n        self,\n        text: str,\n        press_enter: bool,\n        index: Optional[int] = None,\n        coordinate_x: Optional[float] = None,\n        coordinate_y: Optional[float] = None\n    ) -> ToolResult:\n        \"\"\"Input text\"\"\"\n        ...\n    \n    async def move_mouse(\n        self,\n        coordinate_x: float,\n        coordinate_y: float\n    ) -> ToolResult:\n        \"\"\"Move mouse\"\"\"\n        ...\n    \n    async def press_key(self, key: str) -> ToolResult:\n        \"\"\"Simulate key press\"\"\"\n        ...\n    \n    async def select_option(\n        self,\n        index: int,\n        option: int\n    ) -> ToolResult:\n        \"\"\"Select dropdown option\"\"\"\n        ...\n    \n    async def scroll_up(\n        self,\n        to_top: Optional[bool] = None\n    ) -> ToolResult:\n        \"\"\"Scroll up\"\"\"\n        ...\n    \n    async def scroll_down(\n        self,\n        to_bottom: Optional[bool] = None\n    ) -> ToolResult:\n        \"\"\"Scroll down\"\"\"\n        ...\n    \n    async def console_exec(self, javascript: str) -> ToolResult:\n        \"\"\"Execute JavaScript code\"\"\"\n        ...\n    \n    async def console_view(self, max_lines: Optional[int] = None) -> ToolResult:\n        \"\"\"View console output\"\"\"\n        ... ",
      "methods": [
        "<module>.Browser.view_page",
        "<module>.Browser.navigate",
        "<module>.Browser.restart",
        "<module>.Browser.click",
        "<module>.Browser.input",
        "<module>.Browser.move_mouse",
        "<module>.Browser.press_key",
        "<module>.Browser.select_option",
        "<module>.Browser.scroll_up",
        "<module>.Browser.scroll_down",
        "<module>.Browser.console_exec",
        "<module>.Browser.console_view"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/llm.py",
      "name": "LLM",
      "qualname": "<module>.LLM",
      "source": "class LLM(Protocol):\n    \"\"\"AI service gateway interface for interacting with AI services\"\"\"\n    \n    async def ask(\n        self,\n        messages: List[Dict[str, str]],\n        tools: Optional[List[Dict[str, Any]]] = None,\n        response_format: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Send chat request to AI service\n        \n        Args:\n            messages: List of messages, including conversation history\n            tools: Optional list of tools for function calling\n            response_format: Optional response format configuration\n            \n        Returns:\n            Response message from AI service\n        \"\"\"\n        pass \n",
      "methods": [
        "<module>.LLM.ask"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/llm.py",
      "name": "ImageLLM",
      "qualname": "<module>.ImageLLM",
      "source": "class ImageLLM(Protocol):\n    pass\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/llm.py",
      "name": "AudioLLM",
      "qualname": "<module>.AudioLLM",
      "source": "class AudioLLM(Protocol):\n    async def audio_to_text(\n        self,\n        audio_path: str,\n        filename: str\n    ) -> str:\n        pass\n",
      "methods": [
        "<module>.AudioLLM.audio_to_text"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/llm.py",
      "name": "VideoLLM",
      "qualname": "<module>.VideoLLM",
      "source": "class VideoLLM(Protocol):\n    async def video_to_text(\n        self,\n        video_uri: str,\n    ) -> str:\n        pass\n\n    async def ask_video(\n        self,\n        video_uri: str,\n        query: str\n    ) -> str:\n        pass\n",
      "methods": [
        "<module>.VideoLLM.video_to_text",
        "<module>.VideoLLM.ask_video"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/llm.py",
      "name": "ReasonLLM",
      "qualname": "<module>.ReasonLLM",
      "source": "class ReasonLLM(Protocol):\n    async def deep_reasoning(\n        self,\n        problem: str,\n        context: Optional[str] = None\n    ) -> str:\n        pass\n",
      "methods": [
        "<module>.ReasonLLM.deep_reasoning"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/event_subscription_repository.py",
      "name": "EventBroadcastRepository",
      "qualname": "<module>.EventBroadcastRepository",
      "source": "class EventBroadcastRepository(Protocol):\n    \"\"\"事件广播仓储接口\"\"\"\n\n    @abstractmethod\n    async def save_broadcaster(self, broadcaster: AgentEventBroadcaster) -> None:\n        \"\"\"保存广播器\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_broadcaster(self, agent_id: str) -> Optional[AgentEventBroadcaster]:\n        \"\"\"获取广播器\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_broadcaster(self, broadcaster: AgentEventBroadcaster) -> bool:\n        \"\"\"更新广播器\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete_broadcaster(self, agent_id: str) -> bool:\n        \"\"\"删除广播器\"\"\"\n        pass\n",
      "methods": [
        "<module>.EventBroadcastRepository.save_broadcaster",
        "<module>.EventBroadcastRepository.get_broadcaster",
        "<module>.EventBroadcastRepository.update_broadcaster",
        "<module>.EventBroadcastRepository.delete_broadcaster"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/event_subscription_repository.py",
      "name": "EventStreamRepository",
      "qualname": "<module>.EventStreamRepository",
      "source": "class EventStreamRepository(Protocol):\n    \"\"\"事件流仓储接口\"\"\"\n\n    @abstractmethod\n    async def get_events_from_sequence(self, agent_id: str, from_sequence: int = 1) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"从指定序号开始获取事件流（包含历史事件和实时事件）\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_buffered_events(self, agent_id: str, from_sequence: int = 1) -> List[AgentEvent]:\n        \"\"\"获取缓冲区中的事件\"\"\"\n        pass\n\n    @abstractmethod\n    async def notify_new_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"通知新事件\"\"\"\n        pass\n\n    @abstractmethod\n    async def cleanup_agent_stream(self, agent_id: str) -> None:\n        \"\"\"清理agent的事件流\"\"\"\n        pass \n",
      "methods": [
        "<module>.EventStreamRepository.get_events_from_sequence",
        "<module>.EventStreamRepository.get_buffered_events",
        "<module>.EventStreamRepository.notify_new_event",
        "<module>.EventStreamRepository.cleanup_agent_stream"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/external/event_subscription_repository.py",
      "name": "EventSubscriptionManager",
      "qualname": "<module>.EventSubscriptionManager",
      "source": "class EventSubscriptionManager(Protocol):\n    \"\"\"事件订阅管理器接口\"\"\"\n\n    @abstractmethod\n    async def notify_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"通知新事件\"\"\"\n        pass\n",
      "methods": [
        "<module>.EventSubscriptionManager.notify_event"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/conversation_service.py",
      "name": "ConversationService",
      "qualname": "<module>.ConversationService",
      "source": "class ConversationService:\n    \"\"\"会话领域服务\"\"\"\n    \n    def __init__(self, conversation_repository: ConversationRepository):\n        self.conversation_repository = conversation_repository\n        logger.info(\"ConversationService initialized\")\n    \n    async def create_conversation(self, agent_id: str, user_id: Optional[str] = None, flow_id: str = \"plan_act\") -> ConversationHistory:\n        \"\"\"创建新会话\"\"\"\n        history = ConversationHistory(\n            agent_id=agent_id,\n            user_id=user_id,\n            flow_id=flow_id\n        )\n        await self.conversation_repository.save_history(history)\n        logger.info(f\"Created new conversation for agent {agent_id}, user {user_id}, flow {flow_id}\")\n        return history\n    \n    async def record_event(self, agent_id: str, event: AgentEvent) -> ConversationEvent:\n        \"\"\"记录事件到会话历史\"\"\"\n        # 直接存储事件类名和完整的事件数据\n        event_data = {\n            \"event_class\": event.__class__.__name__,\n            **event.model_dump()\n        }\n        \n        # 使用事件类名作为event_type\n        event_type = event.__class__.__name__\n        \n        # 添加事件到仓储\n        conversation_event = await self.conversation_repository.add_event(\n            agent_id=agent_id,\n            event_type=event_type,\n            event_data=event_data\n        )\n        \n        logger.debug(f\"Recorded event {event_type} for agent {agent_id}\")\n        return conversation_event\n    \n    async def delete_conversation(self, agent_id: str) -> bool:\n        \"\"\"删除会话历史\"\"\"\n        result = await self.conversation_repository.delete_history(agent_id)\n        if result:\n            logger.info(f\"Deleted conversation history for agent {agent_id}\")\n        return result\n    \n    async def list_conversations(self, user_id: str, limit: int = 50, offset: int = 0) -> List[ConversationHistory]:\n        \"\"\"列出会话历史\"\"\"\n        return await self.conversation_repository.list_histories(user_id, limit, offset)\n    \n    async def update_title(self, agent_id: str, title: str) -> bool:\n        \"\"\"更新会话标题\"\"\"\n        history = await self.conversation_repository.get_history(agent_id)\n        if not history:\n            logger.warning(f\"Cannot update title for non-existent conversation: {agent_id}\")\n            return False\n        \n        if history.title:\n            return False\n        history.title = title\n        history.updated_at = datetime.now()\n        await self.conversation_repository.save_history(history)\n        logger.info(f\"Updated title for conversation {agent_id}: {title}\")\n        return True\n    \n    def _rebuild_agent_event(self, conversation_event: ConversationEvent) -> Optional[AgentEvent]:\n        \"\"\"从ConversationEvent重建AgentEvent对象\"\"\"\n        try:\n            event_class_name = conversation_event.event_data.get(\"event_class\")\n            if not event_class_name:\n                logger.warning(f\"No event_class found in conversation event {conversation_event.id}\")\n                return None\n            \n            # 获取事件类\n            event_classes = {\n                \"MessageEvent\": MessageEvent,\n                \"ToolCallingEvent\": ToolCallingEvent,\n                \"ToolCalledEvent\": ToolCalledEvent,\n                \"PlanCreatedEvent\": PlanCreatedEvent,\n                \"PlanUpdatedEvent\": PlanUpdatedEvent,\n                \"PlanCompletedEvent\": PlanCompletedEvent,\n                \"StepStartedEvent\": StepStartedEvent,\n                \"StepCompletedEvent\": StepCompletedEvent,\n                \"StepFailedEvent\": StepFailedEvent,\n                \"ErrorEvent\": ErrorEvent,\n                \"DoneEvent\": DoneEvent\n            }\n            \n            event_class = event_classes.get(event_class_name)\n            if not event_class:\n                logger.warning(f\"Unknown event class: {event_class_name}\")\n                return None\n            \n            # 从存储的数据中移除event_class字段，剩下的就是原始事件数据\n            event_data = conversation_event.event_data.copy()\n            event_data.pop(\"event_class\", None)\n            \n            # 重建AgentEvent对象\n            agent_event = event_class(**event_data)\n            logger.debug(f\"Successfully rebuilt {event_class_name} from conversation event\")\n            return agent_event\n            \n        except Exception as e:\n            logger.error(f\"Error rebuilding AgentEvent from conversation event {conversation_event.id}: {str(e)}\")\n            return None ",
      "methods": [
        "<module>.ConversationService.__init__",
        "<module>.ConversationService.create_conversation",
        "<module>.ConversationService.record_event",
        "<module>.ConversationService.delete_conversation",
        "<module>.ConversationService.list_conversations",
        "<module>.ConversationService.update_title",
        "<module>.ConversationService._rebuild_agent_event"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/user_service.py",
      "name": "UserService",
      "qualname": "<module>.UserService",
      "source": "class UserService:\n    \"\"\"领域服务：用户管理\"\"\"\n    \n    def __init__(self, user_repository: UserRepository):\n        \"\"\"\n        初始化用户服务\n        \n        Args:\n            user_repository: 用户仓储接口\n        \"\"\"\n        self.user_repository = user_repository\n    \n    async def get_or_create_user(self, user_info: Dict[str, Any]) -> User:\n        \"\"\"\n        获取现有用户或创建新用户\n        \n        Args:\n            user_info: 从OAuth获取的用户信息\n            \n        Returns:\n            User 对象\n        \"\"\"\n        user_id = user_info.get(\"user_id\")\n        email = user_info.get(\"email\")\n        \n        if not user_id and not email:\n            raise ValueError(\"需要提供用户ID或邮箱\")\n        \n        # 尝试通过ID查找用户\n        if user_id:\n            user = await self.user_repository.get_user(user_id)\n            if user:\n                user.last_login = datetime.now()\n                await self.user_repository.save_user(user)\n                return user\n        \n        # 尝试通过邮箱查找用户\n        if email:\n            user = await self.user_repository.get_user_by_email(email)\n            if user:\n                user.last_login = datetime.now()\n                await self.user_repository.save_user(user)\n                return user\n        \n        # 创建新用户\n        if not user_id:\n            user_id = str(uuid.uuid4())\n            user_info[\"user_id\"] = user_id\n            \n        user = User.from_oauth(user_info)\n        await self.user_repository.save_user(user)\n        logger.info(f\"创建新用户: {user_id}, 邮箱: {email}\")\n        \n        return user\n    \n    async def get_user(self, user_id: str) -> Optional[User]:\n        \"\"\"\n        通过ID获取用户\n        \n        Args:\n            user_id: 用户ID\n            \n        Returns:\n            User对象，如果未找到则返回None\n        \"\"\"\n        return await self.user_repository.get_user(user_id)\n    \n    async def create_task(self, user_id: str, agent_id: str, title: str, metadata: Dict[str, Any] = None) -> UserTask:\n        \"\"\"\n        为用户创建新任务\n        \n        Args:\n            user_id: 用户ID\n            agent_id: Agent ID\n            title: 任务标题\n            metadata: 可选的任务元数据\n            \n        Returns:\n            创建的任务\n        \"\"\"\n        # 检查用户是否存在\n        user = await self.user_repository.get_user(user_id)\n        if not user:\n            raise ValueError(f\"未找到用户: {user_id}\")\n        \n        task_id = str(uuid.uuid4())\n        task = UserTask(\n            id=task_id,\n            user_id=user_id,\n            agent_id=agent_id,\n            title=title,\n            status=\"in_progress\",\n            metadata=metadata or {}\n        )\n        \n        await self.user_repository.save_task(task)\n        \n        logger.info(f\"为用户 {user_id} 创建任务 {task_id}\")\n        return task\n    \n    async def complete_task(self, task_id: str) -> Optional[UserTask]:\n        \"\"\"\n        将任务标记为已完成\n        \n        Args:\n            task_id: 任务ID\n            \n        Returns:\n            更新后的任务，如果未找到则返回None\n        \"\"\"\n        task = await self.user_repository.get_task(task_id)\n        if not task:\n            logger.warning(f\"未找到任务: {task_id}\")\n            return None\n        \n        task.complete()\n        await self.user_repository.save_task(task)\n        \n        logger.info(f\"完成任务 {task_id}\")\n        return task\n    \n    async def create_file(self, user_id: str, filename: str, path: str, metadata: Dict[str, Any] = None) -> UserFile:\n        \"\"\"\n        为用户创建新文件\n        \n        Args:\n            user_id: 用户ID\n            filename: 文件名\n            path: 文件路径\n            metadata: 可选的文件元数据\n            \n        Returns:\n            创建的文件\n        \"\"\"\n        # 检查用户是否存在\n        user = await self.user_repository.get_user(user_id)\n        if not user:\n            raise ValueError(f\"未找到用户: {user_id}\")\n        \n        file_id = str(uuid.uuid4())\n        file = UserFile(\n            id=file_id,\n            user_id=user_id,\n            filename=filename,\n            path=path,\n            metadata=metadata or {}\n        )\n        \n        await self.user_repository.save_file(file)\n        \n        logger.info(f\"为用户 {user_id} 创建文件 {file_id}\")\n        return file\n    \n    async def get_user_tasks(self, user_id: str) -> List[UserTask]:\n        \"\"\"\n        获取用户所有任务\n        \n        Args:\n            user_id: 用户ID\n            \n        Returns:\n            用户任务列表\n        \"\"\"\n        # 检查用户是否存在\n        user = await self.user_repository.get_user(user_id)\n        if not user:\n            logger.warning(f\"未找到用户: {user_id}\")\n            return []\n        \n        return await self.user_repository.get_user_tasks(user_id)\n    \n    async def get_user_files(self, user_id: str) -> List[UserFile]:\n        \"\"\"\n        获取用户所有文件\n        \n        Args:\n            user_id: 用户ID\n            \n        Returns:\n            用户文件列表\n        \"\"\"\n        # 检查用户是否存在\n        user = await self.user_repository.get_user(user_id)\n        if not user:\n            logger.warning(f\"未找到用户: {user_id}\")\n            return []\n        \n        return await self.user_repository.get_user_files(user_id)\n        \n    async def get_file_by_id(self, file_id: str) -> Optional[UserFile]:\n        \"\"\"\n        根据文件ID获取文件信息\n        \n        Args:\n            file_id: 文件ID\n            \n        Returns:\n            UserFile对象，如果未找到则返回None\n        \"\"\"\n        return await self.user_repository.get_file(file_id)\n        \n    async def get_file_content(self, file_id: str) -> Tuple[Optional[bytes], Optional[str], Optional[str]]:\n        \"\"\"\n        根据文件ID获取文件二进制内容\n        \n        Args:\n            file_id: 文件ID\n            \n        Returns:\n            元组(文件内容, 文件名, 内容类型)，如果未找到则返回(None, None, None)\n        \"\"\"\n        file = await self.user_repository.get_file(file_id)\n        if not file:\n            logger.warning(f\"未找到文件: {file_id}\")\n            return None, None, None\n            \n        file_path = file.path\n        if not os.path.exists(file_path):\n            logger.warning(f\"未找到文件路径: {file_path}\")\n            return None, None, None\n            \n        try:\n            with open(file_path, 'rb') as f:\n                content = f.read()\n                \n            # 尝试从元数据获取内容类型\n            content_type = file.metadata.get('content_type', 'application/octet-stream')\n                \n            return content, file.filename, content_type\n        except Exception as e:\n            logger.error(f\"读取文件 {file_id} 出错: {str(e)}\")\n            return None, None, None ",
      "methods": [
        "<module>.UserService.__init__",
        "<module>.UserService.get_or_create_user",
        "<module>.UserService.get_user",
        "<module>.UserService.create_task",
        "<module>.UserService.complete_task",
        "<module>.UserService.create_file",
        "<module>.UserService.get_user_tasks",
        "<module>.UserService.get_user_files",
        "<module>.UserService.get_file_by_id",
        "<module>.UserService.get_file_content"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agent.py",
      "name": "RuntimeAgentContext",
      "qualname": "<module>.RuntimeAgentContext",
      "source": "class RuntimeAgentContext:\n    \"\"\"运行时Agent上下文（包含不可持久化的资源）\"\"\"\n    domain_context: DomainAgentContext\n    flow: BaseFlow\n    sandbox: Sandbox\n    msg_queue: asyncio.Queue\n    event_queue: asyncio.Queue\n    task: Optional[asyncio.Task] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agent.py",
      "name": "AgentDomainService",
      "qualname": "<module>.AgentDomainService",
      "source": "class AgentDomainService:\n    \"\"\"\n    使用仓储模式的Agent领域服务\n\n    将Agent上下文的持久化信息存储在仓储中，运行时资源在内存中管理\n    \"\"\"\n\n    def __init__(\n        self,\n        agent_context_repository: AgentContextRepository,\n        conversation_service: ConversationService,\n        event_subscription_service: Optional[EventSubscriptionDomainService] = None,\n        user_service: Optional[UserService] = None\n    ):\n        # 运行时上下文管理，key是agent_id，value是运行时资源集合\n        self._runtime_contexts: Dict[str, RuntimeAgentContext] = {}\n        self.agent_context_repository = agent_context_repository\n        self.conversation_service = conversation_service\n        self.event_subscription_service = event_subscription_service\n        self.user_service = user_service\n        logger.info(\"AgentDomainServiceWithRepository initialization completed\")\n\n    async def create_agent(self, model_name: str, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM,\n                          video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser,\n                          search_engine: Optional[SearchEngine] = None,\n                          temperature: float = 0.7,\n                          max_tokens: Optional[int] = None,\n                          user_id: Optional[str] = None,\n                          environment: Optional[Environment] = None,\n                          flow_id: str = \"plan_act\") -> Agent:\n        \"\"\"创建并初始化Agent，包括相关代理和资源\"\"\"\n        # 验证flow_id是否有效\n        if not flow_factory.has_flow(flow_id):\n            available_flows = [f[\"flow_id\"] for f in flow_factory.get_available_flows()]\n            raise ValueError(f\"未知的flow类型: {flow_id}. 可用类型: {available_flows}\")\n\n        # 创建Agent实例，ID会自动生成\n        agent = Agent(\n            planner_memory=Memory(),\n            execution_memory=Memory(),\n            model_name=model_name,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            user_id=user_id,\n            environment=environment\n        )\n\n        return await self._initialize_agent_context(agent, llm, audio_llm, image_llm, video_llm, reason_llm,\n                                                   sandbox, browser, search_engine, flow_id)\n\n    async def initialize_agent(self, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM,\n                              video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser,\n                              search_engine: Optional[SearchEngine] = None,\n                              flow_id: str = \"plan_act\") -> Agent:\n        \"\"\"初始化现有Agent实例的资源和上下文\"\"\"\n        # 验证flow_id是否有效\n        if not flow_factory.has_flow(flow_id):\n            available_flows = [f[\"flow_id\"] for f in flow_factory.get_available_flows()]\n            raise ValueError(f\"未知的flow类型: {flow_id}. 可用类型: {available_flows}\")\n\n        return await self._initialize_agent_context(agent, llm, audio_llm, image_llm, video_llm, reason_llm,\n                                                   sandbox, browser, search_engine, flow_id)\n\n    async def _initialize_agent_context(self, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM,\n                                       video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser,\n                                       search_engine: Optional[SearchEngine], flow_id: str) -> Agent:\n        \"\"\"初始化Agent上下文和资源（create_agent和initialize_agent的公共逻辑）\"\"\"\n        agent_id = agent.id\n        logger.info(f\"初始化Agent上下文, ID: {agent_id}, model: {agent.model_name}, user_id: {agent.user_id}, flow_id: {flow_id}\")\n\n        # 检查该agent_id的资源是否已存在（虽然概率很小）\n        if agent_id in self._runtime_contexts:\n            logger.error(f\"Agent with ID {agent_id} already exists\")\n            raise ValueError(f\"Agent with ID {agent_id} already exists\")\n\n        # 使用工厂模式创建flow\n        try:\n            flow = flow_factory.create_flow(\n                flow_id=flow_id,\n                agent=agent,\n                llm=llm,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine\n            )\n            logger.info(f\"Successfully created flow '{flow_id}' for Agent {agent_id}\")\n        except Exception as e:\n            logger.error(f\"Failed to create flow '{flow_id}' for Agent {agent_id}: {str(e)}\")\n            raise\n\n        # 创建领域上下文\n        domain_context = DomainAgentContext(\n            agent_id=agent_id,\n            agent=agent,\n            flow_id=flow_id,\n            status=\"created\"\n        )\n\n        # 保存到仓储\n        try:\n            await self.agent_context_repository.save_context(domain_context)\n            logger.debug(f\"Agent上下文已保存到仓储: {agent_id}\")\n        except Exception as e:\n            logger.error(f\"保存Agent上下文到仓储失败: {agent_id}, 错误: {str(e)}\")\n            raise\n\n        # 创建运行时资源集合\n        runtime_context = RuntimeAgentContext(\n            domain_context=domain_context,\n            flow=flow,\n            sandbox=sandbox,\n            msg_queue=asyncio.Queue(),\n            event_queue=asyncio.Queue()\n        )\n\n        self._runtime_contexts[agent_id] = runtime_context\n\n        # 创建并启动任务\n        runtime_context.task = asyncio.create_task(\n            self._run_flow_task(agent_id)\n        )\n\n        # 更新状态为运行中\n        await self.agent_context_repository.update_status(agent_id, \"running\")\n        domain_context.update_status(\"running\")\n\n        # 创建会话历史记录\n        asyncio.create_task(\n            self.conversation_service.create_conversation(\n                agent_id=agent_id,\n                user_id=agent.user_id,\n                flow_id=flow_id\n            )\n        )\n\n        logger.info(f\"Agent {agent_id} initialization completed and task started\")\n\n        return agent\n\n    async def get_agent(self, agent_id: str) -> Optional[Agent]:\n        \"\"\"获取指定ID的Agent实例\"\"\"\n        # 首先尝试从运行时上下文获取\n        runtime_context = self._runtime_contexts.get(agent_id)\n        if runtime_context:\n            return runtime_context.domain_context.agent\n\n        # 如果运行时上下文不存在，尝试从仓储加载\n        domain_context = await self.agent_context_repository.get_context(agent_id)\n        if domain_context:\n            return domain_context.agent\n\n        logger.warning(f\"Attempted to get non-existent Agent: {agent_id}\")\n        return None\n\n    async def has_agent(self, agent_id: str) -> bool:\n        \"\"\"检查指定ID的Agent是否存在\"\"\"\n        # 首先检查运行时上下文\n        if agent_id in self._runtime_contexts:\n            return True\n\n        # 然后检查仓储\n        domain_context = await self.agent_context_repository.get_context(agent_id)\n        exists = domain_context is not None\n        logger.debug(f\"Checking if Agent {agent_id} exists: {exists}\")\n        return exists\n\n    async def load_agent_from_repository(self, agent_id: str, llm: LLM, audio_llm: AudioLLM,\n                                        image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM,\n                                        sandbox: Sandbox, browser: Browser,\n                                        search_engine: Optional[SearchEngine] = None) -> Optional[Agent]:\n        \"\"\"从仓储加载Agent并恢复运行时上下文\"\"\"\n        domain_context = await self.agent_context_repository.get_context(agent_id)\n        if not domain_context:\n            logger.warning(f\"Agent {agent_id} not found in repository\")\n            return None\n\n        # 如果已经在运行时上下文中，直接返回\n        if agent_id in self._runtime_contexts:\n            logger.info(f\"Agent {agent_id} already loaded in runtime\")\n            return domain_context.agent\n\n        try:\n            # 重新初始化运行时资源\n            await self._restore_runtime_context(domain_context, llm, audio_llm, image_llm, video_llm,\n                                               reason_llm, sandbox, browser, search_engine)\n            logger.info(f\"Agent {agent_id} loaded from repository and runtime context restored\")\n            return domain_context.agent\n        except Exception as e:\n            logger.error(f\"Failed to restore runtime context for Agent {agent_id}: {str(e)}\")\n            raise\n\n    async def _restore_runtime_context(self, domain_context: DomainAgentContext, llm: LLM, audio_llm: AudioLLM,\n                                      image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM,\n                                      sandbox: Sandbox, browser: Browser,\n                                      search_engine: Optional[SearchEngine]) -> None:\n        \"\"\"恢复运行时上下文\"\"\"\n        agent_id = domain_context.agent_id\n        flow_id = domain_context.flow_id\n\n        # 创建flow\n        flow = flow_factory.create_flow(\n            flow_id=flow_id,\n            agent=domain_context.agent,\n            llm=llm,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine\n        )\n\n        # 创建运行时上下文\n        runtime_context = RuntimeAgentContext(\n            domain_context=domain_context,\n            flow=flow,\n            sandbox=sandbox,\n            msg_queue=asyncio.Queue(),\n            event_queue=asyncio.Queue()\n        )\n\n        self._runtime_contexts[agent_id] = runtime_context\n\n        # 启动任务\n        runtime_context.task = asyncio.create_task(\n            self._run_flow_task(agent_id)\n        )\n\n        # 更新状态\n        await self.agent_context_repository.update_status(agent_id, \"running\")\n        domain_context.update_status(\"running\")\n\n    async def _run_flow(self, agent_id: str, message: Optional[str] = None) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        处理用户消息的完整业务流程:\n        1. 创建计划\n        2. 执行计划\n        \"\"\"\n        # 获取相关资源\n        runtime_context = self._runtime_contexts.get(agent_id)\n\n        if not runtime_context:\n            logger.error(f\"Agent {agent_id} not initialized\")\n            yield ErrorEvent(error=\"Agent not initialized\")\n            return\n\n        if not message:\n            logger.warning(f\"Agent {agent_id} received empty message\")\n            yield ErrorEvent(error=\"No message\")\n            return\n\n        async for event in runtime_context.flow.run(message):\n            yield event\n\n    def _ensure_task(self, agent_id: str) -> None:\n        \"\"\"确保指定agent的任务和队列已初始化并正常运行\"\"\"\n        runtime_context = self._runtime_contexts.get(agent_id)\n        if not runtime_context:\n            logger.warning(f\"Attempted to ensure task for non-existent Agent {agent_id}\")\n            return\n\n        # 检查任务是否需要重启（不存在或已完成或已取消或遇到异常）\n        task_needs_restart = (\n            runtime_context.task is None or\n            runtime_context.task.done() or\n            runtime_context.task.cancelled()\n        )\n\n        if task_needs_restart:\n            # 创建并启动新任务\n            logger.info(f\"Agent {agent_id} task needs restart, creating new task\")\n            runtime_context.task = asyncio.create_task(\n                self._run_flow_task(agent_id)\n            )\n\n    async def _run_flow_task(self, agent_id: str) -> None:\n        \"\"\"处理指定agent的消息队列，支持优雅退出\"\"\"\n        try:\n            logger.info(f\"Agent {agent_id} 消息处理任务已启动\")\n            while True:\n                runtime_context = self._runtime_contexts.get(agent_id)\n\n                if not runtime_context:\n                    logger.warning(f\"Agent {agent_id} 运行时上下文不存在，结束任务\")\n                    break\n\n                # 使用带超时的等待，以便能够更快响应取消操作\n                try:\n                    logger.debug(f\"Agent {agent_id} 等待消息...\")\n                    message = await asyncio.wait_for(runtime_context.msg_queue.get(), timeout=1.0)\n                    logger.info(f\"Agent {agent_id} 收到新消息: {message[:50]}...\")\n\n                    # 更新最后消息到仓储\n                    await self.agent_context_repository.update_last_message(agent_id, message)\n                    runtime_context.domain_context.update_last_message(message)\n\n                    # 调用原始chat方法处理消息，并将事件放入队列\n                    try:\n                        async for event in self._run_flow(agent_id, message):\n                            logger.info(f\"Agent {agent_id} 输出事件: {event}\")\n                            if isinstance(event, PlanCreatedEvent):\n                                await self.conversation_service.update_title(agent_id, event.plan.title)\n                            # 将事件放入队列供传统chat方法使用\n                            await runtime_context.event_queue.put(event)\n\n                            # 如果有事件订阅服务，同时广播事件\n                            if self.event_subscription_service:\n                                try:\n                                    await self.event_subscription_service.broadcast_event(agent_id, event)\n                                except Exception as broadcast_error:\n                                    logger.warning(f\"Failed to broadcast event for agent {agent_id}: {str(broadcast_error)}\")\n\n                            # 更新context\n                            self.agent_context_repository.update_context(runtime_context.domain_context)\n\n                            # 如果消息队列不为空，优先处理下一条消息\n                            if not runtime_context.msg_queue.empty():\n                                break\n                    except Exception as flow_error:\n                        # 捕获并处理flow执行中的错误\n                        logger.exception(f\"Agent {agent_id} 在执行flow时发生错误: {str(flow_error)}\")\n                        error_event = ErrorEvent(error=f\"Flow执行错误: {str(flow_error)}\")\n                        done_event = DoneEvent()\n\n                        # 放入队列\n                        await runtime_context.event_queue.put(error_event)\n                        await runtime_context.event_queue.put(done_event)\n\n                        # 广播错误事件\n                        if self.event_subscription_service:\n                            try:\n                                await self.event_subscription_service.broadcast_event(agent_id, error_event)\n                                await self.event_subscription_service.broadcast_event(agent_id, done_event)\n                            except Exception as broadcast_error:\n                                logger.warning(f\"Failed to broadcast error event for agent {agent_id}: {str(broadcast_error)}\")\n\n                        # 更新状态为错误\n                        await self.agent_context_repository.update_status(agent_id, \"error\")\n                        runtime_context.domain_context.update_status(\"error\")\n\n                    runtime_context.msg_queue.task_done()\n                    logger.debug(f\"Agent {agent_id} 完成处理一条消息\")\n                except asyncio.TimeoutError:\n                    # 超时只是用来检查是否需要退出循环，无需处理\n                    continue\n\n        except asyncio.CancelledError:\n            # 任务被取消时的清理工作\n            logger.info(f\"Agent {agent_id} 任务被取消，正在进行清理...\")\n\n            # 获取上下文并进行资源清理\n            runtime_context = self._runtime_contexts.get(agent_id)\n            if runtime_context:\n                # 通知客户端任务已取消\n                try:\n                    # 如果已经结束，则不需要额外操作\n                    if runtime_context.task.done():\n                        return\n\n                    error_event = ErrorEvent(error=\"任务已被取消\")\n                    done_event = DoneEvent()\n\n                    await runtime_context.event_queue.put(error_event)\n                    await runtime_context.event_queue.put(done_event)\n\n                    # 广播取消事件\n                    if self.event_subscription_service:\n                        try:\n                            await self.event_subscription_service.broadcast_event(agent_id, error_event)\n                            await self.event_subscription_service.broadcast_event(agent_id, done_event)\n                        except Exception as broadcast_error:\n                            logger.warning(f\"Failed to broadcast cancellation event for agent {agent_id}: {str(broadcast_error)}\")\n\n                    # 更新状态为停止\n                    await self.agent_context_repository.update_status(agent_id, \"stopped\")\n                    runtime_context.domain_context.update_status(\"stopped\")\n                except Exception as e:\n                    logger.error(f\"取消通知发送失败: {str(e)}\")\n\n            logger.info(f\"Agent {agent_id} 任务已优雅退出\")\n            # 重新抛出异常，确保调用者知道任务被取消\n            raise\n        except Exception as e:\n            # 处理任务执行过程中的其他异常\n            logger.exception(f\"Agent {agent_id} 任务遇到异常: {str(e)}\")\n            runtime_context = self._runtime_contexts.get(agent_id)\n            if runtime_context:\n                try:\n                    error_event = ErrorEvent(error=f\"任务错误: {str(e)}\")\n                    done_event = DoneEvent()\n\n                    await runtime_context.event_queue.put(error_event)\n                    await runtime_context.event_queue.put(done_event)\n\n                    # 广播异常事件\n                    if self.event_subscription_service:\n                        try:\n                            await self.event_subscription_service.broadcast_event(agent_id, error_event)\n                            await self.event_subscription_service.broadcast_event(agent_id, done_event)\n                        except Exception as broadcast_error:\n                            logger.warning(f\"Failed to broadcast exception event for agent {agent_id}: {str(broadcast_error)}\")\n\n                    # 更新状态为错误\n                    await self.agent_context_repository.update_status(agent_id, \"error\")\n                    runtime_context.domain_context.update_status(\"error\")\n                except Exception as e2:\n                    logger.error(f\"错误通知发送失败: {str(e2)}\")\n        finally:\n            # 确保即使在异常情况下也能进行资源清理\n            logger.info(f\"Agent {agent_id} 任务结束，正在清理最终资源\")\n            runtime_context = self._runtime_contexts.get(agent_id)\n            if runtime_context:\n                try:\n                    if not runtime_context.event_queue.empty():\n                        done_event = DoneEvent()\n                        await runtime_context.event_queue.put(done_event)\n\n                        # 广播最终完成事件\n                        if self.event_subscription_service:\n                            try:\n                                await self.event_subscription_service.broadcast_event(agent_id, done_event)\n                            except Exception as broadcast_error:\n                                logger.warning(f\"Failed to broadcast final done event for agent {agent_id}: {str(broadcast_error)}\")\n                except Exception as e:\n                    logger.error(f\"最终清理过程中出错: {str(e)}\")\n\n    async def _clear_queue(self, queue: asyncio.Queue) -> None:\n        \"\"\"清空指定队列\"\"\"\n        cleared_count = 0\n        while not queue.empty():\n            try:\n                queue.get_nowait()\n                cleared_count += 1\n            except asyncio.QueueEmpty:\n                break\n        logger.debug(f\"Cleared queue, removed {cleared_count} items\")\n\n    async def close_agent(self, agent_id: str) -> bool:\n        \"\"\"清理指定Agent的资源\"\"\"\n        logger.info(f\"Starting to close Agent {agent_id}\")\n        runtime_context = self._runtime_contexts.get(agent_id)\n\n        if not runtime_context:\n            logger.warning(f\"Attempted to close non-existent Agent {agent_id}\")\n            # 即使运行时上下文不存在，也尝试从仓储删除\n            try:\n                await self.agent_context_repository.delete_context(agent_id)\n                logger.info(f\"Deleted Agent {agent_id} from repository\")\n                return True\n            except Exception as e:\n                logger.error(f\"Failed to delete Agent {agent_id} from repository: {str(e)}\")\n                return False\n\n        # 1. 取消并清理任务\n        if runtime_context.task and not runtime_context.task.done():\n            logger.debug(f\"Cancelling Agent {agent_id}'s task\")\n            runtime_context.task.cancel()\n            try:\n                await runtime_context.task\n            except asyncio.CancelledError:\n                pass\n\n        # 2. 清理事件订阅\n        if self.event_subscription_service:\n            try:\n                logger.debug(f\"Cleaning up event subscriptions for Agent {agent_id}\")\n                await self.event_subscription_service.cleanup_agent_streams(agent_id)\n            except Exception as e:\n                logger.warning(f\"Failed to cleanup event subscriptions for agent {agent_id}: {str(e)}\")\n\n        # 3. 清理队列资源\n        logger.debug(f\"Clearing Agent {agent_id}'s message queue\")\n        await self._clear_queue(runtime_context.msg_queue)\n        logger.debug(f\"Clearing Agent {agent_id}'s event queue\")\n        await self._clear_queue(runtime_context.event_queue)\n\n        # 4. 销毁沙盒环境\n        if runtime_context.sandbox:\n            logger.debug(f\"Destroying Agent {agent_id}'s sandbox environment\")\n            await runtime_context.sandbox.close()\n\n        # 5. 从仓储删除\n        try:\n            await self.agent_context_repository.delete_context(agent_id)\n            logger.debug(f\"Deleted Agent {agent_id} from repository\")\n        except Exception as e:\n            logger.error(f\"Failed to delete Agent {agent_id} from repository: {str(e)}\")\n\n        # 6. 移除运行时资源集合\n        self._runtime_contexts.pop(agent_id, None)\n        logger.info(f\"Agent {agent_id} has been fully closed and resources cleared\")\n        return True\n\n    async def close_all(self) -> None:\n        \"\"\"清理所有Agent的资源\"\"\"\n        logger.info(f\"Starting to close all Agents, currently {len(self._runtime_contexts)} in runtime\")\n        # 逐个关闭运行时上下文中的agent\n        for agent_id in list(self._runtime_contexts.keys()):\n            await self.close_agent(agent_id)\n        logger.info(\"All runtime Agents have been closed\")\n\n    @staticmethod\n    def get_available_flows():\n        \"\"\"获取所有可用的flow类型\"\"\"\n        return flow_factory.get_available_flows()\n\n    async def delete_conversation_history(self, agent_id: str) -> bool:\n        \"\"\"删除会话历史\"\"\"\n        return await self.conversation_service.delete_conversation(agent_id)\n\n    async def list_conversations(self, user_id: Optional[str] = None, limit: int = 50, offset: int = 0):\n        \"\"\"列出会话历史\"\"\"\n        return await self.conversation_service.list_conversations(user_id, limit, offset)\n\n    async def send_message(\n            self, \n            agent_id: str, \n            message: str, \n            sandbox: Sandbox,\n            timestamp: Optional[int] = None, \n            file_ids: Optional[List[str]] = None\n        ) -> bool:\n        \"\"\"\n        发送消息到Agent（不返回事件流）\n\n        这个方法只负责将消息放入Agent的处理队列，不返回事件流。\n        客户端需要通过其他方式来接收事件。\n\n        Args:\n            agent_id: Agent ID\n            message: 用户消息\n            timestamp: 消息时间戳\n            file_ids: 文件ID列表\n\n        Returns:\n            是否成功将消息放入队列\n\n        Raises:\n            ValueError: 当Agent不存在时\n        \"\"\"\n        if file_ids is None:\n            file_ids = []\n\n        # 提供给agent的信息\n        combined_message = message\n\n        # 文件上传的固定目标路径\n        destination_path = \"/home/ubuntu\"\n\n        # 如果提供了文件ID列表，则先处理文件传输\n        uploaded_files = []\n        if file_ids and len(file_ids) > 0:\n            logger.info(f\"Processing {len(file_ids)} attached files for agent {agent_id}\")\n\n            # 处理每个文件\n            for file_id in file_ids:\n                try:\n                    content, filename, _ = await self.user_service.get_file_content(file_id)\n                    if content:\n                        # 构建沙箱中的完整文件路径\n                        sandbox_file_path = f\"{destination_path}/{filename}\"\n\n                        # 传输文件到沙箱\n                        result = await sandbox.file_upload(\n                            file_path=sandbox_file_path,\n                            content=content,\n                            make_executable=False\n                        )\n\n                        # 将文件信息添加到上传列表\n                        uploaded_files.append({\n                            \"id\": file_id,\n                            \"filename\": filename,\n                            \"path\": sandbox_file_path,\n                            \"size\": result.data.get(\"size\", 0)\n                        })\n\n                        logger.info(f\"Transferred file {filename} to sandbox at {sandbox_file_path}\")\n                    else:\n                        logger.warning(f\"Failed to get content for file {file_id}\")\n                except Exception as e:\n                    logger.exception(f\"Error transferring file {file_id} to sandbox: {str(e)}\")\n\n            # 如果成功上传了文件，将文件信息添加到消息中\n            if uploaded_files:\n                file_info = \"\\n\\n附件信息:\\n\"\n                for idx, file in enumerate(uploaded_files, 1):\n                    file_info += f\"{idx}. {file['filename']} - 位置: {file['path']}\\n\"\n\n                # 将附件信息添加到原始消息\n                combined_message = message + file_info\n\n        logger.info(f\"Sending message to agent {agent_id}: {combined_message[:50]}...\")\n\n        # 检查Agent是否存在（先检查运行时上下文）\n        runtime_context = self._runtime_contexts.get(agent_id)\n        if not runtime_context:\n            # 尝试从仓储加载\n            domain_context = await self.agent_context_repository.get_context(agent_id)\n            if not domain_context:\n                logger.error(f\"Agent {agent_id} not found\")\n                raise ValueError(f\"Agent {agent_id} not found\")\n            else:\n                logger.info(f\"Agent {agent_id} exists in repository but not in runtime context, needs restoration\")\n                raise AgentNotRunningError(f\"Agent {agent_id} is not running\")\n\n        try:\n            # 将消息放入队列（避免重复消息）\n            domain_context = runtime_context.domain_context\n            if not (domain_context.last_message == combined_message and domain_context.last_message_time == timestamp):\n                user_input_event = UserInputEvent(message=message, file_ids=file_ids)\n                await runtime_context.event_queue.put(user_input_event)\n                # 如果有事件订阅服务，同时广播事件\n                if self.event_subscription_service:\n                    try:\n                        await self.event_subscription_service.broadcast_event(agent_id, user_input_event)\n                    except Exception as broadcast_error:\n                        logger.warning(f\"Failed to broadcast event for agent {agent_id}: {str(broadcast_error)}\")\n                await runtime_context.msg_queue.put(combined_message)\n\n                # 更新最后消息到仓储和内存\n                await self.agent_context_repository.update_last_message(agent_id, combined_message, timestamp)\n                domain_context.update_last_message(combined_message, timestamp)\n\n                logger.info(f\"Message queued successfully for agent {agent_id}\")\n\n                # 确保任务正在运行\n                self._ensure_task(agent_id)\n\n                return True\n            else:\n                logger.info(f\"Duplicate message ignored for agent {agent_id}\")\n                return True\n\n        except Exception as e:\n            logger.error(f\"Failed to queue message for agent {agent_id}: {str(e)}\")\n            raise RuntimeError(f\"Failed to queue message: {str(e)}\")\n\n    # Agent上下文管理相关方法\n    async def list_agent_contexts(self, user_id: Optional[str] = None, status: Optional[str] = None,\n                                 limit: int = 50, offset: int = 0) -> List[DomainAgentContext]:\n        \"\"\"列出Agent上下文\"\"\"\n        return await self.agent_context_repository.list_contexts(user_id, status, limit, offset)\n\n    async def get_agent_context(self, agent_id: str) -> Optional[DomainAgentContext]:\n        \"\"\"获取Agent上下文\"\"\"\n        # 首先尝试从运行时上下文获取\n        runtime_context = self._runtime_contexts.get(agent_id)\n        if runtime_context:\n            return runtime_context.domain_context\n\n        # 如果运行时上下文不存在，从仓储获取\n        return await self.agent_context_repository.get_context(agent_id)\n\n    async def update_agent_status(self, agent_id: str, status: str) -> bool:\n        \"\"\"更新Agent状态\"\"\"\n        # 更新仓储\n        success = await self.agent_context_repository.update_status(agent_id, status)\n\n        # 更新运行时上下文\n        runtime_context = self._runtime_contexts.get(agent_id)\n        if runtime_context:\n            runtime_context.domain_context.update_status(status)\n\n        return success\n\n    async def save_agent_context(self, agent: Agent, flow_id: str, sandbox_id: Optional[str] = None,\n                                status: str = \"created\", last_message: Optional[str] = None,\n                                meta_data: Optional[Dict] = None) -> DomainAgentContext:\n        \"\"\"保存Agent上下文到仓储\"\"\"\n        # 创建领域上下文\n        domain_context = DomainAgentContext(\n            agent_id=agent.id,\n            agent=agent,\n            flow_id=flow_id,\n            sandbox_id=sandbox_id,\n            status=status,\n            last_message=last_message,\n            meta_data=meta_data or {}\n        )\n\n        # 保存到仓储\n        await self.agent_context_repository.save_context(domain_context)\n        logger.info(f\"Agent上下文已保存到仓储: {agent.id}\")\n\n        return domain_context\n\n    async def update_agent_last_message(self, agent_id: str, message: str, timestamp: Optional[datetime] = None) -> bool:\n        \"\"\"更新Agent最后消息\"\"\"\n        if timestamp is None:\n            timestamp = datetime.now()\n\n        # 更新仓储\n        success = await self.agent_context_repository.update_last_message(agent_id, message, timestamp)\n\n        # 更新运行时上下文\n        runtime_context = self._runtime_contexts.get(agent_id)\n        if runtime_context:\n            runtime_context.domain_context.update_last_message(message, timestamp)\n\n        return success\n\n    async def create_agent_context(self, agent: Agent, flow_id: str, sandbox_id: Optional[str] = None,\n                                  status: str = \"created\", last_message: Optional[str] = None,\n                                  meta_data: Optional[Dict] = None) -> DomainAgentContext:\n        \"\"\"创建Agent上下文（别名方法）\"\"\"\n        return await self.save_agent_context(agent, flow_id, sandbox_id, status, last_message, meta_data)\n",
      "methods": [
        "<module>.AgentDomainService.__init__",
        "<module>.AgentDomainService.create_agent",
        "<module>.AgentDomainService.initialize_agent",
        "<module>.AgentDomainService._initialize_agent_context",
        "<module>.AgentDomainService.get_agent",
        "<module>.AgentDomainService.has_agent",
        "<module>.AgentDomainService.load_agent_from_repository",
        "<module>.AgentDomainService._restore_runtime_context",
        "<module>.AgentDomainService._run_flow",
        "<module>.AgentDomainService._ensure_task",
        "<module>.AgentDomainService._run_flow_task",
        "<module>.AgentDomainService._clear_queue",
        "<module>.AgentDomainService.close_agent",
        "<module>.AgentDomainService.close_all",
        "<module>.AgentDomainService.get_available_flows",
        "<module>.AgentDomainService.delete_conversation_history",
        "<module>.AgentDomainService.list_conversations",
        "<module>.AgentDomainService.send_message",
        "<module>.AgentDomainService.list_agent_contexts",
        "<module>.AgentDomainService.get_agent_context",
        "<module>.AgentDomainService.update_agent_status",
        "<module>.AgentDomainService.save_agent_context",
        "<module>.AgentDomainService.update_agent_last_message",
        "<module>.AgentDomainService.create_agent_context"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/event_subscription_service.py",
      "name": "EventSubscriptionDomainService",
      "qualname": "<module>.EventSubscriptionDomainService",
      "source": "class EventSubscriptionDomainService:\n    \"\"\"事件订阅领域服务 - 纯发布订阅模式\"\"\"\n\n    def __init__(\n        self,\n        broadcast_repository: EventBroadcastRepository,\n        stream_repository: EventStreamRepository,\n        event_subscription_manager: EventSubscriptionManager\n    ):\n        self.broadcast_repository = broadcast_repository\n        self.stream_repository = stream_repository\n        self.event_subscription_manager = event_subscription_manager\n\n    async def broadcast_event(self, agent_id: str, event: AgentEvent) -> int:\n        \"\"\"广播事件给指定Agent的所有订阅者\"\"\"\n        logger.debug(f\"Broadcasting event {type(event).__name__} for agent {agent_id}\")\n        \n        # 如果有底层管理器，直接调用其notify_event方法（包含广播器创建逻辑）\n        await self.event_subscription_manager.notify_event(agent_id, event)\n        \n        # 获取广播器来返回序号\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if broadcaster:\n            return broadcaster.event_buffer.current_sequence\n        return 1\n\n    async def get_event_stream(self, agent_id: str, from_sequence: int = 1) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"获取事件流（包含历史事件和实时事件）\"\"\"\n        logger.info(f\"Getting event stream for agent {agent_id} from sequence {from_sequence}\")\n        \n        async for event in self.stream_repository.get_events_from_sequence(agent_id, from_sequence):\n            yield event\n\n    async def get_buffered_events(self, agent_id: str, from_sequence: int = 1) -> List[AgentEvent]:\n        \"\"\"获取缓冲区中的事件\"\"\"\n        return await self.stream_repository.get_buffered_events(agent_id, from_sequence)\n\n    async def get_agent_subscription_count(self, agent_id: str) -> int:\n        \"\"\"获取Agent的活跃订阅者数量\"\"\"\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if not broadcaster:\n            return 0\n        return broadcaster.get_active_subscriber_count()\n\n    async def cleanup_agent_streams(self, agent_id: str) -> bool:\n        \"\"\"清理Agent的所有事件流和订阅者\"\"\"\n        logger.info(f\"Cleaning up all streams for agent {agent_id}\")\n        \n        # 清理流（包括所有订阅者）\n        await self.stream_repository.cleanup_agent_stream(agent_id)\n        \n        # 删除广播器\n        await self.broadcast_repository.delete_broadcaster(agent_id)\n        \n        logger.info(f\"Cleaned up streams for agent {agent_id}\")\n        return True\n\n    async def cleanup_inactive_subscribers(self, agent_id: str, timeout_minutes: int = 30) -> int:\n        \"\"\"清理指定Agent的不活跃订阅者\"\"\"\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if not broadcaster:\n            return 0\n        \n        cleaned_count = broadcaster.cleanup_inactive_subscribers(timeout_minutes)\n        \n        if cleaned_count > 0:\n            await self.broadcast_repository.update_broadcaster(broadcaster)\n            logger.info(f\"Cleaned up {cleaned_count} inactive subscribers for agent {agent_id}\")\n        \n        return cleaned_count ",
      "methods": [
        "<module>.EventSubscriptionDomainService.__init__",
        "<module>.EventSubscriptionDomainService.broadcast_event",
        "<module>.EventSubscriptionDomainService.get_event_stream",
        "<module>.EventSubscriptionDomainService.get_buffered_events",
        "<module>.EventSubscriptionDomainService.get_agent_subscription_count",
        "<module>.EventSubscriptionDomainService.cleanup_agent_streams",
        "<module>.EventSubscriptionDomainService.cleanup_inactive_subscribers"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/class_slicer.py",
      "name": "ClassSlice",
      "qualname": "<module>.ClassSlice",
      "source": "class ClassSlice(BaseModel):\n    \"\"\"单个类的切片 + 类内方法列表\"\"\"\n    name: str\n    qualname: str\n    source: str\n    methods: List[str] = Field(default_factory=list)  # 仅直系方法（qualname）\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/class_slicer.py",
      "name": "WorkspaceClass",
      "qualname": "<module>.WorkspaceClass",
      "source": "class WorkspaceClass(BaseModel):\n    file: str\n    name: str\n    qualname: str\n    source: str\n    methods: List[str] = Field(default_factory=list)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/class_slicer.py",
      "name": "SliceError",
      "qualname": "<module>.SliceError",
      "source": "class SliceError(BaseModel):\n    file: str\n    message: str\n    lineno: Optional[int] = None\n    colno: Optional[int] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/class_slicer.py",
      "name": "WorkspaceClassSlices",
      "qualname": "<module>.WorkspaceClassSlices",
      "source": "class WorkspaceClassSlices(BaseModel):\n    root: str\n    classes: List[WorkspaceClass] = Field(default_factory=list)\n    errors: List[SliceError] = Field(default_factory=list)\n    num_files_processed: int = 0\n    num_classes: int = 0\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/class_slicer.py",
      "name": "_ClassCollector",
      "qualname": "<module>._ClassCollector",
      "source": "class _ClassCollector(ast.NodeVisitor):\n    \"\"\"仅收集类定义（包含整个类体），并统计其直接定义的方法名；不负责函数切片或调用关系提取。\"\"\"\n\n    def __init__(self, src: str):\n        self.src = src\n        self.parents: List[str] = []  # 用于构造 qualname\n        self.classes: List[ClassSlice] = []\n\n    def visit_ClassDef(self, node: ast.ClassDef):\n        qual = \".\".join(self.parents + [node.name]) if self.parents else node.name\n\n        # 先收集类内方法名（仅直系成员）\n        method_qualnames: List[str] = []\n        for n in node.body:\n            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                method_qualnames.append(f\"{qual}.{n.name}\")\n\n        cls_slice = ClassSlice(\n            name=node.name,\n            qualname=qual,\n            source=_get_source_segment(self.src, node),\n            methods=method_qualnames,\n        )\n        self.classes.append(cls_slice)\n\n        # 进入类作用域，继续收集内部类\n        self.parents.append(node.name)\n        self.generic_visit(node)\n        self.parents.pop()\n\n    # 函数定义不做记录，但要维持 parents 以便嵌套类 qualname 正确\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        self.parents.append(node.name)\n        self.generic_visit(node)\n        self.parents.pop()\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self.parents.append(node.name)\n        self.generic_visit(node)\n        self.parents.pop()\n",
      "methods": [
        "<module>._ClassCollector.__init__",
        "<module>._ClassCollector.visit_ClassDef",
        "<module>._ClassCollector.visit_FunctionDef",
        "<module>._ClassCollector.visit_AsyncFunctionDef"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/function_slicer.py",
      "name": "WorkspaceFunction",
      "qualname": "<module>.WorkspaceFunction",
      "source": "class WorkspaceFunction(BaseModel):\n    file: str                       # 来自于哪个文件（相对路径）\n    qualname: str                   # 函数（或方法）限定名\n    source: str                     # 函数源代码\n    calls: List[str] = Field(default_factory=list)\n    called_by: List[str] = Field(default_factory=list)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/function_slicer.py",
      "name": "WorkspaceResult",
      "qualname": "<module>.WorkspaceResult",
      "source": "class WorkspaceResult(BaseModel):\n    items: List[WorkspaceFunction]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/function_slicer.py",
      "name": "_FuncDef",
      "qualname": "<module>._FuncDef",
      "source": "class _FuncDef:\n    file: Path\n    qualname: str\n    lineno: int\n    end_lineno: int\n    source: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/function_slicer.py",
      "name": "_QualnameBuilder",
      "qualname": "<module>._QualnameBuilder",
      "source": "class _QualnameBuilder(ast.NodeVisitor):\n    \"\"\"计算限定名：module相对路径 + （Class.）* + func。\"\"\"\n    def __init__(self, module_name: str, code: str):\n        self.stack: List[str] = []\n        self.funcs: List[_FuncDef] = []\n        self.module_name = module_name\n        self.code = code.splitlines(keepends=True)\n\n    def _push(self, name: str):\n        self.stack.append(name)\n\n    def _pop(self):\n        if self.stack:\n            self.stack.pop()\n\n    def _qual(self, leaf: str) -> str:\n        parts = [self.module_name] + self.stack + [leaf]\n        return \".\".join([p for p in parts if p])\n\n    def visit_ClassDef(self, node: ast.ClassDef):\n        self._push(node.name)\n        self.generic_visit(node)\n        self._pop()\n\n    def visit_FunctionDef(self, node: ast.FunctionDef):\n        qn = self._qual(node.name)\n        src = \"\".join(self.code[node.lineno - 1: node.end_lineno])\n        self.funcs.append(\n            _FuncDef(\n                file=Path(self.module_name.replace(\".\", os.sep) + \".py\"),  # 占位；外层会替换为真实相对路径\n                qualname=qn,\n                lineno=node.lineno,\n                end_lineno=node.end_lineno,\n                source=src\n            )\n        )\n        self.generic_visit(node)\n\n    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n        self.visit_FunctionDef(node)  # 处理方式相同\n",
      "methods": [
        "<module>._QualnameBuilder.__init__",
        "<module>._QualnameBuilder._push",
        "<module>._QualnameBuilder._pop",
        "<module>._QualnameBuilder._qual",
        "<module>._QualnameBuilder.visit_ClassDef",
        "<module>._QualnameBuilder.visit_FunctionDef",
        "<module>._QualnameBuilder.visit_AsyncFunctionDef"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/function_slicer.py",
      "name": "_CallCollector",
      "qualname": "<module>._CallCollector",
      "source": "class _CallCollector(ast.NodeVisitor):\n    def __init__(self):\n        self.calls: Set[str] = set()\n\n    def visit_Call(self, node: ast.Call):\n        # 尝试收集简单的 Name/Attribute 调用名\n        name = None\n        if isinstance(node.func, ast.Name):\n            name = node.func.id\n        elif isinstance(node.func, ast.Attribute):\n            # 收集 attr 名称（不含对象全名，作为保底）\n            name = node.func.attr\n        if name:\n            self.calls.add(name)\n        self.generic_visit(node)\n",
      "methods": [
        "<module>._CallCollector.__init__",
        "<module>._CallCollector.visit_Call"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/base.py",
      "name": "BaseFlow",
      "qualname": "<module>.BaseFlow",
      "source": "class BaseFlow(ABC):\n    # 每个flow类都需要定义一个唯一的flow_id\n    flow_id: str = None\n    \n    def __init__(self, agent: Agent, **kwargs):\n        self.agent = agent\n        # 验证flow_id是否已定义\n        if self.flow_id is None:\n            raise ValueError(f\"Flow class {self.__class__.__name__} must define a flow_id\")\n\n    @abstractmethod\n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"执行flow的主要逻辑\"\"\"\n        pass\n    \n    @abstractmethod\n    def is_idle(self) -> bool:\n        \"\"\"检查flow是否处于空闲状态\"\"\"\n        pass\n    \n    @classmethod\n    def get_flow_id(cls) -> str:\n        \"\"\"获取flow的唯一标识符\"\"\"\n        return cls.flow_id\n\n    @classmethod\n    def get_description(cls) -> str:\n        \"\"\"获取flow的描述信息\"\"\"\n        return getattr(cls, 'description', f\"Flow {cls.flow_id}\")\n",
      "methods": [
        "<module>.BaseFlow.__init__",
        "<module>.BaseFlow.run",
        "<module>.BaseFlow.is_idle",
        "<module>.BaseFlow.get_flow_id",
        "<module>.BaseFlow.get_description"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/base.py",
      "name": "BaseSubFlow",
      "qualname": "<module>.BaseSubFlow",
      "source": "class BaseSubFlow(ABC):\n    \"\"\"\n    子规划器流程的基础接口类\n    定义了子规划器流程必须实现的核心方法\n    \"\"\"\n    # 每个flow类都需要定义一个唯一的flow_id\n    flow_id: str = None\n\n    # 初始化SubFlow可用的基础设施\n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Optional[Sandbox] = None,\n        browser: Optional[Browser] = None,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Optional[Enum] = None,\n    ):\n        self.llm = llm\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n        self.task_type = task_type\n\n    @abstractmethod\n    async def run(self, parent_plan: Plan, parent_step: Step, parent_memory: Memory,\n                   task_type: Enum) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行计划中的单个步骤\n        根据步骤类型创建对应的子规划器并执行\n        并生成当前子规划器的最终报告\n        包括执行过程、工具使用和最终结果\n\n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n\n        Yields:\n            AgentEvent: 执行过程中的各种事件\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def is_idle(self) -> bool:\n        \"\"\"检查flow是否处于空闲状态\"\"\"\n        pass\n\n    @classmethod\n    def get_flow_id(cls) -> str:\n        \"\"\"获取flow的唯一标识符\"\"\"\n        return cls.flow_id\n\n    @classmethod\n    def get_description(cls) -> str:\n        \"\"\"获取flow的描述信息\"\"\"\n        return getattr(cls, 'description', f\"Flow {cls.flow_id}\")",
      "methods": [
        "<module>.BaseSubFlow.__init__",
        "<module>.BaseSubFlow.run",
        "<module>.BaseSubFlow.is_idle",
        "<module>.BaseSubFlow.get_flow_id",
        "<module>.BaseSubFlow.get_description"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/sub_planner_flow.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/sub_planner_flow.py",
      "name": "SubPlannerFlow",
      "qualname": "<module>.SubPlannerFlow",
      "source": "class SubPlannerFlow(BaseSubFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"general\"\n    description = \"子计划规划流程：先创建子计划，然后逐步执行，支持动态更新子计划\"\n    \n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Enum = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_flow_logger = setup_sub_planner_flow_logger(f\"sub_planner_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow.__init__ 开始 ===\")\n        self.sub_planner_flow_logger.info(f\"接收到的参数:\")\n        self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n        self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n        self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n        self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n        self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.execution_result=Memory()\n        if task_type:\n            self.sub_planner_flow_logger.info(f\"task_type.value: {task_type.value}\")\n            self.sub_planner_flow_logger.info(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 调用父类构造函数\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        \n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        self.sub_planner_flow_logger.info(f\"=== 开始创建SubPlannerAgent ===\")\n        \n        try:\n            # 创建子规划器代理\n            self.sub_planner_flow_logger.info(f\"准备创建SubPlannerAgent，参数:\")\n            self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n            self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n            self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n            self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n            self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n            \n            self.sub_planner = SubPlannerAgent(\n                llm=llm,\n                task_type=task_type,\n                memory=Memory(),\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n            )\n            self.sub_planner_flow_logger.info(\"创建SubPlanner Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建SubPlannerAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        try:\n            self.sub_planner_flow_logger.info(f\"=== 开始创建ExecutionAgent ===\")\n            # 创建执行代理\n            self.executor = ExecutionAgent(\n                memory=Memory(),\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                type_value=task_type.value\n            )\n            self.sub_planner_flow_logger.info(\"创建Execution Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建ExecutionAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    async def run(\n        self,\n        parent_plan: Plan,\n        parent_step: Step,\n        parent_memory: Memory,\n        task_type: Enum\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行子计划流程\n        \n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n        \"\"\"\n        # TODO\n        self.sub_planner.fix(parent_plan,parent_step)\n\n        self.sub_planner_flow_logger.info(f\"=== 开始执行子计划 ===\")\n        self.sub_planner_flow_logger.info(f\"父计划ID: {parent_plan.id}\")\n        self.sub_planner_flow_logger.info(f\"父步骤ID: {parent_step.id}\")\n        self.sub_planner_flow_logger.info(f\"任务类型: {task_type.value}\")\n        \n        # 根据传入的task_type更新提示词\n        self.sub_planner_flow_logger.info(f\"=== 开始更新系统提示词 ===\")\n\n        # 更新子规划器的系统提示词\n        updated_system_prompt = PromptManager.get_system_prompt_with_tools(self.sub_planner.tools, is_executor=False)\n        updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n        updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n        self.sub_planner.system_prompt = PromptManager.insert_datetime(updated_system_prompt)\n\n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.sub_planner.roll_back()\n            self.executor.roll_back()\n            self.sub_planner_flow_logger.info(\"中断当前流程，重新开始规划\")\n\n        # 使用父步骤的描述作为输入消息\n        message = parent_step.description\n        logger.info(f\"开始处理步骤: {message[:50]}...\")\n        \n        # 创建子计划\n        self.status = AgentStatus.PLANNING\n        self.sub_planner_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n        \n        async for event in self.sub_planner.create_plan(message):\n            updated_system_prompt = self.sub_planner.system_prompt\n            updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n            updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n            self.sub_planner.system_prompt = updated_system_prompt\n            \n            if isinstance(event, PlanCreatedEvent):\n                self.plan = event.plan\n                logger.info(f\"创建子计划成功，包含 {len(event.plan.steps)} 个步骤\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划创建成功 ===\")\n                self.sub_planner_flow_logger.info(f\"子计划ID: {event.plan.id}\")\n                self.sub_planner_flow_logger.info(f\"子计划目标: {event.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"子计划标题: {event.plan.title}\")\n                self.sub_planner_flow_logger.info(f\"子计划步骤数量: {len(event.plan.steps)}\")\n                for i, step in enumerate(event.plan.steps, 1):\n                    self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}\")\n                if event.plan.message:\n                    self.sub_planner_flow_logger.info(f\"子计划说明: {event.plan.message}\")\n            elif isinstance(event, MessageEvent):\n                self.sub_planner_flow_logger.info(f\"Planner输出: {event.message}\")\n            yield event\n            \n        self.status = AgentStatus.EXECUTING\n        self.sub_planner_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n        \n        # 执行子计划\n        while True:\n            if self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"子计划执行完成，状态变更: EXECUTING -> REPORTING\")\n                    self.status = AgentStatus.REPORTING\n                    self.sub_planner_flow_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                    \n                # 执行步骤\n                logger.info(f\"开始执行步骤 {step.id}: {step.description[:50]}...\")\n                self.sub_planner_flow_logger.info(f\"=== 开始执行步骤 ===\")\n                self.sub_planner_flow_logger.info(f\"步骤ID: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤描述: {step.description}\")\n                self.sub_planner_flow_logger.info(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    updated_system_prompt = self.executor.system_prompt\n                    updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.executor.shell_tool)\n                    updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.executor.memory)\n                    self.executor.system_prompt = updated_system_prompt\n                    if isinstance(event, ToolCallingEvent):\n                        self.sub_planner_flow_logger.info(f\"工具调用: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.sub_planner_flow_logger.info(f\"工具结果: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.sub_planner_flow_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"Executor输出: {event.message}\")\n                        # 将执行结果保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n                        \n                logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                self.sub_planner_flow_logger.info(f\"步骤执行完成: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.sub_planner_flow_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.sub_planner_flow_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.sub_planner_flow_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为\n                self.sub_planner_flow_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    yield event\n                    if isinstance(event, MessageEvent):\n                        logger.info(f\"步骤总结完成: {event.message}\")\n                        previous_steps = event.message\n                        self.sub_planner_flow_logger.info(f\"步骤总结完成: {event.message}\")\n                        # 将总结保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                        \n                # 更新计划\n                self.sub_planner_flow_logger.info(f\"=== 开始更新子计划 ===\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                updated_system_prompt = self.sub_planner.system_prompt\n                updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n                updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n                self.sub_planner.system_prompt = updated_system_prompt\n                \n                async for event in self.sub_planner.update_plan(self.plan, previous_steps):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.sub_planner_flow_logger.info(f\"=== 子计划更新完成 ===\")\n                        self.sub_planner_flow_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 将更新信息保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                    yield event\n\n                logger.info(f\"子计划更新完成，状态变更: UPDATING -> EXECUTING\")\n                self.status = AgentStatus.EXECUTING\n                self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"子计划执行完成，准备生成报告\")\n                self.sub_planner_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                async for event in self.executor.report_result(message):\n                    if isinstance(event, MessageEvent):\n                        # 将报告保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n\n                yield ReportEvent(message=str(self.execution_result.get_messages()))\n                self.status = AgentStatus.COMPLETED\n                self.sub_planner_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"子计划执行完成\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划执行完成 ===\")\n                self.sub_planner_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan) \n                self.status = AgentStatus.IDLE\n                self.sub_planner_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n                \n        yield DoneEvent()\n        \n        logger.info(f\"子计划处理完成\")\n        self.sub_planner_flow_logger.info(f\"=== 子计划处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.SubPlannerFlow.__init__",
        "<module>.SubPlannerFlow.run",
        "<module>.SubPlannerFlow.is_idle",
        "<module>.SubPlannerFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/default_flow.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/default_flow.py",
      "name": "DefaultFlow",
      "qualname": "<module>.DefaultFlow",
      "source": "class DefaultFlow(BaseSubFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"default\"\n    description = \"子计划规划流程：先创建子计划，然后逐步执行，支持动态更新子计划\"\n    \n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Enum = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_flow_logger = setup_sub_planner_flow_logger(f\"sub_planner_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        #self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow.__init__ 开始 ===\")\n        # self.sub_planner_flow_logger.debug(f\"接收到的参数:\")\n        # self.sub_planner_flow_logger.debug(f\"  llm: {llm}\")\n        # self.sub_planner_flow_logger.debug(f\"  sandbox: {sandbox}\")\n        # self.sub_planner_flow_logger.debug(f\"  browser: {browser}\")\n        # self.sub_planner_flow_logger.debug(f\"  search_engine: {search_engine}\")\n        # self.sub_planner_flow_logger.debug(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.execution_result=Memory()\n        if task_type:\n            self.sub_planner_flow_logger.debug(f\"task_type.value: {task_type.value}\")\n      #      self.sub_planner_flow_logger.debug(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 调用父类构造函数\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        \n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        self.sub_planner_flow_logger.info(f\"=== 开始创建SubPlannerAgent ===\")\n        \n        try:\n            # 创建子规划器代理\n            self.sub_planner_flow_logger.debug(f\"准备创建SubPlannerAgent，参数:\")\n            self.sub_planner_flow_logger.debug(f\"  llm: {llm}\")\n            self.sub_planner_flow_logger.debug(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n            self.sub_planner_flow_logger.debug(f\"  sandbox: {sandbox}\")\n            self.sub_planner_flow_logger.debug(f\"  browser: {browser}\")\n            self.sub_planner_flow_logger.debug(f\"  search_engine: {search_engine}\")\n            \n            self.sub_planner = SubPlannerAgent(\n                llm=llm,\n                task_type=task_type,\n                memory=Memory(),\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n            )\n            self.sub_planner_flow_logger.info(\"创建SubPlanner Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建SubPlannerAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        try:\n            self.sub_planner_flow_logger.info(f\"=== 开始创建ExecutionAgent ===\")\n            # 创建执行代理\n            self.executor = ExecutionAgent(\n                memory=Memory(),\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                type_value=task_type.value\n            )\n            self.sub_planner_flow_logger.info(\"创建Execution Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建ExecutionAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    async def run(\n        self,\n        parent_plan: Plan,\n        parent_step: Step,\n        parent_memory: Memory,\n        task_type: Enum\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行子计划流程\n        \n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n        \"\"\"\n        # TODO\n        self.sub_planner.fix(parent_plan,parent_step)\n\n        self.sub_planner_flow_logger.info(f\"=== 开始执行子计划 ===\")\n        self.sub_planner_flow_logger.debug(f\"父计划ID: {parent_plan.id}\")\n        self.sub_planner_flow_logger.debug(f\"父步骤ID: {parent_step.id}\")\n        self.sub_planner_flow_logger.debug(f\"任务类型: {task_type.value}\")\n        \n        # 根据传入的task_type更新提示词\n        self.sub_planner_flow_logger.debug(f\"=== 开始更新系统提示词 ===\")\n        try:\n            # 更新子规划器的系统提示词\n            updated_system_prompt = PromptManager.get_system_prompt_with_tools(self.sub_planner.tools, is_executor=False)\n            self.sub_planner_flow_logger.debug(f\"[DEBUG MEM] SubPlannerFlow before update mem: {updated_system_prompt}\")\n            updated_system_prompt = PromptManager.update_mem(updated_system_prompt, parent_memory)\n            self.sub_planner_flow_logger.debug(f\"[DEBUG MEM] SubPlannerFlow after update mem: {updated_system_prompt}\")\n            updated_system_prompt = PromptManager.insert_datetime(updated_system_prompt)\n            if hasattr(self.sub_planner, 'system_prompt'):\n                self.sub_planner.system_prompt = updated_system_prompt\n                self.sub_planner_flow_logger.debug(f\"子规划器系统提示词更新成功\")\n                self.sub_planner_flow_logger.debug(f\"新提示词长度: {len(updated_system_prompt)}\")\n            else:\n                self.sub_planner_flow_logger.warning(f\"子规划器没有system_prompt属性\")\n                \n            # 更新执行器的系统提示词\n            executor_system_prompt = PromptManager.insert_datetime(PromptManager.get_system_prompt_with_tools(self.executor.tools, is_executor=True))\n            if hasattr(self.executor, 'system_prompt'):\n                self.executor.system_prompt = executor_system_prompt\n                self.sub_planner_flow_logger.debug(f\"执行器系统提示词更新成功\")\n                self.sub_planner_flow_logger.debug(f\"执行器新提示词长度: {len(executor_system_prompt)}\")\n            else:\n                self.sub_planner_flow_logger.warning(f\"执行器没有system_prompt属性\")\n                \n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"更新系统提示词失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            # 继续执行，不因为提示词更新失败而中断整个流程\n        \n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.sub_planner.roll_back()\n            self.executor.roll_back()\n            self.sub_planner_flow_logger.debug(\"中断当前流程，重新开始规划\")\n\n        # 使用父步骤的描述作为输入消息\n        message = parent_step.description\n        logger.info(f\"开始处理步骤: {message[:50]}...\")\n        \n        # 创建子计划\n        self.status = AgentStatus.PLANNING\n        self.sub_planner_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n        \n        async for event in self.sub_planner.create_plan(message):\n            if isinstance(event, PlanCreatedEvent):\n                self.plan = event.plan\n                logger.info(f\"创建子计划成功，包含 {len(event.plan.steps)} 个步骤\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划创建成功 ===\")\n                self.sub_planner_flow_logger.debug(f\"子计划ID: {event.plan.id}\")\n                self.sub_planner_flow_logger.info(f\"子计划目标: {event.plan.goal}\")\n                self.sub_planner_flow_logger.debug(f\"子计划标题: {event.plan.title}\")\n                self.sub_planner_flow_logger.debug(f\"子计划步骤数量: {len(event.plan.steps)}\")\n                for i, step in enumerate(event.plan.steps, 1):\n                    self.sub_planner_flow_logger.debug(f\"步骤{i}: [{step.id}] {step.description}\")\n                if event.plan.message:\n                    self.sub_planner_flow_logger.debug(f\"子计划说明: {event.plan.message}\")\n            elif isinstance(event, MessageEvent):\n                self.sub_planner_flow_logger.info(f\"Planner输出: {event.message}\")\n            #yield event\n            \n        self.status = AgentStatus.EXECUTING\n        self.sub_planner_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n        \n        # 执行子计划\n        while True:\n            if self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"子计划执行完成，状态变更: EXECUTING -> REPORTING\")\n                    self.status = AgentStatus.REPORTING\n                    self.sub_planner_flow_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                    \n                # 执行步骤\n                logger.info(f\"开始执行步骤 {step.id}: {step.description[:50]}...\")\n                self.sub_planner_flow_logger.info(f\"=== 开始执行步骤 ===\")\n                self.sub_planner_flow_logger.debug(f\"步骤ID: {step.id}\")\n                self.sub_planner_flow_logger.debug(f\"步骤描述: {step.description}\")\n                self.sub_planner_flow_logger.debug(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    if isinstance(event, ToolCallingEvent):\n                        self.sub_planner_flow_logger.debug(f\"工具调用: {event.tool_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.sub_planner_flow_logger.debug(f\"工具结果: {event.tool_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.sub_planner_flow_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.debug(f\"Executor输出: {event.message}\")\n                        # 将执行结果保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                #    yield event\n                        \n                logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                self.sub_planner_flow_logger.debug(f\"步骤执行完成: {step.id}\")\n                self.sub_planner_flow_logger.debug(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.sub_planner_flow_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.sub_planner_flow_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.sub_planner_flow_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为\n                self.sub_planner_flow_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    # 不转发总结事件到前端，这些是内部实现细节\n                    # yield event\n                    if isinstance(event, MessageEvent):\n                        previous_steps = event.message\n                        # 将总结保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                        \n                # 更新计划\n                self.sub_planner_flow_logger.info(f\"=== 开始更新子计划 ===\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                async for event in self.sub_planner.update_plan(self.plan, previous_steps):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.sub_planner_flow_logger.info(f\"=== 子计划更新完成 ===\")\n                        self.sub_planner_flow_logger.debug(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.sub_planner_flow_logger.debug(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 将更新信息保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                 #   yield event\n\n                logger.info(f\"子计划更新完成，状态变更: UPDATING -> EXECUTING\")\n                self.status = AgentStatus.EXECUTING\n                self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"子计划执行完成，准备生成报告\")\n                self.sub_planner_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                final_report = \"\"\n                async for event in self.executor.report_result(message):\n                    if isinstance(event, MessageEvent):\n                        # 将报告保存到execution_result中\n                        parent_step.result = event.message\n                        final_report = event.message  # 只保留最终报告\n                 #   yield event\n                yield ReportEvent(message=str(self.execution_result.get_messages()))\n                # # 只发送简洁的最终报告，而不是整个执行历史\n                # yield ReportEvent(message=final_report or parent_step.result or \"子任务执行完成\")\n                self.status = AgentStatus.COMPLETED\n                self.sub_planner_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"子计划执行完成\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划执行完成 ===\")\n                self.sub_planner_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan, issubplan=True) \n                self.status = AgentStatus.IDLE\n                self.sub_planner_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n                \n        #yield DoneEvent()\n        \"\"\"需要声明另一种doneevent\"\"\"\n        \n        logger.info(f\"子计划处理完成\")\n        self.sub_planner_flow_logger.info(f\"=== 子计划处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.DefaultFlow.__init__",
        "<module>.DefaultFlow.run",
        "<module>.DefaultFlow.is_idle",
        "<module>.DefaultFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/search_flow.py",
      "name": "SearchFlow",
      "qualname": "<module>.SearchFlow",
      "source": "class SearchFlow(BaseSubFlow):\n    flow_id = \"search\"\n    description = \"多步gap反射搜索流程\"\n\n    def __init__(\n        self,\n        llm,\n        sandbox,\n        browser,\n        search_engine=None,\n        audio_llm=None,\n        image_llm=None,\n        video_llm=None,\n        reason_llm=None,\n        task_type=None,\n    ):\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        self.knowledge: List[Dict[str, Any]] = []\n        self.max_iterations = 3\n\n        self.processed_gaps: set = set()\n\n        # self.executor = ExecutionAgent(\n        #     memory=Memory(),\n        #     llm=llm,\n        #     audio_llm=audio_llm,\n        #     image_llm=image_llm,\n        #     video_llm=video_llm,\n        #     reason_llm=reason_llm,\n        #     sandbox=sandbox,\n        #     browser=browser,\n        #     search_engine=search_engine\n        # )\n\n        self.status = \"idle\"\n\n    def is_idle(self):\n        return self.status == \"idle\"\n\n    async def run(\n            self,\n            parent_plan=None,\n            parent_step=None,\n            parent_memory=None,\n            task_type=None,\n            *args,\n            **kwargs\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        统一入口，兼容原有run和execute_task的参数风格。\n        支持位置参数和关键字参数。\n        \"\"\"\n        # 参数兼容处理\n        memory = parent_memory or kwargs.get('memory') or Memory()\n        plan = parent_plan or kwargs.get('plan')\n        step = parent_step or kwargs.get('step')\n        if not plan or not step:\n            # 兼容通过args传参\n            if len(args) >= 2:\n                plan, step = args[:2]\n            else:\n                raise ValueError(\"run() 必须包含 plan 和 step 两个参数\")\n\n        self.executor = ExecutionAgent(\n            memory=memory,\n            llm=self.llm,\n            audio_llm=self.audio_llm,\n            image_llm=self.image_llm,\n            video_llm=self.video_llm,\n            reason_llm=self.reason_llm,\n            sandbox=self.sandbox,\n            browser=self.browser,\n            search_engine=self.search_engine\n        )\n\n\n        global_question = step.description\n\n        yield MessageEvent(message=f\"初始化，目标问题：{global_question}\")\n\n        # 先选择全局评分模式列表\n        eval_types = await self.select_scoring_mode(global_question)\n\n        # gap主流程（可单独抽成私有方法，见上文）\n        gaps = await self.generate_gaps(global_question)\n        gaps = self._filter_and_update_gaps(gaps)\n        iteration = 0\n\n        #gaps=['下载文件Federico Lauria 2014年论文的全文']\n\n        # 此部分while loop针对单个gap，使用reflect_gap返回针对单个gap的反思gap\n        # while gaps and iteration < self.max_iterations:\n        #     iteration += 1\n        #     yield MessageEvent(message=f\"第{iteration}轮gap处理，待处理gap: {gaps}\")\n        #     # search_tasks = [self.search_gap(gap) for gap in gaps]\n        #     # search_results = await asyncio.gather(*search_tasks)\n        #\n        #     # 尝试不用并发，串行\n        #     search_results = []\n        #     for gap in gaps:\n        #         result = await self.search_gap(gap)\n        #         # print(f\"[DEBUG] search_gap 返回: {result}\")\n        #         search_results.append(result)\n        #\n        #     new_gaps = []\n        #\n        #     for gap, result in zip(gaps, search_results):\n        #         summary = self.format_search_result(result)\n        #         # print(\"debug用， format后summary内容：\")\n        #         # print(summary)\n        #         score, reason = await self.score_gap(gap, {\"result\": summary}, eval_types)\n        #         if score:\n        #             knowledge_item = {\"gap\": gap, \"summary\": summary, \"raw\": result, \"iteration\": iteration}\n        #             self.knowledge.append(knowledge_item)\n        #             yield MessageEvent(message=f\"gap [{gap}] 已解决，总结: {summary}\")\n        #         else:\n        #             error_reason = await self.analyze_gap(gap, result, reason)\n        #             knowledge_item = {\"gap\": gap, \"summary\": f\"失败: {error_reason}\", \"raw\": result,\n        #                               \"iteration\": iteration}\n        #             self.knowledge.append(knowledge_item)\n        #             yield MessageEvent(message=f\"gap [{gap}] 未解决，错误分析: {error_reason}\")\n        #             reflected_gaps = await self.reflect_gap(gap, error_reason)\n        #             yield MessageEvent(message=f\"gap [{gap}] 反射生成新gap: {reflected_gaps}\")\n        #             new_gaps.extend(reflected_gaps)\n        #     gaps = self._filter_and_update_gaps(gaps=[], new_gaps=new_gaps)\n\n        # 此部分while loop针对一整轮gap，使用reflect_batch_gap返回针对一整轮gap的反思gap\n        print(f\"generate后gap内容为:{gaps}\")\n        print(type(gaps), gaps)\n        while gaps and iteration < self.max_iterations:\n            print(\"主循环开始执行\")\n            iteration += 1\n            yield MessageEvent(message=f\"第{iteration}轮gap处理，待处理gap: {gaps}\")\n            print(f\"第{iteration}轮gap处理，待处理gap: {gaps}\")\n\n            search_results = []\n            for gap in gaps:\n                #result = await self.search_gap(gap)\n                print(\"主循环中运行到executor部分\")\n                result = await self.search_gap(gap, global_question)\n                print(f'已完成对gap： {gap} 的搜索')\n                search_results.append(result)\n\n            new_gaps = []\n            failed_gaps_info = []\n\n            for gap, result in zip(gaps, search_results):\n                summary = self.format_search_result(result)\n                score, reason = await self.score_gap(gap, {\"result\": summary}, eval_types)\n                if score:\n                    print(f'gap {gap} 执行成功')\n                    knowledge_item = {\"gap\": gap, \"summary\": summary, \"raw\": result, \"iteration\": iteration}\n                    self.knowledge.append(knowledge_item)\n                    yield MessageEvent(message=f\"gap [{gap}] 已解决，总结: {summary}\")\n                else:\n                    print(f'gap {gap} 执行失败')\n                    error_reason = await self.analyze_gap(gap, result, reason)\n                    knowledge_item = {\"gap\": gap, \"summary\": f\"失败: {error_reason}\", \"raw\": result,\n                                      \"iteration\": iteration}\n                    self.knowledge.append(knowledge_item)\n                    yield MessageEvent(message=f\"gap [{gap}] 未解决，错误分析: {error_reason}\")\n                    failed_gaps_info.append({\n                        \"gap\": gap,\n                        \"error_reason\": error_reason,\n                        \"executor_result\": result\n                    })\n\n            # 一轮gap全处理完后，统一reflect\n            if failed_gaps_info:\n                reflected_gaps = await self.reflect_gap_batch(failed_gaps_info)\n                yield MessageEvent(message=f\"本轮所有失败gap反射生成新gap: {reflected_gaps}\")\n                new_gaps.extend(reflected_gaps)\n\n            gaps = self._filter_and_update_gaps(gaps=[], new_gaps=new_gaps)\n\n        yield MessageEvent(message=\"gap处理完成，准备整合知识库生成最终答案\")\n        final_answer, need_more = await self.generate_final_answer(global_question, self.knowledge)\n        parent_step.result = final_answer\n        yield ReportEvent(message=f\"最终答案：{final_answer}\")\n        print(\"run中已yield最终答案\")\n        if need_more:\n            yield MessageEvent(message=\"LLM认为知识库仍有缺失，重新进入gap循环（本流程暂不再循环）\")\n        else:\n            yield MessageEvent(message=\"任务完成，已获得满意答案\")\n\n    # ========== 以下为各模块实现 ==========\n\n    async def select_scoring_mode(self, global_question: str)  -> List[str]:\n        \"\"\"\n        根据 global_question 的内容简单决策评分模式。\n        \"\"\"\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": prompt.QUESTION_EVALUATION_PROMPT_SYSTEM\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt.QUESTION_EVALUATION_PROMPT_USER.format(\n                    question=global_question\n                ),\n            },\n        ]\n        # 调用 LLM\n        #print(f'select scoring mode的message{messages}')\n        response = await self.llm.ask(messages)\n        # 打印调试内容（可选）\n        #print(\"LLM returned:\", response.content)\n\n\n        eval_types = []\n        # 解析 LLM 输出\n        try:\n            analysis_result = json.loads(response.content)\n        except Exception as e:\n            print(\"LLM输出解析失败，fallback使用basic\", e)\n            eval_types.append(\"basic\") #使用basic进行兜底\n\n        if analysis_result.get(\"needsDefinitive\", True):\n            eval_types.append(\"definitive\")\n        if analysis_result.get(\"needsFreshness\", False):\n            eval_types.append(\"freshness\")\n        if analysis_result.get(\"needsPlurality\", False):\n            eval_types.append(\"plurality\")\n        if analysis_result.get(\"needsCompleteness\", False):\n            #eval_types.append(\"completeness\")\n            print()\n        if analysis_result.get(\"needsFile\", True):\n            eval_types.append(\"file\")\n\n        print(f\"[Eval] 问题需要的评估类型: {eval_types}\")\n        return eval_types\n\n    #生成gap\n    async def generate_gaps(self, global_question: str) -> list[str]:\n        #print(\"generate_gaps 生成问题 运行到了\")\n\n        current_time = datetime.now()\n        system_prompt = prompt.QUERY_REWRITE_PROMPT_SYSTEM.format(\n            currentTime=current_time.isoformat(),\n            currentYear=current_time.year,\n            currentMonth=current_time.month\n        )\n        user_message = prompt.QUERY_GENERATE_PROMPT_USER.format(\n            global_question=global_question,\n            current_time=datetime.now()\n        )\n        messages = [\n            {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + user_message},\n        ]\n        response = await self.llm.ask(messages)\n        print(\"成功获取llm返回的新gaps，raw\")\n        print(response.content)\n        try:\n            data = json.loads(response.content)\n            queries = data.get(\"queries\", [])\n            gaps = []\n            for query in queries:\n                print(\"开始将返回内容格式化为query\")\n                if isinstance(query, dict):\n                    # 按字段顺序拼成 \"key1:value1 key2:value2 ...\"\n                    fields = [f\"{k}:{str(v)}\" for k, v in query.items() if str(v).strip()]\n                    if fields:\n                        gaps.append(\" \".join(fields))\n                        print(\"gaps已经成功append\")\n                        print(fields)\n            return gaps\n        except Exception as e:\n            print(\"解析失败:\", e)\n            return [global_question]\n\n    #由run方法中串行调用，利用executor搜索单个gap\n    # async def search_gap(self, gap: str) -> dict:\n    #     #print(\"search_gap 搜索问题 运行到了\")\n    #     # 1. 构造一个step\n    #     # step = Step(\n    #     #     id=\"search_gap\",\n    #     #     description=f\"请使用搜索工具检索以下内容：{gap}\",\n    #     #     status=ExecutionStatus.PENDING\n    #     # )\n    #     step = Step(\n    #         id=\"search_gap\",\n    #         description=(\n    #             f\"You have access to all available tools, including search engines, web browsers, code execution, and multimedia analysis.\"\n    #             f\"\\nPlease select the most appropriate tool(s) to solve the following sub-question. \"\n    #             f\"Actively call the needed tools, integrate their output, and provide a clear answer.\"\n    #             f\"If you encounter a question that needs reading files(pdf/word/txt) to obtain the answer, you should try to download the file from the internet for more accurate answers.\"\n    #             f\"If you are required to find answers from related essays, articles or books, you should download them and check the file by reading them locally.\"\n    #             f\"In most conditions, searching information about content of an article/book/essay is not a good idea, not much information can be found online, download and read the file if needed.\"\n    #             f\"\\nSub-question: {gap}\"\n    #         ),\n    #         status=ExecutionStatus.PENDING\n    #     )\n    #\n    #     # 2. 构造一个最小Plan\n    #     plan = Plan(\n    #         id=\"search_gap_plan\",\n    #         title=\"Search Gap Task\",\n    #         goal=gap,\n    #         steps=[step]\n    #     )\n    #     all_messages = []\n    #     final_result = None\n    #     final_error = None\n    #\n    #     # 3. 调用executor执行，因后端executor较为标准，暂时使用，后期会针对此处使用的特定工具进行优化\n    #     async for event in self.executor.execute_step(plan, step, gap):\n    #         if hasattr(event, \"message\"):\n    #             all_messages.append(event.message)\n    #         if isinstance(event, StepCompletedEvent):\n    #             # 把最终 result 也放到 messages 最后\n    #             all_messages.append(event.step.result)\n    #             return {\"gap\": gap, \"result\": all_messages}\n    #         elif isinstance(event, StepFailedEvent):\n    #             # 错误处理\n    #             all_messages.append(event.step.error)\n    #             return {\"gap\": gap, \"result\": all_messages}\n    #\n    #\n    #     # 4. fallback，兜底\n    #     #print(\"如果gap no result found，以下会被打印：\")\n    #     #print(f\"[DEBUG][search_gap] gap: {gap} No result found.\") #test\n    #     # return {\"gap\": gap, \"error\": \"No result\"}\n    #     all_messages.append(\"No result\")\n    #     return {\"gap\": gap, \"result\": all_messages}\n\n    async def search_gap(self, gap: str, global_question: str = None) -> dict:\n        print(\"search_gap被调用\")\n        # 1. 知识库标准化并装入prompt\n        knowledge_text = \"\"\n        if self.knowledge:\n            knowledge_text = \"\\n\".join(\n                f\"Sub-question: {item.get('gap', '')}\\nContent: {item.get('summary', '')}\"\n                for item in self.knowledge\n            )\n\n        #局域prompt存储\n        prompt_parts = []\n\n        # =知识库相关prompt\n        if knowledge_text:\n            prompt_parts.append(\n                \"---- KNOWLEDGE BASE ----\\n\"\n                \"Below is the current knowledge base collected from previous sub-questions. \"\n                \"You MUST use this information to answer the current sub-question if possible. \"\n                \"If the knowledge base already contains a clear answer, you should directly summarize or reuse it. \"\n                \"Only use external tools/search if the knowledge base is insufficient.\\n\"\n                f\"{knowledge_text}\\n\"\n            )\n        else:\n            prompt_parts.append(\n                \"---- KNOWLEDGE BASE ----\\n\"\n                \"The knowledge base is currently empty. You may need to use available tools to answer the sub-question.\\n\"\n            )\n        #print(f'知识库部分：{prompt_parts}')\n\n        #关于search_flow所需的特别的executor的prompt\n        execution_prompt=prompt.EXECUTION_DESCRIPTION_PROMPT.format(\n            gap=gap\n        )\n        prompt_parts.append(execution_prompt)\n\n        #来自execution.py，专门用来向executor解释他的能力\n        current_time = datetime.now()  # 当前本地时间，类型为datetime对象\n        system_prompt = prompt.EXECUTION_SYSTEM_PROMPT.format(\n            cur_time=current_time.isoformat()\n        )\n        prompt_parts.append(system_prompt)\n\n        full_prompt = \"\\n\".join(prompt_parts)\n\n        # 3. Compose Step with new prompt\n        step = Step(\n            id=\"search_gap\",\n            description=full_prompt,\n            status=ExecutionStatus.PENDING\n        )\n\n        #2构造一个最小Plan\n        plan = Plan(\n            id=\"search_gap_plan\",\n            title=\"Search Gap Task\",\n            goal=gap,\n            steps=[step]\n        )\n        all_messages = []\n        final_result = None\n        final_error = None\n\n        # 3. 调用executor执行，因后端executor较为标准，暂时使用，后期会针对此处使用的特定工具进行优化\n        print(\"prompt制作完成，开始调用executor\")\n        async for event in self.executor.execute_step(plan, step, gap):\n            if hasattr(event, \"message\"):\n                all_messages.append(event.message)\n                print(\"获取到了message\")\n            if isinstance(event, StepCompletedEvent):\n                # 把最终 result 也放到 messages 最后\n                all_messages.append(event.step.result)\n                print(\"获取到了StepCompletedEvent\")\n                return {\"gap\": gap, \"result\": all_messages}\n            elif isinstance(event, StepFailedEvent):\n                # 错误处理\n                all_messages.append(event.step.error)\n                print(\"获取到了StepFailedEvent\")\n                return {\"gap\": gap, \"result\": all_messages}\n\n        # 4. fallback，兜底\n        print(\"如果gap no result found，以下会被打印：\")\n        # print(f\"[DEBUG][search_gap] gap: {gap} No result found.\") #test\n        # return {\"gap\": gap, \"error\": \"No result\"}\n        all_messages.append(\"No result\")\n        return {\"gap\": gap, \"result\": all_messages}\n\n\n    #为gap执行结果打分，打分为boolean值\n    async def score_gap(self, gap: str, result: dict, eval_types: list = None) -> (bool, str):\n\n        #print(\"score_gap 评价结果 运行到了\")\n        \"\"\"\n        判断搜索结果是否满足gap问题，返回(bool, summary)\n        \"\"\"\n\n        #这里改为根据eval_types选择prompt\n        #遍历eval_types，检查是否每个eval_type都通过\n        satisfied=True\n        reason=\"\"\n        for eval_type in eval_types:\n            eval_type=eval_type\n            question=gap\n            answer_action=result.get('result', '')[:1000]\n            relevant_knowledge=[\"none\"]\n            system_prompt, user_prompt = self._get_prompts(\n                eval_type, question, answer_action, relevant_knowledge\n            )\n\n            messages = [\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt},\n            ]\n            #print(f'为gap评分时的message{messages}')\n            response = await self.llm.ask(messages)\n            #print(response.content)\n            # print(\"score_gap debug内容\")\n            # print(response) #test\n            try:\n                data = json.loads(response.content)\n                passed = data.get(\"pass\", False)\n                if not passed:\n                    satisfied=False\n                reason = reason+data.get(\"think\", \"\")\n            except Exception as e:\n                # 解析失败时降级为“不满足”，并输出原始内容\n                satisfied=False\n                reason=reason+f\"LLM判分输出无法解析，原始内容：{getattr(response, 'content', '')}\"\n        #print(f'satisfied: {satisfied}, reason: {reason}, gap{gap}')\n        return satisfied, reason\n\n\n    def _get_prompts(\n        self,\n        eval_type: str,\n        question: str,\n        answer_action: str,\n        knowledge: List[str],\n    ) -> tuple[str, str]:\n        \"\"\"获取评估类型的提示词模板\"\"\"\n        if eval_type == \"strict\":\n            system_prompt = prompt.REJECT_ALL_ANSWERS_PROMPT_SYSTEM.format(\n                knowledge_str=\"\\n\".join(knowledge)\n            )\n            user_prompt = prompt.REJECT_ALL_ANSWERS_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"definitive\":\n            system_prompt = prompt.DEFEINITE_PROMPT_SYSTEM\n            user_prompt = prompt.DEFEINITE_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"freshness\":\n            system_prompt = prompt.FRESHNESS_PROMPT_SYSTEM.format(\n                currentTime=datetime.now().isoformat()\n            )\n            user_prompt = prompt.FRESHNESS_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"completeness\":\n            system_prompt = prompt.COMPLETENESS_PROMPT_SYSTEM\n            user_prompt = prompt.COMPLETENESS_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"plurality\":\n            system_prompt = prompt.PLURALITY_PROMPT_SYSTEM\n            user_prompt = prompt.PLURALITY_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"basic\":\n            system_prompt = prompt.BASIC_PROMPT_SYSTEM\n            user_prompt = prompt.BASIC_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"file\":\n            system_prompt = prompt.FILE_PROMPT_SYSTEM\n            user_prompt = prompt.FILE_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        else:\n            raise ValueError(f\"未知的评估类型: {eval_type}\")\n\n        return system_prompt, user_prompt\n\n\n    #analyze分析本次gap执行错误的原因\n    async def analyze_gap(self, gap: str, result: dict, reason:str) -> str:\n        #print(\"analyze_gap 分析失败原因 运行到了\")\n        \"\"\"\n        分析gap未被解决的原因，返回分析文本\n        \"\"\"\n        prompt = f\"\"\"\n    你是一个问题诊断专家。现在有一个子问题未能通过已有搜索内容得到解答，请分析原因，并用一句话简明扼要地说明。不要输出多余内容。\n\n    子问题：{gap}\n    搜索内容：{result.get('result', '')[:1000]}\n    对该子问题未成功解决的简单分析{reason}\n    未解决原因：\n    \"\"\"\n        messages = [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        #print(f'分析问题失败原因的message{messages}')\n        response = await self.llm.ask(messages)\n        # 直接返回 LLM 输出内容\n        return getattr(response, \"content\", \"\").strip()\n\n    #reflect负责根据失败原因提供新的gap\n    async def reflect_gap(self, gap: str, error_reason: str) -> list[str]:\n        \"\"\"\n        用LLM结合gap和失败原因，生成新的gap（子问题）或改进的检索表达。\n        \"\"\"\n        #print(\"运行到反射错误问题！！！！！！！！！！！！！！！！！！！！！！！！！！！！\")\n\n        current_time = datetime.now()  # 当前本地时间，类型为datetime对象\n        current_year = current_time.year  # 当前年份，整数\n        current_month = current_time.month\n\n        system_prompt = prompt.QUERY_REWRITE_PROMPT_SYSTEM.format(\n            currentTime=current_time.isoformat(),\n            currentYear=current_year,\n            currentMonth=current_month\n        )\n        user_message = prompt.QUERY_REWRITE_PROMPT_USER.format(\n            query=gap,\n            think=\"分析用户搜索意图，生成更精确的查询\",\n            context=error_reason\n        )\n        messages = [\n            {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + user_message},\n        ]\n        #print(f'反射新gap的message{messages}')\n        response = await self.llm.ask(messages)\n        print(\"成功获取llm返回的新gaps，raw\")\n        print(response.content)\n        try:\n            data = json.loads(response.content)\n            queries = data.get(\"queries\", [])\n            gaps = []\n            for query in queries:\n                print(\"开始将返回内容格式化为query\")\n                if isinstance(query, dict):\n                    # 按字段顺序拼成 \"key1:value1 key2:value2 ...\"\n                    fields = [f\"{k}:{str(v)}\" for k, v in query.items() if str(v).strip()]\n                    if fields:\n                        gaps.append(\" \".join(fields))\n                        print(\"gaps已经成功append\")\n                        print(fields)\n            return gaps\n        except Exception as e:\n            print(\"解析失败:\", e)\n            return []\n\n    #reflect batch负责一整轮gap结束后的反思以及提供新gap，实现一个简单的没有plan的递进\n    async def reflect_gap_batch(self, failed_gaps_info: list[dict]) -> list[str]:\n        \"\"\"\n        批量反射：输入多组gap及分析，生成新gap列表\n        \"\"\"\n        current_time = datetime.now()\n        prompt_lines = []\n        for i, info in enumerate(failed_gaps_info, 1):\n            prompt_lines.append(\n                f\"{i}. 子问题: {info['gap']}\\n失败原因: {info['error_reason']}\\n执行器内容: {self.format_search_result(info['executor_result'])}\\n\"\n            )\n        prompt_str = \"\\n\".join(prompt_lines) #本轮子问题以及失败原因，用于生成新gap\n        system_prompt = prompt.QUERY_REWRITE_PROMPT_SYSTEM.format(\n            currentTime=current_time.isoformat(),\n            currentYear=current_time.year,\n            currentMonth=current_time.month\n        )\n        user_message = prompt.QUERY_REWRITE_PROMPT_USER.format(\n            query_group=prompt_str,\n        )\n        #user_message = f\"以下是本轮未解决的子问题、失败原因和相关内容，请针对每个子问题，结合失败原因给出更精确、可直接搜索的新子问题表达，输出如下格式JSON：\\n{{\\n  \\\"queries\\\": [\\\"新子问题1\\\", \\\"新子问题2\\\", ...]\\n}}\\n\\n{prompt_str}\"\n        messages = [\n            {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + user_message},\n        ]\n        response = await self.llm.ask(messages)\n        try:\n            data = json.loads(response.content)\n            return [str(q).strip() for q in data.get(\"queries\", []) if q]\n        except Exception as e:\n            print(\"批量reflect解析失败:\", e)\n            return []\n\n\n    #为避免出现过于相似或者重复的gap，generate后使用filter去重\n    def _filter_and_update_gaps(self, gaps, new_gaps=None):\n        #print(\"过滤更新 运行到了\")\n        \"\"\"\n        对gaps去重，并更新已处理过的gaps集合。\n        如果提供了new_gaps，则只处理new_gaps，否则处理gaps。\n        返回未被处理过的新gap列表。\n        \"\"\"\n        target_gaps = new_gaps if new_gaps is not None else gaps\n        filtered = [g for g in target_gaps if g not in self.processed_gaps]\n        self.processed_gaps.update(filtered)\n        return filtered\n\n    #此处规范化result，保证知识库内信息不为空\n    def format_search_result(self, result: dict) -> str:\n        #print(\"格式化结果 运行到了\")\n        \"\"\"\n        泛用型，将搜索结果dict转为可读文本。\n        1. 如果是字符串，直接返回；\n        2. 如果是列表，则递归格式化每项，合并输出；\n        3. 如果是dict，尝试读取常见字段，如title、content、summary等，并递归格式化；\n        4. 如果有error，则优先返回error文本；\n        5. 其它类型，直接转字符串。\n        \"\"\"\n        if not result:\n            return \"（无搜索结果）\"\n        if isinstance(result, str):\n            return result.strip()\n        if isinstance(result, list):\n            # 多条结果，递归格式化每条\n            return \"\\n\".join(self.format_search_result(item) for item in result)\n        if isinstance(result, dict):\n            if \"error\" in result and result[\"error\"]:\n                return f\"查询失败：{result['error']}\"\n            # 优先展示result字段\n            if \"result\" in result:\n                # result字段本身可能是字符串、dict或list\n                return self.format_search_result(result[\"result\"])\n            # 常见内容字段\n            text_pieces = []\n            for key in (\"title\", \"question\", \"summary\", \"content\", \"description\", \"answer\"):\n                if key in result and result[key]:\n                    text_pieces.append(str(result[key]).strip())\n            # 其它字段也拼一下\n            other_keys = [k for k in result if\n                          k not in (\"title\", \"question\", \"summary\", \"content\", \"description\", \"answer\", \"error\",\n                                    \"result\") and result[k]]\n            for k in other_keys:\n                text_pieces.append(f\"{k}: {result[k]}\")\n            if text_pieces:\n                return \"\\n\".join(text_pieces)\n            # 如果没有可用字段，直接输出dict\n            return str(result)\n        # 其它类型\n        return str(result)\n\n    #最后一步，生成最终报告\n    async def generate_final_answer(self, global_question: str, knowledge: list[dict]) -> (str, bool):\n        print(\"生成最终答案 运行到了\")\n        \"\"\"\n        用LLM综合知识库和global question生成最终答案，并判断是否还需补充信息。\n        返回：(最终答案, 需补充True/False)\n        \"\"\"\n        # 将知识库内容整理成可阅读的字符串\n        knowledge_text = \"\\n\\n\".join(\n            f\"【子问题】：{item.get('gap', '')}\\n【内容】：{item.get('summary', '')}\" for item in knowledge\n        )\n\n        prompt = f\"\"\"\n    你现在是一位专业问答助手。请根据下方已收集的知识点，回答全局问题。\n    如果你认为已有知识完全可以支持准确回答，请给出最终答案，并标记\"need_more\"为false；如果你认为知识还不够，无法回答或有重大遗漏，请标记\"need_more\"为true，并简要说明原因。\n    只允许输出如下JSON格式（不要有任何其他内容）：\n\n    {{\n      \"answer\": \"最终答案内容\",\n      \"need_more\": true/false,\n      \"reason\": \"如需补充知识，说明原因，否则可省略\"\n    }}\n\n    全局问题：{global_question}\n\n    知识库内容：\n    {knowledge_text}\n    \"\"\"\n        messages = [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        #print(f'最终答案生成message{messages}')\n        response = await self.llm.ask(messages)\n        try:\n            data = json.loads(response.content)\n            answer = data.get(\"answer\", \"\").strip()\n            need_more = bool(data.get(\"need_more\", False))\n            print(\"最终答案生成成功\")\n            return answer, need_more\n        except Exception:\n            # 解析失败时降级为“无法回答，需补充”\n            return \"（无法解析LLM的回答，请补充知识）\", True\n\n    # ========== 可选 summary/report 接口 ==========\n    # 两个方法视情况使用，目前在代码中并未用到\n\n    async def summarize_execution(self) -> AsyncGenerator[AgentEvent, None]:\n        yield MessageEvent(message=\"搜索流程执行总结\")\n        # 可以输出 self.knowledge 等\n\n    async def generate_report(self) -> AsyncGenerator[AgentEvent, None]:\n        yield MessageEvent(message=\"搜索流程最终报告\")\n",
      "methods": [
        "<module>.SearchFlow.__init__",
        "<module>.SearchFlow.is_idle",
        "<module>.SearchFlow.run",
        "<module>.SearchFlow.select_scoring_mode",
        "<module>.SearchFlow.generate_gaps",
        "<module>.SearchFlow.search_gap",
        "<module>.SearchFlow.score_gap",
        "<module>.SearchFlow._get_prompts",
        "<module>.SearchFlow.analyze_gap",
        "<module>.SearchFlow.reflect_gap",
        "<module>.SearchFlow.reflect_gap_batch",
        "<module>.SearchFlow._filter_and_update_gaps",
        "<module>.SearchFlow.format_search_result",
        "<module>.SearchFlow.generate_final_answer",
        "<module>.SearchFlow.summarize_execution",
        "<module>.SearchFlow.generate_report"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/code_flow.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/code_flow.py",
      "name": "CodeFlow",
      "qualname": "<module>.CodeFlow",
      "source": "class CodeFlow(BaseSubFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"code\"\n    description = \"子计划规划流程：先创建子计划，然后逐步执行，支持动态更新子计划\"\n    \n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Enum = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_flow_logger = setup_sub_planner_flow_logger(f\"sub_planner_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_flow_logger.info(f\"=== CodeFlow初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        self.sub_planner_flow_logger.info(f\"=== CodeFlow.__init__ 开始 ===\")\n        self.sub_planner_flow_logger.info(f\"接收到的参数:\")\n        self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n        self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n        self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n        self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n        self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.execution_result=Memory()\n        if task_type:\n            self.sub_planner_flow_logger.info(f\"task_type.value: {task_type.value}\")\n            self.sub_planner_flow_logger.info(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 调用父类构造函数\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        \n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        self.sub_planner_flow_logger.info(f\"=== 开始创建SubPlannerAgent ===\")\n        \n        try:\n            # 创建子规划器代理\n            self.sub_planner_flow_logger.info(f\"准备创建SubPlannerAgent，参数:\")\n            self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n            self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n            self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n            self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n            self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n            \n            self.sub_planner = SubPlannerAgent(\n                llm=llm,\n                task_type=task_type,\n                memory=Memory(),\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n            )\n            self.sub_planner.system_prompt = PromptManager.get_system_prompt_with_tools(self.sub_planner.tools, is_executor=False, is_code=True)\n            self.sub_planner.system_prompt = PromptManager.insert_datetime(self.sub_planner.system_prompt)\n            self.sub_planner_flow_logger.info(\"创建SubPlanner Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建SubPlannerAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        try:\n            self.sub_planner_flow_logger.info(f\"=== 开始创建ExecutionAgent ===\")\n            # 创建执行代理\n            self.executor = ExecutionAgent(\n                memory=Memory(),\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                type_value=task_type.value\n            )\n            \n            self.sub_planner_flow_logger.info(\"创建Execution Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建ExecutionAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    async def run(\n        self,\n        parent_plan: Plan,\n        parent_step: Step,\n        parent_memory: Memory,\n        task_type: Enum\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行子计划流程\n        \n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n        \"\"\"\n        \n        self.sub_planner.fix(parent_plan,parent_step)\n\n        self.sub_planner_flow_logger.info(f\"=== 开始执行子计划 ===\")\n        self.sub_planner_flow_logger.info(f\"父计划ID: {parent_plan.id}\")\n        self.sub_planner_flow_logger.info(f\"父步骤ID: {parent_step.id}\")\n        self.sub_planner_flow_logger.info(f\"任务类型: {task_type.value}\")\n        \n        # 根据传入的task_type更新提示词\n        self.sub_planner_flow_logger.info(f\"=== 开始更新系统提示词 ===\")\n        \n        try:\n            updated_system_prompt = self.sub_planner.system_prompt\n            updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n            updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n            self.sub_planner.system_prompt = PromptManager.insert_datetime(updated_system_prompt)\n            # Debug: print\n            # TODO: remove this\n            self.sub_planner_flow_logger.info(f\"updated_system_prompt: {updated_system_prompt}\")\n            \n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"更新系统提示词失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            # 继续执行，不因为提示词更新失败而中断整个流程\n            \n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.sub_planner.roll_back()\n            self.executor.roll_back()\n            self.sub_planner_flow_logger.info(\"中断当前流程，重新开始规划\")\n\n        # 使用父步骤的描述作为输入消息\n        message = parent_step.description\n        logger.info(f\"开始处理步骤: {message[:50]}...\")\n        \n        # 创建子计划\n        self.status = AgentStatus.PLANNING\n        self.sub_planner_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n        \n        \n        async for event in self.sub_planner.create_plan(message):\n            \n            if isinstance(event, PlanCreatedEvent):\n                self.plan = event.plan\n                logger.info(f\"创建子计划成功，包含 {len(event.plan.steps)} 个步骤\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划创建成功 ===\")\n                self.sub_planner_flow_logger.info(f\"子计划ID: {event.plan.id}\")\n                self.sub_planner_flow_logger.info(f\"子计划目标: {event.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"子计划标题: {event.plan.title}\")\n                self.sub_planner_flow_logger.info(f\"子计划步骤数量: {len(event.plan.steps)}\")\n                for i, step in enumerate(event.plan.steps, 1):\n                    self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}\")\n                if event.plan.message:\n                    self.sub_planner_flow_logger.info(f\"子计划说明: {event.plan.message}\")\n            elif isinstance(event, MessageEvent):\n                self.sub_planner_flow_logger.info(f\"Planner输出: {event.message}\")\n            yield event\n            \n        self.status = AgentStatus.EXECUTING\n        self.sub_planner_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n        \n        # 执行子计划\n        while True:\n            if self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"子计划执行完成，状态变更: EXECUTING -> REPORTING\")\n                    self.status = AgentStatus.REPORTING\n                    self.sub_planner_flow_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                \n                # 执行步骤\n                logger.info(f\"开始执行步骤 {step.id}: {step.description[:50]}...\")\n                self.sub_planner_flow_logger.info(f\"=== 开始执行步骤 ===\")\n                self.sub_planner_flow_logger.info(f\"步骤ID: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤描述: {step.description}\")\n                self.sub_planner_flow_logger.info(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    \n                    updated_system_prompt = self.executor.system_prompt\n                    updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.executor.shell_tool)\n                    updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.executor.memory)\n                    \n                    self.executor.system_prompt = updated_system_prompt\n                    if isinstance(event, ToolCallingEvent):\n                        self.sub_planner_flow_logger.info(f\"工具调用: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.sub_planner_flow_logger.info(f\"工具结果: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.sub_planner_flow_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"Executor输出: {event.message}\")\n                        # 将执行结果保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n                        \n                logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                self.sub_planner_flow_logger.info(f\"步骤执行完成: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.sub_planner_flow_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.sub_planner_flow_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.sub_planner_flow_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为\n                self.sub_planner_flow_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    yield event\n                    if isinstance(event, MessageEvent):\n                        logger.info(f\"步骤总结完成: {event.message}\")\n                        previous_steps = event.message\n                        self.sub_planner_flow_logger.info(f\"步骤总结完成: {event.message}\")\n                        # 将总结保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                        \n                # 更新计划\n                self.sub_planner_flow_logger.info(f\"=== 开始更新子计划 ===\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                updated_system_prompt = self.sub_planner.system_prompt\n                updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n                updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n                \n                self.sub_planner.system_prompt = updated_system_prompt\n                async for event in self.sub_planner.update_plan(self.plan, previous_steps):\n                    \n                    updated_system_prompt = self.sub_planner.system_prompt\n                    updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n                    updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n                    self.sub_planner.system_prompt = updated_system_prompt\n                    \n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.sub_planner_flow_logger.info(f\"=== 子计划更新完成 ===\")\n                        self.sub_planner_flow_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 将更新信息保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                    yield event\n\n                logger.info(f\"子计划更新完成，状态变更: UPDATING -> EXECUTING\")\n                self.status = AgentStatus.EXECUTING\n                self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"子计划执行完成，准备生成报告\")\n                self.sub_planner_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                async for event in self.executor.report_result(message):\n                    if isinstance(event, MessageEvent):\n                        # 将报告保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n\n                yield ReportEvent(message=str(self.execution_result.get_messages()))\n                self.status = AgentStatus.COMPLETED\n                self.sub_planner_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"子计划执行完成\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划执行完成 ===\")\n                self.sub_planner_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan,issubplan=True) \n                self.status = AgentStatus.IDLE\n                self.sub_planner_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n                \n        #yield DoneEvent()\n        \"\"\"需要声明另一种doneevent\"\"\"\n\n        \n        logger.info(f\"子计划处理完成\")\n        self.sub_planner_flow_logger.info(f\"=== 子计划处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.CodeFlow.__init__",
        "<module>.CodeFlow.run",
        "<module>.CodeFlow.is_idle",
        "<module>.CodeFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/factory.py",
      "name": "FlowFactory",
      "qualname": "<module>.FlowFactory",
      "source": "class FlowFactory:\n    \"\"\"Flow工厂类,负责管理和创建不同类型的flow\"\"\"\n    \n    def __init__(self):\n        # 注册所有可用的flow类型\n        self._flow_classes: Dict[str, Type[BaseFlow]] = {}\n        self._register_default_flows()\n    \n    def _register_default_flows(self):\n        \"\"\"注册默认的flow类型\"\"\"\n        self.register_flow(PlanActFlow)\n        self.register_flow(SimpleChatFlow)\n        # 延迟导入 SuperPlannerFlow 以避免循环导入\n        from app.domain.services.flows.super_flow import SuperFlow\n        self.register_flow(SuperFlow)\n        logger.info(\"已注册默认flow类型\")\n    \n    def register_flow(self, flow_class: Type[BaseFlow]) -> None:\n        \"\"\"注册新的flow类型\"\"\"\n        if not issubclass(flow_class, BaseFlow):\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须继承自BaseFlow\")\n        \n        flow_id = flow_class.get_flow_id()\n        if not flow_id:\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须定义flow_id\")\n        \n        if flow_id in self._flow_classes:\n            logger.warning(f\"Flow ID '{flow_id}' 已存在，将被覆盖\")\n        \n        self._flow_classes[flow_id] = flow_class\n        logger.info(f\"已注册flow类型: {flow_id} -> {flow_class.__name__}\")\n    \n    def create_flow(self, flow_id: str, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, \n                   browser: Browser, search_engine: Optional[SearchEngine] = None, \n                   **kwargs) -> BaseFlow:\n        \"\"\"根据flow_id创建对应的flow实例\"\"\"\n    \n        \n        if flow_id not in self._flow_classes:\n            available_flows = list(self._flow_classes.keys())\n            raise ValueError(f\"未知的flow类型: {flow_id}. 可用类型: {available_flows}\")\n        \n        flow_class = self._flow_classes[flow_id]\n        \n        try:\n            # 创建flow实例，传递所有必要的参数\n            flow_instance = flow_class(\n                agent=agent,\n                llm=llm,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                **kwargs\n            )\n            logger.info(f\"成功创建flow实例: {flow_id} for Agent {agent.id}\")\n            return flow_instance\n        except Exception as e:\n            logger.error(f\"创建flow实例失败: {flow_id}, 错误: {str(e)}\")\n            raise\n    \n    def get_available_flows(self) -> List[Dict[str, str]]:\n        \"\"\"获取所有可用的flow类型信息\"\"\"\n        flows = []\n        for flow_id, flow_class in self._flow_classes.items():\n            flows.append({\n                \"flow_id\": flow_id,\n                \"name\": flow_class.__name__,\n                \"description\": flow_class.get_description()\n            })\n        return flows\n    \n    def has_flow(self, flow_id: str) -> bool:\n        \"\"\"检查是否存在指定的flow类型\"\"\"\n        return flow_id in self._flow_classes\n    \n    def get_flow_class(self, flow_id: str) -> Optional[Type[BaseFlow]]:\n        \"\"\"获取指定flow_id对应的flow类\"\"\"\n        return self._flow_classes.get(flow_id)\n",
      "methods": [
        "<module>.FlowFactory.__init__",
        "<module>.FlowFactory._register_default_flows",
        "<module>.FlowFactory.register_flow",
        "<module>.FlowFactory.create_flow",
        "<module>.FlowFactory.get_available_flows",
        "<module>.FlowFactory.has_flow",
        "<module>.FlowFactory.get_flow_class"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/factory.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(Enum):\n    CODE = \"code\"\n    REASONING = \"reasoning\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/factory.py",
      "name": "SubFlowFactory",
      "qualname": "<module>.SubFlowFactory",
      "source": "class SubFlowFactory:\n    \"\"\"\n    子流程工厂类\n    负责创建和管理所有子流程实例\n    \"\"\"\n    \n    def __init__(self):\n        # 注册所有可用的子流程类型\n        self._flow_classes: Dict[str, Type[BaseSubFlow]] = {}\n        \n        # 设置专门的日志记录器\n        self.factory_logger = setup_sub_planner_flow_logger(\"SubFlowFactory\")\n        self.factory_logger.info(f\"=== SubFlowFactory初始化 ===\")\n        \n        # 注册默认流程\n        self._register_default_flows()\n    \n    def _register_default_flows(self):\n        \"\"\"注册默认的子流程类型\"\"\"\n        self.register_flow(DefaultFlow)\n        self.register_flow(SearchFlow)\n        self.register_flow(CodeFlow)\n        self.factory_logger.info(\"已注册默认子流程类型\")\n    \n    def register_flow(self, flow_class: Type[BaseSubFlow]) -> None:\n        \"\"\"注册新的子流程类型\"\"\"\n        if not issubclass(flow_class, BaseSubFlow):\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须继承自BaseSubFlow\")\n        \n        flow_id = flow_class.get_flow_id()\n        if not flow_id:\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须定义flow_id\")\n        \n        if flow_id in self._flow_classes:\n            self.factory_logger.warning(f\"Flow ID '{flow_id}' 已存在，将被覆盖\")\n        \n        self._flow_classes[flow_id] = flow_class\n        self.factory_logger.info(f\"已注册子流程类型: {flow_id} -> {flow_class.__name__}\")\n    \n    def create_flow(self,\n                    llm: LLM,\n                    task_type: Enum,\n                    sandbox: Sandbox,\n                    browser: Browser,\n                    search_engine: Optional[SearchEngine] = None,\n                    audio_llm: Optional[AudioLLM] = None,\n                    image_llm: Optional[ImageLLM] = None,\n                    video_llm: Optional[VideoLLM] = None,\n                    reason_llm: Optional[ReasonLLM] = None,\n                    ) -> BaseSubFlow:\n        \"\"\"根据任务类型创建对应的子流程实例\"\"\"\n        # 添加详细的调试日志\n        self.factory_logger.info(f\"=== create_flow 开始 ===\")\n        self.factory_logger.debug(f\"task_type 参数: {task_type}\")\n        self.factory_logger.debug(f\"task_type 类型: {type(task_type)}\")\n        self.factory_logger.debug(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 获取实际的 flow_type\n        flow_type = task_type.value\n       # self.factory_logger.info(f\"flow_type: {flow_type}\")\n      #  self.factory_logger.debug(f\"可用的flow类型: {list(self._flow_classes.keys())}\")\n            \n        # 重定向逻辑：所有 -> general sub flow\n        if flow_type == \"search\":\n            self.factory_logger.info(f\"flow_type {flow_type} 不重定向\")\n        elif flow_type == \"code\":\n            self.factory_logger.info(f\"flow_type {flow_type} 不重定向 \")\n        elif flow_type == \"file\":\n            self.factory_logger.info(f\"flow_type {flow_type} 重定向到general_flow\")\n            flow_type = \"default\"\n        elif flow_type == 'reasoning':\n            self.factory_logger.info(f\"flow_type {flow_type} 重定向到general_flow\")\n            flow_type = \"default\"\n        else:\n            available_flows = list(self._flow_classes.keys())\n            self.factory_logger.error(f\"未知的子流程类型: {flow_type}. 可用类型: {available_flows}\")\n            raise ValueError(f\"未知的子流程类型: {flow_type}. 可用类型: {available_flows}\")\n        \n        flow_class = self._flow_classes[flow_type]\n        self.factory_logger.debug(f\"选择的flow_class: {flow_class}\")\n        self.factory_logger.debug(f\"flow_class 类型: {type(flow_class)}\")\n        \n        try:\n            self.factory_logger.info(f\"=== 开始创建flow实例 ===\")\n            self.factory_logger.debug(f\"检查flow_class是否在预期列表中: {flow_class in [DefaultFlow, SearchFlow, CodeFlow]}\")\n            \n            # 针对不同子类传递不同参数\n            # self.factory_logger.debug(f\"使用完整参数创建flow实例\")\n            # self.factory_logger.debug(f\"传递的参数:\")\n            # self.factory_logger.debug(f\"llm: {llm}\")\n            # self.factory_logger.debug(f\"sandbox: {sandbox}\")\n            # self.factory_logger.debug(f\"browser: {browser}\")\n            # self.factory_logger.debug(f\"search_engine: {search_engine}\")\n            # self.factory_logger.debug(f\"task_type: {task_type} (类型: {type(task_type)})\")\n\n            flow_instance = flow_class(\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                task_type=task_type,\n            )\n            self.factory_logger.info(f\"成功创建子流程实例: {flow_type}\")\n            return flow_instance\n        except Exception as e:\n            self.factory_logger.error(f\"创建子流程实例失败: {flow_type}, 错误: {str(e)}\")\n            self.factory_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.factory_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n    \n    def get_available_flows(self) -> List[Dict[str, str]]:\n        \"\"\"获取所有可用的子流程类型信息\"\"\"\n        flows = []\n        for flow_id, flow_class in self._flow_classes.items():\n            flows.append({\n                \"flow_id\": flow_id,\n                \"name\": flow_class.__name__,\n                \"description\": flow_class.get_description()\n            })\n        return flows\n\n    def get_available_flows_enum(self,enum_name: str = \"SubPlannerType\") -> type[Enum]:\n        flows = self.get_available_flows()\n        # 构造枚举成员字典: { \"MESSAGE\": \"message\", ... }\n        enum_members = {}\n        for flow in flows:\n            raw_name = flow[\"name\"]\n            enum_key = raw_name.replace(\"Flow\", \"\").upper()\n            enum_value = flow[\"flow_id\"]\n            enum_members[enum_key] = enum_value\n\n        # 使用 type() + EnumMeta 创建类\n        return Enum(enum_name, enum_members)\n\n    def has_flow(self, flow_id: str) -> bool:\n        \"\"\"检查是否存在指定的子流程类型\"\"\"\n        return flow_id in self._flow_classes\n    \n    def get_flow_class(self, flow_id: str) -> Optional[Type[BaseSubFlow]]:\n        \"\"\"获取指定flow_id对应的子流程类\"\"\"\n        return self._flow_classes.get(flow_id)\n",
      "methods": [
        "<module>.SubFlowFactory.__init__",
        "<module>.SubFlowFactory._register_default_flows",
        "<module>.SubFlowFactory.register_flow",
        "<module>.SubFlowFactory.create_flow",
        "<module>.SubFlowFactory.get_available_flows",
        "<module>.SubFlowFactory.get_available_flows_enum",
        "<module>.SubFlowFactory.has_flow",
        "<module>.SubFlowFactory.get_flow_class"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/simple_chat.py",
      "name": "SimpleChatFlow",
      "qualname": "<module>.SimpleChatFlow",
      "source": "class SimpleChatFlow(BaseFlow):\n    \"\"\"简单聊天流程：直接与LLM对话，不进行计划和执行\"\"\"\n    \n    # 定义flow的唯一标识符\n    flow_id = \"simple_chat\"\n    description = \"简单聊天流程：直接与LLM对话，适用于简单的问答场景\"\n    \n    def __init__(self, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser, \n                 search_engine: Optional[SearchEngine] = None, **kwargs):\n        super().__init__(agent, **kwargs)\n        self.llm = llm\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self._is_idle = True\n        logger.debug(f\"Created SimpleChatFlow for Agent {self.agent.id}\")\n    \n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"执行简单聊天流程\"\"\"\n        self._is_idle = False\n        logger.info(f\"Agent {self.agent.id} started simple chat with message: {message[:50]}...\")\n        \n        try:\n            # 构建简单的提示词\n            prompt = f\"\"\"你是一个有用的AI助手。请回答用户的问题。\n\n用户问题: {message}\n\n请提供有用和准确的回答：\"\"\"\n            \n            # 调用LLM获取回复\n            response = await self.llm.ask(\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            # 发送回复事件\n            yield MessageEvent(message=response.content)\n            logger.info(f\"Agent {self.agent.id} completed simple chat response\")\n            \n        except Exception as e:\n            logger.error(f\"Agent {self.agent.id} simple chat failed: {str(e)}\")\n            yield MessageEvent(message=f\"抱歉，处理您的请求时出现错误：{str(e)}\")\n        \n        finally:\n            self._is_idle = True\n            yield DoneEvent()\n    \n    def is_idle(self) -> bool:\n        \"\"\"检查flow是否处于空闲状态\"\"\"\n        return self._is_idle ",
      "methods": [
        "<module>.SimpleChatFlow.__init__",
        "<module>.SimpleChatFlow.run",
        "<module>.SimpleChatFlow.is_idle"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/super_flow.py",
      "name": "FlowStatus",
      "qualname": "<module>.FlowStatus",
      "source": "class FlowStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/super_flow.py",
      "name": "SuperFlow",
      "qualname": "<module>.SuperFlow",
      "source": "class SuperFlow(BaseFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"TreeFLow\"\n    description = \"a flow that uses multiple planners to handle complex tasks\"\n\n    def __init__(self, agent: Agent, llm: LLM, sandbox: Sandbox, browser: Browser,\n                 search_engine: Optional[SearchEngine] = None, \n                 audio_llm: Optional[AudioLLM] = None,\n                 image_llm: Optional[ImageLLM] = None,\n                 video_llm: Optional[VideoLLM] = None,\n                 reason_llm: Optional[ReasonLLM] = None,\n                 **kwargs):\n        super().__init__(agent, **kwargs)\n        self.status = FlowStatus.IDLE\n\n        # 设置专门的日志记录器\n        self.super_flow_logger = setup_super_planner_flow_logger(\"SuperPlannerFlow\")\n        self.super_flow_logger.info(f\"=== SuperPlannerFlow初始化 Agent ID: {agent.id} ===\")\n\n        # 初始化可用的基础设施\n        self.llm = llm\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n\n        # 初始化planner memory\n        self.planner_memory = Memory()\n        # 初始化knowledge memory\n        self.knowledge = Memory()\n\n        # 创建 planer agent\n        self.planner_agent = PlannerAgent(\n            llm=llm,\n            memory = self.planner_memory,\n            knowledge=self.knowledge,\n        )\n        self.super_flow_logger.debug(f\"创建Planner Agent完成\")\n\n        self.report_agent = ReportAgent(\n            llm=llm,\n            memory = Memory(),\n            knowledge=self.knowledge,\n        )\n        self.super_flow_logger.debug(f\"创建Report Agent完成\")\n\n        # 创建 sub_flow_factory\n        from app.domain.services.flows.factory import sub_flow_factory\n        self.sub_flow_factory = sub_flow_factory\n        self.sub_flow_type = self.sub_flow_factory.get_available_flows_enum()\n\n        # 创建通知代理，通知用户进度\n        self.notifier = NotifyAgent(\n            llm=llm,\n            memory=Memory(),\n        )\n        self.super_flow_logger.debug(f\"创建Notify Agent完成\")\n\n        # 用于控制流和并发实现\n        # 按照并发组划分的sub planner\n        self.parallel_sub_flow_groups = None\n        # 记录使用过的sub planner\n        self.sub_flow_instance_used = []\n        # 管理活动的子规划器\n        self._active_sub_flow: Dict[str, BaseSubFlow] = {}\n        # 记录子规划器的执行历史\n        self._sub_flow_history: Dict[str, Dict] = {}\n\n\n    @staticmethod\n    def _determine_task_type(description: str) -> str:\n        \"\"\"\n        根据步骤描述确定流程类型\n        \"\"\"\n        description_lower = description.lower()\n        if any(cmd in description_lower for cmd in [\"run\", \"execute\", \"command\", \"shell\"]):\n            return \"code\"\n        elif any(cmd in description_lower for cmd in [\"browse\", \"visit\", \"web\", \"url\", \"search\", \"find\", \"lookup\"]):\n            return \"search\"\n        elif any(cmd in description_lower for cmd in [\"reason\", \"think\", \"analyze\", \"deduce\", \"infer\"]):\n            return \"reasoning\"\n        elif any(cmd in description_lower for cmd in [\"file\", \"document\", \"read\", \"write\", \"process\"]):\n            return \"file\"\n        else:\n            return \"search\" # 默认使用搜索流程\n\n\n    async def execute_step(self, step: Step) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行计划中的单个步骤\n        根据步骤类型创建对应的子流程并执行\n        \"\"\"\n        self.super_flow_logger.info(f\"执行子任务步骤 {step.id}: {step.description}\")\n        \n        # 确定任务类型\n        if step.sub_flow_type:\n            # 添加调试信息\n            self.super_flow_logger.debug(f\"step.sub_flow_type 类型: {type(step.sub_flow_type)}\")\n\n            # 标准化处理\n            if isinstance(step.sub_flow_type, str):\n                # 如果是字符串，转换为 SubPlannerType 枚举\n                task_type = self.sub_flow_type(step.sub_flow_type.lower())\n                self.super_flow_logger.debug(f\"字符串转换为枚举: {task_type}\")\n            else:\n                # 如果是枚举，直接使用\n                task_type = step.sub_flow_type\n                self.super_flow_logger.debug(f\"使用枚举: {task_type}\")\n\n            self.super_flow_logger.debug(f\"使用 SuperPlanner 指定的任务类型: {task_type}\")\n        else:\n            # 如果没有指定，才根据描述判断\n            task_type = self._determine_task_type(step.description)\n            self.super_flow_logger.debug(f\"根据描述推断的任务类型: {task_type}\")\n\n        # 创建新的子规划器 SubFlow\n        sub_flow = self.sub_flow_factory.create_flow(\n            llm=self.llm,\n            task_type=task_type,\n            sandbox=self.sandbox,\n            browser=self.browser,\n            search_engine=self.search_engine,\n            audio_llm=self.audio_llm,\n            image_llm=self.image_llm,\n            video_llm=self.video_llm,\n            reason_llm=self.reason_llm,\n        )\n\n        step.status = ExecutionStatus.RUNNING\n        yield StepStartedEvent(step=step, plan=self.plan)\n\n        try:\n            async for event in sub_flow.run(\n                parent_plan = self.plan,\n                parent_step = step,\n                parent_memory = self.knowledge,\n                task_type = task_type,\n            ):\n                # sub flow返回值处理 \n                if isinstance(event, ErrorEvent):\n                    step.status = ExecutionStatus.FAILED\n                    step.error = event.error\n                    yield StepFailedEvent(step=step, plan=self.plan)\n                    return\n\n                if isinstance(event, PauseEvent):\n                    yield event\n                    return\n\n                if isinstance(event, MessageEvent):\n                    step.status = ExecutionStatus.COMPLETED\n                    step.result = event.message\n                    yield StepCompletedEvent(step=step, plan=self.plan)\n                \n                # 只转发 ReportEvent，但转换为更简洁的消息\n                if isinstance(event, ReportEvent):\n                    yield MessageEvent(message=f\"✅ {step.description} - 完成\")\n                # 完全过滤掉实现细节：ToolCallingEvent, ToolCalledEvent, MessageEvent, \n                # PlanCreatedEvent, PlanUpdatedEvent, PlanCompletedEvent, DoneEvent\n                # ErrorEvent 和 PauseEvent 已在上面单独处理\n\n        except Exception as e:\n\n            step.status = ExecutionStatus.FAILED\n            step.error = str(e)\n            yield StepFailedEvent(step=step, plan=self.plan)\n            return\n\n        step.status = ExecutionStatus.COMPLETED\n\n\n    def _build_parallel_execution_groups(self) -> Optional[deque]:\n        # Concurrent Execution Groups\n        self.parallel_sub_flow_groups = []\n        prev_step = -1\n        for i in range(len(self.plan.steps)):\n            step = self.plan.steps[i]\n            try:\n                # 0. 跳过已完成或失败的步骤\n                if step.status in [ExecutionStatus.COMPLETED, ExecutionStatus.FAILED]:\n                    self.super_flow_logger.debug(\n                        f\"跳过已完成/失败的步骤 {step.id}: {step.description} (状态: {step.status})\")\n                    continue\n\n                # 1. 安全地处理 subplan_step 转换\n                if not step.sub_plan_step:\n                    self.super_flow_logger.error(f\"步骤 {step.id} 缺少 subplan_step 属性\")\n                    step.status = ExecutionStatus.FAILED\n                    step.error = \"Missing subplan_step attribute\"\n                    continue\n\n                try:\n                    cur_step = int(step.sub_plan_step)\n                except ValueError:\n                    self.super_flow_logger.error(\n                        f\"步骤 {step.id} 的 subplan_step 值 '{step.sub_plan_step}' 无法转换为整数\")\n                    step.status = ExecutionStatus.FAILED\n                    step.error = f\"Invalid subplan_step value: {step.sub_plan_step}\"\n                    continue\n\n                # 2. 检查步骤顺序\n                if cur_step < prev_step:\n                    error_msg = f\"步骤顺序错误：当前步骤 {step.id} (subplan_step={cur_step}) 小于前一步骤 (subplan_step={prev_step})\"\n                    self.super_flow_logger.error(error_msg)\n                    step.status = ExecutionStatus.FAILED\n                    step.error = error_msg\n                    continue\n\n                # 3. 正常的步骤处理逻辑\n                if cur_step > prev_step:\n                    # case 1: this step is a new step\n                    self.parallel_sub_flow_groups.append([step])\n                    prev_step = cur_step\n                elif cur_step == prev_step:\n                    # case 2: this step is the same step as the previous step\n                    self.parallel_sub_flow_groups[-1].append(step)\n\n            except Exception as e:\n                error_msg = f\"处理步骤 {step.id} 时发生错误: {str(e)}\"\n                self.super_flow_logger.error(error_msg)\n                step.status = ExecutionStatus.FAILED\n                step.error = error_msg\n                continue\n\n        self.parallel_sub_flow_groups = deque(self.parallel_sub_flow_groups)\n        self.super_flow_logger.info(\n            f\"构建了 {len(self.parallel_sub_flow_groups)} 个执行组，共 {sum(len(group) for group in self.parallel_sub_flow_groups)} 个待执行步骤\")\n\n\n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \n        self.super_flow_logger.info(f\"=== Super Flow开始处理用户消息 ===\")\n        self.super_flow_logger.info(f\"用户输入: {message}\")\n        step = None\n\n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = FlowStatus.PLANNING\n            self.planner_agent.roll_back()\n            self.report_agent.roll_back()\n            self.super_flow_logger.debug(\"中断当前流程，重新开始规划\")\n\n        while True:\n            if self.status == FlowStatus.IDLE:\n                self.status = FlowStatus.PLANNING\n                self.super_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n\n                # 通知用户开始规划\n                async for event in self.notifier.notify_received_message(message):\n                  \n                    if not isinstance(event, MessageEvent):\n                        yield event\n\n            elif self.status == FlowStatus.PLANNING:\n                # 创建计划\n                self.super_flow_logger.info(f\"=== Super Flow开始创建计划 ===\")\n             #   self.super_flow_logger.debug(f\"Super Planner输入: {message}\")\n\n                async for event in self.planner_agent.create_plan(message):\n                    if isinstance(event, PlanCreatedEvent):\n                        self.plan = event.plan\n                        self.super_flow_logger.info(f\"=== 计划创建成功 ===\")\n                        self.super_flow_logger.debug(f\"计划ID: {event.plan.id}\")\n                        self.super_flow_logger.info(f\"计划目标: {event.plan.goal}\")\n                        self.super_flow_logger.debug(f\"计划标题: {event.plan.title}\")\n                        self.super_flow_logger.debug(f\"计划步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            self.super_flow_logger.debug(f\"步骤{i}: [{step.id}] {step.description}\")\n                        if event.plan.message:\n                            self.super_flow_logger.info(f\"计划说明: {event.plan.message}\")\n                    elif isinstance(event, MessageEvent):\n                        self.super_flow_logger.warning(f\"Planner输出MessageEvent: {event.message}\")\n               #     yield event\n\n                # 创建计划完成后，准备执行步骤\n                if self.plan:\n                    self._build_parallel_execution_groups()\n                    # 检查是否有任何步骤可以执行,如果没有进入报告阶段\n                    if not self.parallel_sub_flow_groups:\n                        self.super_flow_logger.info(\"没有剩余的待执行步骤，进入报告阶段\")\n                        self.status = FlowStatus.REPORTING\n                        continue\n                    # 状态转换到执行阶段\n                    self.status = FlowStatus.EXECUTING\n                    self.super_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n\n            elif self.status == FlowStatus.EXECUTING:\n                self.plan.status = ExecutionStatus.RUNNING\n\n                if not self.parallel_sub_flow_groups:\n                    self.status = FlowStatus.REPORTING\n                    self.super_flow_logger.info(\"状态变更: EXECUTING -> REPORTING\")\n                    continue\n                # 并发处理\n                current_parallel_group = self.parallel_sub_flow_groups[0]  # 只查看，不弹出\n                self.super_flow_logger.info(f\"=== 开始执行步骤组（{len(current_parallel_group)}个步骤） ===\")\n                # 添加顺序执行逻辑\n                if current_parallel_group:  # 确保当前组还有步骤\n                    step = current_parallel_group.pop(0)  # 取出第一个步骤\n\n                    self.knowledge.add_message({\n                        'role': \"user\",\n                        'content': step.description\n                    })\n\n                    async for execute_event in self.execute_step(step=step):\n                        yield execute_event  # 传播 execute_step 内部过滤后的事件\n                        self.super_flow_logger.debug(f\"执行事件类型: {type(execute_event).__name__}\")\n\n                        if isinstance(execute_event, AgentEvent):\n                            event_type = type(execute_event).__name__\n                            self.super_flow_logger.debug(\"=\" * 50)\n                            self.super_flow_logger.debug(f\">>> 执行事件类型: {event_type} <<<\")\n                            self.super_flow_logger.debug(\"=\" * 50)\n\n                    self.knowledge.add_message({\n                        'role': \"assistant\",\n                        'content': step.result\n                    })\n\n                    self.knowledge.add_file(step.file)\n                    self.knowledge.add_web(step.web)\n\n                    # 每个步骤执行完后立即进入更新状态\n                    self.status = FlowStatus.UPDATING\n                    self.super_flow_logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                \n                # 并发处理，如果当前组为空，移除它\n                if not current_parallel_group:\n                    self.parallel_sub_flow_groups.popleft()  # 安全地移除空组\n\n            elif self.status == FlowStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                # 更新计划\n                logger.info(f\"Agent {self.agent.id} started updating plan\")\n                self.super_flow_logger.info(f\"=== 开始更新计划 ===\")\n                async for event in self.planner_agent.update_plan(plan=self.plan, step=step):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.super_flow_logger.info(f\"=== 计划更新完成 ===\")\n                        self.super_flow_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.super_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                        # 发送简洁的计划更新通知\n                        yield MessageEvent(message=f\"🔄 计划已更新，当前剩余{len([s for s in event.plan.steps if s.status == ExecutionStatus.PENDING])}个待执行步骤\")\n                    elif isinstance(event, MessageEvent):\n                        self.super_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 不转发JSON格式的MessageEvent\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.super_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                        # 转发重要的状态变化事件\n                        yield event\n\n                    # 创建计划完成后，准备执行步骤\n                    if self.plan:\n                        self._build_parallel_execution_groups()\n\n                        # 检查是否有任何步骤可以执行,如果没有进入报告阶段\n                        if not self.parallel_sub_flow_groups:\n                            self.super_flow_logger.info(\"没有剩余的待执行步骤，进入报告阶段\")\n                            self.status = FlowStatus.REPORTING\n                            continue\n                        # 状态转换到执行阶段\n                        self.status = FlowStatus.EXECUTING\n                        self.super_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == FlowStatus.REPORTING:\n                logger.info(f\"Agent {self.agent.id} plan has been completed\")\n                self.super_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                # 发送简洁的完成通知\n                yield MessageEvent(message=\"所有步骤已完成，正在生成最终报告...\")\n\n                # 生成最终报告\n                async for event in self.report_agent.generate_report(plan=self.plan):\n                    yield event\n\n                self.status = FlowStatus.COMPLETED\n                self.super_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n\n            elif self.status == FlowStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                self.super_flow_logger.info(f\"=== 计划执行完成 ===\")\n                self.super_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                yield PlanCompletedEvent(plan=self.plan, issuperplan=True)\n                self.status = FlowStatus.IDLE\n                self.super_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n        yield DoneEvent()\n\n        logger.info(f\"Agent {self.agent.id} message processing completed\")\n        self.super_flow_logger.info(f\"=== 消息处理完成 ===\")\n\n    def is_idle(self) -> bool:\n        return self.status == FlowStatus.IDLE\n\n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(\n                f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n\n    def add_report_to_knowledge(self, current_report):\n        self.knowledge.add_message({\n            'role': \"assistant\",\n            'message': current_report\n        })\n\n    def add_step_to_knowledge(self, current_step):\n        self.knowledge.add_message({\n            'role': \"user\",\n            'message': current_step\n        })",
      "methods": [
        "<module>.SuperFlow.__init__",
        "<module>.SuperFlow._determine_task_type",
        "<module>.SuperFlow.execute_step",
        "<module>.SuperFlow._build_parallel_execution_groups",
        "<module>.SuperFlow.run",
        "<module>.SuperFlow.is_idle",
        "<module>.SuperFlow._show_plan",
        "<module>.SuperFlow.add_report_to_knowledge",
        "<module>.SuperFlow.add_step_to_knowledge"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/plan_act.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/plan_act.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(Enum):\n    MESSAGE = \"message\"\n    SHELL = \"shell\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/rag/sample_workspace/flows/plan_act.py",
      "name": "PlanActFlow",
      "qualname": "<module>.PlanActFlow",
      "source": "class PlanActFlow(BaseFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"plan_act\"\n    description = \"计划-执行流程：先创建计划，然后逐步执行，支持动态更新计划\"\n    \n    def __init__(self, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser, \n                 search_engine: Optional[SearchEngine] = None, **kwargs):\n        super().__init__(agent, **kwargs)\n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        # 设置专门的日志记录器\n        self.plan_act_logger = setup_plan_act_logger(\"plan_act\")\n        self.plan_act_logger.info(f\"=== PlanActFlow初始化 Agent ID: {agent.id} ===\")\n        \n        # 创建计划代理和执行代理\n        self.planner = PlannerAgent(\n            llm=llm,\n            memory=agent.planner_memory,\n        )\n        logger.debug(f\"Created planner agent for Agent {self.agent.id}\")\n        self.plan_act_logger.info(f\"创建Planner Agent完成\")\n        \n        self.executor = ExecutionAgent(\n            llm=llm,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            memory=agent.execution_memory,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n        )\n        logger.debug(f\"Created execution agent for Agent {self.agent.id}\")\n        self.plan_act_logger.info(f\"创建Execution Agent完成\")\n        \n        # 创建通知代理，与执行代理共用memory\n        self.notifier = NotifyAgent(\n            llm=llm,\n            memory=Memory(),  # 与execution agent共用memory\n        )\n        logger.debug(f\"Created notify agent for Agent {self.agent.id}\")\n        self.plan_act_logger.info(f\"创建Notify Agent完成\")\n\n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        self.plan_act_logger.info(f\"=== 开始处理用户消息 ===\")\n        self.plan_act_logger.info(f\"用户输入: {message}\")\n        \n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.planner.roll_back()\n            self.executor.roll_back()\n            self.notifier.roll_back()  # 同时回滚notify agent\n            self.plan_act_logger.info(\"中断当前流程，重新开始规划\")\n\n        logger.info(f\"Agent {self.agent.id} started processing message: {message[:50]}...\")\n        step = None\n        while True:\n            if self.status == AgentStatus.IDLE:\n                logger.info(f\"Agent {self.agent.id} state changed from {AgentStatus.IDLE} to {AgentStatus.PLANNING}\")\n                self.status = AgentStatus.PLANNING\n                self.plan_act_logger.info(f\"状态变更: IDLE -> PLANNING\")\n                \n                # 通知用户开始规划\n                async for event in self.notifier.notify_received_message(message):\n                    yield event\n                    \n            elif self.status == AgentStatus.PLANNING:\n                # 创建计划\n                logger.info(f\"Agent {self.agent.id} started creating plan\")\n                self.plan_act_logger.info(f\"=== 开始创建计划 ===\")\n                self.plan_act_logger.info(f\"Planner输入: {message}\")\n                \n                async for event in self.planner.create_plan(message):\n                    if isinstance(event, PlanCreatedEvent):\n                        self.plan = event.plan\n                        logger.info(f\"Agent {self.agent.id} created plan successfully with {len(event.plan.steps)} steps\")\n                        self.plan_act_logger.info(f\"=== 计划创建成功 ===\")\n                        self.plan_act_logger.info(f\"计划ID: {event.plan.id}\")\n                        self.plan_act_logger.info(f\"计划目标: {event.plan.goal}\")\n                        self.plan_act_logger.info(f\"计划标题: {event.plan.title}\")\n                        self.plan_act_logger.info(f\"计划步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            self.plan_act_logger.info(f\"步骤{i}: [{step.id}] {step.description}\")\n                        if event.plan.message:\n                            self.plan_act_logger.info(f\"计划说明: {event.plan.message}\")\n                    elif isinstance(event, MessageEvent):\n                        self.plan_act_logger.info(f\"Planner输出: {event.message}\")\n                    yield event\n                logger.info(f\"Agent {self.agent.id} state changed from {AgentStatus.PLANNING} to {AgentStatus.EXECUTING}\")\n                self.status = AgentStatus.EXECUTING\n                self.plan_act_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n                    \n            elif self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"Agent {self.agent.id} has no more steps, state changed from {AgentStatus.EXECUTING} to {AgentStatus.REPORTING}\")\n                    self.status = AgentStatus.REPORTING\n                    self.plan_act_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                    \n                # 执行步骤\n                logger.info(f\"Agent {self.agent.id} started executing step {step.id}: {step.description[:50]}...\")\n                self.plan_act_logger.info(f\"=== 开始执行步骤 ===\")\n                self.plan_act_logger.info(f\"步骤ID: {step.id}\")\n                self.plan_act_logger.info(f\"步骤描述: {step.description}\")\n                self.plan_act_logger.info(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    if isinstance(event, ToolCallingEvent):\n                        self.plan_act_logger.info(f\"工具调用: {event.tool_name}\")\n                        self.plan_act_logger.info(f\"工具函数: {event.function_name}\")\n                        self.plan_act_logger.info(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.plan_act_logger.info(f\"工具结果: {event.tool_name}\")\n                        self.plan_act_logger.info(f\"工具函数: {event.function_name}\")\n                        self.plan_act_logger.info(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.plan_act_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.plan_act_logger.info(f\"Executor输出: {event.message}\")\n                    yield event\n                        \n                logger.info(f\"Agent {self.agent.id} completed step {step.id}, state changed from {AgentStatus.EXECUTING} to {AgentStatus.UPDATING}\")\n                self.plan_act_logger.info(f\"步骤执行完成: {step.id}\")\n                self.plan_act_logger.info(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.plan_act_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.plan_act_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.plan_act_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为 / 压缩记忆上下文 / 获取浓缩的记忆，给到更新计划Agent\n                self.plan_act_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    yield event\n                    if isinstance(event, MessageEvent):\n                        logger.info(f\"Agent {self.agent.id} summarized steps, message: {event.message}\")\n                        previous_steps = event.message\n                        self.plan_act_logger.info(f\"步骤总结完成: {event.message}\")\n                        \n                # 更新计划\n                logger.info(f\"Agent {self.agent.id} started updating plan\")\n                self.plan_act_logger.info(f\"=== 开始更新计划 ===\")\n                self.plan_act_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.plan_act_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.plan_act_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                async for event in self.planner.update_plan(self.plan, previous_steps):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.plan_act_logger.info(f\"=== 计划更新完成 ===\")\n                        self.plan_act_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.plan_act_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.plan_act_logger.info(f\"计划更新输出: {event.message}\")\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.plan_act_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                    yield event\n\n                logger.info(f\"Agent {self.agent.id} plan update completed, state changed from {AgentStatus.UPDATING} to {AgentStatus.EXECUTING}\")\n                self.status = AgentStatus.EXECUTING\n                self.plan_act_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"Agent {self.agent.id} plan has been completed\")\n                self.plan_act_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                # 通知用户计划全部完成\n                async for notify_event in self.notifier.notify_plan_progress(self.plan, \"所有步骤已完成，正在准备最终报告\"):\n                    yield notify_event\n                    \n                async for event in self.executor.report_result(message):\n                    yield event\n                    \n                self.status = AgentStatus.COMPLETED\n                self.plan_act_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"Agent {self.agent.id} plan has been completed\")\n                self.plan_act_logger.info(f\"=== 计划执行完成 ===\")\n                self.plan_act_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan) \n                self.status = AgentStatus.IDLE\n                self.plan_act_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n        yield DoneEvent()\n        \n        logger.info(f\"Agent {self.agent.id} message processing completed\")\n        self.plan_act_logger.info(f\"=== 消息处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.PlanActFlow.__init__",
        "<module>.PlanActFlow.run",
        "<module>.PlanActFlow.is_idle",
        "<module>.PlanActFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/base.py",
      "name": "BaseFlow",
      "qualname": "<module>.BaseFlow",
      "source": "class BaseFlow(ABC):\n    # 每个flow类都需要定义一个唯一的flow_id\n    flow_id: str = None\n    \n    def __init__(self, agent: Agent, **kwargs):\n        self.agent = agent\n        # 验证flow_id是否已定义\n        if self.flow_id is None:\n            raise ValueError(f\"Flow class {self.__class__.__name__} must define a flow_id\")\n\n    @abstractmethod\n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"执行flow的主要逻辑\"\"\"\n        pass\n    \n    @abstractmethod\n    def is_idle(self) -> bool:\n        \"\"\"检查flow是否处于空闲状态\"\"\"\n        pass\n    \n    @classmethod\n    def get_flow_id(cls) -> str:\n        \"\"\"获取flow的唯一标识符\"\"\"\n        return cls.flow_id\n\n    @classmethod\n    def get_description(cls) -> str:\n        \"\"\"获取flow的描述信息\"\"\"\n        return getattr(cls, 'description', f\"Flow {cls.flow_id}\")\n",
      "methods": [
        "<module>.BaseFlow.__init__",
        "<module>.BaseFlow.run",
        "<module>.BaseFlow.is_idle",
        "<module>.BaseFlow.get_flow_id",
        "<module>.BaseFlow.get_description"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/base.py",
      "name": "BaseSubFlow",
      "qualname": "<module>.BaseSubFlow",
      "source": "class BaseSubFlow(ABC):\n    \"\"\"\n    子规划器流程的基础接口类\n    定义了子规划器流程必须实现的核心方法\n    \"\"\"\n    # 每个flow类都需要定义一个唯一的flow_id\n    flow_id: str = None\n\n    # 初始化SubFlow可用的基础设施\n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Optional[Sandbox] = None,\n        browser: Optional[Browser] = None,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Optional[Enum] = None,\n    ):\n        self.llm = llm\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n        self.task_type = task_type\n\n    @abstractmethod\n    async def run(self, parent_plan: Plan, parent_step: Step, parent_memory: Memory,\n                   task_type: Enum) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行计划中的单个步骤\n        根据步骤类型创建对应的子规划器并执行\n        并生成当前子规划器的最终报告\n        包括执行过程、工具使用和最终结果\n\n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n\n        Yields:\n            AgentEvent: 执行过程中的各种事件\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def is_idle(self) -> bool:\n        \"\"\"检查flow是否处于空闲状态\"\"\"\n        pass\n\n    @classmethod\n    def get_flow_id(cls) -> str:\n        \"\"\"获取flow的唯一标识符\"\"\"\n        return cls.flow_id\n\n    @classmethod\n    def get_description(cls) -> str:\n        \"\"\"获取flow的描述信息\"\"\"\n        return getattr(cls, 'description', f\"Flow {cls.flow_id}\")",
      "methods": [
        "<module>.BaseSubFlow.__init__",
        "<module>.BaseSubFlow.run",
        "<module>.BaseSubFlow.is_idle",
        "<module>.BaseSubFlow.get_flow_id",
        "<module>.BaseSubFlow.get_description"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/sub_planner_flow.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/sub_planner_flow.py",
      "name": "SubPlannerFlow",
      "qualname": "<module>.SubPlannerFlow",
      "source": "class SubPlannerFlow(BaseSubFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"general\"\n    description = \"子计划规划流程：先创建子计划，然后逐步执行，支持动态更新子计划\"\n    \n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Enum = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_flow_logger = setup_sub_planner_flow_logger(f\"sub_planner_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow.__init__ 开始 ===\")\n        self.sub_planner_flow_logger.info(f\"接收到的参数:\")\n        self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n        self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n        self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n        self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n        self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.execution_result=Memory()\n        if task_type:\n            self.sub_planner_flow_logger.info(f\"task_type.value: {task_type.value}\")\n            self.sub_planner_flow_logger.info(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 调用父类构造函数\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        \n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        self.sub_planner_flow_logger.info(f\"=== 开始创建SubPlannerAgent ===\")\n        \n        try:\n            # 创建子规划器代理\n            self.sub_planner_flow_logger.info(f\"准备创建SubPlannerAgent，参数:\")\n            self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n            self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n            self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n            self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n            self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n            \n            self.sub_planner = SubPlannerAgent(\n                llm=llm,\n                task_type=task_type,\n                memory=Memory(),\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n            )\n            self.sub_planner_flow_logger.info(\"创建SubPlanner Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建SubPlannerAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        try:\n            self.sub_planner_flow_logger.info(f\"=== 开始创建ExecutionAgent ===\")\n            # 创建执行代理\n            self.executor = ExecutionAgent(\n                memory=Memory(),\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                type_value=task_type.value\n            )\n            self.sub_planner_flow_logger.info(\"创建Execution Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建ExecutionAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    async def run(\n        self,\n        parent_plan: Plan,\n        parent_step: Step,\n        parent_memory: Memory,\n        task_type: Enum\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行子计划流程\n        \n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n        \"\"\"\n        # TODO\n        self.sub_planner.fix(parent_plan,parent_step)\n\n        self.sub_planner_flow_logger.info(f\"=== 开始执行子计划 ===\")\n        self.sub_planner_flow_logger.info(f\"父计划ID: {parent_plan.id}\")\n        self.sub_planner_flow_logger.info(f\"父步骤ID: {parent_step.id}\")\n        self.sub_planner_flow_logger.info(f\"任务类型: {task_type.value}\")\n        \n        # 根据传入的task_type更新提示词\n        self.sub_planner_flow_logger.info(f\"=== 开始更新系统提示词 ===\")\n\n        # 更新子规划器的系统提示词\n        updated_system_prompt = PromptManager.get_system_prompt_with_tools(self.sub_planner.tools, is_executor=False)\n        updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n        updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n        self.sub_planner.system_prompt = PromptManager.insert_datetime(updated_system_prompt)\n\n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.sub_planner.roll_back()\n            self.executor.roll_back()\n            self.sub_planner_flow_logger.info(\"中断当前流程，重新开始规划\")\n\n        # 使用父步骤的描述作为输入消息\n        message = parent_step.description\n        logger.info(f\"开始处理步骤: {message[:50]}...\")\n        \n        # 创建子计划\n        self.status = AgentStatus.PLANNING\n        self.sub_planner_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n        \n        async for event in self.sub_planner.create_plan(message):\n            updated_system_prompt = self.sub_planner.system_prompt\n            updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n            updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n            self.sub_planner.system_prompt = updated_system_prompt\n            \n            if isinstance(event, PlanCreatedEvent):\n                self.plan = event.plan\n                logger.info(f\"创建子计划成功，包含 {len(event.plan.steps)} 个步骤\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划创建成功 ===\")\n                self.sub_planner_flow_logger.info(f\"子计划ID: {event.plan.id}\")\n                self.sub_planner_flow_logger.info(f\"子计划目标: {event.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"子计划标题: {event.plan.title}\")\n                self.sub_planner_flow_logger.info(f\"子计划步骤数量: {len(event.plan.steps)}\")\n                for i, step in enumerate(event.plan.steps, 1):\n                    self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}\")\n                if event.plan.message:\n                    self.sub_planner_flow_logger.info(f\"子计划说明: {event.plan.message}\")\n            elif isinstance(event, MessageEvent):\n                self.sub_planner_flow_logger.info(f\"Planner输出: {event.message}\")\n            yield event\n            \n        self.status = AgentStatus.EXECUTING\n        self.sub_planner_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n        \n        # 执行子计划\n        while True:\n            if self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"子计划执行完成，状态变更: EXECUTING -> REPORTING\")\n                    self.status = AgentStatus.REPORTING\n                    self.sub_planner_flow_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                    \n                # 执行步骤\n                logger.info(f\"开始执行步骤 {step.id}: {step.description[:50]}...\")\n                self.sub_planner_flow_logger.info(f\"=== 开始执行步骤 ===\")\n                self.sub_planner_flow_logger.info(f\"步骤ID: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤描述: {step.description}\")\n                self.sub_planner_flow_logger.info(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    updated_system_prompt = self.executor.system_prompt\n                    updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.executor.shell_tool)\n                    updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.executor.memory)\n                    self.executor.system_prompt = updated_system_prompt\n                    if isinstance(event, ToolCallingEvent):\n                        self.sub_planner_flow_logger.info(f\"工具调用: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.sub_planner_flow_logger.info(f\"工具结果: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.sub_planner_flow_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"Executor输出: {event.message}\")\n                        # 将执行结果保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n                        \n                logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                self.sub_planner_flow_logger.info(f\"步骤执行完成: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.sub_planner_flow_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.sub_planner_flow_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.sub_planner_flow_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为\n                self.sub_planner_flow_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    yield event\n                    if isinstance(event, MessageEvent):\n                        logger.info(f\"步骤总结完成: {event.message}\")\n                        previous_steps = event.message\n                        self.sub_planner_flow_logger.info(f\"步骤总结完成: {event.message}\")\n                        # 将总结保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                        \n                # 更新计划\n                self.sub_planner_flow_logger.info(f\"=== 开始更新子计划 ===\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                updated_system_prompt = self.sub_planner.system_prompt\n                updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n                updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n                self.sub_planner.system_prompt = updated_system_prompt\n                \n                async for event in self.sub_planner.update_plan(self.plan, previous_steps):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.sub_planner_flow_logger.info(f\"=== 子计划更新完成 ===\")\n                        self.sub_planner_flow_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 将更新信息保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                    yield event\n\n                logger.info(f\"子计划更新完成，状态变更: UPDATING -> EXECUTING\")\n                self.status = AgentStatus.EXECUTING\n                self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"子计划执行完成，准备生成报告\")\n                self.sub_planner_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                async for event in self.executor.report_result(message):\n                    if isinstance(event, MessageEvent):\n                        # 将报告保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n\n                yield ReportEvent(message=str(self.execution_result.get_messages()))\n                self.status = AgentStatus.COMPLETED\n                self.sub_planner_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"子计划执行完成\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划执行完成 ===\")\n                self.sub_planner_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan) \n                self.status = AgentStatus.IDLE\n                self.sub_planner_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n                \n        yield DoneEvent()\n        \n        logger.info(f\"子计划处理完成\")\n        self.sub_planner_flow_logger.info(f\"=== 子计划处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.SubPlannerFlow.__init__",
        "<module>.SubPlannerFlow.run",
        "<module>.SubPlannerFlow.is_idle",
        "<module>.SubPlannerFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/default_flow.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/default_flow.py",
      "name": "DefaultFlow",
      "qualname": "<module>.DefaultFlow",
      "source": "class DefaultFlow(BaseSubFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"default\"\n    description = \"子计划规划流程：先创建子计划，然后逐步执行，支持动态更新子计划\"\n    \n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Enum = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_flow_logger = setup_sub_planner_flow_logger(f\"sub_planner_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        #self.sub_planner_flow_logger.info(f\"=== SubPlannerFlow.__init__ 开始 ===\")\n        # self.sub_planner_flow_logger.debug(f\"接收到的参数:\")\n        # self.sub_planner_flow_logger.debug(f\"  llm: {llm}\")\n        # self.sub_planner_flow_logger.debug(f\"  sandbox: {sandbox}\")\n        # self.sub_planner_flow_logger.debug(f\"  browser: {browser}\")\n        # self.sub_planner_flow_logger.debug(f\"  search_engine: {search_engine}\")\n        # self.sub_planner_flow_logger.debug(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.execution_result=Memory()\n        if task_type:\n            self.sub_planner_flow_logger.debug(f\"task_type.value: {task_type.value}\")\n      #      self.sub_planner_flow_logger.debug(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 调用父类构造函数\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        \n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        self.sub_planner_flow_logger.info(f\"=== 开始创建SubPlannerAgent ===\")\n        \n        try:\n            # 创建子规划器代理\n            self.sub_planner_flow_logger.debug(f\"准备创建SubPlannerAgent，参数:\")\n            self.sub_planner_flow_logger.debug(f\"  llm: {llm}\")\n            self.sub_planner_flow_logger.debug(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n            self.sub_planner_flow_logger.debug(f\"  sandbox: {sandbox}\")\n            self.sub_planner_flow_logger.debug(f\"  browser: {browser}\")\n            self.sub_planner_flow_logger.debug(f\"  search_engine: {search_engine}\")\n            \n            self.sub_planner = SubPlannerAgent(\n                llm=llm,\n                task_type=task_type,\n                memory=Memory(),\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n            )\n            self.sub_planner_flow_logger.info(\"创建SubPlanner Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建SubPlannerAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        try:\n            self.sub_planner_flow_logger.info(f\"=== 开始创建ExecutionAgent ===\")\n            # 创建执行代理\n            self.executor = ExecutionAgent(\n                memory=Memory(),\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                type_value=task_type.value\n            )\n            self.sub_planner_flow_logger.info(\"创建Execution Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建ExecutionAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    async def run(\n        self,\n        parent_plan: Plan,\n        parent_step: Step,\n        parent_memory: Memory,\n        task_type: Enum\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行子计划流程\n        \n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n        \"\"\"\n        # TODO\n        self.sub_planner.fix(parent_plan,parent_step)\n\n        self.sub_planner_flow_logger.info(f\"=== 开始执行子计划 ===\")\n        self.sub_planner_flow_logger.debug(f\"父计划ID: {parent_plan.id}\")\n        self.sub_planner_flow_logger.debug(f\"父步骤ID: {parent_step.id}\")\n        self.sub_planner_flow_logger.debug(f\"任务类型: {task_type.value}\")\n        \n        # 根据传入的task_type更新提示词\n        self.sub_planner_flow_logger.debug(f\"=== 开始更新系统提示词 ===\")\n        try:\n            # 更新子规划器的系统提示词\n            updated_system_prompt = PromptManager.get_system_prompt_with_tools(self.sub_planner.tools, is_executor=False)\n            self.sub_planner_flow_logger.debug(f\"[DEBUG MEM] SubPlannerFlow before update mem: {updated_system_prompt}\")\n            updated_system_prompt = PromptManager.update_mem(updated_system_prompt, parent_memory)\n            self.sub_planner_flow_logger.debug(f\"[DEBUG MEM] SubPlannerFlow after update mem: {updated_system_prompt}\")\n            updated_system_prompt = PromptManager.insert_datetime(updated_system_prompt)\n            if hasattr(self.sub_planner, 'system_prompt'):\n                self.sub_planner.system_prompt = updated_system_prompt\n                self.sub_planner_flow_logger.debug(f\"子规划器系统提示词更新成功\")\n                self.sub_planner_flow_logger.debug(f\"新提示词长度: {len(updated_system_prompt)}\")\n            else:\n                self.sub_planner_flow_logger.warning(f\"子规划器没有system_prompt属性\")\n                \n            # 更新执行器的系统提示词\n            executor_system_prompt = PromptManager.insert_datetime(PromptManager.get_system_prompt_with_tools(self.executor.tools, is_executor=True))\n            if hasattr(self.executor, 'system_prompt'):\n                self.executor.system_prompt = executor_system_prompt\n                self.sub_planner_flow_logger.debug(f\"执行器系统提示词更新成功\")\n                self.sub_planner_flow_logger.debug(f\"执行器新提示词长度: {len(executor_system_prompt)}\")\n            else:\n                self.sub_planner_flow_logger.warning(f\"执行器没有system_prompt属性\")\n                \n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"更新系统提示词失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            # 继续执行，不因为提示词更新失败而中断整个流程\n        \n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.sub_planner.roll_back()\n            self.executor.roll_back()\n            self.sub_planner_flow_logger.debug(\"中断当前流程，重新开始规划\")\n\n        # 使用父步骤的描述作为输入消息\n        message = parent_step.description\n        logger.info(f\"开始处理步骤: {message[:50]}...\")\n        \n        # 创建子计划\n        self.status = AgentStatus.PLANNING\n        self.sub_planner_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n        \n        async for event in self.sub_planner.create_plan(message):\n            if isinstance(event, PlanCreatedEvent):\n                self.plan = event.plan\n                logger.info(f\"创建子计划成功，包含 {len(event.plan.steps)} 个步骤\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划创建成功 ===\")\n                self.sub_planner_flow_logger.debug(f\"子计划ID: {event.plan.id}\")\n                self.sub_planner_flow_logger.info(f\"子计划目标: {event.plan.goal}\")\n                self.sub_planner_flow_logger.debug(f\"子计划标题: {event.plan.title}\")\n                self.sub_planner_flow_logger.debug(f\"子计划步骤数量: {len(event.plan.steps)}\")\n                for i, step in enumerate(event.plan.steps, 1):\n                    self.sub_planner_flow_logger.debug(f\"步骤{i}: [{step.id}] {step.description}\")\n                if event.plan.message:\n                    self.sub_planner_flow_logger.debug(f\"子计划说明: {event.plan.message}\")\n            elif isinstance(event, MessageEvent):\n                self.sub_planner_flow_logger.info(f\"Planner输出: {event.message}\")\n            #yield event\n            \n        self.status = AgentStatus.EXECUTING\n        self.sub_planner_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n        \n        # 执行子计划\n        while True:\n            if self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"子计划执行完成，状态变更: EXECUTING -> REPORTING\")\n                    self.status = AgentStatus.REPORTING\n                    self.sub_planner_flow_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                    \n                # 执行步骤\n                logger.info(f\"开始执行步骤 {step.id}: {step.description[:50]}...\")\n                self.sub_planner_flow_logger.info(f\"=== 开始执行步骤 ===\")\n                self.sub_planner_flow_logger.debug(f\"步骤ID: {step.id}\")\n                self.sub_planner_flow_logger.debug(f\"步骤描述: {step.description}\")\n                self.sub_planner_flow_logger.debug(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    if isinstance(event, ToolCallingEvent):\n                        self.sub_planner_flow_logger.debug(f\"工具调用: {event.tool_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.sub_planner_flow_logger.debug(f\"工具结果: {event.tool_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.debug(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.sub_planner_flow_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.debug(f\"Executor输出: {event.message}\")\n                        # 将执行结果保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                #    yield event\n                        \n                logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                self.sub_planner_flow_logger.debug(f\"步骤执行完成: {step.id}\")\n                self.sub_planner_flow_logger.debug(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.sub_planner_flow_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.sub_planner_flow_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.sub_planner_flow_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为\n                self.sub_planner_flow_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    # 不转发总结事件到前端，这些是内部实现细节\n                    # yield event\n                    if isinstance(event, MessageEvent):\n                        previous_steps = event.message\n                        # 将总结保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                        \n                # 更新计划\n                self.sub_planner_flow_logger.info(f\"=== 开始更新子计划 ===\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                async for event in self.sub_planner.update_plan(self.plan, previous_steps):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.sub_planner_flow_logger.info(f\"=== 子计划更新完成 ===\")\n                        self.sub_planner_flow_logger.debug(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.sub_planner_flow_logger.debug(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 将更新信息保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                 #   yield event\n\n                logger.info(f\"子计划更新完成，状态变更: UPDATING -> EXECUTING\")\n                self.status = AgentStatus.EXECUTING\n                self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"子计划执行完成，准备生成报告\")\n                self.sub_planner_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                final_report = \"\"\n                async for event in self.executor.report_result(message):\n                    if isinstance(event, MessageEvent):\n                        # 将报告保存到execution_result中\n                        parent_step.result = event.message\n                        final_report = event.message  # 只保留最终报告\n                 #   yield event\n                yield ReportEvent(message=str(self.execution_result.get_messages()))\n                # # 只发送简洁的最终报告，而不是整个执行历史\n                # yield ReportEvent(message=final_report or parent_step.result or \"子任务执行完成\")\n                self.status = AgentStatus.COMPLETED\n                self.sub_planner_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"子计划执行完成\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划执行完成 ===\")\n                self.sub_planner_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan, issubplan=True) \n                self.status = AgentStatus.IDLE\n                self.sub_planner_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n                \n        #yield DoneEvent()\n        \"\"\"需要声明另一种doneevent\"\"\"\n        \n        logger.info(f\"子计划处理完成\")\n        self.sub_planner_flow_logger.info(f\"=== 子计划处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.DefaultFlow.__init__",
        "<module>.DefaultFlow.run",
        "<module>.DefaultFlow.is_idle",
        "<module>.DefaultFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/search_flow.py",
      "name": "SearchFlow",
      "qualname": "<module>.SearchFlow",
      "source": "class SearchFlow(BaseSubFlow):\n    flow_id = \"search\"\n    description = \"多步gap反射搜索流程\"\n\n    def __init__(\n        self,\n        llm,\n        sandbox,\n        browser,\n        search_engine=None,\n        audio_llm=None,\n        image_llm=None,\n        video_llm=None,\n        reason_llm=None,\n        task_type=None,\n    ):\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        self.knowledge: List[Dict[str, Any]] = []\n        self.max_iterations = 3\n\n        self.processed_gaps: set = set()\n\n        # self.executor = ExecutionAgent(\n        #     memory=Memory(),\n        #     llm=llm,\n        #     audio_llm=audio_llm,\n        #     image_llm=image_llm,\n        #     video_llm=video_llm,\n        #     reason_llm=reason_llm,\n        #     sandbox=sandbox,\n        #     browser=browser,\n        #     search_engine=search_engine\n        # )\n\n        self.status = \"idle\"\n\n    def is_idle(self):\n        return self.status == \"idle\"\n\n    async def run(\n            self,\n            parent_plan=None,\n            parent_step=None,\n            parent_memory=None,\n            task_type=None,\n            *args,\n            **kwargs\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        统一入口，兼容原有run和execute_task的参数风格。\n        支持位置参数和关键字参数。\n        \"\"\"\n        # 参数兼容处理\n        memory = parent_memory or kwargs.get('memory') or Memory()\n        plan = parent_plan or kwargs.get('plan')\n        step = parent_step or kwargs.get('step')\n        if not plan or not step:\n            # 兼容通过args传参\n            if len(args) >= 2:\n                plan, step = args[:2]\n            else:\n                raise ValueError(\"run() 必须包含 plan 和 step 两个参数\")\n\n        self.executor = ExecutionAgent(\n            memory=memory,\n            llm=self.llm,\n            audio_llm=self.audio_llm,\n            image_llm=self.image_llm,\n            video_llm=self.video_llm,\n            reason_llm=self.reason_llm,\n            sandbox=self.sandbox,\n            browser=self.browser,\n            search_engine=self.search_engine\n        )\n\n\n        global_question = step.description\n\n        yield MessageEvent(message=f\"初始化，目标问题：{global_question}\")\n\n        # 先选择全局评分模式列表\n        eval_types = await self.select_scoring_mode(global_question)\n\n        # gap主流程（可单独抽成私有方法，见上文）\n        gaps = await self.generate_gaps(global_question)\n        gaps = self._filter_and_update_gaps(gaps)\n        iteration = 0\n\n        #gaps=['下载文件Federico Lauria 2014年论文的全文']\n\n        # 此部分while loop针对单个gap，使用reflect_gap返回针对单个gap的反思gap\n        # while gaps and iteration < self.max_iterations:\n        #     iteration += 1\n        #     yield MessageEvent(message=f\"第{iteration}轮gap处理，待处理gap: {gaps}\")\n        #     # search_tasks = [self.search_gap(gap) for gap in gaps]\n        #     # search_results = await asyncio.gather(*search_tasks)\n        #\n        #     # 尝试不用并发，串行\n        #     search_results = []\n        #     for gap in gaps:\n        #         result = await self.search_gap(gap)\n        #         # print(f\"[DEBUG] search_gap 返回: {result}\")\n        #         search_results.append(result)\n        #\n        #     new_gaps = []\n        #\n        #     for gap, result in zip(gaps, search_results):\n        #         summary = self.format_search_result(result)\n        #         # print(\"debug用， format后summary内容：\")\n        #         # print(summary)\n        #         score, reason = await self.score_gap(gap, {\"result\": summary}, eval_types)\n        #         if score:\n        #             knowledge_item = {\"gap\": gap, \"summary\": summary, \"raw\": result, \"iteration\": iteration}\n        #             self.knowledge.append(knowledge_item)\n        #             yield MessageEvent(message=f\"gap [{gap}] 已解决，总结: {summary}\")\n        #         else:\n        #             error_reason = await self.analyze_gap(gap, result, reason)\n        #             knowledge_item = {\"gap\": gap, \"summary\": f\"失败: {error_reason}\", \"raw\": result,\n        #                               \"iteration\": iteration}\n        #             self.knowledge.append(knowledge_item)\n        #             yield MessageEvent(message=f\"gap [{gap}] 未解决，错误分析: {error_reason}\")\n        #             reflected_gaps = await self.reflect_gap(gap, error_reason)\n        #             yield MessageEvent(message=f\"gap [{gap}] 反射生成新gap: {reflected_gaps}\")\n        #             new_gaps.extend(reflected_gaps)\n        #     gaps = self._filter_and_update_gaps(gaps=[], new_gaps=new_gaps)\n\n        # 此部分while loop针对一整轮gap，使用reflect_batch_gap返回针对一整轮gap的反思gap\n        print(f\"generate后gap内容为:{gaps}\")\n        print(type(gaps), gaps)\n        while gaps and iteration < self.max_iterations:\n            print(\"主循环开始执行\")\n            iteration += 1\n            yield MessageEvent(message=f\"第{iteration}轮gap处理，待处理gap: {gaps}\")\n            print(f\"第{iteration}轮gap处理，待处理gap: {gaps}\")\n\n            search_results = []\n            for gap in gaps:\n                #result = await self.search_gap(gap)\n                print(\"主循环中运行到executor部分\")\n                result = await self.search_gap(gap, global_question)\n                print(f'已完成对gap： {gap} 的搜索')\n                search_results.append(result)\n\n            new_gaps = []\n            failed_gaps_info = []\n\n            for gap, result in zip(gaps, search_results):\n                summary = self.format_search_result(result)\n                score, reason = await self.score_gap(gap, {\"result\": summary}, eval_types)\n                if score:\n                    print(f'gap {gap} 执行成功')\n                    knowledge_item = {\"gap\": gap, \"summary\": summary, \"raw\": result, \"iteration\": iteration}\n                    self.knowledge.append(knowledge_item)\n                    yield MessageEvent(message=f\"gap [{gap}] 已解决，总结: {summary}\")\n                else:\n                    print(f'gap {gap} 执行失败')\n                    error_reason = await self.analyze_gap(gap, result, reason)\n                    knowledge_item = {\"gap\": gap, \"summary\": f\"失败: {error_reason}\", \"raw\": result,\n                                      \"iteration\": iteration}\n                    self.knowledge.append(knowledge_item)\n                    yield MessageEvent(message=f\"gap [{gap}] 未解决，错误分析: {error_reason}\")\n                    failed_gaps_info.append({\n                        \"gap\": gap,\n                        \"error_reason\": error_reason,\n                        \"executor_result\": result\n                    })\n\n            # 一轮gap全处理完后，统一reflect\n            if failed_gaps_info:\n                reflected_gaps = await self.reflect_gap_batch(failed_gaps_info)\n                yield MessageEvent(message=f\"本轮所有失败gap反射生成新gap: {reflected_gaps}\")\n                new_gaps.extend(reflected_gaps)\n\n            gaps = self._filter_and_update_gaps(gaps=[], new_gaps=new_gaps)\n\n        yield MessageEvent(message=\"gap处理完成，准备整合知识库生成最终答案\")\n        final_answer, need_more = await self.generate_final_answer(global_question, self.knowledge)\n        parent_step.result = final_answer\n        yield ReportEvent(message=f\"最终答案：{final_answer}\")\n        print(\"run中已yield最终答案\")\n        if need_more:\n            yield MessageEvent(message=\"LLM认为知识库仍有缺失，重新进入gap循环（本流程暂不再循环）\")\n        else:\n            yield MessageEvent(message=\"任务完成，已获得满意答案\")\n\n    # ========== 以下为各模块实现 ==========\n\n    async def select_scoring_mode(self, global_question: str)  -> List[str]:\n        \"\"\"\n        根据 global_question 的内容简单决策评分模式。\n        \"\"\"\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": prompt.QUESTION_EVALUATION_PROMPT_SYSTEM\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt.QUESTION_EVALUATION_PROMPT_USER.format(\n                    question=global_question\n                ),\n            },\n        ]\n        # 调用 LLM\n        #print(f'select scoring mode的message{messages}')\n        response = await self.llm.ask(messages)\n        # 打印调试内容（可选）\n        #print(\"LLM returned:\", response.content)\n\n\n        eval_types = []\n        # 解析 LLM 输出\n        try:\n            analysis_result = json.loads(response.content)\n        except Exception as e:\n            print(\"LLM输出解析失败，fallback使用basic\", e)\n            eval_types.append(\"basic\") #使用basic进行兜底\n\n        if analysis_result.get(\"needsDefinitive\", True):\n            eval_types.append(\"definitive\")\n        if analysis_result.get(\"needsFreshness\", False):\n            eval_types.append(\"freshness\")\n        if analysis_result.get(\"needsPlurality\", False):\n            eval_types.append(\"plurality\")\n        if analysis_result.get(\"needsCompleteness\", False):\n            #eval_types.append(\"completeness\")\n            print()\n        if analysis_result.get(\"needsFile\", True):\n            eval_types.append(\"file\")\n\n        print(f\"[Eval] 问题需要的评估类型: {eval_types}\")\n        return eval_types\n\n    #生成gap\n    async def generate_gaps(self, global_question: str) -> list[str]:\n        #print(\"generate_gaps 生成问题 运行到了\")\n\n        current_time = datetime.now()\n        system_prompt = prompt.QUERY_REWRITE_PROMPT_SYSTEM.format(\n            currentTime=current_time.isoformat(),\n            currentYear=current_time.year,\n            currentMonth=current_time.month\n        )\n        user_message = prompt.QUERY_GENERATE_PROMPT_USER.format(\n            global_question=global_question,\n            current_time=datetime.now()\n        )\n        messages = [\n            {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + user_message},\n        ]\n        response = await self.llm.ask(messages)\n        print(\"成功获取llm返回的新gaps，raw\")\n        print(response.content)\n        try:\n            data = json.loads(response.content)\n            queries = data.get(\"queries\", [])\n            gaps = []\n            for query in queries:\n                print(\"开始将返回内容格式化为query\")\n                if isinstance(query, dict):\n                    # 按字段顺序拼成 \"key1:value1 key2:value2 ...\"\n                    fields = [f\"{k}:{str(v)}\" for k, v in query.items() if str(v).strip()]\n                    if fields:\n                        gaps.append(\" \".join(fields))\n                        print(\"gaps已经成功append\")\n                        print(fields)\n            return gaps\n        except Exception as e:\n            print(\"解析失败:\", e)\n            return [global_question]\n\n    #由run方法中串行调用，利用executor搜索单个gap\n    # async def search_gap(self, gap: str) -> dict:\n    #     #print(\"search_gap 搜索问题 运行到了\")\n    #     # 1. 构造一个step\n    #     # step = Step(\n    #     #     id=\"search_gap\",\n    #     #     description=f\"请使用搜索工具检索以下内容：{gap}\",\n    #     #     status=ExecutionStatus.PENDING\n    #     # )\n    #     step = Step(\n    #         id=\"search_gap\",\n    #         description=(\n    #             f\"You have access to all available tools, including search engines, web browsers, code execution, and multimedia analysis.\"\n    #             f\"\\nPlease select the most appropriate tool(s) to solve the following sub-question. \"\n    #             f\"Actively call the needed tools, integrate their output, and provide a clear answer.\"\n    #             f\"If you encounter a question that needs reading files(pdf/word/txt) to obtain the answer, you should try to download the file from the internet for more accurate answers.\"\n    #             f\"If you are required to find answers from related essays, articles or books, you should download them and check the file by reading them locally.\"\n    #             f\"In most conditions, searching information about content of an article/book/essay is not a good idea, not much information can be found online, download and read the file if needed.\"\n    #             f\"\\nSub-question: {gap}\"\n    #         ),\n    #         status=ExecutionStatus.PENDING\n    #     )\n    #\n    #     # 2. 构造一个最小Plan\n    #     plan = Plan(\n    #         id=\"search_gap_plan\",\n    #         title=\"Search Gap Task\",\n    #         goal=gap,\n    #         steps=[step]\n    #     )\n    #     all_messages = []\n    #     final_result = None\n    #     final_error = None\n    #\n    #     # 3. 调用executor执行，因后端executor较为标准，暂时使用，后期会针对此处使用的特定工具进行优化\n    #     async for event in self.executor.execute_step(plan, step, gap):\n    #         if hasattr(event, \"message\"):\n    #             all_messages.append(event.message)\n    #         if isinstance(event, StepCompletedEvent):\n    #             # 把最终 result 也放到 messages 最后\n    #             all_messages.append(event.step.result)\n    #             return {\"gap\": gap, \"result\": all_messages}\n    #         elif isinstance(event, StepFailedEvent):\n    #             # 错误处理\n    #             all_messages.append(event.step.error)\n    #             return {\"gap\": gap, \"result\": all_messages}\n    #\n    #\n    #     # 4. fallback，兜底\n    #     #print(\"如果gap no result found，以下会被打印：\")\n    #     #print(f\"[DEBUG][search_gap] gap: {gap} No result found.\") #test\n    #     # return {\"gap\": gap, \"error\": \"No result\"}\n    #     all_messages.append(\"No result\")\n    #     return {\"gap\": gap, \"result\": all_messages}\n\n    async def search_gap(self, gap: str, global_question: str = None) -> dict:\n        print(\"search_gap被调用\")\n        # 1. 知识库标准化并装入prompt\n        knowledge_text = \"\"\n        if self.knowledge:\n            knowledge_text = \"\\n\".join(\n                f\"Sub-question: {item.get('gap', '')}\\nContent: {item.get('summary', '')}\"\n                for item in self.knowledge\n            )\n\n        #局域prompt存储\n        prompt_parts = []\n\n        # =知识库相关prompt\n        if knowledge_text:\n            prompt_parts.append(\n                \"---- KNOWLEDGE BASE ----\\n\"\n                \"Below is the current knowledge base collected from previous sub-questions. \"\n                \"You MUST use this information to answer the current sub-question if possible. \"\n                \"If the knowledge base already contains a clear answer, you should directly summarize or reuse it. \"\n                \"Only use external tools/search if the knowledge base is insufficient.\\n\"\n                f\"{knowledge_text}\\n\"\n            )\n        else:\n            prompt_parts.append(\n                \"---- KNOWLEDGE BASE ----\\n\"\n                \"The knowledge base is currently empty. You may need to use available tools to answer the sub-question.\\n\"\n            )\n        #print(f'知识库部分：{prompt_parts}')\n\n        #关于search_flow所需的特别的executor的prompt\n        execution_prompt=prompt.EXECUTION_DESCRIPTION_PROMPT.format(\n            gap=gap\n        )\n        prompt_parts.append(execution_prompt)\n\n        #来自execution.py，专门用来向executor解释他的能力\n        current_time = datetime.now()  # 当前本地时间，类型为datetime对象\n        system_prompt = prompt.EXECUTION_SYSTEM_PROMPT.format(\n            cur_time=current_time.isoformat()\n        )\n        prompt_parts.append(system_prompt)\n\n        full_prompt = \"\\n\".join(prompt_parts)\n\n        # 3. Compose Step with new prompt\n        step = Step(\n            id=\"search_gap\",\n            description=full_prompt,\n            status=ExecutionStatus.PENDING\n        )\n\n        #2构造一个最小Plan\n        plan = Plan(\n            id=\"search_gap_plan\",\n            title=\"Search Gap Task\",\n            goal=gap,\n            steps=[step]\n        )\n        all_messages = []\n        final_result = None\n        final_error = None\n\n        # 3. 调用executor执行，因后端executor较为标准，暂时使用，后期会针对此处使用的特定工具进行优化\n        print(\"prompt制作完成，开始调用executor\")\n        async for event in self.executor.execute_step(plan, step, gap):\n            if hasattr(event, \"message\"):\n                all_messages.append(event.message)\n                print(\"获取到了message\")\n            if isinstance(event, StepCompletedEvent):\n                # 把最终 result 也放到 messages 最后\n                all_messages.append(event.step.result)\n                print(\"获取到了StepCompletedEvent\")\n                return {\"gap\": gap, \"result\": all_messages}\n            elif isinstance(event, StepFailedEvent):\n                # 错误处理\n                all_messages.append(event.step.error)\n                print(\"获取到了StepFailedEvent\")\n                return {\"gap\": gap, \"result\": all_messages}\n\n        # 4. fallback，兜底\n        print(\"如果gap no result found，以下会被打印：\")\n        # print(f\"[DEBUG][search_gap] gap: {gap} No result found.\") #test\n        # return {\"gap\": gap, \"error\": \"No result\"}\n        all_messages.append(\"No result\")\n        return {\"gap\": gap, \"result\": all_messages}\n\n\n    #为gap执行结果打分，打分为boolean值\n    async def score_gap(self, gap: str, result: dict, eval_types: list = None) -> (bool, str):\n\n        #print(\"score_gap 评价结果 运行到了\")\n        \"\"\"\n        判断搜索结果是否满足gap问题，返回(bool, summary)\n        \"\"\"\n\n        #这里改为根据eval_types选择prompt\n        #遍历eval_types，检查是否每个eval_type都通过\n        satisfied=True\n        reason=\"\"\n        for eval_type in eval_types:\n            eval_type=eval_type\n            question=gap\n            answer_action=result.get('result', '')[:1000]\n            relevant_knowledge=[\"none\"]\n            system_prompt, user_prompt = self._get_prompts(\n                eval_type, question, answer_action, relevant_knowledge\n            )\n\n            messages = [\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt},\n            ]\n            #print(f'为gap评分时的message{messages}')\n            response = await self.llm.ask(messages)\n            #print(response.content)\n            # print(\"score_gap debug内容\")\n            # print(response) #test\n            try:\n                data = json.loads(response.content)\n                passed = data.get(\"pass\", False)\n                if not passed:\n                    satisfied=False\n                reason = reason+data.get(\"think\", \"\")\n            except Exception as e:\n                # 解析失败时降级为“不满足”，并输出原始内容\n                satisfied=False\n                reason=reason+f\"LLM判分输出无法解析，原始内容：{getattr(response, 'content', '')}\"\n        #print(f'satisfied: {satisfied}, reason: {reason}, gap{gap}')\n        return satisfied, reason\n\n\n    def _get_prompts(\n        self,\n        eval_type: str,\n        question: str,\n        answer_action: str,\n        knowledge: List[str],\n    ) -> tuple[str, str]:\n        \"\"\"获取评估类型的提示词模板\"\"\"\n        if eval_type == \"strict\":\n            system_prompt = prompt.REJECT_ALL_ANSWERS_PROMPT_SYSTEM.format(\n                knowledge_str=\"\\n\".join(knowledge)\n            )\n            user_prompt = prompt.REJECT_ALL_ANSWERS_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"definitive\":\n            system_prompt = prompt.DEFEINITE_PROMPT_SYSTEM\n            user_prompt = prompt.DEFEINITE_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"freshness\":\n            system_prompt = prompt.FRESHNESS_PROMPT_SYSTEM.format(\n                currentTime=datetime.now().isoformat()\n            )\n            user_prompt = prompt.FRESHNESS_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"completeness\":\n            system_prompt = prompt.COMPLETENESS_PROMPT_SYSTEM\n            user_prompt = prompt.COMPLETENESS_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"plurality\":\n            system_prompt = prompt.PLURALITY_PROMPT_SYSTEM\n            user_prompt = prompt.PLURALITY_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"basic\":\n            system_prompt = prompt.BASIC_PROMPT_SYSTEM\n            user_prompt = prompt.BASIC_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        elif eval_type == \"file\":\n            system_prompt = prompt.FILE_PROMPT_SYSTEM\n            user_prompt = prompt.FILE_PROMPT_USER.format(\n                question=question, answer=answer_action\n            )\n        else:\n            raise ValueError(f\"未知的评估类型: {eval_type}\")\n\n        return system_prompt, user_prompt\n\n\n    #analyze分析本次gap执行错误的原因\n    async def analyze_gap(self, gap: str, result: dict, reason:str) -> str:\n        #print(\"analyze_gap 分析失败原因 运行到了\")\n        \"\"\"\n        分析gap未被解决的原因，返回分析文本\n        \"\"\"\n        prompt = f\"\"\"\n    你是一个问题诊断专家。现在有一个子问题未能通过已有搜索内容得到解答，请分析原因，并用一句话简明扼要地说明。不要输出多余内容。\n\n    子问题：{gap}\n    搜索内容：{result.get('result', '')[:1000]}\n    对该子问题未成功解决的简单分析{reason}\n    未解决原因：\n    \"\"\"\n        messages = [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        #print(f'分析问题失败原因的message{messages}')\n        response = await self.llm.ask(messages)\n        # 直接返回 LLM 输出内容\n        return getattr(response, \"content\", \"\").strip()\n\n    #reflect负责根据失败原因提供新的gap\n    async def reflect_gap(self, gap: str, error_reason: str) -> list[str]:\n        \"\"\"\n        用LLM结合gap和失败原因，生成新的gap（子问题）或改进的检索表达。\n        \"\"\"\n        #print(\"运行到反射错误问题！！！！！！！！！！！！！！！！！！！！！！！！！！！！\")\n\n        current_time = datetime.now()  # 当前本地时间，类型为datetime对象\n        current_year = current_time.year  # 当前年份，整数\n        current_month = current_time.month\n\n        system_prompt = prompt.QUERY_REWRITE_PROMPT_SYSTEM.format(\n            currentTime=current_time.isoformat(),\n            currentYear=current_year,\n            currentMonth=current_month\n        )\n        user_message = prompt.QUERY_REWRITE_PROMPT_USER.format(\n            query=gap,\n            think=\"分析用户搜索意图，生成更精确的查询\",\n            context=error_reason\n        )\n        messages = [\n            {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + user_message},\n        ]\n        #print(f'反射新gap的message{messages}')\n        response = await self.llm.ask(messages)\n        print(\"成功获取llm返回的新gaps，raw\")\n        print(response.content)\n        try:\n            data = json.loads(response.content)\n            queries = data.get(\"queries\", [])\n            gaps = []\n            for query in queries:\n                print(\"开始将返回内容格式化为query\")\n                if isinstance(query, dict):\n                    # 按字段顺序拼成 \"key1:value1 key2:value2 ...\"\n                    fields = [f\"{k}:{str(v)}\" for k, v in query.items() if str(v).strip()]\n                    if fields:\n                        gaps.append(\" \".join(fields))\n                        print(\"gaps已经成功append\")\n                        print(fields)\n            return gaps\n        except Exception as e:\n            print(\"解析失败:\", e)\n            return []\n\n    #reflect batch负责一整轮gap结束后的反思以及提供新gap，实现一个简单的没有plan的递进\n    async def reflect_gap_batch(self, failed_gaps_info: list[dict]) -> list[str]:\n        \"\"\"\n        批量反射：输入多组gap及分析，生成新gap列表\n        \"\"\"\n        current_time = datetime.now()\n        prompt_lines = []\n        for i, info in enumerate(failed_gaps_info, 1):\n            prompt_lines.append(\n                f\"{i}. 子问题: {info['gap']}\\n失败原因: {info['error_reason']}\\n执行器内容: {self.format_search_result(info['executor_result'])}\\n\"\n            )\n        prompt_str = \"\\n\".join(prompt_lines) #本轮子问题以及失败原因，用于生成新gap\n        system_prompt = prompt.QUERY_REWRITE_PROMPT_SYSTEM.format(\n            currentTime=current_time.isoformat(),\n            currentYear=current_time.year,\n            currentMonth=current_time.month\n        )\n        user_message = prompt.QUERY_REWRITE_PROMPT_USER.format(\n            query_group=prompt_str,\n        )\n        #user_message = f\"以下是本轮未解决的子问题、失败原因和相关内容，请针对每个子问题，结合失败原因给出更精确、可直接搜索的新子问题表达，输出如下格式JSON：\\n{{\\n  \\\"queries\\\": [\\\"新子问题1\\\", \\\"新子问题2\\\", ...]\\n}}\\n\\n{prompt_str}\"\n        messages = [\n            {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + user_message},\n        ]\n        response = await self.llm.ask(messages)\n        try:\n            data = json.loads(response.content)\n            return [str(q).strip() for q in data.get(\"queries\", []) if q]\n        except Exception as e:\n            print(\"批量reflect解析失败:\", e)\n            return []\n\n\n    #为避免出现过于相似或者重复的gap，generate后使用filter去重\n    def _filter_and_update_gaps(self, gaps, new_gaps=None):\n        #print(\"过滤更新 运行到了\")\n        \"\"\"\n        对gaps去重，并更新已处理过的gaps集合。\n        如果提供了new_gaps，则只处理new_gaps，否则处理gaps。\n        返回未被处理过的新gap列表。\n        \"\"\"\n        target_gaps = new_gaps if new_gaps is not None else gaps\n        filtered = [g for g in target_gaps if g not in self.processed_gaps]\n        self.processed_gaps.update(filtered)\n        return filtered\n\n    #此处规范化result，保证知识库内信息不为空\n    def format_search_result(self, result: dict) -> str:\n        #print(\"格式化结果 运行到了\")\n        \"\"\"\n        泛用型，将搜索结果dict转为可读文本。\n        1. 如果是字符串，直接返回；\n        2. 如果是列表，则递归格式化每项，合并输出；\n        3. 如果是dict，尝试读取常见字段，如title、content、summary等，并递归格式化；\n        4. 如果有error，则优先返回error文本；\n        5. 其它类型，直接转字符串。\n        \"\"\"\n        if not result:\n            return \"（无搜索结果）\"\n        if isinstance(result, str):\n            return result.strip()\n        if isinstance(result, list):\n            # 多条结果，递归格式化每条\n            return \"\\n\".join(self.format_search_result(item) for item in result)\n        if isinstance(result, dict):\n            if \"error\" in result and result[\"error\"]:\n                return f\"查询失败：{result['error']}\"\n            # 优先展示result字段\n            if \"result\" in result:\n                # result字段本身可能是字符串、dict或list\n                return self.format_search_result(result[\"result\"])\n            # 常见内容字段\n            text_pieces = []\n            for key in (\"title\", \"question\", \"summary\", \"content\", \"description\", \"answer\"):\n                if key in result and result[key]:\n                    text_pieces.append(str(result[key]).strip())\n            # 其它字段也拼一下\n            other_keys = [k for k in result if\n                          k not in (\"title\", \"question\", \"summary\", \"content\", \"description\", \"answer\", \"error\",\n                                    \"result\") and result[k]]\n            for k in other_keys:\n                text_pieces.append(f\"{k}: {result[k]}\")\n            if text_pieces:\n                return \"\\n\".join(text_pieces)\n            # 如果没有可用字段，直接输出dict\n            return str(result)\n        # 其它类型\n        return str(result)\n\n    #最后一步，生成最终报告\n    async def generate_final_answer(self, global_question: str, knowledge: list[dict]) -> (str, bool):\n        print(\"生成最终答案 运行到了\")\n        \"\"\"\n        用LLM综合知识库和global question生成最终答案，并判断是否还需补充信息。\n        返回：(最终答案, 需补充True/False)\n        \"\"\"\n        # 将知识库内容整理成可阅读的字符串\n        knowledge_text = \"\\n\\n\".join(\n            f\"【子问题】：{item.get('gap', '')}\\n【内容】：{item.get('summary', '')}\" for item in knowledge\n        )\n\n        prompt = f\"\"\"\n    你现在是一位专业问答助手。请根据下方已收集的知识点，回答全局问题。\n    如果你认为已有知识完全可以支持准确回答，请给出最终答案，并标记\"need_more\"为false；如果你认为知识还不够，无法回答或有重大遗漏，请标记\"need_more\"为true，并简要说明原因。\n    只允许输出如下JSON格式（不要有任何其他内容）：\n\n    {{\n      \"answer\": \"最终答案内容\",\n      \"need_more\": true/false,\n      \"reason\": \"如需补充知识，说明原因，否则可省略\"\n    }}\n\n    全局问题：{global_question}\n\n    知识库内容：\n    {knowledge_text}\n    \"\"\"\n        messages = [\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        #print(f'最终答案生成message{messages}')\n        response = await self.llm.ask(messages)\n        try:\n            data = json.loads(response.content)\n            answer = data.get(\"answer\", \"\").strip()\n            need_more = bool(data.get(\"need_more\", False))\n            print(\"最终答案生成成功\")\n            return answer, need_more\n        except Exception:\n            # 解析失败时降级为“无法回答，需补充”\n            return \"（无法解析LLM的回答，请补充知识）\", True\n\n    # ========== 可选 summary/report 接口 ==========\n    # 两个方法视情况使用，目前在代码中并未用到\n\n    async def summarize_execution(self) -> AsyncGenerator[AgentEvent, None]:\n        yield MessageEvent(message=\"搜索流程执行总结\")\n        # 可以输出 self.knowledge 等\n\n    async def generate_report(self) -> AsyncGenerator[AgentEvent, None]:\n        yield MessageEvent(message=\"搜索流程最终报告\")\n",
      "methods": [
        "<module>.SearchFlow.__init__",
        "<module>.SearchFlow.is_idle",
        "<module>.SearchFlow.run",
        "<module>.SearchFlow.select_scoring_mode",
        "<module>.SearchFlow.generate_gaps",
        "<module>.SearchFlow.search_gap",
        "<module>.SearchFlow.score_gap",
        "<module>.SearchFlow._get_prompts",
        "<module>.SearchFlow.analyze_gap",
        "<module>.SearchFlow.reflect_gap",
        "<module>.SearchFlow.reflect_gap_batch",
        "<module>.SearchFlow._filter_and_update_gaps",
        "<module>.SearchFlow.format_search_result",
        "<module>.SearchFlow.generate_final_answer",
        "<module>.SearchFlow.summarize_execution",
        "<module>.SearchFlow.generate_report"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/code_flow.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/code_flow.py",
      "name": "CodeFlow",
      "qualname": "<module>.CodeFlow",
      "source": "class CodeFlow(BaseSubFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"code\"\n    description = \"子计划规划流程：先创建子计划，然后逐步执行，支持动态更新子计划\"\n    \n    def __init__(\n        self,\n        llm: LLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n        task_type: Enum = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_flow_logger = setup_sub_planner_flow_logger(f\"sub_planner_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_flow_logger.info(f\"=== CodeFlow初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        self.sub_planner_flow_logger.info(f\"=== CodeFlow.__init__ 开始 ===\")\n        self.sub_planner_flow_logger.info(f\"接收到的参数:\")\n        self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n        self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n        self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n        self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n        self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.execution_result=Memory()\n        if task_type:\n            self.sub_planner_flow_logger.info(f\"task_type.value: {task_type.value}\")\n            self.sub_planner_flow_logger.info(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 调用父类构造函数\n        super().__init__(\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            task_type=task_type,\n        )\n        \n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        self.sub_planner_flow_logger.info(f\"=== 开始创建SubPlannerAgent ===\")\n        \n        try:\n            # 创建子规划器代理\n            self.sub_planner_flow_logger.info(f\"准备创建SubPlannerAgent，参数:\")\n            self.sub_planner_flow_logger.info(f\"  llm: {llm}\")\n            self.sub_planner_flow_logger.info(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n            self.sub_planner_flow_logger.info(f\"  sandbox: {sandbox}\")\n            self.sub_planner_flow_logger.info(f\"  browser: {browser}\")\n            self.sub_planner_flow_logger.info(f\"  search_engine: {search_engine}\")\n            \n            self.sub_planner = SubPlannerAgent(\n                llm=llm,\n                task_type=task_type,\n                memory=Memory(),\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n            )\n            self.sub_planner.system_prompt = PromptManager.get_system_prompt_with_tools(self.sub_planner.tools, is_executor=False, is_code=True)\n            self.sub_planner.system_prompt = PromptManager.insert_datetime(self.sub_planner.system_prompt)\n            self.sub_planner_flow_logger.info(\"创建SubPlanner Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建SubPlannerAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        try:\n            self.sub_planner_flow_logger.info(f\"=== 开始创建ExecutionAgent ===\")\n            # 创建执行代理\n            self.executor = ExecutionAgent(\n                memory=Memory(),\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                type_value=task_type.value\n            )\n            \n            self.sub_planner_flow_logger.info(\"创建Execution Agent完成\")\n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"创建ExecutionAgent失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    async def run(\n        self,\n        parent_plan: Plan,\n        parent_step: Step,\n        parent_memory: Memory,\n        task_type: Enum\n    ) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行子计划流程\n        \n        Args:\n            parent_plan: 父规划器当前的计划\n            parent_step: 要执行的步骤\n            parent_memory: 父规划器当前的记忆\n            task_type: 当前步骤的任务类型\n        \"\"\"\n        \n        self.sub_planner.fix(parent_plan,parent_step)\n\n        self.sub_planner_flow_logger.info(f\"=== 开始执行子计划 ===\")\n        self.sub_planner_flow_logger.info(f\"父计划ID: {parent_plan.id}\")\n        self.sub_planner_flow_logger.info(f\"父步骤ID: {parent_step.id}\")\n        self.sub_planner_flow_logger.info(f\"任务类型: {task_type.value}\")\n        \n        # 根据传入的task_type更新提示词\n        self.sub_planner_flow_logger.info(f\"=== 开始更新系统提示词 ===\")\n        \n        try:\n            updated_system_prompt = self.sub_planner.system_prompt\n            updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n            updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n            self.sub_planner.system_prompt = PromptManager.insert_datetime(updated_system_prompt)\n            # Debug: print\n            # TODO: remove this\n            self.sub_planner_flow_logger.info(f\"updated_system_prompt: {updated_system_prompt}\")\n            \n        except Exception as e:\n            self.sub_planner_flow_logger.error(f\"更新系统提示词失败: {str(e)}\")\n            self.sub_planner_flow_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_flow_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            # 继续执行，不因为提示词更新失败而中断整个流程\n            \n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.sub_planner.roll_back()\n            self.executor.roll_back()\n            self.sub_planner_flow_logger.info(\"中断当前流程，重新开始规划\")\n\n        # 使用父步骤的描述作为输入消息\n        message = parent_step.description\n        logger.info(f\"开始处理步骤: {message[:50]}...\")\n        \n        # 创建子计划\n        self.status = AgentStatus.PLANNING\n        self.sub_planner_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n        \n        \n        async for event in self.sub_planner.create_plan(message):\n            \n            if isinstance(event, PlanCreatedEvent):\n                self.plan = event.plan\n                logger.info(f\"创建子计划成功，包含 {len(event.plan.steps)} 个步骤\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划创建成功 ===\")\n                self.sub_planner_flow_logger.info(f\"子计划ID: {event.plan.id}\")\n                self.sub_planner_flow_logger.info(f\"子计划目标: {event.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"子计划标题: {event.plan.title}\")\n                self.sub_planner_flow_logger.info(f\"子计划步骤数量: {len(event.plan.steps)}\")\n                for i, step in enumerate(event.plan.steps, 1):\n                    self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}\")\n                if event.plan.message:\n                    self.sub_planner_flow_logger.info(f\"子计划说明: {event.plan.message}\")\n            elif isinstance(event, MessageEvent):\n                self.sub_planner_flow_logger.info(f\"Planner输出: {event.message}\")\n            yield event\n            \n        self.status = AgentStatus.EXECUTING\n        self.sub_planner_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n        \n        # 执行子计划\n        while True:\n            if self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"子计划执行完成，状态变更: EXECUTING -> REPORTING\")\n                    self.status = AgentStatus.REPORTING\n                    self.sub_planner_flow_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                \n                # 执行步骤\n                logger.info(f\"开始执行步骤 {step.id}: {step.description[:50]}...\")\n                self.sub_planner_flow_logger.info(f\"=== 开始执行步骤 ===\")\n                self.sub_planner_flow_logger.info(f\"步骤ID: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤描述: {step.description}\")\n                self.sub_planner_flow_logger.info(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    \n                    updated_system_prompt = self.executor.system_prompt\n                    updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.executor.shell_tool)\n                    updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.executor.memory)\n                    \n                    self.executor.system_prompt = updated_system_prompt\n                    if isinstance(event, ToolCallingEvent):\n                        self.sub_planner_flow_logger.info(f\"工具调用: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.sub_planner_flow_logger.info(f\"工具结果: {event.tool_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具函数: {event.function_name}\")\n                        self.sub_planner_flow_logger.info(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.sub_planner_flow_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"Executor输出: {event.message}\")\n                        # 将执行结果保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n                        \n                logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                self.sub_planner_flow_logger.info(f\"步骤执行完成: {step.id}\")\n                self.sub_planner_flow_logger.info(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.sub_planner_flow_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.sub_planner_flow_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.sub_planner_flow_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为\n                self.sub_planner_flow_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    yield event\n                    if isinstance(event, MessageEvent):\n                        logger.info(f\"步骤总结完成: {event.message}\")\n                        previous_steps = event.message\n                        self.sub_planner_flow_logger.info(f\"步骤总结完成: {event.message}\")\n                        # 将总结保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                        \n                # 更新计划\n                self.sub_planner_flow_logger.info(f\"=== 开始更新子计划 ===\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.sub_planner_flow_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                updated_system_prompt = self.sub_planner.system_prompt\n                updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n                updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n                \n                self.sub_planner.system_prompt = updated_system_prompt\n                async for event in self.sub_planner.update_plan(self.plan, previous_steps):\n                    \n                    updated_system_prompt = self.sub_planner.system_prompt\n                    updated_system_prompt = await PromptManager.update_ls(updated_system_prompt, self.sub_planner.shell_tool)\n                    updated_system_prompt = PromptManager.update_mem(updated_system_prompt, self.sub_planner.memory)\n                    self.sub_planner.system_prompt = updated_system_prompt\n                    \n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.sub_planner_flow_logger.info(f\"=== 子计划更新完成 ===\")\n                        self.sub_planner_flow_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.sub_planner_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.sub_planner_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 将更新信息保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                    yield event\n\n                logger.info(f\"子计划更新完成，状态变更: UPDATING -> EXECUTING\")\n                self.status = AgentStatus.EXECUTING\n                self.sub_planner_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"子计划执行完成，准备生成报告\")\n                self.sub_planner_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                async for event in self.executor.report_result(message):\n                    if isinstance(event, MessageEvent):\n                        # 将报告保存到execution_result中\n                        self.execution_result.add_message({\n                            \"role\": \"assistant\",\n                            \"content\": event.message\n                        })\n                    yield event\n\n                yield ReportEvent(message=str(self.execution_result.get_messages()))\n                self.status = AgentStatus.COMPLETED\n                self.sub_planner_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"子计划执行完成\")\n                self.sub_planner_flow_logger.info(f\"=== 子计划执行完成 ===\")\n                self.sub_planner_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan,issubplan=True) \n                self.status = AgentStatus.IDLE\n                self.sub_planner_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n                \n        #yield DoneEvent()\n        \"\"\"需要声明另一种doneevent\"\"\"\n\n        \n        logger.info(f\"子计划处理完成\")\n        self.sub_planner_flow_logger.info(f\"=== 子计划处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.CodeFlow.__init__",
        "<module>.CodeFlow.run",
        "<module>.CodeFlow.is_idle",
        "<module>.CodeFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/factory.py",
      "name": "FlowFactory",
      "qualname": "<module>.FlowFactory",
      "source": "class FlowFactory:\n    \"\"\"Flow工厂类,负责管理和创建不同类型的flow\"\"\"\n    \n    def __init__(self):\n        # 注册所有可用的flow类型\n        self._flow_classes: Dict[str, Type[BaseFlow]] = {}\n        self._register_default_flows()\n    \n    def _register_default_flows(self):\n        \"\"\"注册默认的flow类型\"\"\"\n        self.register_flow(PlanActFlow)\n        self.register_flow(SimpleChatFlow)\n        # 延迟导入 SuperPlannerFlow 以避免循环导入\n        from app.domain.services.flows.super_flow import SuperFlow\n        self.register_flow(SuperFlow)\n        logger.info(\"已注册默认flow类型\")\n    \n    def register_flow(self, flow_class: Type[BaseFlow]) -> None:\n        \"\"\"注册新的flow类型\"\"\"\n        if not issubclass(flow_class, BaseFlow):\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须继承自BaseFlow\")\n        \n        flow_id = flow_class.get_flow_id()\n        if not flow_id:\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须定义flow_id\")\n        \n        if flow_id in self._flow_classes:\n            logger.warning(f\"Flow ID '{flow_id}' 已存在，将被覆盖\")\n        \n        self._flow_classes[flow_id] = flow_class\n        logger.info(f\"已注册flow类型: {flow_id} -> {flow_class.__name__}\")\n    \n    def create_flow(self, flow_id: str, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, \n                   browser: Browser, search_engine: Optional[SearchEngine] = None, \n                   **kwargs) -> BaseFlow:\n        \"\"\"根据flow_id创建对应的flow实例\"\"\"\n    \n        \n        if flow_id not in self._flow_classes:\n            available_flows = list(self._flow_classes.keys())\n            raise ValueError(f\"未知的flow类型: {flow_id}. 可用类型: {available_flows}\")\n        \n        flow_class = self._flow_classes[flow_id]\n        \n        try:\n            # 创建flow实例，传递所有必要的参数\n            flow_instance = flow_class(\n                agent=agent,\n                llm=llm,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                **kwargs\n            )\n            logger.info(f\"成功创建flow实例: {flow_id} for Agent {agent.id}\")\n            return flow_instance\n        except Exception as e:\n            logger.error(f\"创建flow实例失败: {flow_id}, 错误: {str(e)}\")\n            raise\n    \n    def get_available_flows(self) -> List[Dict[str, str]]:\n        \"\"\"获取所有可用的flow类型信息\"\"\"\n        flows = []\n        for flow_id, flow_class in self._flow_classes.items():\n            flows.append({\n                \"flow_id\": flow_id,\n                \"name\": flow_class.__name__,\n                \"description\": flow_class.get_description()\n            })\n        return flows\n    \n    def has_flow(self, flow_id: str) -> bool:\n        \"\"\"检查是否存在指定的flow类型\"\"\"\n        return flow_id in self._flow_classes\n    \n    def get_flow_class(self, flow_id: str) -> Optional[Type[BaseFlow]]:\n        \"\"\"获取指定flow_id对应的flow类\"\"\"\n        return self._flow_classes.get(flow_id)\n",
      "methods": [
        "<module>.FlowFactory.__init__",
        "<module>.FlowFactory._register_default_flows",
        "<module>.FlowFactory.register_flow",
        "<module>.FlowFactory.create_flow",
        "<module>.FlowFactory.get_available_flows",
        "<module>.FlowFactory.has_flow",
        "<module>.FlowFactory.get_flow_class"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/factory.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(Enum):\n    CODE = \"code\"\n    REASONING = \"reasoning\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/factory.py",
      "name": "SubFlowFactory",
      "qualname": "<module>.SubFlowFactory",
      "source": "class SubFlowFactory:\n    \"\"\"\n    子流程工厂类\n    负责创建和管理所有子流程实例\n    \"\"\"\n    \n    def __init__(self):\n        # 注册所有可用的子流程类型\n        self._flow_classes: Dict[str, Type[BaseSubFlow]] = {}\n        \n        # 设置专门的日志记录器\n        self.factory_logger = setup_sub_planner_flow_logger(\"SubFlowFactory\")\n        self.factory_logger.info(f\"=== SubFlowFactory初始化 ===\")\n        \n        # 注册默认流程\n        self._register_default_flows()\n    \n    def _register_default_flows(self):\n        \"\"\"注册默认的子流程类型\"\"\"\n        self.register_flow(DefaultFlow)\n        self.register_flow(SearchFlow)\n        self.register_flow(CodeFlow)\n        self.factory_logger.info(\"已注册默认子流程类型\")\n    \n    def register_flow(self, flow_class: Type[BaseSubFlow]) -> None:\n        \"\"\"注册新的子流程类型\"\"\"\n        if not issubclass(flow_class, BaseSubFlow):\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须继承自BaseSubFlow\")\n        \n        flow_id = flow_class.get_flow_id()\n        if not flow_id:\n            raise ValueError(f\"Flow类 {flow_class.__name__} 必须定义flow_id\")\n        \n        if flow_id in self._flow_classes:\n            self.factory_logger.warning(f\"Flow ID '{flow_id}' 已存在，将被覆盖\")\n        \n        self._flow_classes[flow_id] = flow_class\n        self.factory_logger.info(f\"已注册子流程类型: {flow_id} -> {flow_class.__name__}\")\n    \n    def create_flow(self,\n                    llm: LLM,\n                    task_type: Enum,\n                    sandbox: Sandbox,\n                    browser: Browser,\n                    search_engine: Optional[SearchEngine] = None,\n                    audio_llm: Optional[AudioLLM] = None,\n                    image_llm: Optional[ImageLLM] = None,\n                    video_llm: Optional[VideoLLM] = None,\n                    reason_llm: Optional[ReasonLLM] = None,\n                    ) -> BaseSubFlow:\n        \"\"\"根据任务类型创建对应的子流程实例\"\"\"\n        # 添加详细的调试日志\n        self.factory_logger.info(f\"=== create_flow 开始 ===\")\n        self.factory_logger.debug(f\"task_type 参数: {task_type}\")\n        self.factory_logger.debug(f\"task_type 类型: {type(task_type)}\")\n        self.factory_logger.debug(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 获取实际的 flow_type\n        flow_type = task_type.value\n       # self.factory_logger.info(f\"flow_type: {flow_type}\")\n      #  self.factory_logger.debug(f\"可用的flow类型: {list(self._flow_classes.keys())}\")\n            \n        # 重定向逻辑：所有 -> general sub flow\n        if flow_type == \"search\":\n            self.factory_logger.info(f\"flow_type {flow_type} 不重定向\")\n        elif flow_type == \"code\":\n            self.factory_logger.info(f\"flow_type {flow_type} 不重定向 \")\n        elif flow_type == \"file\":\n            self.factory_logger.info(f\"flow_type {flow_type} 重定向到general_flow\")\n            flow_type = \"default\"\n        elif flow_type == 'reasoning':\n            self.factory_logger.info(f\"flow_type {flow_type} 重定向到general_flow\")\n            flow_type = \"default\"\n        else:\n            available_flows = list(self._flow_classes.keys())\n            self.factory_logger.error(f\"未知的子流程类型: {flow_type}. 可用类型: {available_flows}\")\n            raise ValueError(f\"未知的子流程类型: {flow_type}. 可用类型: {available_flows}\")\n        \n        flow_class = self._flow_classes[flow_type]\n        self.factory_logger.debug(f\"选择的flow_class: {flow_class}\")\n        self.factory_logger.debug(f\"flow_class 类型: {type(flow_class)}\")\n        \n        try:\n            self.factory_logger.info(f\"=== 开始创建flow实例 ===\")\n            self.factory_logger.debug(f\"检查flow_class是否在预期列表中: {flow_class in [DefaultFlow, SearchFlow, CodeFlow]}\")\n            \n            # 针对不同子类传递不同参数\n            # self.factory_logger.debug(f\"使用完整参数创建flow实例\")\n            # self.factory_logger.debug(f\"传递的参数:\")\n            # self.factory_logger.debug(f\"llm: {llm}\")\n            # self.factory_logger.debug(f\"sandbox: {sandbox}\")\n            # self.factory_logger.debug(f\"browser: {browser}\")\n            # self.factory_logger.debug(f\"search_engine: {search_engine}\")\n            # self.factory_logger.debug(f\"task_type: {task_type} (类型: {type(task_type)})\")\n\n            flow_instance = flow_class(\n                llm=llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=search_engine,\n                audio_llm=audio_llm,\n                image_llm=image_llm,\n                video_llm=video_llm,\n                reason_llm=reason_llm,\n                task_type=task_type,\n            )\n            self.factory_logger.info(f\"成功创建子流程实例: {flow_type}\")\n            return flow_instance\n        except Exception as e:\n            self.factory_logger.error(f\"创建子流程实例失败: {flow_type}, 错误: {str(e)}\")\n            self.factory_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.factory_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n    \n    def get_available_flows(self) -> List[Dict[str, str]]:\n        \"\"\"获取所有可用的子流程类型信息\"\"\"\n        flows = []\n        for flow_id, flow_class in self._flow_classes.items():\n            flows.append({\n                \"flow_id\": flow_id,\n                \"name\": flow_class.__name__,\n                \"description\": flow_class.get_description()\n            })\n        return flows\n\n    def get_available_flows_enum(self,enum_name: str = \"SubPlannerType\") -> type[Enum]:\n        flows = self.get_available_flows()\n        # 构造枚举成员字典: { \"MESSAGE\": \"message\", ... }\n        enum_members = {}\n        for flow in flows:\n            raw_name = flow[\"name\"]\n            enum_key = raw_name.replace(\"Flow\", \"\").upper()\n            enum_value = flow[\"flow_id\"]\n            enum_members[enum_key] = enum_value\n\n        # 使用 type() + EnumMeta 创建类\n        return Enum(enum_name, enum_members)\n\n    def has_flow(self, flow_id: str) -> bool:\n        \"\"\"检查是否存在指定的子流程类型\"\"\"\n        return flow_id in self._flow_classes\n    \n    def get_flow_class(self, flow_id: str) -> Optional[Type[BaseSubFlow]]:\n        \"\"\"获取指定flow_id对应的子流程类\"\"\"\n        return self._flow_classes.get(flow_id)\n",
      "methods": [
        "<module>.SubFlowFactory.__init__",
        "<module>.SubFlowFactory._register_default_flows",
        "<module>.SubFlowFactory.register_flow",
        "<module>.SubFlowFactory.create_flow",
        "<module>.SubFlowFactory.get_available_flows",
        "<module>.SubFlowFactory.get_available_flows_enum",
        "<module>.SubFlowFactory.has_flow",
        "<module>.SubFlowFactory.get_flow_class"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/simple_chat.py",
      "name": "SimpleChatFlow",
      "qualname": "<module>.SimpleChatFlow",
      "source": "class SimpleChatFlow(BaseFlow):\n    \"\"\"简单聊天流程：直接与LLM对话，不进行计划和执行\"\"\"\n    \n    # 定义flow的唯一标识符\n    flow_id = \"simple_chat\"\n    description = \"简单聊天流程：直接与LLM对话，适用于简单的问答场景\"\n    \n    def __init__(self, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser, \n                 search_engine: Optional[SearchEngine] = None, **kwargs):\n        super().__init__(agent, **kwargs)\n        self.llm = llm\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self._is_idle = True\n        logger.debug(f\"Created SimpleChatFlow for Agent {self.agent.id}\")\n    \n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"执行简单聊天流程\"\"\"\n        self._is_idle = False\n        logger.info(f\"Agent {self.agent.id} started simple chat with message: {message[:50]}...\")\n        \n        try:\n            # 构建简单的提示词\n            prompt = f\"\"\"你是一个有用的AI助手。请回答用户的问题。\n\n用户问题: {message}\n\n请提供有用和准确的回答：\"\"\"\n            \n            # 调用LLM获取回复\n            response = await self.llm.ask(\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            # 发送回复事件\n            yield MessageEvent(message=response.content)\n            logger.info(f\"Agent {self.agent.id} completed simple chat response\")\n            \n        except Exception as e:\n            logger.error(f\"Agent {self.agent.id} simple chat failed: {str(e)}\")\n            yield MessageEvent(message=f\"抱歉，处理您的请求时出现错误：{str(e)}\")\n        \n        finally:\n            self._is_idle = True\n            yield DoneEvent()\n    \n    def is_idle(self) -> bool:\n        \"\"\"检查flow是否处于空闲状态\"\"\"\n        return self._is_idle ",
      "methods": [
        "<module>.SimpleChatFlow.__init__",
        "<module>.SimpleChatFlow.run",
        "<module>.SimpleChatFlow.is_idle"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/super_flow.py",
      "name": "FlowStatus",
      "qualname": "<module>.FlowStatus",
      "source": "class FlowStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/super_flow.py",
      "name": "SuperFlow",
      "qualname": "<module>.SuperFlow",
      "source": "class SuperFlow(BaseFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"TreeFLow\"\n    description = \"a flow that uses multiple planners to handle complex tasks\"\n\n    def __init__(self, agent: Agent, llm: LLM, sandbox: Sandbox, browser: Browser,\n                 search_engine: Optional[SearchEngine] = None, \n                 audio_llm: Optional[AudioLLM] = None,\n                 image_llm: Optional[ImageLLM] = None,\n                 video_llm: Optional[VideoLLM] = None,\n                 reason_llm: Optional[ReasonLLM] = None,\n                 **kwargs):\n        super().__init__(agent, **kwargs)\n        self.status = FlowStatus.IDLE\n\n        # 设置专门的日志记录器\n        self.super_flow_logger = setup_super_planner_flow_logger(\"SuperPlannerFlow\")\n        self.super_flow_logger.info(f\"=== SuperPlannerFlow初始化 Agent ID: {agent.id} ===\")\n\n        # 初始化可用的基础设施\n        self.llm = llm\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n\n        # 初始化planner memory\n        self.planner_memory = Memory()\n        # 初始化knowledge memory\n        self.knowledge = Memory()\n\n        # 创建 planer agent\n        self.planner_agent = PlannerAgent(\n            llm=llm,\n            memory = self.planner_memory,\n            knowledge=self.knowledge,\n        )\n        self.super_flow_logger.debug(f\"创建Planner Agent完成\")\n\n        self.report_agent = ReportAgent(\n            llm=llm,\n            memory = Memory(),\n            knowledge=self.knowledge,\n        )\n        self.super_flow_logger.debug(f\"创建Report Agent完成\")\n\n        # 创建 sub_flow_factory\n        from app.domain.services.flows.factory import sub_flow_factory\n        self.sub_flow_factory = sub_flow_factory\n        self.sub_flow_type = self.sub_flow_factory.get_available_flows_enum()\n\n        # 创建通知代理，通知用户进度\n        self.notifier = NotifyAgent(\n            llm=llm,\n            memory=Memory(),\n        )\n        self.super_flow_logger.debug(f\"创建Notify Agent完成\")\n\n        # 用于控制流和并发实现\n        # 按照并发组划分的sub planner\n        self.parallel_sub_flow_groups = None\n        # 记录使用过的sub planner\n        self.sub_flow_instance_used = []\n        # 管理活动的子规划器\n        self._active_sub_flow: Dict[str, BaseSubFlow] = {}\n        # 记录子规划器的执行历史\n        self._sub_flow_history: Dict[str, Dict] = {}\n\n\n    @staticmethod\n    def _determine_task_type(description: str) -> str:\n        \"\"\"\n        根据步骤描述确定流程类型\n        \"\"\"\n        description_lower = description.lower()\n        if any(cmd in description_lower for cmd in [\"run\", \"execute\", \"command\", \"shell\"]):\n            return \"code\"\n        elif any(cmd in description_lower for cmd in [\"browse\", \"visit\", \"web\", \"url\", \"search\", \"find\", \"lookup\"]):\n            return \"search\"\n        elif any(cmd in description_lower for cmd in [\"reason\", \"think\", \"analyze\", \"deduce\", \"infer\"]):\n            return \"reasoning\"\n        elif any(cmd in description_lower for cmd in [\"file\", \"document\", \"read\", \"write\", \"process\"]):\n            return \"file\"\n        else:\n            return \"search\" # 默认使用搜索流程\n\n\n    async def execute_step(self, step: Step) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        执行计划中的单个步骤\n        根据步骤类型创建对应的子流程并执行\n        \"\"\"\n        self.super_flow_logger.info(f\"执行子任务步骤 {step.id}: {step.description}\")\n        \n        # 确定任务类型\n        if step.sub_flow_type:\n            # 添加调试信息\n            self.super_flow_logger.debug(f\"step.sub_flow_type 类型: {type(step.sub_flow_type)}\")\n\n            # 标准化处理\n            if isinstance(step.sub_flow_type, str):\n                # 如果是字符串，转换为 SubPlannerType 枚举\n                task_type = self.sub_flow_type(step.sub_flow_type.lower())\n                self.super_flow_logger.debug(f\"字符串转换为枚举: {task_type}\")\n            else:\n                # 如果是枚举，直接使用\n                task_type = step.sub_flow_type\n                self.super_flow_logger.debug(f\"使用枚举: {task_type}\")\n\n            self.super_flow_logger.debug(f\"使用 SuperPlanner 指定的任务类型: {task_type}\")\n        else:\n            # 如果没有指定，才根据描述判断\n            task_type = self._determine_task_type(step.description)\n            self.super_flow_logger.debug(f\"根据描述推断的任务类型: {task_type}\")\n\n        # 创建新的子规划器 SubFlow\n        sub_flow = self.sub_flow_factory.create_flow(\n            llm=self.llm,\n            task_type=task_type,\n            sandbox=self.sandbox,\n            browser=self.browser,\n            search_engine=self.search_engine,\n            audio_llm=self.audio_llm,\n            image_llm=self.image_llm,\n            video_llm=self.video_llm,\n            reason_llm=self.reason_llm,\n        )\n\n        step.status = ExecutionStatus.RUNNING\n        yield StepStartedEvent(step=step, plan=self.plan)\n\n        try:\n            async for event in sub_flow.run(\n                parent_plan = self.plan,\n                parent_step = step,\n                parent_memory = self.knowledge,\n                task_type = task_type,\n            ):\n                # sub flow返回值处理 \n                if isinstance(event, ErrorEvent):\n                    step.status = ExecutionStatus.FAILED\n                    step.error = event.error\n                    yield StepFailedEvent(step=step, plan=self.plan)\n                    return\n\n                if isinstance(event, PauseEvent):\n                    yield event\n                    return\n\n                if isinstance(event, MessageEvent):\n                    step.status = ExecutionStatus.COMPLETED\n                    step.result = event.message\n                    yield StepCompletedEvent(step=step, plan=self.plan)\n                \n                # 只转发 ReportEvent，但转换为更简洁的消息\n                if isinstance(event, ReportEvent):\n                    yield MessageEvent(message=f\"✅ {step.description} - 完成\")\n                # 完全过滤掉实现细节：ToolCallingEvent, ToolCalledEvent, MessageEvent, \n                # PlanCreatedEvent, PlanUpdatedEvent, PlanCompletedEvent, DoneEvent\n                # ErrorEvent 和 PauseEvent 已在上面单独处理\n\n        except Exception as e:\n\n            step.status = ExecutionStatus.FAILED\n            step.error = str(e)\n            yield StepFailedEvent(step=step, plan=self.plan)\n            return\n\n        step.status = ExecutionStatus.COMPLETED\n\n\n    def _build_parallel_execution_groups(self) -> Optional[deque]:\n        # Concurrent Execution Groups\n        self.parallel_sub_flow_groups = []\n        prev_step = -1\n        for i in range(len(self.plan.steps)):\n            step = self.plan.steps[i]\n            try:\n                # 0. 跳过已完成或失败的步骤\n                if step.status in [ExecutionStatus.COMPLETED, ExecutionStatus.FAILED]:\n                    self.super_flow_logger.debug(\n                        f\"跳过已完成/失败的步骤 {step.id}: {step.description} (状态: {step.status})\")\n                    continue\n\n                # 1. 安全地处理 subplan_step 转换\n                if not step.sub_plan_step:\n                    self.super_flow_logger.error(f\"步骤 {step.id} 缺少 subplan_step 属性\")\n                    step.status = ExecutionStatus.FAILED\n                    step.error = \"Missing subplan_step attribute\"\n                    continue\n\n                try:\n                    cur_step = int(step.sub_plan_step)\n                except ValueError:\n                    self.super_flow_logger.error(\n                        f\"步骤 {step.id} 的 subplan_step 值 '{step.sub_plan_step}' 无法转换为整数\")\n                    step.status = ExecutionStatus.FAILED\n                    step.error = f\"Invalid subplan_step value: {step.sub_plan_step}\"\n                    continue\n\n                # 2. 检查步骤顺序\n                if cur_step < prev_step:\n                    error_msg = f\"步骤顺序错误：当前步骤 {step.id} (subplan_step={cur_step}) 小于前一步骤 (subplan_step={prev_step})\"\n                    self.super_flow_logger.error(error_msg)\n                    step.status = ExecutionStatus.FAILED\n                    step.error = error_msg\n                    continue\n\n                # 3. 正常的步骤处理逻辑\n                if cur_step > prev_step:\n                    # case 1: this step is a new step\n                    self.parallel_sub_flow_groups.append([step])\n                    prev_step = cur_step\n                elif cur_step == prev_step:\n                    # case 2: this step is the same step as the previous step\n                    self.parallel_sub_flow_groups[-1].append(step)\n\n            except Exception as e:\n                error_msg = f\"处理步骤 {step.id} 时发生错误: {str(e)}\"\n                self.super_flow_logger.error(error_msg)\n                step.status = ExecutionStatus.FAILED\n                step.error = error_msg\n                continue\n\n        self.parallel_sub_flow_groups = deque(self.parallel_sub_flow_groups)\n        self.super_flow_logger.info(\n            f\"构建了 {len(self.parallel_sub_flow_groups)} 个执行组，共 {sum(len(group) for group in self.parallel_sub_flow_groups)} 个待执行步骤\")\n\n\n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \n        self.super_flow_logger.info(f\"=== Super Flow开始处理用户消息 ===\")\n        self.super_flow_logger.info(f\"用户输入: {message}\")\n        step = None\n\n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = FlowStatus.PLANNING\n            self.planner_agent.roll_back()\n            self.report_agent.roll_back()\n            self.super_flow_logger.debug(\"中断当前流程，重新开始规划\")\n\n        while True:\n            if self.status == FlowStatus.IDLE:\n                self.status = FlowStatus.PLANNING\n                self.super_flow_logger.info(f\"状态变更: IDLE -> PLANNING\")\n\n                # 通知用户开始规划\n                async for event in self.notifier.notify_received_message(message):\n                  \n                    if not isinstance(event, MessageEvent):\n                        yield event\n\n            elif self.status == FlowStatus.PLANNING:\n                # 创建计划\n                self.super_flow_logger.info(f\"=== Super Flow开始创建计划 ===\")\n             #   self.super_flow_logger.debug(f\"Super Planner输入: {message}\")\n\n                async for event in self.planner_agent.create_plan(message):\n                    if isinstance(event, PlanCreatedEvent):\n                        self.plan = event.plan\n                        self.super_flow_logger.info(f\"=== 计划创建成功 ===\")\n                        self.super_flow_logger.debug(f\"计划ID: {event.plan.id}\")\n                        self.super_flow_logger.info(f\"计划目标: {event.plan.goal}\")\n                        self.super_flow_logger.debug(f\"计划标题: {event.plan.title}\")\n                        self.super_flow_logger.debug(f\"计划步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            self.super_flow_logger.debug(f\"步骤{i}: [{step.id}] {step.description}\")\n                        if event.plan.message:\n                            self.super_flow_logger.info(f\"计划说明: {event.plan.message}\")\n                    elif isinstance(event, MessageEvent):\n                        self.super_flow_logger.warning(f\"Planner输出MessageEvent: {event.message}\")\n               #     yield event\n\n                # 创建计划完成后，准备执行步骤\n                if self.plan:\n                    self._build_parallel_execution_groups()\n                    # 检查是否有任何步骤可以执行,如果没有进入报告阶段\n                    if not self.parallel_sub_flow_groups:\n                        self.super_flow_logger.info(\"没有剩余的待执行步骤，进入报告阶段\")\n                        self.status = FlowStatus.REPORTING\n                        continue\n                    # 状态转换到执行阶段\n                    self.status = FlowStatus.EXECUTING\n                    self.super_flow_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n\n            elif self.status == FlowStatus.EXECUTING:\n                self.plan.status = ExecutionStatus.RUNNING\n\n                if not self.parallel_sub_flow_groups:\n                    self.status = FlowStatus.REPORTING\n                    self.super_flow_logger.info(\"状态变更: EXECUTING -> REPORTING\")\n                    continue\n                # 并发处理\n                current_parallel_group = self.parallel_sub_flow_groups[0]  # 只查看，不弹出\n                self.super_flow_logger.info(f\"=== 开始执行步骤组（{len(current_parallel_group)}个步骤） ===\")\n                # 添加顺序执行逻辑\n                if current_parallel_group:  # 确保当前组还有步骤\n                    step = current_parallel_group.pop(0)  # 取出第一个步骤\n\n                    self.knowledge.add_message({\n                        'role': \"user\",\n                        'content': step.description\n                    })\n\n                    async for execute_event in self.execute_step(step=step):\n                        yield execute_event  # 传播 execute_step 内部过滤后的事件\n                        self.super_flow_logger.debug(f\"执行事件类型: {type(execute_event).__name__}\")\n\n                        if isinstance(execute_event, AgentEvent):\n                            event_type = type(execute_event).__name__\n                            self.super_flow_logger.debug(\"=\" * 50)\n                            self.super_flow_logger.debug(f\">>> 执行事件类型: {event_type} <<<\")\n                            self.super_flow_logger.debug(\"=\" * 50)\n\n                    self.knowledge.add_message({\n                        'role': \"assistant\",\n                        'content': step.result\n                    })\n\n                    self.knowledge.add_file(step.file)\n                    self.knowledge.add_web(step.web)\n\n                    # 每个步骤执行完后立即进入更新状态\n                    self.status = FlowStatus.UPDATING\n                    self.super_flow_logger.info(f\"步骤 {step.id} 执行完成，状态变更: EXECUTING -> UPDATING\")\n                \n                # 并发处理，如果当前组为空，移除它\n                if not current_parallel_group:\n                    self.parallel_sub_flow_groups.popleft()  # 安全地移除空组\n\n            elif self.status == FlowStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                # 更新计划\n                logger.info(f\"Agent {self.agent.id} started updating plan\")\n                self.super_flow_logger.info(f\"=== 开始更新计划 ===\")\n                async for event in self.planner_agent.update_plan(plan=self.plan, step=step):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.super_flow_logger.info(f\"=== 计划更新完成 ===\")\n                        self.super_flow_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.super_flow_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                        # 发送简洁的计划更新通知\n                        yield MessageEvent(message=f\"🔄 计划已更新，当前剩余{len([s for s in event.plan.steps if s.status == ExecutionStatus.PENDING])}个待执行步骤\")\n                    elif isinstance(event, MessageEvent):\n                        self.super_flow_logger.info(f\"计划更新输出: {event.message}\")\n                        # 不转发JSON格式的MessageEvent\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.super_flow_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                        # 转发重要的状态变化事件\n                        yield event\n\n                    # 创建计划完成后，准备执行步骤\n                    if self.plan:\n                        self._build_parallel_execution_groups()\n\n                        # 检查是否有任何步骤可以执行,如果没有进入报告阶段\n                        if not self.parallel_sub_flow_groups:\n                            self.super_flow_logger.info(\"没有剩余的待执行步骤，进入报告阶段\")\n                            self.status = FlowStatus.REPORTING\n                            continue\n                        # 状态转换到执行阶段\n                        self.status = FlowStatus.EXECUTING\n                        self.super_flow_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == FlowStatus.REPORTING:\n                logger.info(f\"Agent {self.agent.id} plan has been completed\")\n                self.super_flow_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                # 发送简洁的完成通知\n                yield MessageEvent(message=\"所有步骤已完成，正在生成最终报告...\")\n\n                # 生成最终报告\n                async for event in self.report_agent.generate_report(plan=self.plan):\n                    yield event\n\n                self.status = FlowStatus.COMPLETED\n                self.super_flow_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n\n            elif self.status == FlowStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                self.super_flow_logger.info(f\"=== 计划执行完成 ===\")\n                self.super_flow_logger.info(f\"最终计划状态: {self.plan.status}\")\n                yield PlanCompletedEvent(plan=self.plan, issuperplan=True)\n                self.status = FlowStatus.IDLE\n                self.super_flow_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n        yield DoneEvent()\n\n        logger.info(f\"Agent {self.agent.id} message processing completed\")\n        self.super_flow_logger.info(f\"=== 消息处理完成 ===\")\n\n    def is_idle(self) -> bool:\n        return self.status == FlowStatus.IDLE\n\n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(\n                f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n\n    def add_report_to_knowledge(self, current_report):\n        self.knowledge.add_message({\n            'role': \"assistant\",\n            'message': current_report\n        })\n\n    def add_step_to_knowledge(self, current_step):\n        self.knowledge.add_message({\n            'role': \"user\",\n            'message': current_step\n        })",
      "methods": [
        "<module>.SuperFlow.__init__",
        "<module>.SuperFlow._determine_task_type",
        "<module>.SuperFlow.execute_step",
        "<module>.SuperFlow._build_parallel_execution_groups",
        "<module>.SuperFlow.run",
        "<module>.SuperFlow.is_idle",
        "<module>.SuperFlow._show_plan",
        "<module>.SuperFlow.add_report_to_knowledge",
        "<module>.SuperFlow.add_step_to_knowledge"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/plan_act.py",
      "name": "AgentStatus",
      "qualname": "<module>.AgentStatus",
      "source": "class AgentStatus(str, Enum):\n    IDLE = \"idle\"\n    PLANNING = \"planning\"\n    EXECUTING = \"executing\"\n    COMPLETED = \"completed\"\n    UPDATING = \"updating\"\n    REPORTING = \"reporting\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/plan_act.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(Enum):\n    MESSAGE = \"message\"\n    SHELL = \"shell\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/flows/plan_act.py",
      "name": "PlanActFlow",
      "qualname": "<module>.PlanActFlow",
      "source": "class PlanActFlow(BaseFlow):\n    # 定义flow的唯一标识符\n    flow_id = \"plan_act\"\n    description = \"计划-执行流程：先创建计划，然后逐步执行，支持动态更新计划\"\n    \n    def __init__(self, agent: Agent, llm: LLM, audio_llm: AudioLLM, image_llm: ImageLLM, video_llm: VideoLLM, reason_llm: ReasonLLM, sandbox: Sandbox, browser: Browser, \n                 search_engine: Optional[SearchEngine] = None, **kwargs):\n        super().__init__(agent, **kwargs)\n        self.status = AgentStatus.IDLE\n        self.plan = None\n        \n        # 设置专门的日志记录器\n        self.plan_act_logger = setup_plan_act_logger(\"plan_act\")\n        self.plan_act_logger.info(f\"=== PlanActFlow初始化 Agent ID: {agent.id} ===\")\n        \n        # 创建计划代理和执行代理\n        self.planner = PlannerAgent(\n            llm=llm,\n            memory=agent.planner_memory,\n        )\n        logger.debug(f\"Created planner agent for Agent {self.agent.id}\")\n        self.plan_act_logger.info(f\"创建Planner Agent完成\")\n        \n        self.executor = ExecutionAgent(\n            llm=llm,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            memory=agent.execution_memory,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n        )\n        logger.debug(f\"Created execution agent for Agent {self.agent.id}\")\n        self.plan_act_logger.info(f\"创建Execution Agent完成\")\n        \n        # 创建通知代理，与执行代理共用memory\n        self.notifier = NotifyAgent(\n            llm=llm,\n            memory=Memory(),  # 与execution agent共用memory\n        )\n        logger.debug(f\"Created notify agent for Agent {self.agent.id}\")\n        self.plan_act_logger.info(f\"创建Notify Agent完成\")\n\n    async def run(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        self.plan_act_logger.info(f\"=== 开始处理用户消息 ===\")\n        self.plan_act_logger.info(f\"用户输入: {message}\")\n        \n        if not self.is_idle():\n            # interrupt the current flow\n            self.status = AgentStatus.PLANNING\n            self.planner.roll_back()\n            self.executor.roll_back()\n            self.notifier.roll_back()  # 同时回滚notify agent\n            self.plan_act_logger.info(\"中断当前流程，重新开始规划\")\n\n        logger.info(f\"Agent {self.agent.id} started processing message: {message[:50]}...\")\n        step = None\n        while True:\n            if self.status == AgentStatus.IDLE:\n                logger.info(f\"Agent {self.agent.id} state changed from {AgentStatus.IDLE} to {AgentStatus.PLANNING}\")\n                self.status = AgentStatus.PLANNING\n                self.plan_act_logger.info(f\"状态变更: IDLE -> PLANNING\")\n                \n                # 通知用户开始规划\n                async for event in self.notifier.notify_received_message(message):\n                    yield event\n                    \n            elif self.status == AgentStatus.PLANNING:\n                # 创建计划\n                logger.info(f\"Agent {self.agent.id} started creating plan\")\n                self.plan_act_logger.info(f\"=== 开始创建计划 ===\")\n                self.plan_act_logger.info(f\"Planner输入: {message}\")\n                \n                async for event in self.planner.create_plan(message):\n                    if isinstance(event, PlanCreatedEvent):\n                        self.plan = event.plan\n                        logger.info(f\"Agent {self.agent.id} created plan successfully with {len(event.plan.steps)} steps\")\n                        self.plan_act_logger.info(f\"=== 计划创建成功 ===\")\n                        self.plan_act_logger.info(f\"计划ID: {event.plan.id}\")\n                        self.plan_act_logger.info(f\"计划目标: {event.plan.goal}\")\n                        self.plan_act_logger.info(f\"计划标题: {event.plan.title}\")\n                        self.plan_act_logger.info(f\"计划步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            self.plan_act_logger.info(f\"步骤{i}: [{step.id}] {step.description}\")\n                        if event.plan.message:\n                            self.plan_act_logger.info(f\"计划说明: {event.plan.message}\")\n                    elif isinstance(event, MessageEvent):\n                        self.plan_act_logger.info(f\"Planner输出: {event.message}\")\n                    yield event\n                logger.info(f\"Agent {self.agent.id} state changed from {AgentStatus.PLANNING} to {AgentStatus.EXECUTING}\")\n                self.status = AgentStatus.EXECUTING\n                self.plan_act_logger.info(f\"状态变更: PLANNING -> EXECUTING\")\n                    \n            elif self.status == AgentStatus.EXECUTING:\n                # 执行计划\n                self.plan.status = ExecutionStatus.RUNNING\n                step = self.plan.get_next_step()\n                if not step:\n                    logger.info(f\"Agent {self.agent.id} has no more steps, state changed from {AgentStatus.EXECUTING} to {AgentStatus.REPORTING}\")\n                    self.status = AgentStatus.REPORTING\n                    self.plan_act_logger.info(f\"所有步骤执行完成，状态变更: EXECUTING -> REPORTING\")\n                    continue\n                    \n                # 执行步骤\n                logger.info(f\"Agent {self.agent.id} started executing step {step.id}: {step.description[:50]}...\")\n                self.plan_act_logger.info(f\"=== 开始执行步骤 ===\")\n                self.plan_act_logger.info(f\"步骤ID: {step.id}\")\n                self.plan_act_logger.info(f\"步骤描述: {step.description}\")\n                self.plan_act_logger.info(f\"Executor输入: 目标={self.plan.goal}, 步骤={step.description}\")\n                \n                async for event in self.executor.execute_step(self.plan, step, message):\n                    if isinstance(event, ToolCallingEvent):\n                        self.plan_act_logger.info(f\"工具调用: {event.tool_name}\")\n                        self.plan_act_logger.info(f\"工具函数: {event.function_name}\")\n                        self.plan_act_logger.info(f\"工具参数: {event.function_args}\")\n                    elif isinstance(event, ToolCalledEvent):\n                        self.plan_act_logger.info(f\"工具结果: {event.tool_name}\")\n                        self.plan_act_logger.info(f\"工具函数: {event.function_name}\")\n                        self.plan_act_logger.info(f\"工具输出: {event.function_result}\")\n                        if hasattr(event, 'error') and event.error:\n                            self.plan_act_logger.error(f\"工具错误: {event.error}\")\n                    elif isinstance(event, MessageEvent):\n                        self.plan_act_logger.info(f\"Executor输出: {event.message}\")\n                    yield event\n                        \n                logger.info(f\"Agent {self.agent.id} completed step {step.id}, state changed from {AgentStatus.EXECUTING} to {AgentStatus.UPDATING}\")\n                self.plan_act_logger.info(f\"步骤执行完成: {step.id}\")\n                self.plan_act_logger.info(f\"步骤状态: {step.status}\")\n                if step.result:\n                    self.plan_act_logger.info(f\"步骤结果: {step.result}\")\n                if step.error:\n                    self.plan_act_logger.error(f\"步骤错误: {step.error}\")\n                self.status = AgentStatus.UPDATING\n                self.plan_act_logger.info(f\"状态变更: EXECUTING -> UPDATING\")\n                \n            elif self.status == AgentStatus.UPDATING:\n                if self.plan.status == ExecutionStatus.PAUSED:\n                    break\n                    \n                # 执行Agent总结所作所为 / 压缩记忆上下文 / 获取浓缩的记忆，给到更新计划Agent\n                self.plan_act_logger.info(f\"=== 开始总结步骤 ===\")\n                previous_steps = \"\"\n                async for event in self.executor.summarize_steps():\n                    yield event\n                    if isinstance(event, MessageEvent):\n                        logger.info(f\"Agent {self.agent.id} summarized steps, message: {event.message}\")\n                        previous_steps = event.message\n                        self.plan_act_logger.info(f\"步骤总结完成: {event.message}\")\n                        \n                # 更新计划\n                logger.info(f\"Agent {self.agent.id} started updating plan\")\n                self.plan_act_logger.info(f\"=== 开始更新计划 ===\")\n                self.plan_act_logger.info(f\"计划更新输入 - 当前计划: {self.plan.model_dump_json(include={'steps'})}\")\n                self.plan_act_logger.info(f\"计划更新输入 - 目标: {self.plan.goal}\")\n                self.plan_act_logger.info(f\"计划更新输入 - 已完成步骤总结: {previous_steps}\")\n                \n                async for event in self.planner.update_plan(self.plan, previous_steps):\n                    if isinstance(event, PlanUpdatedEvent):\n                        self._show_plan(event.plan)\n                        self.plan_act_logger.info(f\"=== 计划更新完成 ===\")\n                        self.plan_act_logger.info(f\"更新后步骤数量: {len(event.plan.steps)}\")\n                        for i, step in enumerate(event.plan.steps, 1):\n                            status_info = f\" (状态: {step.status})\" if step.status != ExecutionStatus.PENDING else \"\"\n                            self.plan_act_logger.info(f\"步骤{i}: [{step.id}] {step.description}{status_info}\")\n                    elif isinstance(event, MessageEvent):\n                        self.plan_act_logger.info(f\"计划更新输出: {event.message}\")\n                    elif isinstance(event, PauseEvent):\n                        self.plan.status = ExecutionStatus.COMPLETED\n                        self.plan_act_logger.info(f\"状态变更: UPDATING -> COMPLETED\")\n                    yield event\n\n                logger.info(f\"Agent {self.agent.id} plan update completed, state changed from {AgentStatus.UPDATING} to {AgentStatus.EXECUTING}\")\n                self.status = AgentStatus.EXECUTING\n                self.plan_act_logger.info(f\"状态变更: UPDATING -> EXECUTING\")\n\n            elif self.status == AgentStatus.REPORTING:\n                logger.info(f\"Agent {self.agent.id} plan has been completed\")\n                self.plan_act_logger.info(f\"=== 正在准备最终报告 ===\")\n                \n                # 通知用户计划全部完成\n                async for notify_event in self.notifier.notify_plan_progress(self.plan, \"所有步骤已完成，正在准备最终报告\"):\n                    yield notify_event\n                    \n                async for event in self.executor.report_result(message):\n                    yield event\n                    \n                self.status = AgentStatus.COMPLETED\n                self.plan_act_logger.info(f\"状态变更: REPORTING -> COMPLETED\")\n                \n            elif self.status == AgentStatus.COMPLETED:\n                self.plan.status = ExecutionStatus.COMPLETED\n                logger.info(f\"Agent {self.agent.id} plan has been completed\")\n                self.plan_act_logger.info(f\"=== 计划执行完成 ===\")\n                self.plan_act_logger.info(f\"最终计划状态: {self.plan.status}\")\n                    \n                yield PlanCompletedEvent(plan=self.plan) \n                self.status = AgentStatus.IDLE\n                self.plan_act_logger.info(f\"状态变更: COMPLETED -> IDLE\")\n                break\n        yield DoneEvent()\n        \n        logger.info(f\"Agent {self.agent.id} message processing completed\")\n        self.plan_act_logger.info(f\"=== 消息处理完成 ===\")\n    \n    def is_idle(self) -> bool:\n        return self.status == AgentStatus.IDLE\n    \n    def _show_plan(self, plan: Plan):\n        logger.info(\"-\" * 30)\n        logger.info(f\"Plan ID: {plan.id}\")\n        logger.info(f\"Plan Goal: {plan.goal}\")\n        for step in plan.steps:\n            logger.info(f\"[{step.id}] {step.description}, Status: {step.status}, Result: {step.result}, Error: {step.error}\")\n        logger.info(\"-\" * 30)\n",
      "methods": [
        "<module>.PlanActFlow.__init__",
        "<module>.PlanActFlow.run",
        "<module>.PlanActFlow.is_idle",
        "<module>.PlanActFlow._show_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/prompts/prompt_manager.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(str, Enum):\n    \"\"\"\n    子规划器类型枚举\n    使用 str 作为基类以确保与 factory.py 和 sub_planner_flow.py 中的枚举兼容\n    \"\"\"\n    CODE = \"code\"\n    REASONING = \"reasoning\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/prompts/prompt_manager.py",
      "name": "PromptManager",
      "qualname": "<module>.PromptManager",
      "source": "class PromptManager:\n    \"\"\"\n    提示词管理器，负责根据任务类型选择合适的提示词\n    \"\"\"\n    \n    @staticmethod\n    def _get_task_value(task_type) -> str:\n        \"\"\"\n        安全地获取任务类型的值\n        \n        Args:\n            task_type: 任务类型，可以是枚举、字符串或其他类型\n            \n        Returns:\n            str: 任务类型的字符串值\n        \"\"\"\n        try:\n            if isinstance(task_type, Enum):\n                return task_type.value\n            elif isinstance(task_type, str):\n                # 检查是否是有效的任务类型值\n                valid_values = [t.value for t in SubPlannerType]\n                if task_type in valid_values:\n                    return task_type\n                logger.warning(f\"无效的任务类型字符串: {task_type}，使用默认值\")\n            elif hasattr(task_type, 'value'):\n                return task_type.value\n            else:\n                logger.warning(f\"未知的任务类型: {task_type}，使用默认值\")\n                return str(task_type)\n        except Exception as e:\n            logger.error(f\"获取任务类型值失败: {str(e)}\")\n            return SubPlannerType.MESSAGE.value  # 默认返回 message\n    \n    @staticmethod\n    def get_subplanner_prompt(task_type) -> str:\n        \"\"\"\n        根据任务类型获取对应的 SubPlanner 系统提示词\n        \n        Args:\n            task_type: 任务类型，可以是枚举、字符串或其他类型\n            \n        Returns:\n            str: 对应的系统提示词\n        \"\"\"\n        try:\n            task_value = PromptManager._get_task_value(task_type)\n            \n            if task_value == SubPlannerType.CODE.value:\n                from app.domain.services.prompts.code_sub_planner_prompt import CODE_SUB_PLANNER_SYSTEM_PROMPT\n                return CODE_SUB_PLANNER_SYSTEM_PROMPT\n            elif task_value == SubPlannerType.FILE.value:\n                from app.domain.services.prompts.file_sub_planner_prompt import FILE_SUB_PLANNER_SYSTEM_PROMPT\n                return FILE_SUB_PLANNER_SYSTEM_PROMPT\n            elif task_value == SubPlannerType.SEARCH.value:\n                from app.domain.services.prompts.search_sub_planner_prompt import SEARCH_SUB_PLANNER_SYSTEM_PROMPT\n                return SEARCH_SUB_PLANNER_SYSTEM_PROMPT\n            elif task_value == SubPlannerType.REASONING.value:\n                from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_SYSTEM_PROMPT\n                return REASONING_SUB_PLANNER_SYSTEM_PROMPT\n                \n        except Exception as e:\n            logger.error(f\"获取 SubPlanner 提示词失败: {str(e)}\")\n            from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_SYSTEM_PROMPT\n            return REASONING_SUB_PLANNER_SYSTEM_PROMPT\n\n    @staticmethod\n    def get_create_plan_prompt(task_type) -> str:\n        \"\"\"\n        根据任务类型获取创建计划的提示词\n        \"\"\"\n        try:\n            task_value = PromptManager._get_task_value(task_type)\n            \n            if task_value == SubPlannerType.CODE.value:\n                from backend.app.domain.services.prompts.code_sub_planner_prompt import CODE_SUB_PLANNER_CREATE_PLAN_PROMPT\n                return CODE_SUB_PLANNER_CREATE_PLAN_PROMPT\n            elif task_value == SubPlannerType.FILE.value:\n                from app.domain.services.prompts.file_sub_planner_prompt import FILE_SUB_PLANNER_CREATE_PLAN_PROMPT\n                return FILE_SUB_PLANNER_CREATE_PLAN_PROMPT\n            elif task_value == SubPlannerType.SEARCH.value:\n                from app.domain.services.prompts.search_sub_planner_prompt import SEARCH_SUB_PLANNER_CREATE_PLAN_PROMPT\n                return SEARCH_SUB_PLANNER_CREATE_PLAN_PROMPT\n            elif task_value == SubPlannerType.REASONING.value:\n                from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_CREATE_PLAN_PROMPT\n                return REASONING_SUB_PLANNER_CREATE_PLAN_PROMPT\n\n                \n        except Exception as e:\n            logger.error(f\"获取创建计划提示词失败: {str(e)}\")\n            from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_CREATE_PLAN_PROMPT\n            return REASONING_SUB_PLANNER_CREATE_PLAN_PROMPT\n\n    @staticmethod\n    def get_update_plan_prompt(task_type) -> str:\n        \"\"\"\n        根据任务类型获取更新计划的提示词\n        \"\"\"\n        try:\n            task_value = PromptManager._get_task_value(task_type)\n            \n            if task_value == SubPlannerType.CODE.value:\n                from backend.app.domain.services.prompts.code_sub_planner_prompt import CODE_SUB_PLANNER_UPDATE_PLAN_PROMPT\n                return CODE_SUB_PLANNER_UPDATE_PLAN_PROMPT\n            elif task_value == SubPlannerType.FILE.value:\n                from app.domain.services.prompts.file_sub_planner_prompt import FILE_SUB_PLANNER_UPDATE_PLAN_PROMPT\n                return FILE_SUB_PLANNER_UPDATE_PLAN_PROMPT\n            elif task_value == SubPlannerType.SEARCH.value:\n                from app.domain.services.prompts.search_sub_planner_prompt import SEARCH_SUB_PLANNER_UPDATE_PLAN_PROMPT\n                return SEARCH_SUB_PLANNER_UPDATE_PLAN_PROMPT\n            elif task_value == SubPlannerType.REASONING.value:\n                from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_UPDATE_PLAN_PROMPT\n                return REASONING_SUB_PLANNER_UPDATE_PLAN_PROMPT\n\n                \n        except Exception as e:\n            logger.error(f\"获取更新计划提示词失败: {str(e)}\")\n            from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_UPDATE_PLAN_PROMPT\n            return REASONING_SUB_PLANNER_UPDATE_PLAN_PROMPT\n\n    @staticmethod\n    def get_execute_prompt(task_type) -> str:\n        \"\"\"\n        根据任务类型获取执行任务的提示词\n        \"\"\"\n        try:\n            task_value = PromptManager._get_task_value(task_type)\n            \n            if task_value == SubPlannerType.CODE.value:\n                from backend.app.domain.services.prompts.code_sub_planner_prompt import CODE_SUB_PLANNER_EXECUTE_PROMPT\n                return CODE_SUB_PLANNER_EXECUTE_PROMPT\n            elif task_value == SubPlannerType.FILE.value:\n                from app.domain.services.prompts.file_sub_planner_prompt import FILE_SUB_PLANNER_EXECUTE_PROMPT\n                return FILE_SUB_PLANNER_EXECUTE_PROMPT\n            elif task_value == SubPlannerType.SEARCH.value:\n                from app.domain.services.prompts.search_sub_planner_prompt import SEARCH_SUB_PLANNER_EXECUTE_PROMPT\n                return SEARCH_SUB_PLANNER_EXECUTE_PROMPT\n            elif task_value == SubPlannerType.REASONING.value:\n                from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_EXECUTE_PROMPT\n                return REASONING_SUB_PLANNER_EXECUTE_PROMPT\n\n                \n        except Exception as e:\n            logger.error(f\"获取执行任务提示词失败: {str(e)}\")\n            from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_EXECUTE_PROMPT\n            return REASONING_SUB_PLANNER_EXECUTE_PROMPT\n\n    @staticmethod\n    def get_summarize_prompt(task_type) -> str:\n        \"\"\"\n        根据任务类型获取总结执行的提示词\n        \"\"\"\n        try:\n            task_value = PromptManager._get_task_value(task_type)\n            \n            if task_value == SubPlannerType.CODE.value:\n                from backend.app.domain.services.prompts.code_sub_planner_prompt import CODE_SUB_PLANNER_SUMMARIZE_PROMPT\n                return CODE_SUB_PLANNER_SUMMARIZE_PROMPT\n            elif task_value == SubPlannerType.FILE.value:\n                from app.domain.services.prompts.file_sub_planner_prompt import FILE_SUB_PLANNER_SUMMARIZE_PROMPT\n                return FILE_SUB_PLANNER_SUMMARIZE_PROMPT\n            elif task_value == SubPlannerType.SEARCH.value:\n                from app.domain.services.prompts.search_sub_planner_prompt import SEARCH_SUB_PLANNER_SUMMARIZE_PROMPT\n                return SEARCH_SUB_PLANNER_SUMMARIZE_PROMPT\n            elif task_value == SubPlannerType.REASONING.value:\n                from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_SUMMARIZE_PROMPT\n                return REASONING_SUB_PLANNER_SUMMARIZE_PROMPT\n\n                \n        except Exception as e:\n            logger.error(f\"获取总结执行提示词失败: {str(e)}\")\n            from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_SUMMARIZE_PROMPT\n            return REASONING_SUB_PLANNER_SUMMARIZE_PROMPT\n\n    @staticmethod\n    def get_report_prompt(task_type) -> str:\n        \"\"\"\n        根据任务类型获取生成报告的提示词\n        \"\"\"\n        try:\n            task_value = PromptManager._get_task_value(task_type)\n            \n            if task_value == SubPlannerType.CODE.value:\n                from backend.app.domain.services.prompts.code_sub_planner_prompt import CODE_SUB_PLANNER_REPORT_PROMPT\n                return CODE_SUB_PLANNER_REPORT_PROMPT\n            elif task_value == SubPlannerType.FILE.value:\n                from app.domain.services.prompts.file_sub_planner_prompt import FILE_SUB_PLANNER_REPORT_PROMPT\n                return FILE_SUB_PLANNER_REPORT_PROMPT\n            elif task_value == SubPlannerType.SEARCH.value:\n                from app.domain.services.prompts.search_sub_planner_prompt import SEARCH_SUB_PLANNER_REPORT_PROMPT\n                return SEARCH_SUB_PLANNER_REPORT_PROMPT\n            elif task_value == SubPlannerType.REASONING.value:\n                from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_REPORT_PROMPT\n                return REASONING_SUB_PLANNER_REPORT_PROMPT\n           \n                \n        except Exception as e:\n            logger.error(f\"获取生成报告提示词失败: {str(e)}\")\n            from app.domain.services.prompts.reasoning_sub_planner_prompt import REASONING_SUB_PLANNER_REPORT_PROMPT\n            return REASONING_SUB_PLANNER_REPORT_PROMPT\n\n\n    @staticmethod\n    def clear_tag(prompt: str = \"\", tag: str = \"\", save_tag = False):\n        \n        if tag == \"\":\n            return prompt\n        \n        # Remove content between tags, optionally keeping the tags themselves\n        if save_tag:\n            # Keep tags but remove content between them\n            pattern = f\"<{tag}>(.*?)</{tag}>\"\n            return re.sub(pattern, f\"<{tag}></{tag}>\", prompt, flags=re.DOTALL)\n        else:\n            # Remove tags and content between them\n            pattern = f\"<{tag}>.*?</{tag}>\"\n            return re.sub(pattern, \"\", prompt, flags=re.DOTALL)\n    \n    @staticmethod\n    async def update_ls(prompt: str = \"\", shell_tool: ShellTool = None):\n        \n        if shell_tool is None:\n            logger.warning(\"Shell tool not available, using default values\")\n            return prompt\n        \n        DIR_PROMPT = \"\"\"\n            <dir>\n            Current directory: {current_dir}\n            Current list: {current_list}\n            </dir>\n            \"\"\"\n        \n        prompt = PromptManager.clear_tag(prompt, \"dir\", save_tag = False)\n        \n        # Use shell tool to get actual sandbox container directory info\n        try:\n            # Create a unique session ID for this shell operation\n            session_id = f\"dir_check_{uuid.uuid4().hex[:8]}\"\n            logger.info(f\"Creating dir check session with ID: {session_id}\")\n            \n            logger.info(\"Shell tool available, executing pwd command...\")\n            cwd_result = await shell_tool.shell_exec(\n                id=session_id,\n                exec_dir=\"/home/ubuntu\",  # Start from default sandbox home\n                command=\"pwd\"\n            )\n            \n            # Get directory listing\n            logger.info(\"Executing ls command...\")\n            ls_result = await shell_tool.shell_exec(\n                id=session_id,\n                exec_dir=\"/home/ubuntu\",  # Start from default sandbox home\n                command=\"ls -la\"\n            )\n            \n            # Extract results\n            current_dir = cwd_result.data.get('output', '').strip() if cwd_result.success and cwd_result.data else \"/home/ubuntu\"\n            current_list = ls_result.data.get('output', '').strip() if ls_result.success and ls_result.data else \"No files found\"\n            \n            # Update the system prompt\n            dir_info = DIR_PROMPT.format(current_dir=current_dir, current_list=current_list)\n            prompt += dir_info\n            \n            return prompt\n            \n        except Exception as e:\n            logger.error(f\"Error updating system prompt: {str(e)}\")\n            logger.error(f\"Error type: {type(e)}\")\n            import traceback\n            logger.error(f\"Error traceback: {traceback.format_exc()}\")\n            return prompt\n        \n    @staticmethod\n    def update_mem(prompt: str, memory: Memory) -> str:\n        \"\"\"\n        根据memory更新prompt，检查是否存在<memory>标签\n        如果存在则替换内容，如果不存在则在末尾追加\n        \"\"\"\n        if memory is None:\n            return prompt\n        \n        MEMORY_PROMPT = \"\"\"\n        <memory>\n        Messages History:\n        {messages}\n        Tool Usage History:\n        {tool_history}\n        </memory>\n        \"\"\"\n        \n        # 清除现有的memory标签内容\n        prompt = PromptManager.clear_tag(prompt, \"memory\", save_tag=False)\n        \n        try:\n            # 获取消息历史\n            messages = memory.get_filtered_messages()\n            messages_str = \"\\n\".join([\n                f\"{msg.get('role', 'unknown')}: {msg.get('content', '')}\"\n                for msg in messages\n            ])\n            \n            # 获取工具使用历史\n            tool_history = memory.get_tool_history()\n            \n            # 安全地更新prompt，避免格式化冲突\n            memory_info = MEMORY_PROMPT.replace(\"{messages}\", messages_str).replace(\"{tool_history}\", tool_history)\n            prompt += memory_info\n            \n            return prompt\n            \n        except Exception as e:\n            import logging\n            logger = logging.getLogger(__name__)\n            logger.error(f\"Error updating memory in prompt: {str(e)}\")\n            return prompt\n\n    # TODO: \"update_step\" function?\n    \n    def _find_tool_rule(tool: BaseTool, is_executor: bool = False) -> str:\n        \"\"\"\n        根据工具类型获取对应的工具规则\n        \"\"\"\n        tool_collection = execution_tools if is_executor else sub_planner_tools\n        if isinstance(tool, ShellTool):\n            return tool_collection.SHELL\n        elif isinstance(tool, SearchTool):\n            return tool_collection.SEARCH\n        elif isinstance(tool, FileTool):\n            return tool_collection.FILE\n        elif isinstance(tool, MessageTool):\n            return tool_collection.MESSAGE\n        return \"\"\n    \n    def _find_all_tools_rules(tools = List[BaseTool], is_executor: bool = False) -> str:\n        \n        result = \"\"\n        for tool in tools:\n            if tool is None:\n                continue\n            result += PromptManager._find_tool_rule(tool, is_executor)\n        return result\n    \n    def get_system_prompt_with_tools(tools: List[BaseTool], is_executor: bool = False, is_code: bool = False) -> str:\n        \n        if is_executor:\n            prompt = EXECUTION_SYSTEM_PROMPT_NO_TOOL\n        else:\n            prompt = CODE_SUB_PLANNER_SYSTEM_PROMPT_NO_TOOL if is_code else SUB_PLANNER_SYSTEM_PROMPT_NO_TOOL\n        \n        tool_rules = PromptManager._find_all_tools_rules(tools, is_executor)\n        logger.info(f\"tool_rules: {tool_rules}\")\n        if tool_rules:\n            prompt = prompt.replace('{tool_rules}', tool_rules)\n        return prompt\n\n    def insert_datetime(prompt: str) -> str:\n        \"\"\"\n        安全地插入当前时间到prompt中，只替换{cur_time}占位符\n        \"\"\"\n        try:\n            # 只替换{cur_time}占位符，避免与其他占位符冲突\n            return prompt.replace(\"{cur_time}\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        except Exception as e:\n            logger.error(f\"插入时间到prompt失败: {str(e)}\")\n            return prompt\n",
      "methods": [
        "<module>.PromptManager._get_task_value",
        "<module>.PromptManager.get_subplanner_prompt",
        "<module>.PromptManager.get_create_plan_prompt",
        "<module>.PromptManager.get_update_plan_prompt",
        "<module>.PromptManager.get_execute_prompt",
        "<module>.PromptManager.get_summarize_prompt",
        "<module>.PromptManager.get_report_prompt",
        "<module>.PromptManager.clear_tag",
        "<module>.PromptManager.update_ls",
        "<module>.PromptManager.update_mem",
        "<module>.PromptManager._find_tool_rule",
        "<module>.PromptManager._find_all_tools_rules",
        "<module>.PromptManager.get_system_prompt_with_tools",
        "<module>.PromptManager.insert_datetime"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/base.py",
      "name": "BaseTool",
      "qualname": "<module>.BaseTool",
      "source": "class BaseTool:\n    \"\"\"Base tool class, providing common tool calling methods\"\"\"\n\n    name: str = \"\"\n    \n    def __init__(self):\n        \"\"\"Initialize base tool class\"\"\"\n        self._tools_cache = None\n    \n    async def get_tools(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all registered tools\n        \n        Returns:\n            List of tools\n        \"\"\"\n        if self._tools_cache is not None:\n            return self._tools_cache\n        \n        tools = []\n        for _, method in inspect.getmembers(self, inspect.ismethod):\n            if hasattr(method, '_tool_schema'):\n                tools.append(method._tool_schema)\n        \n        self._tools_cache = tools\n        return tools\n    \n    async def has_function(self, function_name: str) -> bool:\n        \"\"\"Check if specified function exists\n        \n        Args:\n            function_name: Function name\n            \n        Returns:\n            Whether the tool exists\n        \"\"\"\n        for _, method in inspect.getmembers(self, inspect.ismethod):\n            if hasattr(method, '_function_name') and method._function_name == function_name:\n                return True\n        return False\n    \n    async def invoke_function(self, function_name: str, **kwargs) -> ToolResult:\n        \"\"\"Invoke specified tool\n        \n        Args:\n            function_name: Function name\n            **kwargs: Parameters\n            \n        Returns:\n            Invocation result\n            \n        Raises:\n            ValueError: Raised when tool doesn't exist\n        \"\"\"\n        for _, method in inspect.getmembers(self, inspect.ismethod):\n            if hasattr(method, '_function_name') and method._function_name == function_name:\n                return await method(**kwargs)\n        \n        raise ValueError(f\"Tool '{function_name}' not found\") ",
      "methods": [
        "<module>.BaseTool.__init__",
        "<module>.BaseTool.get_tools",
        "<module>.BaseTool.has_function",
        "<module>.BaseTool.invoke_function"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/file.py",
      "name": "FileTool",
      "qualname": "<module>.FileTool",
      "source": "class FileTool(BaseTool):\n    \"\"\"File tool class, providing file operation functions\"\"\"\n\n    name: str = \"file\"\n    \n    def __init__(self, sandbox: Sandbox):\n        \"\"\"Initialize file tool class\n        \n        Args:\n            sandbox: Sandbox service\n        \"\"\"\n        super().__init__()\n        self.sandbox = sandbox\n        \n    @tool(\n        name=\"file_read\",\n        description=\"Read file content. Use for checking file contents, analyzing logs, or reading configuration files.\",\n        parameters={\n            \"file\": {\n                \"type\": \"string\",\n                \"description\": \"Absolute path of the file to read\"\n            },\n            \"start_line\": {\n                \"type\": \"integer\",\n                \"description\": \"(Optional) Starting line to read from, 0-based\"\n            },\n            \"end_line\": {\n                \"type\": \"integer\",\n                \"description\": \"(Optional) Ending line number (exclusive)\"\n            },\n            \"sudo\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to use sudo privileges\"\n            }\n        },\n        required=[\"file\"]\n    )\n    async def file_read(\n        self,\n        file: str,\n        start_line: Optional[int] = None,\n        end_line: Optional[int] = None,\n        sudo: Optional[bool] = False\n    ) -> ToolResult:\n        \"\"\"Read file content\n        \n        Args:\n            file: Absolute path of the file to read\n            start_line: (Optional) Starting line, 0-based\n            end_line: (Optional) Ending line (exclusive)\n            sudo: (Optional) Whether to use sudo privileges\n            \n        Returns:\n            File content\n        \"\"\"\n        # Directly call sandbox's file_read method\n        return await self.sandbox.file_read(\n            file=file,\n            start_line=start_line,\n            end_line=end_line,\n            sudo=sudo\n        )\n    \n    @tool(\n        name=\"file_write\",\n        description=\"Overwrite or append content to a file. Use for creating new files, appending content, or modifying existing files.\",\n        parameters={\n            \"file\": {\n                \"type\": \"string\",\n                \"description\": \"Absolute path of the file to write to\"\n            },\n            \"content\": {\n                \"type\": \"string\",\n                \"description\": \"Text content to write\"\n            },\n            \"append\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to use append mode\"\n            },\n            \"leading_newline\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to add a leading newline\"\n            },\n            \"trailing_newline\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to add a trailing newline\"\n            },\n            \"sudo\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to use sudo privileges\"\n            }\n        },\n        required=[\"file\", \"content\"]\n    )\n    async def file_write(\n        self,\n        file: str,\n        content: str,\n        append: Optional[bool] = False,\n        leading_newline: Optional[bool] = False,\n        trailing_newline: Optional[bool] = False,\n        sudo: Optional[bool] = False\n    ) -> ToolResult:\n        \"\"\"Write content to file\n        \n        Args:\n            file: Absolute path of the file to write to\n            content: Text content to write\n            append: (Optional) Whether to use append mode\n            leading_newline: (Optional) Whether to add a leading newline\n            trailing_newline: (Optional) Whether to add a trailing newline\n            sudo: (Optional) Whether to use sudo privileges\n            \n        Returns:\n            Write result\n        \"\"\"\n        # Prepare content\n        final_content = content\n        if leading_newline:\n            final_content = \"\\n\" + final_content\n        if trailing_newline:\n            final_content = final_content + \"\\n\"\n            \n        # Directly call sandbox's file_write method, pass all parameters\n        return await self.sandbox.file_write(\n            file=file, \n            content=final_content,\n            append=append,\n            leading_newline=False,  # Already handled in final_content\n            trailing_newline=False,  # Already handled in final_content\n            sudo=sudo\n        )\n    \n    @tool(\n        name=\"file_str_replace\",\n        description=\"Replace specified string in a file. Use for updating specific content in files or fixing errors in code.\",\n        parameters={\n            \"file\": {\n                \"type\": \"string\",\n                \"description\": \"Absolute path of the file to perform replacement on\"\n            },\n            \"old_str\": {\n                \"type\": \"string\",\n                \"description\": \"Original string to be replaced\"\n            },\n            \"new_str\": {\n                \"type\": \"string\",\n                \"description\": \"New string to replace with\"\n            },\n            \"sudo\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to use sudo privileges\"\n            }\n        },\n        required=[\"file\", \"old_str\", \"new_str\"]\n    )\n    async def file_str_replace(\n        self,\n        file: str,\n        old_str: str,\n        new_str: str,\n        sudo: Optional[bool] = False\n    ) -> ToolResult:\n        \"\"\"Replace specified string in file\n        \n        Args:\n            file: Absolute path of the file to perform replacement on\n            old_str: Original string to be replaced\n            new_str: New string to replace with\n            sudo: (Optional) Whether to use sudo privileges\n            \n        Returns:\n            Replacement result\n        \"\"\"\n        # Directly call sandbox's file_replace method\n        return await self.sandbox.file_replace(\n            file=file,\n            old_str=old_str,\n            new_str=new_str,\n            sudo=sudo\n        )\n    \n    @tool(\n        name=\"file_find_in_content\",\n        description=\"Search for matching text within file content. Use for finding specific content or patterns in files.\",\n        parameters={\n            \"file\": {\n                \"type\": \"string\",\n                \"description\": \"Absolute path of the file to search within\"\n            },\n            \"regex\": {\n                \"type\": \"string\",\n                \"description\": \"Regular expression pattern to match\"\n            },\n            \"sudo\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to use sudo privileges\"\n            }\n        },\n        required=[\"file\", \"regex\"]\n    )\n    async def file_find_in_content(\n        self,\n        file: str,\n        regex: str,\n        sudo: Optional[bool] = False\n    ) -> ToolResult:\n        \"\"\"Search for matching text in file content\n        \n        Args:\n            file: Absolute path of the file to search\n            regex: Regular expression pattern for matching\n            sudo: (Optional) Whether to use sudo privileges\n            \n        Returns:\n            Search results\n        \"\"\"\n        # Directly call sandbox's file_search method\n        return await self.sandbox.file_search(\n            file=file,\n            regex=regex,\n            sudo=sudo\n        )\n    \n    @tool(\n        name=\"file_find_by_name\",\n        description=\"Find files by name pattern in specified directory. Use for locating files with specific naming patterns.\",\n        parameters={\n            \"path\": {\n                \"type\": \"string\",\n                \"description\": \"Absolute path of directory to search\"\n            },\n            \"glob\": {\n                \"type\": \"string\",\n                \"description\": \"Filename pattern using glob syntax wildcards\"\n            }\n        },\n        required=[\"path\", \"glob\"]\n    )\n    async def file_find_by_name(\n        self,\n        path: str,\n        glob: str\n    ) -> ToolResult:\n        \"\"\"Find files by name pattern in specified directory\n        \n        Args:\n            path: Absolute path of directory to search\n            glob: Filename pattern using glob syntax wildcards\n            \n        Returns:\n            Search results\n        \"\"\"\n        # Directly call sandbox's file_find method\n        return await self.sandbox.file_find(\n            path=path,\n            glob_pattern=glob\n        ) ",
      "methods": [
        "<module>.FileTool.__init__",
        "<module>.FileTool.file_read",
        "<module>.FileTool.file_write",
        "<module>.FileTool.file_str_replace",
        "<module>.FileTool.file_find_in_content",
        "<module>.FileTool.file_find_by_name"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/message.py",
      "name": "MessageTool",
      "qualname": "<module>.MessageTool",
      "source": "class MessageTool(BaseTool):\n    \"\"\"Message tool class, providing message sending functions for user interaction\"\"\"\n\n    name: str = \"message\"\n    \n    def __init__(self):\n        \"\"\"Initialize message tool class\"\"\"\n        super().__init__()\n    \n    # @tool(\n    #     name=\"message_request_user_clarification\",\n    #     description=\"Send a message to user to request clarification. Use for asking for more information, confirming understanding, or requesting specific details.\",\n    #     parameters={\n    #         \"text\": {\n    #             \"type\": \"string\",\n    #             \"description\": \"Message text to display to user\"\n    #         }\n    #     },\n    #     required=[\"text\"]\n    # )\n    # async def message_request_user_clarification(\n    #     self,\n    #     text: str\n    # ) -> ToolResult:\n    #     \"\"\"Send message to user to request clarification\n        \n    #     Args:\n    #         text: Message text to display to user\n            \n    #     Returns:\n    #         Message sending result\n    #     \"\"\"\n            \n    #     # Return success result, actual UI display logic implemented by caller\n    #     return ToolResult(\n    #         success=True,\n    #         data=text\n    #     )\n    @tool(\n        name=\"message_done\",\n        description=\"A special tool to indicate the task is done, and stop the execution immediately.\",\n        parameters={\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"Message text to display to user\"\n            }\n        },\n        required=[\"text\"]\n    )\n    async def message_done(\n        self,\n        text: str\n    ) -> ToolResult:\n        \"\"\"Send message to user to indicate the task is done\n        \n        Args:\n            text: Message text to display to user\n\n        Returns:\n            Message sending result\n        \"\"\"\n            \n        # Return success result, actual UI display logic implemented by caller\n        result = {\n            \"text\": text\n        }\n        return ToolResult(\n            success=True,\n            data=result\n        )\n",
      "methods": [
        "<module>.MessageTool.__init__",
        "<module>.MessageTool.message_done"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/message.py",
      "name": "MessageNotifyUserTool",
      "qualname": "<module>.MessageNotifyUserTool",
      "source": "class MessageNotifyUserTool(BaseTool):\n    \"\"\"Message notify user tool class, providing message sending functions for user interaction\"\"\"\n\n    name: str = \"message_notify_user\"\n    \n    def __init__(self):\n        \"\"\"Initialize message notify user tool class\"\"\"\n        super().__init__()\n            \n    @tool(\n        name=\"message_notify_user\",\n        description=\"Send a message to user without requiring a response. Use for acknowledging receipt of messages, providing progress updates, reporting task completion, or explaining changes in approach.\",\n        parameters={\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"Message text to display to user\"\n            }\n        },\n        required=[\"text\"]\n    )\n    async def message_notify_user(\n        self,\n        text: str\n    ) -> ToolResult:\n        \"\"\"Send notification message to user, no response needed\n        \n        Args:\n            text: Message text to display to user\n            \n        Returns:\n            Message sending result\n        \"\"\"\n            \n        # Return success result, actual UI display logic implemented by caller\n        return ToolResult(\n            success=True,\n            data=text\n        )\n",
      "methods": [
        "<module>.MessageNotifyUserTool.__init__",
        "<module>.MessageNotifyUserTool.message_notify_user"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/message.py",
      "name": "MessageDeliverArtifactTool",
      "qualname": "<module>.MessageDeliverArtifactTool",
      "source": "class MessageDeliverArtifactTool(BaseTool):\n    \"\"\"Message deliver artifact tool class, providing message sending functions for user interaction\"\"\"\n\n    name: str = \"message_deliver_artifact\"\n    \n    def __init__(self):\n        \"\"\"Initialize message deliver artifact tool class\"\"\"\n        super().__init__()\n\n    @tool(\n        name=\"message_deliver_artifact\",\n        description=\"Send a message to user to deliver artifact. Use for delivering files, images, or other binary data.\",\n        parameters={\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"Message text to display to user\"\n            },\n            \"artifacts\": {\n                \"type\": \"array\",\n                \"description\": \"(Optional) Array of the paths of the artifacts to deliver\",\n                \"items\": {\n                    \"type\": \"string\",\n                    \"description\": \"Artifact file path\"\n                }\n            }\n        },\n        required=[\"text\"]\n    )\n    async def message_deliver_artifact(\n        self,\n        text: str,\n        artifacts: Optional[List[str]] = None\n    ) -> ToolResult:\n        \"\"\"Send message to user to deliver artifact\n        \n        Args:\n            text: Message text to display to user\n            artifacts: Array of the paths of the artifacts to deliver\n\n        Returns:\n            Message sending result\n        \"\"\"\n            \n        # Return success result, actual UI display logic implemented by caller\n        result = {\n            \"text\": text,\n            \"artifacts\": artifacts\n        }\n        return ToolResult(\n            success=True,\n            data=result\n        )",
      "methods": [
        "<module>.MessageDeliverArtifactTool.__init__",
        "<module>.MessageDeliverArtifactTool.message_deliver_artifact"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/context_manager.py",
      "name": "ContextManager",
      "qualname": "<module>.ContextManager",
      "source": "class ContextManager:\n    \"\"\"上下文长度管理器，用于控制消息和工具结果的长度\"\"\"\n    \n    # 默认配置\n    DEFAULT_MAX_TOOL_CONTENT_TOKENS = 16000  # 工具返回内容最大token数\n    DEFAULT_MAX_TOTAL_TOKENS = 128000  # 总上下文最大token数\n    DEFAULT_PRESERVE_RECENT_MESSAGES = 10  # 保留最近消息数量\n    \n    # 估算token数的简单方法：1 token ≈ 4 字符（英文）或 1.5 字符（中文）\n    CHARS_PER_TOKEN_EN = 4\n    CHARS_PER_TOKEN_ZH = 1.5\n    \n    def __init__(self, \n                 max_tool_content_tokens: int = DEFAULT_MAX_TOOL_CONTENT_TOKENS,\n                 max_total_tokens: int = DEFAULT_MAX_TOTAL_TOKENS,\n                 preserve_recent_messages: int = DEFAULT_PRESERVE_RECENT_MESSAGES):\n        \"\"\"\n        初始化上下文管理器\n        \n        Args:\n            max_tool_content_tokens: 工具返回内容最大token数\n            max_total_tokens: 总上下文最大token数\n            preserve_recent_messages: 保留最近消息数量\n        \"\"\"\n        self.max_tool_content_tokens = max_tool_content_tokens\n        self.max_total_tokens = max_total_tokens\n        self.preserve_recent_messages = preserve_recent_messages\n        \n    def estimate_tokens(self, text: str) -> int:\n        \"\"\"\n        估算文本的token数量\n        \n        Args:\n            text: 要估算的文本\n            \n        Returns:\n            估算的token数量\n        \"\"\"\n        if not text:\n            return 0\n            \n        # 简单的token估算：根据中英文字符比例\n        chinese_chars = sum(1 for char in text if '\\u4e00' <= char <= '\\u9fff')\n        english_chars = len(text) - chinese_chars\n        \n        estimated_tokens = (\n            chinese_chars / self.CHARS_PER_TOKEN_ZH + \n            english_chars / self.CHARS_PER_TOKEN_EN\n        )\n        \n        return int(estimated_tokens)\n    \n    def truncate_text(self, text: str, max_tokens: int) -> str:\n        \"\"\"\n        截断文本到指定token数量\n        \n        Args:\n            text: 要截断的文本\n            max_tokens: 最大token数\n            \n        Returns:\n            截断后的文本\n        \"\"\"\n        if not text:\n            return text\n            \n        current_tokens = self.estimate_tokens(text)\n        if current_tokens <= max_tokens:\n            return text\n            \n        # 省略标记的token数\n        ellipsis_text = \"\\n\\n[内容因长度限制被截断...]\"\n        ellipsis_tokens = self.estimate_tokens(ellipsis_text)\n        \n        # 如果最大token数太小，无法容纳省略标记\n        if max_tokens <= ellipsis_tokens:\n            return ellipsis_text[:max(1, int(max_tokens * self.CHARS_PER_TOKEN_ZH))]\n            \n        # 计算实际可用于内容的token数\n        available_tokens = max_tokens - ellipsis_tokens\n        \n        # 计算需要保留的字符比例\n        ratio = available_tokens / current_tokens\n        target_length = int(len(text) * ratio * 0.8)  # 留更多余量确保不超限\n        \n        if target_length <= 0:\n            return ellipsis_text\n            \n        # 截断文本\n        truncated = text[:target_length]\n        \n        # 尝试在合适的位置截断（避免截断到单词中间）\n        if target_length < len(text):\n            # 寻找最近的换行符或句号\n            for delimiter in ['\\n', '。', '.', '!', '?', '！', '？']:\n                last_pos = truncated.rfind(delimiter)\n                if last_pos > target_length * 0.6:  # 如果找到的位置不太远\n                    truncated = truncated[:last_pos + 1]\n                    break\n        \n        result = truncated + ellipsis_text\n        \n        # 确保结果不超过限制（如果仍然超过，进一步截断）\n        result_tokens = self.estimate_tokens(result)\n        if result_tokens > max_tokens:\n            # 进一步减少内容长度\n            excess_ratio = result_tokens / max_tokens\n            new_target_length = int(len(truncated) / excess_ratio * 0.9)\n            if new_target_length > 0:\n                truncated = truncated[:new_target_length]\n                result = truncated + ellipsis_text\n        \n        return result\n    \n    def limit_tool_result_content(self, tool_result: ToolResult) -> ToolResult:\n        \"\"\"\n        限制工具结果内容的长度\n        \n        Args:\n            tool_result: 工具执行结果\n            \n        Returns:\n            长度受限的工具结果\n        \"\"\"\n        if not tool_result:\n            return tool_result\n            \n        # 创建新的工具结果对象\n        limited_result = ToolResult(\n            success=tool_result.success,\n            message=tool_result.message,\n            data=tool_result.data\n        )\n        \n        # 限制message字段长度\n        if limited_result.message:\n            message_tokens = self.estimate_tokens(limited_result.message)\n            if message_tokens > self.max_tool_content_tokens:\n                limited_result.message = self.truncate_text(\n                    limited_result.message, \n                    self.max_tool_content_tokens\n                )\n                logger.info(f\"工具结果message被截断: {message_tokens} -> {self.estimate_tokens(limited_result.message)} tokens\")\n        \n        # 限制data字段长度（如果是字符串类型）\n        if limited_result.data:\n            if isinstance(limited_result.data, str):\n                data_tokens = self.estimate_tokens(limited_result.data)\n                if data_tokens > self.max_tool_content_tokens:\n                    limited_result.data = self.truncate_text(\n                        limited_result.data,\n                        self.max_tool_content_tokens\n                    )\n                    logger.info(f\"工具结果data被截断: {data_tokens} -> {self.estimate_tokens(limited_result.data)} tokens\")\n            elif isinstance(limited_result.data, dict):\n                # 对字典中的字符串值进行限制\n                limited_result.data = self._limit_dict_content(limited_result.data)\n            elif isinstance(limited_result.data, list):\n                # 对列表中的内容进行限制\n                limited_result.data = self._limit_list_content(limited_result.data)\n        \n        return limited_result\n    \n    def _limit_dict_content(self, data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"限制字典内容的长度\"\"\"\n        limited_data = {}\n        total_tokens = 0\n        \n        for key, value in data.items():\n            if isinstance(value, str):\n                value_tokens = self.estimate_tokens(value)\n                if value_tokens > self.max_tool_content_tokens // 4:  # 单个字段不超过总限制的1/4\n                    value = self.truncate_text(value, self.max_tool_content_tokens // 4)\n                    value_tokens = self.estimate_tokens(value)\n                \n                total_tokens += value_tokens\n                if total_tokens > self.max_tool_content_tokens:\n                    limited_data[key] = \"[内容因长度限制被省略...]\"\n                    break\n                else:\n                    limited_data[key] = value\n            elif isinstance(value, dict):\n                limited_data[key] = self._limit_dict_content(value)\n            elif isinstance(value, list):\n                limited_data[key] = self._limit_list_content(value)\n            else:\n                limited_data[key] = value\n        \n        return limited_data\n    \n    def _limit_list_content(self, data: List[Any]) -> List[Any]:\n        \"\"\"限制列表内容的长度\"\"\"\n        limited_data = []\n        total_tokens = 0\n        \n        for item in data:\n            if isinstance(item, str):\n                item_tokens = self.estimate_tokens(item)\n                if item_tokens > self.max_tool_content_tokens // 10:  # 单个列表项不超过总限制的1/10\n                    item = self.truncate_text(item, self.max_tool_content_tokens // 10)\n                    item_tokens = self.estimate_tokens(item)\n                \n                total_tokens += item_tokens\n                if total_tokens > self.max_tool_content_tokens:\n                    limited_data.append(\"[后续内容因长度限制被省略...]\")\n                    break\n                else:\n                    limited_data.append(item)\n            elif isinstance(item, dict):\n                limited_data.append(self._limit_dict_content(item))\n            elif isinstance(item, list):\n                limited_data.append(self._limit_list_content(item))\n            else:\n                limited_data.append(item)\n        \n        return limited_data\n    \n    def optimize_memory_context(self, memory: Memory) -> None:\n        \"\"\"\n        优化Memory中的上下文长度\n        \n        Args:\n            memory: 要优化的Memory对象\n        \"\"\"\n        messages = memory.get_messages()\n        if not messages:\n            return\n            \n        # 计算当前总token数\n        total_tokens = sum(self.estimate_tokens(self._message_to_text(msg)) for msg in messages)\n        \n        # 如果消息数量很多（超过20条）或者token数超限，都需要优化\n        needs_optimization = total_tokens > self.max_total_tokens\n        \n        if not needs_optimization:\n            return\n            \n        logger.info(f\"上下文长度超限，开始优化: {total_tokens} tokens, {len(messages)} messages > {self.max_total_tokens} tokens\")\n        \n        # 获取最新的系统消息\n        latest_system = memory.get_latest_system_message()\n        non_system_messages = memory.get_non_system_messages()\n        \n        # 如果非系统消息数量少于等于保留数量，不需要优化\n        if len(non_system_messages) <= self.preserve_recent_messages:\n            return\n        \n        # 保留最近的消息\n        preserved_messages = non_system_messages[-self.preserve_recent_messages:]\n        older_messages = non_system_messages[:-self.preserve_recent_messages]\n        \n        # 计算保留消息的token数\n        preserved_tokens = sum(self.estimate_tokens(self._message_to_text(msg)) for msg in preserved_messages)\n        system_tokens = self.estimate_tokens(self._message_to_text(latest_system)) if latest_system else 0\n        \n        # 计算可用于旧消息的token数\n        available_tokens = max(100, self.max_total_tokens - preserved_tokens - system_tokens)\n        \n        # 压缩旧消息\n        compressed_older = self._compress_messages(older_messages, available_tokens)\n        \n        # 重建消息列表\n        new_messages = []\n        if latest_system:\n            new_messages.append(latest_system)\n        new_messages.extend(compressed_older)\n        new_messages.extend(preserved_messages)\n        \n        # 临时禁用自动优化，避免递归调用\n        original_auto_optimize = memory.auto_optimize\n        memory.auto_optimize = False\n        \n        try:\n            # 更新Memory\n            memory.clear_messages()\n            memory.add_messages(new_messages)\n        finally:\n            # 恢复原始的自动优化设置\n            memory.auto_optimize = original_auto_optimize\n        \n        new_total_tokens = sum(self.estimate_tokens(self._message_to_text(msg)) for msg in new_messages)\n        logger.info(f\"上下文优化完成: {len(messages)} -> {len(new_messages)} messages, {total_tokens} -> {new_total_tokens} tokens\")\n    \n    def _message_to_text(self, message: Union[Dict[str, Any], Any]) -> str:\n        \"\"\"将消息转换为文本用于token计算\"\"\"\n        if isinstance(message, dict):\n            content = message.get('content', '')\n            if isinstance(content, str):\n                return content\n            else:\n                return json.dumps(content, ensure_ascii=False)\n        else:\n            # 处理ChatCompletionMessage等对象\n            if hasattr(message, 'content'):\n                content = message.content\n                if isinstance(content, str):\n                    return content\n                else:\n                    return json.dumps(content, ensure_ascii=False) if content else \"\"\n            else:\n                return str(message)\n    \n    def _get_message_role(self, message: Union[Dict[str, Any], Any]) -> str:\n        \"\"\"安全地获取消息的role\"\"\"\n        if isinstance(message, dict):\n            return message.get('role', '')\n        else:\n            # 处理ChatCompletionMessage等对象\n            if hasattr(message, 'role'):\n                return message.role\n            else:\n                return ''\n\n    def _compress_messages(self, messages: List[Dict[str, Any]], max_tokens: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        压缩消息列表到指定token数内\n        \n        Args:\n            messages: 要压缩的消息列表\n            max_tokens: 最大token数\n            \n        Returns:\n            压缩后的消息列表\n        \"\"\"\n        if not messages or max_tokens <= 0:\n            return []\n        \n        # 如果消息很少，直接返回\n        if len(messages) <= 3:\n            return messages\n        \n        # 计算当前token数\n        current_tokens = sum(self.estimate_tokens(self._message_to_text(msg)) for msg in messages)\n        \n        if current_tokens <= max_tokens:\n            return messages\n        \n        # 创建摘要消息\n        summary_content = f\"[历史对话摘要: 共{len(messages)}条消息被压缩，原始长度约{current_tokens}个token]\"\n        \n        # 尝试保留一些关键消息（用户消息和重要的助手回复）\n        key_messages = []\n        for msg in messages[-6:]:  # 保留最后6条消息\n            if self._get_message_role(msg) in ['user', 'assistant']:\n                key_messages.append(msg)\n        \n        # 如果关键消息的token数仍然超限，进一步压缩\n        key_tokens = sum(self.estimate_tokens(self._message_to_text(msg)) for msg in key_messages)\n        summary_tokens = self.estimate_tokens(summary_content)\n        \n        if key_tokens + summary_tokens > max_tokens:\n            # 进一步压缩关键消息\n            available_for_key = max_tokens - summary_tokens\n            key_messages = self._truncate_messages(key_messages, available_for_key)\n        \n        # 构建压缩后的消息列表\n        compressed = [{\"role\": \"system\", \"content\": summary_content}]\n        compressed.extend(key_messages)\n        \n        return compressed\n    \n    def _truncate_messages(self, messages: List[Dict[str, Any]], max_tokens: int) -> List[Dict[str, Any]]:\n        \"\"\"截断消息列表到指定token数\"\"\"\n        if not messages:\n            return []\n        \n        truncated = []\n        current_tokens = 0\n        \n        # 从后往前添加消息，确保最新的消息被保留\n        for msg in reversed(messages):\n            msg_tokens = self.estimate_tokens(self._message_to_text(msg))\n            \n            if current_tokens + msg_tokens <= max_tokens:\n                truncated.insert(0, msg)\n                current_tokens += msg_tokens\n            else:\n                # 如果这是第一条消息且超限，尝试截断内容\n                if not truncated and max_tokens > 100:\n                    content = self._message_to_text(msg)\n                    truncated_content = self.truncate_text(content, max_tokens - 50)\n                    truncated_msg = msg.copy()\n                    truncated_msg['content'] = truncated_content\n                    truncated.insert(0, truncated_msg)\n                break\n        \n        return truncated\n",
      "methods": [
        "<module>.ContextManager.__init__",
        "<module>.ContextManager.estimate_tokens",
        "<module>.ContextManager.truncate_text",
        "<module>.ContextManager.limit_tool_result_content",
        "<module>.ContextManager._limit_dict_content",
        "<module>.ContextManager._limit_list_content",
        "<module>.ContextManager.optimize_memory_context",
        "<module>.ContextManager._message_to_text",
        "<module>.ContextManager._get_message_role",
        "<module>.ContextManager._compress_messages",
        "<module>.ContextManager._truncate_messages"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/search.py",
      "name": "SearchTool",
      "qualname": "<module>.SearchTool",
      "source": "class SearchTool(BaseTool):\n    \"\"\"Search tool class, providing search engine interaction functions\"\"\"\n\n    name: str = \"search\"\n    \n    def __init__(self, search_engine: SearchEngine):\n        \"\"\"Initialize search tool class\n        \n        Args:\n            search_engine: Search engine service\n        \"\"\"\n        super().__init__()\n        self.search_engine = search_engine\n    \n    @tool(\n        name=\"info_search_web\",\n        description=\"Search web pages using search engine. Use for obtaining latest information or finding references.\",\n        parameters={\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"Search query in Google search style, using 3-5 keywords.\"\n            },\n            \"date_range\": {\n                \"type\": \"string\",\n                \"enum\": [\"all\", \"past_hour\", \"past_day\", \"past_week\", \"past_month\", \"past_year\"],\n                \"description\": \"(Optional) Time range filter for search results.\"\n            }\n        },\n        required=[\"query\"]\n    )\n    async def info_search_web(\n        self,\n        query: str,\n        date_range: Optional[str] = None\n    ) -> ToolResult:\n        \"\"\"Search webpages using search engine\n        \n        Args:\n            query: Search query, Google search style, using 3-5 keywords\n            date_range: (Optional) Time range filter for search results\n            \n        Returns:\n            Search results\n        \"\"\"\n        return await self.search_engine.search(query, date_range) ",
      "methods": [
        "<module>.SearchTool.__init__",
        "<module>.SearchTool.info_search_web"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/shell.py",
      "name": "ShellTool",
      "qualname": "<module>.ShellTool",
      "source": "class ShellTool(BaseTool):\n    \"\"\"Shell tool class, providing Shell interaction related functions\"\"\"\n\n    name: str = \"shell\"\n    \n    def __init__(self, sandbox: Sandbox):\n        \"\"\"Initialize Shell tool class\n        \n        Args:\n            sandbox: Sandbox service\n        \"\"\"\n        super().__init__()\n        self.sandbox = sandbox\n        \n    @tool(\n        name=\"shell_exec\",\n        description=\"Execute commands in a specified shell session. Use for running code, installing packages, or managing files.\",\n        parameters={\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"Unique identifier of the target shell session\"\n            },\n            \"exec_dir\": {\n                \"type\": \"string\",\n                \"description\": \"Working directory for command execution (must use absolute path)\"\n            },\n            \"command\": {\n                \"type\": \"string\",\n                \"description\": \"Shell command to execute\"\n            }\n        },\n        required=[\"id\", \"exec_dir\", \"command\"]\n    )\n    async def shell_exec(\n        self,\n        id: str,\n        exec_dir: str,\n        command: str\n    ) -> ToolResult:\n        \"\"\"Execute Shell command\n        \n        Args:\n            id: Unique identifier of the target Shell session\n            exec_dir: Working directory for command execution (must use absolute path)\n            command: Shell command to execute\n            \n        Returns:\n            Command execution result\n        \"\"\"\n        return await self.sandbox.exec_command(id, exec_dir, command)\n    \n    @tool(\n        name=\"shell_view\",\n        description=\"View the content of a specified shell session. Use for checking command execution results or monitoring output.\",\n        parameters={\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"Unique identifier of the target shell session\"\n            }\n        },\n        required=[\"id\"]\n    )\n    async def shell_view(self, id: str) -> ToolResult:\n        \"\"\"View Shell session content\n        \n        Args:\n            id: Unique identifier of the target Shell session\n            \n        Returns:\n            Shell session content\n        \"\"\"\n        return await self.sandbox.view_shell(id)\n    \n    @tool(\n        name=\"shell_wait\",\n        description=\"Wait for the running process in a specified shell session to return. Use after running commands that require longer runtime.\",\n        parameters={\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"Unique identifier of the target shell session\"\n            },\n            \"seconds\": {\n                \"type\": \"integer\",\n                \"description\": \"Wait duration in seconds\"\n            }\n        },\n        required=[\"id\"]\n    )\n    async def shell_wait(\n        self,\n        id: str,\n        seconds: Optional[int] = None\n    ) -> ToolResult:\n        \"\"\"Wait for the running process in Shell session to return\n        \n        Args:\n            id: Unique identifier of the target Shell session\n            seconds: Wait time (seconds)\n            \n        Returns:\n            Wait result\n        \"\"\"\n        return await self.sandbox.wait_for_process(id, seconds)\n    \n    @tool(\n        name=\"shell_write_to_process\",\n        description=\"Write input to a running process in a specified shell session. Use for responding to interactive command prompts.\",\n        parameters={\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"Unique identifier of the target shell session\"\n            },\n            \"input\": {\n                \"type\": \"string\",\n                \"description\": \"Input content to write to the process\"\n            },\n            \"press_enter\": {\n                \"type\": \"boolean\",\n                \"description\": \"Whether to press Enter key after input\"\n            }\n        },\n        required=[\"id\", \"input\", \"press_enter\"]\n    )\n    async def shell_write_to_process(\n        self,\n        id: str,\n        input: str,\n        press_enter: bool\n    ) -> ToolResult:\n        \"\"\"Write input to the running process in Shell session\n        \n        Args:\n            id: Unique identifier of the target Shell session\n            input: Input content to write to the process\n            press_enter: Whether to press Enter key after input\n            \n        Returns:\n            Write result\n        \"\"\"\n        return await self.sandbox.write_to_process(id, input, press_enter)\n    \n    @tool(\n        name=\"shell_kill_process\",\n        description=\"Terminate a running process in a specified shell session. Use for stopping long-running processes or handling frozen commands.\",\n        parameters={\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"Unique identifier of the target shell session\"\n            }\n        },\n        required=[\"id\"]\n    )\n    async def shell_kill_process(self, id: str) -> ToolResult:\n        \"\"\"Terminate the running process in Shell session\n        \n        Args:\n            id: Unique identifier of the target Shell session\n            \n        Returns:\n            Termination result\n        \"\"\"\n        return await self.sandbox.kill_process(id)\n",
      "methods": [
        "<module>.ShellTool.__init__",
        "<module>.ShellTool.shell_exec",
        "<module>.ShellTool.shell_view",
        "<module>.ShellTool.shell_wait",
        "<module>.ShellTool.shell_write_to_process",
        "<module>.ShellTool.shell_kill_process"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/audio.py",
      "name": "AudioTool",
      "qualname": "<module>.AudioTool",
      "source": "class AudioTool(BaseTool):\n    \"\"\"Audio tool class, providing audio generation functions\"\"\"\n\n    name: str = \"audio\"\n    \n    def __init__(self, sandbox: Sandbox, audio_llm: AudioLLM, llm: LLM):\n        \"\"\"Initialize audio tool class\n        \n        Args:\n            sandbox: Sandbox service\n            audio_llm: Audio LLM service\n        \"\"\"\n        super().__init__()\n        self.sandbox = sandbox\n        self.audio_llm = audio_llm\n        self.llm = llm\n\n    @tool(\n        name=\"audio_to_text\",\n        description=\"Generate text from audio. Use for generating text from audio.\",\n        parameters={\n            \"audio_path\": {\n                \"type\": \"string\",\n                \"description\": \"Audio file path\"\n            }\n        },\n        required=[\"audio_path\"]\n    )\n    async def audio_to_text(\n        self,\n        audio_path: str\n    ) -> ToolResult:\n        \"\"\"Generate text from audio\n        \n        Args:\n            audio_path: Audio file path\n            \n        Returns:\n            Text from audio\n        \"\"\"\n        audio_file = await self.sandbox.file_download(audio_path)\n        filename = os.path.basename(audio_path)\n        response = await self.audio_llm.audio_to_text(audio_file, filename) \n        return ToolResult(\n            success=True,\n            data=response\n        )\n    \n    @tool(\n        name=\"ask_question_about_audio\",\n        description=\"Ask a question about the audio. Use for asking a question about the audio.\",\n        parameters={\n            \"audio_path\": {\n                \"type\": \"string\",\n                \"description\": \"Audio file path\"\n            },\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"Question about the audio\"\n            }\n        },\n        required=[\"audio_path\", \"text\"]\n    )\n    async def ask_question_about_audio(\n        self,\n        audio_path: str,\n        text: str\n    ) -> ToolResult:\n        \"\"\"Ask a question about the audio\n        \n        Args:\n            audio_path: Audio file path\n            text: Question about the audio\n            \n        Returns:\n            Answer to the question\n        \"\"\"\n        audio_file = await self.sandbox.file_download(audio_path)\n        filename = os.path.basename(audio_path)\n        transcript = await self.audio_llm.audio_to_text(audio_file, filename) \n        \n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about audios transcript.\"},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": transcript},\n                {\"type\": \"text\", \"text\": text}\n            ]}\n        ]\n        response = await self.llm.ask(messages) \n        return ToolResult(\n            success=True,\n            data=response\n        )\n",
      "methods": [
        "<module>.AudioTool.__init__",
        "<module>.AudioTool.audio_to_text",
        "<module>.AudioTool.ask_question_about_audio"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/image.py",
      "name": "ImageTool",
      "qualname": "<module>.ImageTool",
      "source": "class ImageTool(BaseTool):\n    \"\"\"Image tool class, providing image generation functions\"\"\"\n\n    name: str = \"image\"\n    \n    def __init__(self, sandbox: Sandbox, image_llm: ImageLLM):\n        \"\"\"Initialize image tool class\n        \n        Args:\n            sandbox: Sandbox service\n            image_llm: Image LLM service\n        \"\"\"\n        super().__init__()\n        self.sandbox = sandbox\n        self.image_llm = image_llm\n    \n    @tool(\n        name=\"image_to_text\",\n        description=\"Generate text from image. Use for generating text from image.\",\n        parameters={\n            \"image_path\": {\n                \"type\": \"string\",\n                \"description\": \"Image file path\"\n            }\n        },\n        required=[\"image_path\"]\n    )\n    async def image_to_text(\n        self,\n        image_path: str\n    ) -> ToolResult:\n        \"\"\"Generate text from image\n        \n        Args:\n            image_path: Image file path\n            \n        Returns:\n            Text from image\n        \"\"\"\n        image_file = await self.sandbox.file_download(image_path)\n        image_base64 = base64.b64encode(image_file).decode('utf-8')\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can describe the content of images.\"},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\", \"detail\": \"auto\"}},\n                {\"type\": \"text\", \"text\": \"Please describe the content of the image.\"}\n            ]}\n        ]\n        response = await self.image_llm.ask(messages) \n        return ToolResult(\n            success=True,\n            data=response.content\n        )\n    \n    @tool(\n        name=\"ask_question_about_image\",\n        description=\"Ask a question about the image. Use for asking a question about the image.\",\n        parameters={\n            \"image_path\": {\n                \"type\": \"string\",\n                \"description\": \"Image file path\"\n            },\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"Question about the image\"\n            }\n        },\n        required=[\"image_path\", \"text\"]\n    )\n    async def ask_question_about_image(\n        self,\n        image_path: str,\n        text: str\n    ) -> ToolResult:\n        \"\"\"Ask a question about the image\n        \n        Args:\n            image_path: Image file path\n            text: Question about the image\n            \n        Returns:\n            Answer to the question\n        \"\"\"\n        image_file = await self.sandbox.file_download(image_path)\n        image_base64 = base64.b64encode(image_file).decode('utf-8')\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions about images.\"},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\", \"detail\": \"auto\"}},\n                {\"type\": \"text\", \"text\": text}\n            ]}\n        ]\n        response = await self.image_llm.ask(messages) \n        return ToolResult(\n            success=True,\n            data=response.content\n        )\n",
      "methods": [
        "<module>.ImageTool.__init__",
        "<module>.ImageTool.image_to_text",
        "<module>.ImageTool.ask_question_about_image"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/mcp.py",
      "name": "McpServerConfig",
      "qualname": "<module>.McpServerConfig",
      "source": "class McpServerConfig:\n    \"\"\"Configuration for an MCP server to be pre-installed.\"\"\"\n    \n    def __init__(\n        self,\n        package_name: str,\n        language: str = \"python\",\n        args: Optional[List[str]] = None,\n        description: Optional[str] = None\n    ):\n        \"\"\"Initialize MCP server configuration.\n        \n        Args:\n            package_name: Name of the MCP package to install\n            language: Programming language (\"python\" or \"node\")\n            args: Optional list of arguments to pass to the server\n            description: Optional description for logging\n        \"\"\"\n        self.package_name = package_name\n        self.language = language\n        self.args = args or []\n        self.description = description or package_name\n",
      "methods": [
        "<module>.McpServerConfig.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/mcp.py",
      "name": "McpTool",
      "qualname": "<module>.McpTool",
      "source": "class McpTool(BaseTool):\n    \"\"\"Dynamic tool for managing MCP (Model Context Protocol) servers and exposing their tools.\"\"\"\n\n    name: str = \"mcp\"\n\n    def __init__(\n        self, \n        sandbox: Sandbox,\n        pre_install_servers: Optional[List[Union[str, Dict[str, Any], McpServerConfig]]] = None\n    ):\n        \"\"\"Initialize MCP tool with sandbox interface and optional pre-installed servers.\n        \n        Args:\n            sandbox: Sandbox interface for MCP operations\n            pre_install_servers: Optional list of servers to pre-install. Can be:\n                - List of package names (strings)\n                - List of dictionaries with server config\n                - List of McpServerConfig objects\n                Example:\n                    [\"mcp-filesystem\", \"mcp-brave-search\"]\n                    [{\"package_name\": \"mcp-filesystem\", \"language\": \"python\"}]\n                    [McpServerConfig(\"mcp-filesystem\", \"python\", [\"/home/ubuntu\"])]\n        \"\"\"\n        super().__init__()\n        self.sandbox = sandbox\n        self._dynamic_tools_cache = None\n        self._pre_install_servers = self._parse_pre_install_servers(pre_install_servers or [])\n        self._initialized = False\n        self._initialization_results = []\n\n    def _parse_pre_install_servers(\n        self, \n        pre_install_servers: List[Union[str, Dict[str, Any], McpServerConfig]]\n    ) -> List[McpServerConfig]:\n        \"\"\"Parse and normalize pre-install servers configuration.\n        \n        Args:\n            pre_install_servers: List of server configurations in various formats\n            \n        Returns:\n            List of normalized McpServerConfig objects\n        \"\"\"\n        configs = []\n        \n        for server in pre_install_servers:\n            try:\n                if isinstance(server, str):\n                    # Simple package name\n                    configs.append(McpServerConfig(server))\n                elif isinstance(server, dict):\n                    # Dictionary configuration\n                    package_name = server.get(\"package_name\")\n                    if not package_name:\n                        logger.warning(f\"Skipping server config without package_name: {server}\")\n                        continue\n                    \n                    configs.append(McpServerConfig(\n                        package_name=package_name,\n                        language=server.get(\"language\", \"python\"),\n                        args=server.get(\"args\"),\n                        description=server.get(\"description\")\n                    ))\n                elif isinstance(server, McpServerConfig):\n                    # Already a proper config object\n                    configs.append(server)\n                else:\n                    logger.warning(f\"Skipping invalid server config: {server}\")\n            except Exception as e:\n                logger.error(f\"Error parsing server config {server}: {e}\")\n                \n        return configs\n\n    async def initialize(self) -> bool:\n        \"\"\"Initialize the MCP tool by pre-installing configured servers.\n        \n        This method should be called after creating the McpTool instance\n        to install any pre-configured MCP servers.\n        \n        Returns:\n            Initialization result with details about installed servers\n        \"\"\"\n        if self._initialized:\n            return True\n\n        logger.info(f\"Initializing MCP tool with {len(self._pre_install_servers)} pre-install servers\")\n        \n        installation_results = []\n        successful_installs = 0\n        failed_installs = 0\n\n        for server_config in self._pre_install_servers:\n            try:\n                logger.info(f\"Pre-installing MCP server: {server_config.description}\")\n                \n                result = await self.install_server(\n                    package_name=server_config.package_name,\n                    language=server_config.language,\n                    args=server_config.args\n                )\n                \n                installation_results.append({\n                    \"package_name\": server_config.package_name,\n                    \"success\": result.success,\n                    \"message\": result.message,\n                    \"language\": server_config.language\n                })\n                \n                if result.success:\n                    successful_installs += 1\n                    logger.info(f\"Successfully pre-installed: {server_config.package_name}\")\n                else:\n                    failed_installs += 1\n                    logger.error(f\"Failed to pre-install {server_config.package_name}: {result.message}\")\n                    \n            except Exception as e:\n                failed_installs += 1\n                error_msg = f\"Error pre-installing {server_config.package_name}: {str(e)}\"\n                logger.error(error_msg)\n                installation_results.append({\n                    \"package_name\": server_config.package_name,\n                    \"success\": False,\n                    \"message\": error_msg,\n                    \"language\": server_config.language\n                })\n\n        self._initialization_results = installation_results\n        self._initialized = True\n\n        # 清除缓存以确保新安装的工具被发现\n        self.invalidate_cache()\n\n        total_servers = len(self._pre_install_servers)\n        if total_servers == 0:\n            message = \"MCP tool initialized with no pre-install servers\"\n        elif failed_installs == 0:\n            message = f\"MCP tool initialized successfully. All {successful_installs} servers installed.\"\n        elif successful_installs == 0:\n            message = f\"MCP tool initialized with warnings. All {failed_installs} server installations failed.\"\n        else:\n            message = f\"MCP tool initialized with warnings. {successful_installs} succeeded, {failed_installs} failed.\"\n\n        logger.info(message)\n\n        return failed_installs < total_servers\n\n    async def _get_dynamic_tools(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all tools from installed MCP servers dynamically.\n        \n        Returns:\n            List of dynamic tools from MCP servers\n        \"\"\"\n        if self._dynamic_tools_cache is not None:\n            return self._dynamic_tools_cache\n        \n        # 确保初始化\n        await self.initialize()\n\n        dynamic_tools = []\n        \n        try:\n            # 获取所有已安装的MCP服务器\n            servers_result = await self.sandbox.mcp_list_servers()\n            if not servers_result.success or not servers_result.data:\n                logger.debug(\"No MCP servers found or failed to list servers\")\n                self._dynamic_tools_cache = []\n                return []\n\n            servers = servers_result.data\n            \n            for server in servers:\n                package_name = server.get(\"pkg\")\n                alive = server.get(\"alive\")\n                \n                if not package_name or not alive:\n                    continue\n                \n                try:\n                    # 获取服务器的工具列表\n                    tools_result = await self.sandbox.mcp_get_capabilities(package_name)\n                    if tools_result.success and tools_result.data:\n                        tools = tools_result.data.get(\"tools\", [])\n                        \n                        for tool_info in tools:\n                            tool_name = tool_info.get(\"name\")\n                            if not tool_name:\n                                continue\n                            \n                            # 构造动态工具的schema\n                            dynamic_tool = {\n                                \"type\": \"function\",\n                                \"function\": {\n                                    \"name\": f\"mcp_{package_name}_{tool_name}\",\n                                    \"description\": f\"[MCP:{package_name}] {tool_info.get('description', tool_name)}\",\n                                    \"parameters\": tool_info.get('inputSchema', {\n                                        \"type\": \"object\",\n                                        \"properties\": {},\n                                        \"required\": []\n                                    })\n                                }\n                            }\n                            \n                            dynamic_tools.append(dynamic_tool)\n                            \n                except Exception as e:\n                    logger.error(f\"Failed to get tools from MCP server {package_name}: {e}\")\n                    continue\n                    \n        except Exception as e:\n            logger.error(f\"Error getting dynamic MCP tools: {e}\")\n        \n        self._dynamic_tools_cache = dynamic_tools\n        return dynamic_tools\n\n    async def get_tools(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all tools including dynamic MCP tools (async version).\n        \n        Returns:\n            List of all tools including dynamic ones\n        \"\"\"\n        static_tools = await super().get_tools()\n        dynamic_tools = await self._get_dynamic_tools()\n        return static_tools + dynamic_tools\n\n    async def has_function(self, function_name: str) -> bool:\n        \"\"\"Check if specified function exists (async version for dynamic tools).\n        \n        Args:\n            function_name: Function name\n            \n        Returns:\n            Whether the tool exists\n        \"\"\"\n        # 先检查静态工具\n        if await (super().has_function(function_name)):\n            return True\n        \n        # 检查动态工具\n        if function_name.startswith(\"mcp_\"):\n            dynamic_tools = await self._get_dynamic_tools()\n            for tool in dynamic_tools:\n                if tool[\"function\"][\"name\"] == function_name:\n                    return True\n        \n        return False\n\n    async def invoke_function(self, function_name: str, **kwargs) -> ToolResult:\n        \"\"\"Invoke specified tool (supports both static and dynamic tools).\n        \n        Args:\n            function_name: Function name\n            **kwargs: Parameters\n            \n        Returns:\n            Invocation result\n            \n        Raises:\n            ValueError: Raised when tool doesn't exist\n        \"\"\"\n        # 确保初始化\n        await self.initialize()\n\n        # 先尝试调用静态工具\n        try:\n            return await super().invoke_function(function_name, **kwargs)\n        except ValueError:\n            pass\n        \n        # 尝试调用动态MCP工具\n        if function_name.startswith(\"mcp_\"):\n            try:\n                # 为了稳健地解析包名和工具名（即使它们包含下划线），\n                # 我们从缓存的工具定义中查找函数，并从其描述中提取包名。\n                dynamic_tools = await self._get_dynamic_tools()\n                target_tool_schema = next(\n                    (t for t in dynamic_tools if t.get(\"function\", {}).get(\"name\") == function_name),\n                    None\n                )\n\n                if not target_tool_schema:\n                    raise ValueError(f\"Tool '{function_name}' not found among dynamic MCP tools.\")\n\n                description = target_tool_schema[\"function\"].get(\"description\", \"\")\n                # 描述格式为: \"[MCP:{package_name}] {description}\"\n                if not description.startswith(\"[MCP:\") or \"]\" not in description:\n                    raise ValueError(\n                        f\"Could not determine package name for MCP tool '{function_name}' from description.\"\n                    )\n\n                start_index = 5  # len(\"[MCP:\")\n                end_index = description.find(\"]\")\n                package_name = description[start_index:end_index]\n                \n                prefix = f\"mcp_{package_name}_\"\n                if not function_name.startswith(prefix):\n                    # 正常情况下不应发生，作为安全措施\n                    raise ValueError(\n                        f\"Mismatch between function name '{function_name}' and package name '{package_name}'.\"\n                    )\n\n                tool_name = function_name[len(prefix):]\n                \n                return await self.call_tool(package_name, tool_name, kwargs)\n            except Exception as e:\n                return ToolResult(success=False, message=f\"Error calling MCP tool {function_name}: {str(e)}\")\n        \n        raise ValueError(f\"Tool '{function_name}' not found\")\n\n    def invalidate_cache(self):\n        \"\"\"Invalidate the dynamic tools cache to force refresh.\"\"\"\n        self._dynamic_tools_cache = None\n        self._tools_cache = None\n\n    @tool(\n        name=\"mcp_install_server\",\n        description=\"Install and start an MCP server in the sandbox environment\",\n        parameters={\n            \"package_name\": {\n                \"type\": \"string\",\n                \"description\": \"Name of the MCP package to install (e.g., 'mcp-filesystem', '@modelcontextprotocol/server-filesystem')\"\n            },\n            \"language\": {\n                \"type\": \"string\",\n                \"description\": \"Programming language of the server\",\n                \"enum\": [\"python\", \"node\"],\n                \"default\": \"python\"\n            },\n            \"args\": {\n                \"type\": \"array\",\n                \"description\": \"Optional list of arguments to pass to the server\",\n                \"items\": {\"type\": \"string\"},\n                \"default\": []\n            }\n        },\n        required=[\"package_name\"]\n    )\n    async def install_server(\n        self, \n        package_name: str, \n        language: str = \"python\", \n        args: Optional[List[str]] = None\n    ) -> ToolResult:\n        \"\"\"Install and start an MCP server.\n        \n        Args:\n            package_name: Name of the MCP package to install\n            language: Programming language (\"python\" or \"node\")\n            args: Optional list of arguments to pass to the server\n            \n        Returns:\n            Installation result\n        \"\"\"\n        try:\n            logger.info(f\"Installing MCP server: {package_name} ({language})\")\n            \n            result = await self.sandbox.mcp_install(\n                pkg=package_name,\n                lang=language,\n                args=args\n            )\n            \n            # 安装成功后清除缓存，强制重新获取工具列表\n            if result.success:\n                logger.info(f\"Successfully installed MCP server: {package_name}\")\n                self.invalidate_cache()\n            else:\n                logger.error(f\"Failed to install MCP server {package_name}: {result.message}\")\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error installing MCP server {package_name}: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n\n    @tool(\n        name=\"mcp_get_capabilities\",\n        description=\"Get the capabilities of a specific MCP server\",\n        parameters={\n            \"package_name\": {\n                \"type\": \"string\",\n                \"description\": \"Name of the MCP package\"\n            }\n        },\n        required=[\"package_name\"]\n    )\n    async def get_capabilities(self, package_name: str) -> ToolResult:\n        \"\"\"Get the capabilities of an MCP server.\n        \n        Args:\n            package_name: Name of the MCP package\n            \n        Returns:\n            Server capabilities information\n        \"\"\"\n        try:\n            # 确保初始化\n            await self.initialize()\n\n            logger.debug(f\"Getting capabilities of MCP server: {package_name}\")\n            \n            result = await self.sandbox.mcp_get_capabilities(pkg=package_name)\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error getting MCP server capabilities {package_name}: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n\n    @tool(\n        name=\"mcp_list_tools\",\n        description=\"List all tools available in a specific MCP server\",\n        parameters={\n            \"package_name\": {\n                \"type\": \"string\",\n                \"description\": \"Name of the MCP package\"\n            }\n        },\n        required=[\"package_name\"]\n    )\n    async def list_tools(self, package_name: str) -> ToolResult:\n        \"\"\"List tools available in an MCP server.\n        \n        Args:\n            package_name: Name of the MCP package\n            \n        Returns:\n            Available tools list\n        \"\"\"\n        try:\n            # 确保初始化\n            await self.initialize()\n\n            logger.debug(f\"Listing tools for MCP server: {package_name}\")\n            \n            request = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": 1,\n                \"method\": \"tools/list\",\n                \"params\": {}\n            }\n            \n            result = await self.sandbox.mcp_proxy_request(\n                pkg=package_name,\n                request=request\n            )\n            \n            if result.success and result.data:\n                try:\n                    response = result.data if isinstance(result.data, dict) else json.loads(result.data)\n                    if \"result\" in response and \"tools\" in response[\"result\"]:\n                        tools = response[\"result\"][\"tools\"]\n                        tool_list = [\n                            {\n                                \"name\": tool.get(\"name\"),\n                                \"description\": tool.get(\"description\", \"\"),\n                                \"inputSchema\": tool.get(\"inputSchema\", {})\n                            }\n                            for tool in tools\n                        ]\n                        return ToolResult(\n                            success=True,\n                            message=f\"Found {len(tool_list)} tools\",\n                            data={\"tools\": tool_list}\n                        )\n                    else:\n                        return ToolResult(success=False, message=\"Invalid response format\")\n                except json.JSONDecodeError as e:\n                    return ToolResult(success=False, message=f\"Failed to parse response: {e}\")\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error listing tools for MCP server {package_name}: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n\n    async def call_tool(\n        self, \n        package_name: str, \n        tool_name: str, \n        arguments: Dict[str, Any]\n    ) -> ToolResult:\n        \"\"\"Call a specific tool on an MCP server.\n        \n        Args:\n            package_name: Name of the MCP package\n            tool_name: Name of the tool to call\n            arguments: Arguments to pass to the tool\n            \n        Returns:\n            Tool execution result\n        \"\"\"\n        try:\n            # 确保初始化\n            await self.initialize()\n\n            logger.info(f\"Calling tool {tool_name} on MCP server {package_name}\")\n            \n            request = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": 1,\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": tool_name,\n                    \"arguments\": arguments\n                }\n            }\n            \n            result = await self.sandbox.mcp_proxy_request(\n                pkg=package_name,\n                request=request\n            )\n            \n            if result.success and result.data:\n                try:\n                    response = result.data if isinstance(result.data, dict) else json.loads(result.data)\n                    if \"result\" in response:\n                        return ToolResult(\n                            success=True,\n                            message=f\"Tool {tool_name} executed successfully\",\n                            data=response[\"result\"]\n                        )\n                    elif \"error\" in response:\n                        error = response[\"error\"]\n                        return ToolResult(\n                            success=False,\n                            message=f\"Tool error: {error.get('message', 'Unknown error')}\"\n                        )\n                    else:\n                        return ToolResult(success=False, message=\"Invalid response format\")\n                except json.JSONDecodeError as e:\n                    return ToolResult(success=False, message=f\"Failed to parse response: {e}\")\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error calling tool {tool_name} on MCP server {package_name}: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n\n    async def list_servers(self) -> ToolResult:\n        \"\"\"List all installed MCP servers and their status.\n        \n        Returns:\n            Server list with status information\n        \"\"\"\n        try:\n            # 确保初始化\n            await self.initialize()\n\n            logger.debug(\"Listing MCP servers\")\n            \n            result = await self.sandbox.mcp_list_servers()\n            \n            if result.success:\n                logger.debug(f\"Found MCP servers: {result.data}\")\n            else:\n                logger.error(f\"Failed to list MCP servers: {result.message}\")\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error listing MCP servers: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n\n    async def list_resources(self, package_name: str) -> ToolResult:\n        \"\"\"List resources available in an MCP server.\n        \n        Args:\n            package_name: Name of the MCP package\n            \n        Returns:\n            Available resources list\n        \"\"\"\n        try:\n            # 确保初始化\n            await self.initialize()\n\n            logger.debug(f\"Listing resources for MCP server: {package_name}\")\n            \n            request = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": 1,\n                \"method\": \"resources/list\",\n                \"params\": {}\n            }\n            \n            result = await self.sandbox.mcp_proxy_request(\n                pkg=package_name,\n                request=request\n            )\n            \n            if result.success and result.data:\n                try:\n                    response = result.data if isinstance(result.data, dict) else json.loads(result.data)\n                    if \"result\" in response and \"resources\" in response[\"result\"]:\n                        resources = response[\"result\"][\"resources\"]\n                        resource_list = [\n                            {\n                                \"uri\": resource.get(\"uri\"),\n                                \"name\": resource.get(\"name\", \"\"),\n                                \"description\": resource.get(\"description\", \"\"),\n                                \"mimeType\": resource.get(\"mimeType\", \"\")\n                            }\n                            for resource in resources\n                        ]\n                        return ToolResult(\n                            success=True,\n                            message=f\"Found {len(resource_list)} resources\",\n                            data={\"resources\": resource_list}\n                        )\n                    else:\n                        return ToolResult(success=False, message=\"Invalid response format\")\n                except json.JSONDecodeError as e:\n                    return ToolResult(success=False, message=f\"Failed to parse response: {e}\")\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error listing resources for MCP server {package_name}: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n\n    async def read_resource(self, package_name: str, uri: str) -> ToolResult:\n        \"\"\"Read a specific resource from an MCP server.\n        \n        Args:\n            package_name: Name of the MCP package\n            uri: URI of the resource to read\n            \n        Returns:\n            Resource content\n        \"\"\"\n        try:\n            # 确保初始化\n            await self.initialize()\n\n            logger.debug(f\"Reading resource {uri} from MCP server: {package_name}\")\n            \n            request = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": 1,\n                \"method\": \"resources/read\",\n                \"params\": {\n                    \"uri\": uri\n                }\n            }\n            \n            result = await self.sandbox.mcp_proxy_request(\n                pkg=package_name,\n                request=request\n            )\n            \n            if result.success and result.data:\n                try:\n                    response = result.data if isinstance(result.data, dict) else json.loads(result.data)\n                    if \"result\" in response:\n                        return ToolResult(\n                            success=True,\n                            message=f\"Resource {uri} read successfully\",\n                            data=response[\"result\"]\n                        )\n                    elif \"error\" in response:\n                        error = response[\"error\"]\n                        return ToolResult(\n                            success=False,\n                            message=f\"Resource error: {error.get('message', 'Unknown error')}\"\n                        )\n                    else:\n                        return ToolResult(success=False, message=\"Invalid response format\")\n                except json.JSONDecodeError as e:\n                    return ToolResult(success=False, message=f\"Failed to parse response: {e}\")\n            \n            return result\n            \n        except Exception as e:\n            error_msg = f\"Error reading resource {uri} from MCP server {package_name}: {str(e)}\"\n            logger.error(error_msg)\n            return ToolResult(success=False, message=error_msg)\n",
      "methods": [
        "<module>.McpTool.__init__",
        "<module>.McpTool._parse_pre_install_servers",
        "<module>.McpTool.initialize",
        "<module>.McpTool._get_dynamic_tools",
        "<module>.McpTool.get_tools",
        "<module>.McpTool.has_function",
        "<module>.McpTool.invoke_function",
        "<module>.McpTool.invalidate_cache",
        "<module>.McpTool.install_server",
        "<module>.McpTool.get_capabilities",
        "<module>.McpTool.list_tools",
        "<module>.McpTool.call_tool",
        "<module>.McpTool.list_servers",
        "<module>.McpTool.list_resources",
        "<module>.McpTool.read_resource"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/browser.py",
      "name": "BrowserTool",
      "qualname": "<module>.BrowserTool",
      "source": "class BrowserTool(BaseTool):\n    \"\"\"Browser tool class, providing browser interaction functions\"\"\"\n\n    name: str = \"browser\"\n    \n    def __init__(self, browser: Browser):\n        \"\"\"Initialize browser tool class\n        \n        Args:\n            browser: Browser service\n        \"\"\"\n        super().__init__()\n        self.browser = browser\n    \n    @tool(\n        name=\"browser_view\",\n        description=\"View content of the current browser page. Use for checking the latest state of previously opened pages.\",\n        parameters={},\n        required=[]\n    )\n    async def browser_view(self) -> ToolResult:\n        \"\"\"View current browser page content\n        \n        Returns:\n            Browser page content\n        \"\"\"\n        return await self.browser.view_page()\n    \n    @tool(\n        name=\"browser_navigate\",\n        description=\"Navigate browser to specified URL. Use when accessing new pages is needed.\",\n        parameters={\n            \"url\": {\n                \"type\": \"string\",\n                \"description\": \"Complete URL to visit. Must include protocol prefix.\"\n            }\n        },\n        required=[\"url\"]\n    )\n    async def browser_navigate(self, url: str) -> ToolResult:\n        \"\"\"Navigate browser to specified URL\n        \n        Args:\n            url: Complete URL address, must include protocol prefix\n            \n        Returns:\n            Navigation result\n        \"\"\"\n        return await self.browser.navigate(url)\n    \n    @tool(\n        name=\"browser_restart\",\n        description=\"Restart browser and navigate to specified URL. Use when browser state needs to be reset.\",\n        parameters={\n            \"url\": {\n                \"type\": \"string\",\n                \"description\": \"Complete URL to visit after restart. Must include protocol prefix.\"\n            }\n        },\n        required=[\"url\"]\n    )\n    async def browser_restart(self, url: str) -> ToolResult:\n        \"\"\"Restart browser and navigate to specified URL\n        \n        Args:\n            url: Complete URL address to visit after restart, must include protocol prefix\n            \n        Returns:\n            Restart result\n        \"\"\"\n        return await self.browser.restart(url)\n    \n    @tool(\n        name=\"browser_click\",\n        description=\"Click on elements in the current browser page. Use when clicking page elements is needed.\",\n        parameters={\n            \"index\": {\n                \"type\": \"integer\",\n                \"description\": \"(Optional) Index number of the element to click\"\n            },\n            \"coordinate_x\": {\n                \"type\": \"number\",\n                \"description\": \"(Optional) X coordinate of click position\"\n            },\n            \"coordinate_y\": {\n                \"type\": \"number\",\n                \"description\": \"(Optional) Y coordinate of click position\"\n            }\n        },\n        required=[]\n    )\n    async def browser_click(\n        self,\n        index: Optional[int] = None,\n        coordinate_x: Optional[float] = None,\n        coordinate_y: Optional[float] = None\n    ) -> ToolResult:\n        \"\"\"Click on elements in the current browser page\n        \n        Args:\n            index: (Optional) Index number of the element to click\n            coordinate_x: (Optional) X coordinate of click position\n            coordinate_y: (Optional) Y coordinate of click position\n            \n        Returns:\n            Click result\n        \"\"\"\n        return await self.browser.click(index, coordinate_x, coordinate_y)\n    \n    @tool(\n        name=\"browser_input\",\n        description=\"Overwrite text in editable elements on the current browser page. Use when filling content in input fields.\",\n        parameters={\n            \"index\": {\n                \"type\": \"integer\",\n                \"description\": \"(Optional) Index number of the element to overwrite text\"\n            },\n            \"coordinate_x\": {\n                \"type\": \"number\",\n                \"description\": \"(Optional) X coordinate of the element to overwrite text\"\n            },\n            \"coordinate_y\": {\n                \"type\": \"number\",\n                \"description\": \"(Optional) Y coordinate of the element to overwrite text\"\n            },\n            \"text\": {\n                \"type\": \"string\",\n                \"description\": \"Complete text content to overwrite\"\n            },\n            \"press_enter\": {\n                \"type\": \"boolean\",\n                \"description\": \"Whether to press Enter key after input\"\n            }\n        },\n        required=[\"text\", \"press_enter\"]\n    )\n    async def browser_input(\n        self,\n        text: str,\n        press_enter: bool,\n        index: Optional[int] = None,\n        coordinate_x: Optional[float] = None,\n        coordinate_y: Optional[float] = None\n    ) -> ToolResult:\n        \"\"\"Overwrite text in editable elements on the current browser page\n        \n        Args:\n            text: Complete text content to overwrite\n            press_enter: Whether to press Enter key after input\n            index: (Optional) Index number of the element to overwrite text\n            coordinate_x: (Optional) X coordinate of the element to overwrite text\n            coordinate_y: (Optional) Y coordinate of the element to overwrite text\n            \n        Returns:\n            Input result\n        \"\"\"\n        return await self.browser.input(text, press_enter, index, coordinate_x, coordinate_y)\n    \n    @tool(\n        name=\"browser_move_mouse\",\n        description=\"Move cursor to specified position on the current browser page. Use when simulating user mouse movement.\",\n        parameters={\n            \"coordinate_x\": {\n                \"type\": \"number\",\n                \"description\": \"X coordinate of target cursor position\"\n            },\n            \"coordinate_y\": {\n                \"type\": \"number\",\n                \"description\": \"Y coordinate of target cursor position\"\n            }\n        },\n        required=[\"coordinate_x\", \"coordinate_y\"]\n    )\n    async def browser_move_mouse(\n        self,\n        coordinate_x: float,\n        coordinate_y: float\n    ) -> ToolResult:\n        \"\"\"Move mouse cursor to specified position on the current browser page\n        \n        Args:\n            coordinate_x: X coordinate of target cursor position\n            coordinate_y: Y coordinate of target cursor position\n            \n        Returns:\n            Move result\n        \"\"\"\n        return await self.browser.move_mouse(coordinate_x, coordinate_y)\n    \n    @tool(\n        name=\"browser_press_key\",\n        description=\"Simulate key press in the current browser page. Use when specific keyboard operations are needed.\",\n        parameters={\n            \"key\": {\n                \"type\": \"string\",\n                \"description\": \"Key name to simulate (e.g., Enter, Tab, ArrowUp), supports key combinations (e.g., Control+Enter).\"\n            }\n        },\n        required=[\"key\"]\n    )\n    async def browser_press_key(\n        self,\n        key: str\n    ) -> ToolResult:\n        \"\"\"Simulate key press in the current browser page\n        \n        Args:\n            key: Key name to simulate (e.g., Enter, Tab, ArrowUp), supports key combinations (e.g., Control+Enter)\n            \n        Returns:\n            Key press result\n        \"\"\"\n        return await self.browser.press_key(key)\n    \n    @tool(\n        name=\"browser_select_option\",\n        description=\"Select specified option from dropdown list element in the current browser page. Use when selecting dropdown menu options.\",\n        parameters={\n            \"index\": {\n                \"type\": \"integer\",\n                \"description\": \"Index number of the dropdown list element\"\n            },\n            \"option\": {\n                \"type\": \"integer\",\n                \"description\": \"Option number to select, starting from 0.\"\n            }\n        },\n        required=[\"index\", \"option\"]\n    )\n    async def browser_select_option(\n        self,\n        index: int,\n        option: int\n    ) -> ToolResult:\n        \"\"\"Select specified option from dropdown list element in the current browser page\n        \n        Args:\n            index: Index number of the dropdown list element\n            option: Option number to select, starting from 0\n            \n        Returns:\n            Selection result\n        \"\"\"\n        return await self.browser.select_option(index, option)\n    \n    @tool(\n        name=\"browser_scroll_up\",\n        description=\"Scroll up the current browser page. Use when viewing content above or returning to page top.\",\n        parameters={\n            \"to_top\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to scroll directly to page top instead of one viewport up.\"\n            }\n        },\n        required=[]\n    )\n    async def browser_scroll_up(\n        self,\n        to_top: Optional[bool] = None\n    ) -> ToolResult:\n        \"\"\"Scroll up the current browser page\n        \n        Args:\n            to_top: (Optional) Whether to scroll directly to page top instead of one viewport up\n            \n        Returns:\n            Scroll result\n        \"\"\"\n        return await self.browser.scroll_up(to_top)\n    \n    @tool(\n        name=\"browser_scroll_down\",\n        description=\"Scroll down the current browser page. Use when viewing content below or jumping to page bottom.\",\n        parameters={\n            \"to_bottom\": {\n                \"type\": \"boolean\",\n                \"description\": \"(Optional) Whether to scroll directly to page bottom instead of one viewport down.\"\n            }\n        },\n        required=[]\n    )\n    async def browser_scroll_down(\n        self,\n        to_bottom: Optional[bool] = None\n    ) -> ToolResult:\n        \"\"\"Scroll down the current browser page\n        \n        Args:\n            to_bottom: (Optional) Whether to scroll directly to page bottom instead of one viewport down\n            \n        Returns:\n            Scroll result\n        \"\"\"\n        return await self.browser.scroll_down(to_bottom)\n    \n    @tool(\n        name=\"browser_console_exec\",\n        description=\"Execute JavaScript code in browser console. Use when custom scripts need to be executed.\",\n        parameters={\n            \"javascript\": {\n                \"type\": \"string\",\n                \"description\": \"JavaScript code to execute. Note that the runtime environment is browser console.\"\n            }\n        },\n        required=[\"javascript\"]\n    )\n    async def browser_console_exec(\n        self,\n        javascript: str\n    ) -> ToolResult:\n        \"\"\"Execute JavaScript code in browser console\n        \n        Args:\n            javascript: JavaScript code to execute, note that the runtime environment is browser console\n            \n        Returns:\n            Execution result\n        \"\"\"\n        return await self.browser.console_exec(javascript)\n    \n    @tool(\n        name=\"browser_console_view\",\n        description=\"View browser console output. Use when checking JavaScript logs or debugging page errors.\",\n        parameters={\n            \"max_lines\": {\n                \"type\": \"integer\",\n                \"description\": \"(Optional) Maximum number of log lines to return.\"\n            }\n        },\n        required=[]\n    )\n    async def browser_console_view(\n        self,\n        max_lines: Optional[int] = None\n    ) -> ToolResult:\n        \"\"\"View browser console output\n        \n        Args:\n            max_lines: (Optional) Maximum number of log lines to return\n            \n        Returns:\n            Console output\n        \"\"\"\n        return await self.browser.console_view(max_lines) ",
      "methods": [
        "<module>.BrowserTool.__init__",
        "<module>.BrowserTool.browser_view",
        "<module>.BrowserTool.browser_navigate",
        "<module>.BrowserTool.browser_restart",
        "<module>.BrowserTool.browser_click",
        "<module>.BrowserTool.browser_input",
        "<module>.BrowserTool.browser_move_mouse",
        "<module>.BrowserTool.browser_press_key",
        "<module>.BrowserTool.browser_select_option",
        "<module>.BrowserTool.browser_scroll_up",
        "<module>.BrowserTool.browser_scroll_down",
        "<module>.BrowserTool.browser_console_exec",
        "<module>.BrowserTool.browser_console_view"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/reasoning.py",
      "name": "DeepReasoningTool",
      "qualname": "<module>.DeepReasoningTool",
      "source": "class DeepReasoningTool(BaseTool):\n    \"\"\"深度推理工具\"\"\"\n\n    name: str = \"reasoning\"\n\n    def __init__(self, reason_llm: ReasonLLM):\n        \"\"\"Initialize deep reasoning tool class\n        \n        Args:\n            reason_llm: Reasoning LLM service\n        \"\"\"\n        super().__init__()\n        self.reason_llm = reason_llm\n\n    @tool(\n        name=\"deep_reasoning\",\n        description=\"Perform deep reasoning analysis on complex problems. Use for logical analysis, code problem solving, and critical thinking.\",\n        parameters={\n            \"problem\": {\n                \"type\": \"string\",\n                \"description\": \"The problem or question that requires deep reasoning\"\n            },\n            \"context\": {\n                \"type\": \"string\",\n                \"description\": \"Optional background information or context for the problem\"\n            }\n        },\n        required=[\"problem\", \"context\"]\n    )\n    async def deep_reasoning(self, problem: str, context: str) -> str:\n        \"\"\"\n        进行深度推理分析\n        \n        Args:\n            problem: 需要推理的问题\n            context: 可选的上下文信息\n            \n        Returns:\n            推理分析结果\n        \"\"\"\n        try:\n            logger.info(f\"开始深度推理: {problem[:50]}...\")\n            \n            result = await self.reason_llm.deep_reasoning(problem, context)\n            \n            logger.info(f\"深度推理完成，结果长度: {len(result)}\")\n            return result\n            \n        except Exception as e:\n            error_msg = f\"深度推理失败: {str(e)}\"\n            logger.error(error_msg)\n            raise Exception(error_msg)\n",
      "methods": [
        "<module>.DeepReasoningTool.__init__",
        "<module>.DeepReasoningTool.deep_reasoning"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/tools/video.py",
      "name": "VideoTool",
      "qualname": "<module>.VideoTool",
      "source": "class VideoTool(BaseTool):\n    \"\"\"视频分析工具\"\"\"\n\n    name: str = \"video\"\n    \n    def __init__(self, sandbox: Sandbox, video_llm: VideoLLM):\n        \"\"\"Initialize video tool class\n        \n        Args:\n            sandbox: Sandbox service\n            video_llm: Video LLM service\n        \"\"\"\n        super().__init__()\n        self.sandbox = sandbox\n        self.video_llm = video_llm\n    \n    @tool(\n        name=\"analyze_video\",\n        description=\"Analyze video content. Use for analyzing Youtube video content.\",\n        parameters={\n            \"video_path\": {\n                \"type\": \"string\",\n                \"description\": \"Youtube video URL\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"Query for video details or content\"\n            }\n        },\n        required=[\"video_path\", \"query\"]\n    )\n    async def analyze_video(self, video_path: str, query: str) -> str:\n        \"\"\"\n        分析视频内容\n        \n        Args:\n            video_path: 视频文件路径或URL\n            query: 关于视频的问题，如果为None则返回视频描述\n            \n        Returns:\n            视频分析结果\n        \"\"\"\n        try:\n            logger.info(f\"开始分析视频: {video_path}\")\n            \n            # 如果没有提供查询，使用默认的描述查询\n            if not query:\n                query = \"请详细描述这个视频的内容，包括视觉元素、动作、场景、人物等。\"\n            \n            # 判断是否为网络URL\n            if video_path.startswith('http://') or video_path.startswith('https://'):\n                # 网络视频URL，直接传递给VideoLLM\n                result = await self.video_llm.ask_video(video_path, query)\n            else:\n                # 本地文件路径，需要转换为沙盒内的绝对路径\n                if not video_path.startswith('/'):\n                    # 相对路径，转换为绝对路径\n                    video_path = f\"/home/ubuntu/{video_path}\"\n                \n                # 检查文件是否存在\n                file_exists_result = await self.sandbox.file_exists(video_path)\n                if not file_exists_result.success:\n                    raise FileNotFoundError(f\"视频文件不存在: {video_path}\")\n                \n                # 调用VideoLLM分析视频\n                result = await self.video_llm.ask_video(video_path, query)\n            \n            logger.info(f\"视频分析完成，结果长度: {len(result)}\")\n            return result\n            \n        except Exception as e:\n            error_msg = f\"视频分析失败: {str(e)}\"\n            logger.error(error_msg)\n            raise Exception(error_msg)\n    \n    @tool(\n        name=\"video_to_text\",\n        description=\"Transcribe video content. Use for transcribing Youtube video content.\",\n        parameters={\n            \"video_path\": {\n                \"type\": \"string\",\n                \"description\": \"Youtube video URL\"\n            },\n        },\n        required=[\"video_path\"]\n    )\n    async def video_to_text(self, video_path: str) -> str:\n        \"\"\"\n        获取视频的详细描述\n        \n        Args:\n            video_path: 视频文件路径或URL\n            \n        Returns:\n            视频描述\n        \"\"\"\n        try:\n            logger.info(f\"开始描述视频: {video_path}\")\n            \n            # 判断是否为网络URL\n            if video_path.startswith('http://') or video_path.startswith('https://'):\n                # 网络视频URL\n                result = await self.video_llm.video_to_text(video_path)\n            else:\n                # 本地文件路径\n                if not video_path.startswith('/'):\n                    video_path = f\"/home/ubuntu/{video_path}\"\n                \n                file_exists_result = await self.sandbox.file_exists(video_path)\n                if not file_exists_result.success:\n                    raise FileNotFoundError(f\"视频文件不存在: {video_path}\")\n                \n                result = await self.video_llm.video_to_text(video_path)\n            \n            logger.info(f\"视频描述完成，结果长度: {len(result)}\")\n            return result\n            \n        except Exception as e:\n            error_msg = f\"视频描述失败: {str(e)}\"\n            logger.error(error_msg)\n            raise Exception(error_msg) ",
      "methods": [
        "<module>.VideoTool.__init__",
        "<module>.VideoTool.analyze_video",
        "<module>.VideoTool.video_to_text"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/notify.py",
      "name": "NotifyAgent",
      "qualname": "<module>.NotifyAgent",
      "source": "class NotifyAgent(BaseAgent):\n    \"\"\"\n    Notify agent class, defining the basic behavior of notification\n    专门用于通知用户任务进展的代理，只能调用message_notify_user工具\n    \"\"\"\n\n    system_prompt: str = NOTIFY_SYSTEM_PROMPT.format(cur_time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n    def __init__(\n        self,\n        memory: Memory,\n        llm: LLM,\n    ):\n        # 只初始化MessageTool，限制只能使用message_notify_user工具\n        super().__init__(memory, llm, [MessageNotifyUserTool()])\n        self.max_iterations = 1\n    \n    async def notify_step_progress(self, plan: Plan, step: Step, status: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        通知用户步骤进展\n        \n        Args:\n            plan: 当前执行的计划\n            step: 当前执行的步骤\n            status: 步骤状态描述\n            \n        Yields:\n            AgentEvent: 代理事件流\n        \"\"\"\n        message = NOTIFY_PROMPT.format(\n            goal=plan.goal, \n            step=step.description,\n            status=status\n        )\n        \n        async for event in self.execute(message):\n            if isinstance(event, ErrorEvent):\n                # 如果通知失败，记录错误但不中断主流程\n                self.logger.error(f\"Notification failed: {event.error}\")\n            yield event\n    \n    async def notify_plan_progress(self, plan: Plan, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        通知用户计划整体进展\n        \n        Args:\n            plan: 当前执行的计划\n            message: 自定义通知消息\n            \n        Yields:\n            AgentEvent: 代理事件流\n        \"\"\"\n        notify_message = f\"\"\"\n你正在为以下计划提供通知服务：\n\n计划目标：\n{plan.goal}\n\n计划标题：\n{plan.title}\n\n通知内容：\n{message}\n\n请向用户发送适当的通知消息，说明当前计划的整体进展情况。\n\"\"\"\n        \n        async for event in self.execute(notify_message):\n            if isinstance(event, ErrorEvent):\n                # 如果通知失败，记录错误但不中断主流程\n                self.logger.error(f\"Plan notification failed: {event.error}\")\n            yield event\n\n    async def notify_received_message(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        通知用户收到消息\n        \"\"\"\n        notify_message = f\"\"\"回复用户你已经收到消息，并且尽快开始分析。\n        \n        用户请求：\n        {message}\n        \"\"\"\n\n        async for event in self.execute(notify_message):\n            if isinstance(event, ErrorEvent):\n                # 如果通知失败，记录错误但不中断主流程\n                self.logger.error(f\"Received message notification failed: {event.error}\")\n            yield event\n\n    \n    async def notify_custom_message(self, custom_message: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        发送自定义通知消息\n        \n        Args:\n            custom_message: 自定义通知内容\n            \n        Yields:\n            AgentEvent: 代理事件流\n        \"\"\"\n        notify_message = f\"\"\"\n请向用户发送以下通知消息：\n\n{custom_message}\n\n确保消息简洁明了，使用用户友好的语言。\n\"\"\"\n        \n        async for event in self.execute(notify_message):\n            if isinstance(event, ErrorEvent):\n                # 如果通知失败，记录错误但不中断主流程\n                self.logger.error(f\"Custom notification failed: {event.error}\")\n            yield event\n",
      "methods": [
        "<module>.NotifyAgent.__init__",
        "<module>.NotifyAgent.notify_step_progress",
        "<module>.NotifyAgent.notify_plan_progress",
        "<module>.NotifyAgent.notify_received_message",
        "<module>.NotifyAgent.notify_custom_message"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/base.py",
      "name": "BaseAgent",
      "qualname": "<module>.BaseAgent",
      "source": "class BaseAgent(ABC):\n    \"\"\"\n    Base agent class, defining the basic behavior of the agent\n    \"\"\"\n\n    system_prompt: str = \"\"\n    format: Optional[str] = None\n    max_iterations: int = 30\n    max_retries: int = 3\n    retry_interval: float = 2.0\n\n    def __init__(self, memory: Memory, llm: LLM, tools: List[BaseTool] = []):\n        self.memory = memory\n        self.llm = llm\n        self.memory.add_message({\n            \"role\": \"system\", \"content\": self.system_prompt,\n        })\n        self.tools = tools\n        self.logger = setup_agent_logger(self.__class__.__name__)\n    \n    async def get_available_tools(self) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Get all available tools list\"\"\"\n        available_tools = []\n        for tool in self.tools:\n            available_tools.extend(await tool.get_tools())\n        return available_tools\n    \n    async def get_tool(self, function_name: str) -> BaseTool:\n        \"\"\"Get specified tool\"\"\"\n        for tool in self.tools:\n            if await tool.has_function(function_name):\n                return tool\n        raise ValueError(f\"Unknown tool: {function_name}\")\n\n    async def execute_tool(self, tool: BaseTool, function_name: str, arguments: Dict[str, Any]) -> ToolResult:\n        \"\"\"Execute specified tool, with retry mechanism and content length limiting\"\"\"\n\n        retries = 0\n        while retries <= self.max_retries:\n            try:\n                self.logger.info(f\"Executing tool: {tool.name}, function: {function_name}, arguments: {arguments}\")\n                result = await tool.invoke_function(function_name, **arguments)\n                \n                # 限制工具结果内容长度\n                try:\n                    from app.domain.services.tools.context_manager import limit_tool_result_content\n                    limited_result = limit_tool_result_content(result)\n                    \n                    # 如果内容被截断，记录日志\n                    if limited_result != result:\n                        self.logger.info(f\"工具结果内容被截断以控制上下文长度: {tool.name}.{function_name}\")\n                    \n                    return limited_result\n                except ImportError:\n                    # 如果上下文管理器不可用，返回原始结果\n                    self.logger.warning(\"上下文管理器不可用，跳过工具结果长度限制\")\n                    return result\n                    \n            except Exception as e:\n                last_error = str(e)\n                retries += 1\n                if retries <= self.max_retries:\n                    await asyncio.sleep(self.retry_interval * retries)\n                else:\n                    break\n        \n        raise ValueError(f\"Tool execution failed, retried {self.max_retries} times: {last_error}\")\n    \n    async def execute(self, request: str) -> AsyncGenerator[AgentEvent, None]:\n        self.logger.info(f\"Executing request: {request}\")\n        message = await self.ask(request, self.format)\n        for _ in range(self.max_iterations):\n            if not message.tool_calls:\n                break\n            tool_responses = []\n            logger.info(f\"Tool calls: {message.tool_calls}\")\n            # 暂停：1. 向用户请求澄清 2. 向用户请求交付产物\n            pause = False\n            \n            for tool_call in message.tool_calls:\n                function_name = tool_call.function.name\n                function_args = json.loads(tool_call.function.arguments)\n                tool_call_id = tool_call.id\n                \n                try:\n                    tool = await self.get_tool(function_name)\n                except ValueError as e:\n                    self.logger.error(f\"Error getting tool: {e}\")\n                    tool_response = {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call_id,\n                        \"content\": f\"Error getting tool: {e}. Review your avaliable tools and DO NOT use this tool again.\"\n                    }\n                    tool_responses.append(tool_response)\n                    continue\n\n                # Generate event before tool call\n                yield ToolCallingEvent(\n                    tool_name=tool.name,\n                    function_name=function_name,\n                    function_args=function_args\n                )\n\n                if function_name in [\n                    \"message_request_user_clarification\", \n                    \"message_done\"\n                ]:\n                    pause = True\n\n                try:\n                    result = await self.execute_tool(tool, function_name, function_args)\n                except Exception as e:\n                    self.logger.exception(f\"Tool execution failed: {e}\")\n                    tool_response = {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call_id,\n                        \"content\": f\"Tool execution failed: {e}.\"\n                    }\n                    tool_responses.append(tool_response)\n                    continue\n\n                # Generate event after tool call\n                yield ToolCalledEvent(\n                    tool_name=tool.name,\n                    function_name=function_name,\n                    function_args=function_args,\n                    function_result=result\n                )\n\n                tool_response = {\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call_id,\n                    \"content\": result.model_dump_json()\n                }\n                tool_responses.append(tool_response)\n\n            # 确保所有工具响应都被添加到内存中\n            if tool_responses:\n                self.memory.add_messages(tool_responses)\n            \n            # 如果需要暂停，则暂停，不需要继续问LLM\n            if pause:\n                # 在暂停前，先返回工具执行结果\n                if len(tool_responses) > 0:\n                    last_response = tool_responses[-1]\n                    try:\n                        result_data = json.loads(last_response[\"content\"])\n                        if result_data.get(\"data\"):\n                            yield MessageEvent(message=str(result_data[\"data\"]))\n                    except:\n                        pass\n                yield PauseEvent()\n                return\n                \n            # 继续询问LLM（不重复添加工具响应）\n            if tool_responses:\n                message = await self.ask_continue()\n        \n        if message.content:\n            yield MessageEvent(message=message.content)\n    \n    async def ask_continue(self, format: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"继续对话，不添加新消息到内存\"\"\"\n        response_format = None\n        if format:\n            response_format = {\"type\": format}\n\n        self.logger.info(f\"Asking LLM with messages: {self.memory.get_messages()}\")\n        message = await self.llm.ask(self.memory.get_messages(), \n                                     tools=(await self.get_available_tools()), \n                                     response_format=response_format)\n        self.logger.info(f\"Response: {message}\")\n        \n        # [DEBUG 1] 检查OpenAI响应消息\n        logger = logging.getLogger(__name__)\n        logger.info(f\"[DEBUG 1] BaseAgent收到LLM响应: type={type(message)}, content={getattr(message, 'content', 'N/A')}\")\n        logger.info(f\"[DEBUG 1] 响应是否有工具调用: {bool(getattr(message, 'tool_calls', None))}\")\n        \n        # 处理工具调用响应中的None content问题\n        if hasattr(message, 'content') and message.content is None and hasattr(message, 'tool_calls') and message.tool_calls:\n            logger.info(f\"[DEBUG 1] 检测到工具调用响应，content为None，这是正常情况\")\n            # 为工具调用响应设置空的content，避免在Memory中产生错误\n            if hasattr(message, '__dict__'):\n                message.content = \"\"\n                logger.info(f\"[DEBUG 1] 已将工具调用响应的content从None修复为空字符串\")\n        \n        if message.tool_calls:\n            message.tool_calls = message.tool_calls[:1]\n        self.memory.add_message(message)\n        return message\n\n    async def ask_with_messages(self, messages: List[Dict[str, Any]], format: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"添加消息到内存并继续对话\"\"\"\n        self.memory.add_messages(messages)\n        return await self.ask_continue(format)\n\n    async def ask(self, request: str, format: Optional[str] = None) -> Dict[str, Any]:\n        return await self.ask_with_messages([\n            {\n                \"role\": \"user\", \"content\": request\n            }\n        ], format)\n    \n    def roll_back(self):\n        self.memory.roll_back()\n",
      "methods": [
        "<module>.BaseAgent.__init__",
        "<module>.BaseAgent.get_available_tools",
        "<module>.BaseAgent.get_tool",
        "<module>.BaseAgent.execute_tool",
        "<module>.BaseAgent.execute",
        "<module>.BaseAgent.ask_continue",
        "<module>.BaseAgent.ask_with_messages",
        "<module>.BaseAgent.ask",
        "<module>.BaseAgent.roll_back"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/sub_planner.py",
      "name": "SubPlannerType",
      "qualname": "<module>.SubPlannerType",
      "source": "class SubPlannerType(Enum):\n    CODE = \"code\"\n    REASONING = \"reasoning\"\n    SEARCH = \"search\"\n    FILE = \"file\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/sub_planner.py",
      "name": "SubPlannerAgent",
      "qualname": "<module>.SubPlannerAgent",
      "source": "class SubPlannerAgent(BaseAgent):\n    \"\"\"\n    子规划器代理类，负责执行超级规划器分配的具体任务\n    根据任务类型选择合适的工具，并通过execution agent执行具体操作\n    \"\"\"\n\n    system_prompt: str = None  # 初始化为 None，实际在 __init__ 里赋值\n    format: Optional[str] = \"json_object\"\n\n    def __init__(\n        self,\n        llm: LLM,\n        task_type: Enum,\n        # for shared memory between executors\n        memory: Memory = None,\n        sandbox: Optional[Sandbox] = None,\n        browser: Optional[Browser] = None,\n        search_engine: Optional[SearchEngine] = None,\n        audio_llm: Optional[AudioLLM] = None,\n        image_llm: Optional[ImageLLM] = None,\n        video_llm: Optional[VideoLLM] = None,\n        reason_llm: Optional[ReasonLLM] = None,\n    ):\n        # 设置专门的日志记录器\n        self.sub_planner_agent_logger = setup_sub_planner_agent_logger(f\"sub_planner_agent_{task_type.value if task_type else 'unknown'}\")\n        self.sub_planner_agent_logger.debug(f\"=== SubPlannerAgent初始化 任务类型: {task_type.value if task_type else 'None'} ===\")\n        \n        # 添加详细的调试日志\n        self.sub_planner_agent_logger.debug(f\"=== SubPlannerAgent.__init__ 开始 ===\")\n        self.sub_planner_agent_logger.debug(f\"接收到的参数:\")\n        self.sub_planner_agent_logger.debug(f\"  llm: {llm}\")\n        self.sub_planner_agent_logger.debug(f\"  task_type: {task_type} (类型: {type(task_type)})\")\n        self.sub_planner_agent_logger.debug(f\"  memory: {memory}\")\n        self.sub_planner_agent_logger.debug(f\"  sandbox: {sandbox}\")\n        self.sub_planner_agent_logger.debug(f\"  browser: {browser}\")\n        self.sub_planner_agent_logger.debug(f\"  search_engine: {search_engine}\")\n        \n        if task_type:\n            self.sub_planner_agent_logger.debug(f\"task_type.value: {task_type.value}\")\n            self.sub_planner_agent_logger.debug(f\"task_type.value 类型: {type(task_type.value)}\")\n        \n        # 根据任务类型初始化工具\n        tools = []\n        from app.domain.services.tools.file import FileTool\n        from app.domain.services.tools.message import MessageTool\n        tools.append(FileTool(sandbox))\n        tools.append(MessageTool())\n\n        if task_type.value == \"code\":\n            from app.domain.services.tools.shell import ShellTool\n            if sandbox:\n                tools.append(ShellTool(sandbox))\n        elif task_type.value == \"search\":\n            from app.domain.services.tools.search import SearchTool\n            from app.domain.services.tools.browser import BrowserTool\n            from app.domain.services.tools.audio import AudioTool\n            from app.domain.services.tools.image import ImageTool\n            if search_engine:\n                tools.append(SearchTool(search_engine))\n            if browser:\n                tools.append(BrowserTool(browser))\n            if sandbox and audio_llm and llm:\n                tools.append(AudioTool(sandbox, audio_llm, llm))\n            if sandbox and image_llm:\n                tools.append(ImageTool(sandbox, image_llm))\n        elif task_type.value == \"file\":\n            from app.domain.services.tools.image import ImageTool\n            from app.domain.services.tools.audio import AudioTool\n            from app.domain.services.tools.shell import ShellTool\n            if sandbox and image_llm:\n                tools.append(ImageTool(sandbox, image_llm))\n            if sandbox and audio_llm and llm:\n                tools.append(AudioTool(sandbox, audio_llm, llm))\n            if sandbox:\n                tools.append(ShellTool(sandbox))\n        elif task_type.value == \"reasoning\":\n            from app.domain.services.tools.reasoning import DeepReasoningTool\n            from app.domain.services.tools.shell import ShellTool\n            if reason_llm:\n                tools.append(DeepReasoningTool(reason_llm))\n            if sandbox:\n                tools.append(ShellTool(sandbox))\n        self.sub_planner_agent_logger.debug(f\"工具初始化完成，共{len(tools)}个工具\")\n        for i, tool in enumerate(tools):\n            self.sub_planner_agent_logger.debug(f\"工具{i+1}: {type(tool).__name__}\")\n\n        # 设置可用工具列表（动态）\n        self.tools = tools\n        self._setup_tools()\n        self.sub_planner_agent_logger.debug(f\"可用工具列表: {self.available_tools}\")\n        \n        # 生成系统提示词\n        self.sub_planner_agent_logger.debug(f\"=== 开始生成系统提示词 ===\")\n        try:\n            self.system_prompt = PromptManager.get_subplanner_prompt(task_type).format(cur_time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n            self.sub_planner_agent_logger.debug(f\"系统提示词生成成功\")\n            self.sub_planner_agent_logger.debug(f\"系统提示词长度: {len(self.system_prompt)}\")\n        except Exception as e:\n            self.sub_planner_agent_logger.error(f\"生成系统提示词失败: {str(e)}\")\n            self.sub_planner_agent_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_agent_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        # 调用父类构造函数\n      #  self.sub_planner_agent_logger.info(f\"=== 开始调用父类构造函数 ===\")\n        try:\n            super().__init__(\n                memory=memory,\n                llm=llm,\n                tools=tools\n            )\n         #   self.sub_planner_agent_logger.info(f\"父类构造函数调用成功\")\n        except Exception as e:\n            self.sub_planner_agent_logger.error(f\"调用父类构造函数失败: {str(e)}\")\n            self.sub_planner_agent_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_agent_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n        \n        # 存储额外的参数作为实例变量\n        self.sandbox = sandbox\n        self.browser = browser\n        self.search_engine = search_engine\n        self.audio_llm = audio_llm\n        self.image_llm = image_llm\n        self.video_llm = video_llm\n        self.reason_llm = reason_llm\n        \n        # 设置其他属性\n        self.task_type = task_type\n        self.task_description = ''\n        self.goal = ''\n\n        self.sub_planner_agent_logger.info(f\"=== SubPlannerAgent初始化完成 ===\")\n    #    self.sub_planner_agent_logger.info(f\"任务类型: {self.task_type.value}\")\n    #    self.sub_planner_agent_logger.info(f\"可用工具: {self.available_tools}\")\n        \n        self.execution_result = None\n        self.status = ExecutionStatus.PENDING\n\n        # 创建execution agent用于执行具体操作，共享memory\n        self.executor = ExecutionAgent(\n            memory=Memory(), # executors share memory\n            llm=llm,\n            sandbox=sandbox,\n            browser=browser,\n            search_engine=search_engine,\n            audio_llm=audio_llm,\n            image_llm=image_llm,\n            video_llm=video_llm,\n            reason_llm=reason_llm,\n            type_value=task_type.value\n        )\n        \n        # 生成系统提示词 - 使用正确的方法处理工具规则\n        self.sub_planner_agent_logger.debug(f\"=== 开始生成系统提示词 ===\")\n        try:\n            self.system_prompt = PromptManager.insert_datetime(PromptManager.get_system_prompt_with_tools(self.executor.tools, is_executor = False))\n            self.sub_planner_agent_logger.debug(f\"系统提示词生成成功\")\n            self.sub_planner_agent_logger.debug(f\"系统提示词长度: {len(self.system_prompt)}\")\n        except Exception as e:\n            self.sub_planner_agent_logger.error(f\"生成系统提示词失败: {str(e)}\")\n            self.sub_planner_agent_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.sub_planner_agent_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            raise\n\n    def fix(self,parent_plan: Plan, parent_step: Step):\n        self.goal = parent_plan.goal\n        self.task_description = parent_step.description\n\n    def _setup_tools(self):\n        \"\"\"根据实际初始化的工具设置可用工具名称\"\"\"\n        # 支持的工具类型与名称映射\n        tool_type_map = {\n            'ShellTool': 'shell',\n            'BrowserTool': 'browser',\n            'SearchTool': 'search',\n            'FileTool': 'file',\n            'MessageTool': 'message',\n            'AudioTool': 'audio',\n            'ImageTool': 'image',\n            'DeepReasoningTool': 'reasoning',\n            'VideoTool': 'video',\n        }\n        self.available_tools = []\n        for tool in self.tools:\n            tool_class = tool.__class__.__name__\n            tool_name = tool_type_map.get(tool_class)\n            if tool_name and tool_name not in self.available_tools:\n                self.available_tools.append(tool_name)\n        # 如果没有任何工具，使用默认的message工具\n        if not self.available_tools:\n            self.available_tools = [\"message\"]\n        # 添加调试日志\n        self.sub_planner_agent_logger.debug(f\"检测到的工具: {[tool.__class__.__name__ for tool in self.tools]}\")\n        self.sub_planner_agent_logger.debug(f\"设置的可用工具: {self.available_tools}\")\n\n    async def create_plan(self, message: Optional[str] = None) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        创建子计划，传递任务特定的参数\n        \"\"\"\n        prompt_template = PromptManager.get_create_plan_prompt(self.task_type)\n\n        prompt_message = prompt_template.format(\n            goal=self.goal,\n            task_description=self.task_description,\n            task_type=self.task_type.value,\n            available_tools=self.available_tools,\n            user_message=message or self.task_description\n        )\n        \n        plan = None\n        while plan is None:\n            async for event in self.execute(prompt_message):\n                if isinstance(event, MessageEvent):\n              #      self.sub_planner_agent_logger.info(event.message)\n                    try:\n                        good_json_string = repair_json(event.message)\n                        parsed_response = json.loads(good_json_string)\n                        \n                        # 验证JSON结构\n                        if not isinstance(parsed_response, dict):\n                            self.sub_planner_agent_logger.error(f\"Expected dict, got {type(parsed_response)}: {parsed_response}\")\n                            continue\n                            \n                        if \"steps\" not in parsed_response:\n                            self.sub_planner_agent_logger.error(f\"Missing 'steps' field in parsed response: {parsed_response}\")\n                            continue\n                            \n                        if not isinstance(parsed_response[\"steps\"], list):\n                            self.sub_planner_agent_logger.error(f\"Expected 'steps' to be list, got {type(parsed_response['steps'])}: {parsed_response['steps']}\")\n                            continue\n                        \n                        steps = [Step(id=step[\"id\"], description=step[\"description\"]) \n                                for step in parsed_response[\"steps\"] if isinstance(step, dict)]\n                        plan = Plan(\n                            id=f\"plan_{self.task_type.value}_{len(steps)}\", \n                            goal=parsed_response[\"goal\"], \n                            title=parsed_response[\"title\"],\n                            steps=steps, \n                            message=parsed_response[\"message\"]\n                        )\n                        yield PlanCreatedEvent(plan=plan, issubplan=True)\n                    except json.JSONDecodeError as e:\n                        self.sub_planner_agent_logger.error(f\"JSON decode error: {e}, message: {event.message}\")\n                        continue\n                    except KeyError as e:\n                        self.sub_planner_agent_logger.error(f\"Missing required field: {e}, parsed_response: {parsed_response}\")\n                        continue\n                    except Exception as e:\n                        self.sub_planner_agent_logger.error(f\"Error parsing plan: {e}, message: {event.message}\")\n                        continue\n                else:\n                    yield event\n\n    async def update_plan(self, plan: Plan, previous_steps: str) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        更新子计划，传递任务特定的参数\n        \"\"\"\n        prompt_template = PromptManager.get_update_plan_prompt(self.task_type)\n        prompt_message = prompt_template.format(\n            goal=self.goal,\n            task_type=self.task_type.value,\n            #task_description=self.task_description,\n            available_tools=self.available_tools,\n            plan=plan.model_dump_json(include={\"steps\"}), \n            previous_steps=previous_steps\n        )\n        \n        async for event in self.execute(prompt_message):\n            if isinstance(event, MessageEvent):\n                self.sub_planner_agent_logger.info(event.message)\n                try:\n                    good_json_string = repair_json(event.message)\n                    parsed_response = json.loads(good_json_string)\n                    \n                    # 验证JSON结构\n                    if not isinstance(parsed_response, dict):\n                        self.sub_planner_agent_logger.error(f\"Expected dict, got {type(parsed_response)}: {parsed_response}\")\n                        continue\n                    \n                    # 检测是否是其他格式的响应（如总结格式）\n                    summary_fields = [\"task_completion_status\", \"key_findings_and_results\", \n                                    \"tool_usage_summary\", \"issues_and_challenges\", \n                                    \"next_steps\", \"executive_summary\"]\n                    \n                    is_summary_format = any(field in parsed_response for field in summary_fields)\n                    \n                    if is_summary_format:\n                        self.sub_planner_agent_logger.warning(f\"LLM returned summary format instead of plan update format. Generating fallback plan.\")\n                        # 生成一个默认的计划更新：保持剩余的未完成步骤\n                        remaining_steps = [step for step in plan.steps if not step.is_done()]\n                        new_steps = remaining_steps\n                        self.sub_planner_agent_logger.info(f\"Fallback plan generated with {len(new_steps)} remaining steps\")\n                        \n                    elif \"steps\" not in parsed_response:\n                        self.sub_planner_agent_logger.error(f\"Missing 'steps' field in parsed response: {parsed_response}\")\n                        # 自动补充默认的 steps 字段\n                        remaining_steps = [step for step in plan.steps if not step.is_done()]\n                        new_steps = remaining_steps\n                        self.sub_planner_agent_logger.info(f\"Auto-generated fallback plan with {len(new_steps)} remaining steps due to missing 'steps' field\")\n                        \n                    elif not isinstance(parsed_response[\"steps\"], list):\n                        self.sub_planner_agent_logger.error(f\"Expected 'steps' to be list, got {type(parsed_response['steps'])}: {parsed_response['steps']}\")\n                        # 自动补充默认的 steps 列表\n                        remaining_steps = [step for step in plan.steps if not step.is_done()]\n                        new_steps = remaining_steps\n                        self.sub_planner_agent_logger.info(f\"Auto-generated fallback plan with {len(new_steps)} remaining steps due to invalid 'steps' format\")\n                        \n                    else:\n                        # 正常的计划更新格式，但需要检查和补充缺少的字段\n                        new_steps = []\n                        for step_data in parsed_response[\"steps\"]:\n                            if isinstance(step_data, dict):\n                                # 自动补充缺少的字段，提供默认值\n                                step_dict = {\n                                    \"id\": step_data.get(\"id\", f\"step_{len(new_steps) + 1}\"),\n                                    \"description\": step_data.get(\"description\", \"未指定描述的步骤\"),\n                                    \"subplan_step\": step_data.get(\"subplan_step\"),\n                                    \"subplanner_type\": step_data.get(\"subplanner_type\", \"\").lower() if step_data.get(\"subplanner_type\") else None\n                                }\n                                \n                                # 记录补充了哪些字段\n                                missing_fields = []\n                                if \"id\" not in step_data:\n                                    missing_fields.append(\"id\")\n                                if \"description\" not in step_data:\n                                    missing_fields.append(\"description\")\n                                    \n                                if missing_fields:\n                                    self.sub_planner_agent_logger.warning(f\"Auto-filled missing fields for step: {missing_fields}\")\n                                \n                                new_step = Step(\n                                    id=step_dict[\"id\"],\n                                    description=step_dict[\"description\"],\n                                    sub_plan_step=step_dict[\"subplan_step\"],\n                                    sub_flow_type=step_dict[\"subplanner_type\"]\n                                )\n                                new_steps.append(new_step)\n                            else:\n                                self.sub_planner_agent_logger.warning(f\"Skipping invalid step data: {step_data}\")\n\n                    # 自动补充其他响应字段的默认值\n                    if \"message\" not in parsed_response:\n                        parsed_response[\"message\"] = \"计划已更新\"\n                        self.sub_planner_agent_logger.info(\"Auto-filled missing 'message' field\")\n                    \n                    if \"goal\" not in parsed_response:\n                        parsed_response[\"goal\"] = self.goal\n                        self.sub_planner_agent_logger.info(\"Auto-filled missing 'goal' field\")\n                    \n                    if \"title\" not in parsed_response:\n                        parsed_response[\"title\"] = f\"更新的{self.task_type.value}子计划\"\n                        self.sub_planner_agent_logger.info(\"Auto-filled missing 'title' field\")\n\n                    # Find the index of the first pending step\n                    first_pending_index = None\n                    for i, step in enumerate(plan.steps):\n                        if not step.is_done():\n                            first_pending_index = i\n                            break\n\n                    # If there are pending steps, replace all pending steps\n                    if first_pending_index is not None:\n                        # Keep completed steps\n                        updated_steps = plan.steps[:first_pending_index]\n                        # Add new steps\n                        updated_steps.extend(new_steps)\n                        # Update steps in plan\n                        plan.steps = updated_steps\n                    else:\n                        # 如果没有待处理的步骤，直接使用新步骤\n                        plan.steps.extend(new_steps)\n\n                    yield PlanUpdatedEvent(plan=plan,issubplan=True)\n\n                    if not plan.steps:\n                        yield PauseEvent()\n                        \n                except json.JSONDecodeError as e:\n                    self.sub_planner_agent_logger.error(f\"JSON decode error: {e}, message: {event.message}\")\n                    # 生成默认计划：保持剩余未完成的步骤\n                    remaining_steps = [step for step in plan.steps if not step.is_done()]\n                    \n                    # Find the index of the first pending step\n                    first_pending_index = None\n                    for i, step in enumerate(plan.steps):\n                        if not step.is_done():\n                            first_pending_index = i\n                            break\n\n                    # If there are pending steps, keep them\n                    if first_pending_index is not None:\n                        plan.steps = plan.steps[:first_pending_index] + remaining_steps\n                    \n                    self.sub_planner_agent_logger.info(f\"Generated fallback plan with {len(remaining_steps)} remaining steps due to JSON decode error\")\n                    yield PlanUpdatedEvent(plan=plan)\n                    return\n                except KeyError as e:\n                    self.sub_planner_agent_logger.error(f\"Missing required field: {e}, parsed_response: {parsed_response}\")\n                    continue\n                except Exception as e:\n                    self.sub_planner_agent_logger.error(f\"Error parsing plan update: {e}, message: {event.message}\")\n                    continue\n            \n            yield event",
      "methods": [
        "<module>.SubPlannerAgent.__init__",
        "<module>.SubPlannerAgent.fix",
        "<module>.SubPlannerAgent._setup_tools",
        "<module>.SubPlannerAgent.create_plan",
        "<module>.SubPlannerAgent.update_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/planner.py",
      "name": "PlannerAgent",
      "qualname": "<module>.PlannerAgent",
      "source": "class PlannerAgent(BaseAgent):\n    \"\"\"\n    Planner agent class, defining the basic behavior of planning\n    \"\"\"\n\n    system_prompt: str = PLANNER_SYSTEM_PROMPT.format(cur_time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n    format: Optional[str] = \"json_object\"\n\n    async def create_plan(self, message: Optional[str] = None) -> AsyncGenerator[AgentEvent, None]:\n        message = CREATE_PLAN_PROMPT.format(user_message=message) if message else None\n        plan = None\n        while plan is None:\n            async for event in self.execute(message):\n                if isinstance(event, MessageEvent):\n                    logger.info(event.message)\n                    good_json_string = repair_json(event.message)\n                    parsed_response = json.loads(good_json_string)\n                    steps = [Step(id=step[\"id\"], description=step[\"description\"]) for step in parsed_response[\"steps\"]]\n                    plan = Plan(id=f\"plan_{len(steps)}\", goal=parsed_response[\"goal\"], title=parsed_response[\"title\"], steps=steps, message=parsed_response[\"message\"], todo=parsed_response.get(\"todo\", \"\"))\n                    yield PlanCreatedEvent(plan=plan)\n                else:\n                    yield event\n\n    async def update_plan(self, plan: Plan, previous_steps: str) -> AsyncGenerator[AgentEvent, None]:\n        message = UPDATE_PLAN_PROMPT.format(plan=plan.model_dump_json(include={\"steps\"}), goal=plan.goal, previous_steps=previous_steps)\n        async for event in self.execute(message):\n            if isinstance(event, MessageEvent):\n                good_json_string = repair_json(event.message)\n                try:\n                    parsed_response = json.loads(good_json_string)\n                    new_steps = [Step(id=step[\"id\"], description=step[\"description\"]) for step in parsed_response[\"steps\"]]\n                except Exception as e:\n                    logger.exception(f\"Error parsing plan: {e}\")\n                    continue\n                \n                # Find the index of the first pending step\n                first_pending_index = None\n                for i, step in enumerate(plan.steps):\n                    if not step.is_done():\n                        first_pending_index = i\n                        break\n                \n                # If there are pending steps, replace all pending steps\n                if first_pending_index is not None:\n                    # Keep completed steps\n                    updated_steps = plan.steps[:first_pending_index]\n                    # Add new steps\n                    updated_steps.extend(new_steps)\n                    # Update steps in plan\n                    plan.steps = updated_steps\n                \n                yield PlanUpdatedEvent(plan=plan)\n\n                if not plan.steps:\n                    yield PauseEvent()\n                \n                # 更新计划之后直接结束update_plan\n                return\n            else:\n                yield event",
      "methods": [
        "<module>.PlannerAgent.create_plan",
        "<module>.PlannerAgent.update_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/execution.py",
      "name": "ExecutionAgent",
      "qualname": "<module>.ExecutionAgent",
      "source": "class ExecutionAgent(BaseAgent):\n    \"\"\"\n    Execution agent class, defining the basic behavior of execution\n    \"\"\"\n\n    def __init__(\n        self,\n        memory: Memory,\n        llm: LLM,\n        audio_llm: AudioLLM,\n        image_llm: ImageLLM,\n        video_llm: VideoLLM,\n        reason_llm: ReasonLLM,\n        sandbox: Sandbox,\n        browser: Browser,\n        search_engine: Optional[SearchEngine] = None,\n        type_value: str = \"message\"\n    ):\n        super().__init__(memory, llm, [   \n            ShellTool(sandbox),\n            BrowserTool(browser),\n            FileTool(sandbox),\n            MessageDeliverArtifactTool(),\n            AudioTool(sandbox, audio_llm, llm),\n            ImageTool(sandbox, image_llm),\n            VideoTool(sandbox, video_llm),\n            DeepReasoningTool(reason_llm),\n            McpTool(\n                sandbox,\n                pre_install_servers=[\n                    \"mcp-server-site-search\"\n                ]\n            )\n        ])\n        \n        # Only add search tool when search_engine is not None\n        if search_engine:\n            self.tools.append(SearchTool(search_engine))\n        self.system_prompt = PromptManager.insert_datetime(PromptManager.get_system_prompt_with_tools(self.tools, is_executor=True))\n        self.execution_agent_logger = setup_agent_logger(\"execution_agent\")\n\n    @property\n    def shell_tool(self) -> Optional[ShellTool]:\n        \"\"\"Get the shell tool from tools list\"\"\"\n        for tool in self.tools:\n            if isinstance(tool, ShellTool):\n                return tool\n        return None\n\n    async def execute_step(self, plan: Plan, step: Step, message: str) -> AsyncGenerator[AgentEvent, None]:\n        \n        # update prompt\n        try:\n            self.system_prompt = await PromptManager.update_ls(self.system_prompt, self.shell_tool)\n        except Exception as e:\n            self.execution_agent_logger.error(f\"更新系统提示词失败: {str(e)}\")\n            self.execution_agent_logger.error(f\"错误类型: {type(e)}\")\n            import traceback\n            self.execution_agent_logger.error(f\"错误堆栈: {traceback.format_exc()}\")\n            # 继续执行，不因为提示词更新失败而中断整个流程\n        \n        message = EXECUTION_PROMPT.format(goal=plan.goal, all_steps=plan.steps, step=step.description, message=message)\n        \n        step.status = ExecutionStatus.RUNNING\n        yield StepStartedEvent(step=step, plan=plan)\n\n        # debug H\n        self.execution_agent_logger.info(\"===\"*10)\n        self.execution_agent_logger.info(f\"EXECUTOR\")\n        self.execution_agent_logger.info(f\"self.system_prompt: {self.system_prompt}\")\n        self.execution_agent_logger.info(\"===\"*10)\n\n        async for event in self.execute(message):\n            if isinstance(event, ErrorEvent):\n                step.status = ExecutionStatus.FAILED\n                step.error = event.error\n                yield StepFailedEvent(\n                    step=Step(\n                        id=\"sub_task\",\n                        description=step.description,\n                        status=ExecutionStatus.FAILED,\n                        error=event.error\n                    ),\n                    plan=Plan(\n                        id=f\"sub_plan_{step.id}\",\n                        title=f\"Sub Plan for {step.id} task\",\n                        goal=plan.goal,\n                        steps=[Step(\n                            id=\"sub_task\",\n                            description=step.description,\n                            status=ExecutionStatus.FAILED,\n                            error=event.error\n                        )]\n                    )\n                )\n                return\n            \n            if isinstance(event, PauseEvent):\n                yield event\n                return\n            \n            if isinstance(event, MessageEvent):\n                step.status = ExecutionStatus.COMPLETED\n                step.result = event.message\n                yield StepCompletedEvent(step=step, plan=plan)\n            yield event\n        step.status = ExecutionStatus.COMPLETED\n\n    async def summarize_steps(self) -> AsyncGenerator[AgentEvent, None]:\n        async for event in self.execute(PERSISTENT_RESULT_PROMPT):\n            yield event\n\n        async for event in self.execute(SUMMARIZE_STEP_PROMPT):\n            if isinstance(event, MessageEvent):\n                self.memory.clear_messages()\n                self.memory.add_message({\n                    \"role\": \"system\",\n                    \"content\": self.system_prompt\n                })\n                self.memory.add_message({\n                    \"role\": \"system\",\n                    \"content\": FLUSH_MEMORY_PROMPT.format(previous_steps=event.message)\n                })\n            yield event\n        \n    async def report_result(self, message: str) -> AsyncGenerator[AgentEvent, None]:\n        async for event in self.execute(REPORT_RESULT_PROMPT.format(message=message)):\n            if isinstance(event, MessageEvent):\n                yield ReportEvent(message=event.message)\n                return\n            yield event\n",
      "methods": [
        "<module>.ExecutionAgent.__init__",
        "<module>.ExecutionAgent.shell_tool",
        "<module>.ExecutionAgent.execute_step",
        "<module>.ExecutionAgent.summarize_steps",
        "<module>.ExecutionAgent.report_result"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/super_planner.py",
      "name": "PlannerAgent",
      "qualname": "<module>.PlannerAgent",
      "source": "class PlannerAgent(BaseAgent):\n    \"\"\"\n    Planner agent class, defining the basic behavior of planning\n    \"\"\"\n    def __init__(\n            self,\n            memory: Memory,\n            llm: LLM,\n            knowledge: Memory,\n    ):\n        super().__init__(memory, llm, [])\n        self.max_iterations = 3\n        self.knowledge = knowledge\n\n    system_prompt: str = PLANNER_SYSTEM_PROMPT.format(cur_time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n    async def create_plan(self, message: Optional[str] = None) -> AsyncGenerator[AgentEvent, None]:\n        message = CREATE_PLAN_PROMPT.format(user_message=message) if message else None\n\n        plan = None\n        while plan is None:\n            async for event in self.execute(message):\n                if isinstance(event, MessageEvent):\n                    logger.info(event.message)\n                    parsed_response = []\n                    try:\n                        good_json_string = repair_json(event.message)\n                        parsed_response = json.loads(good_json_string)\n\n                        # 验证JSON结构\n                        if not isinstance(parsed_response, dict):\n                            logger.error(f\"Expected dict, got {type(parsed_response)}: {parsed_response}\")\n                            continue\n                        if \"steps\" not in parsed_response:\n                            logger.error(f\"Missing 'steps' field in parsed response: {parsed_response}\")\n                            continue\n                        if not isinstance(parsed_response[\"steps\"], list):\n                            logger.error(f\"Expected 'steps' to be list, got {type(parsed_response['steps'])}: {parsed_response['steps']}\")\n                            continue\n\n                        steps = [Step(\n                            id=step[\"id\"], \n                            description=step[\"description\"],\n                            sub_plan_step=step.get(\"sub_flow_step\"),\n                            sub_flow_type=step.get(\"sub_flow_type\", \"\").lower() if step.get(\"sub_flow_type\") else None\n                        ) for step in parsed_response[\"steps\"] if isinstance(step, dict)]\n                        \n                        plan = Plan(id=f\"plan_{len(steps)}\", goal=parsed_response[\"goal\"], title=parsed_response[\"title\"],\n                                    steps=steps, message=parsed_response[\"message\"])\n                        yield PlanCreatedEvent(plan=plan, issuperplan=True)\n                    except json.JSONDecodeError as e:\n                        logger.error(f\"JSON decode error: {e}, message: {event.message}\")\n                        continue\n                    except KeyError as e:\n                        logger.error(f\"Missing required field: {e}, parsed_response: {parsed_response}\")\n                        continue\n                    except Exception as e:\n                        logger.error(f\"Error parsing plan: {e}, message: {event.message}\")\n                        continue\n                else:\n                    yield event\n\n\n    async def update_plan(self, plan: Plan, step: Step) -> AsyncGenerator[AgentEvent, None]:\n        \n        message = UPDATE_PLAN_PROMPT.format(\n            step_description=step.description,\n            report=step.result,\n        )\n\n        async for event in self.execute(message):\n            parsed_response = None\n            if isinstance(event, MessageEvent):\n                logger.info(event.message)\n                try:\n                    good_json_string = repair_json(event.message)\n                    parsed_response = json.loads(good_json_string)\n\n                    # 验证JSON结构\n                    if not isinstance(parsed_response, dict):\n                        logger.error(f\"Expected dict, got {type(parsed_response)}: {parsed_response}\")\n                        continue\n                    if \"steps\" not in parsed_response:\n                        logger.error(f\"Missing 'steps' field in parsed response: {parsed_response}\")\n                        continue\n                    if not isinstance(parsed_response[\"steps\"], list):\n                        logger.error(f\"Expected 'steps' to be list, got {type(parsed_response['steps'])}: {parsed_response['steps']}\")\n                        continue\n                        \n                    new_steps = [Step(id=step[\"id\"],\n                                      description=step[\"description\"],\n                                      sub_plan_step=step.get(\"sub_flow_step\"),\n                                      sub_flow_type=step.get(\"sub_flow_type\", \"\").lower() if step.get(\"sub_flow_type\") else None\n                                      ) for step in parsed_response[\"steps\"] if isinstance(step, dict)]\n\n                    # Find the index of the first pending step\n                    first_pending_index = None\n                    for i, step in enumerate(plan.steps):\n                        if not step.is_done():\n                            first_pending_index = i\n                            break\n\n                    updated_steps = []\n                    # If there are pending steps, replace all pending steps\n                    if first_pending_index is not None:\n                        # Keep completed steps\n                        updated_steps = plan.steps[:first_pending_index]\n                    # Add new steps\n                    updated_steps.extend(new_steps)\n                    # Update steps in plan\n                    plan.steps = updated_steps\n\n                    yield PlanUpdatedEvent(plan=plan, issuperplan=True)\n\n                    if not plan.steps:\n                        yield PauseEvent()\n                    # 更新计划之后直接结束update_plan\n                    return\n                except json.JSONDecodeError as e:\n                    logger.error(f\"JSON decode error: {e}, message: {event.message}\")\n                    continue\n                except KeyError as e:\n                    logger.error(f\"Missing required field: {e}, parsed_response: {parsed_response}\")\n                    continue\n                except Exception as e:\n                    logger.error(f\"Error parsing plan update: {e}, message: {event.message}\")\n                    continue\n            else:\n                yield event\n",
      "methods": [
        "<module>.PlannerAgent.__init__",
        "<module>.PlannerAgent.create_plan",
        "<module>.PlannerAgent.update_plan"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/domain/services/agents/super_planner.py",
      "name": "ReportAgent",
      "qualname": "<module>.ReportAgent",
      "source": "class ReportAgent(BaseAgent):\n    \"\"\"\n    Planner agent class, defining the basic behavior of planning\n    \"\"\"\n\n    def __init__(\n            self,\n            memory: Memory,\n            llm: LLM,\n            knowledge: Memory,\n    ):\n        super().__init__(memory, llm, [])\n        self.max_iterations = 3\n        self.knowledge = knowledge\n\n    system_prompt: str = REPORT_SYSTEM_PROMPT.format(cur_time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n    async def generate_report(self, plan: Plan) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"\n        总结任务执行情况\n        包括工具使用情况和执行结果\n        \"\"\"\n        if not self.knowledge:\n            yield ErrorEvent(error=\"No knowledge available for generating report.\")\n            return\n\n        message = REPORT_PROMPT.format(\n            goal = plan.goal,\n            memory = self.knowledge.get_messages(),\n        )\n\n        async for event in BaseAgent.execute(self, message):\n            if isinstance(event, MessageEvent):\n                yield ReportEvent(message=event.message)",
      "methods": [
        "<module>.ReportAgent.__init__",
        "<module>.ReportAgent.generate_report"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/interfaces/api/middlewares.py",
      "name": "UserContextMiddleware",
      "qualname": "<module>.UserContextMiddleware",
      "source": "class UserContextMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware for setting up user context.\"\"\"\n    \n    async def dispatch(self, request: Request, call_next):\n        \"\"\"\n        Process the request and load user information.\n        \n        Args:\n            request: The incoming request\n            call_next: The next middleware or endpoint\n\n        Returns:\n            The response\n        \"\"\"\n        try:\n            # 尝试获取用户信息\n            await UserContext.get_current_user_info(request)\n            logger.debug(\"User context loaded\")\n        except Exception as e:\n            logger.warning(f\"Failed to load user context: {e}\")\n        \n        response = await call_next(request)\n        return response\n",
      "methods": [
        "<module>.UserContextMiddleware.dispatch"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/interfaces/api/middlewares.py",
      "name": "CodeServerSubdomainMiddleware",
      "qualname": "<module>.CodeServerSubdomainMiddleware",
      "source": "class CodeServerSubdomainMiddleware(BaseHTTPMiddleware):\n    \"\"\"Code Server子域名代理中间件\"\"\"\n    \n    def __init__(self, app):\n        super().__init__(app)\n        self.settings = get_settings()\n        self.client = httpx.AsyncClient(timeout=httpx.Timeout(60.0))\n        self.agent_service = None  # 将在__call__中获取\n        \n    def __del__(self):\n        \"\"\"清理资源\"\"\"\n        if hasattr(self, 'client') and self.client:\n            asyncio.create_task(self.client.aclose())\n    \n    async def dispatch(self, request: Request, call_next):\n        \"\"\"处理请求分发\"\"\"\n        host = request.headers.get(\"host\", \"\")\n        \n        # 检查是否是Code Server子域名请求\n        agent_id = self._extract_agent_id_from_subdomain(host)\n        if agent_id:\n            logger.info(f\"Detected Code Server subdomain request for agent {agent_id}, host: {host}\")\n            \n            # 只处理HTTP请求，WebSocket请求由专门的路由处理\n            if not self._is_websocket_request(request):\n                return await self._handle_code_server_request(request, agent_id)\n            else:\n                logger.info(f\"WebSocket request detected, will be handled by dedicated WebSocket route\")\n        \n        # 不是子域名请求，或者是WebSocket请求\n        return await call_next(request)\n    \n    def _extract_agent_id_from_subdomain(self, host: str) -> str | None:\n        \"\"\"从子域名中提取agent_id\n        \n        Args:\n            host: 请求的Host头值\n            \n        Returns:\n            提取的agent_id，如果不匹配则返回None\n        \"\"\"\n        if not host:\n            return None\n        \n        # 构建正则表达式匹配模式：code-{agent_id}.localhost.betterspace.top\n        pattern = rf\"^code-([a-f0-9]{{16}})\\.{re.escape(self.settings.code_server_origin)}(?::\\d+)?$\"\n        match = re.match(pattern, host)\n        \n        if match:\n            agent_id = match.group(1)\n            logger.debug(f\"Extracted agent_id: {agent_id} from host: {host}\")\n            return agent_id\n        \n        return None\n    \n    async def _handle_code_server_request(self, request: Request, agent_id: str) -> Response:\n        \"\"\"处理Code Server请求\n        \n        Args:\n            request: 原始请求\n            agent_id: 提取的agent_id\n            \n        Returns:\n            代理响应\n        \"\"\"\n        try:\n            # 懒加载AgentService，避免循环导入\n            if not self.agent_service:\n                from app.application.services.agent import AgentService\n                self.agent_service = AgentService()\n            \n            # 检查Agent是否存在\n            if not await self.agent_service.agent_exists(agent_id):\n                logger.warning(f\"Agent {agent_id} not found for Code Server request\")\n                return JSONResponse(\n                    status_code=404,\n                    content={\"error\": f\"Agent {agent_id} not found or expired\"}\n                )\n            \n            # 获取沙箱的Code Server URL\n            target_url = await self.agent_service.get_code_server_url(agent_id)\n            if not target_url:\n                logger.warning(f\"target_url for agent {agent_id} not found\")\n                return JSONResponse(\n                    status_code=502,\n                    content={\"error\": \"Code Server service temporarily unavailable\"}\n                )\n            logger.info(f\"Proxying Code Server request to: {target_url}\")\n            \n            # 处理HTTP请求代理\n            return await self._handle_http_proxy(request, target_url)\n        \n        except NotFoundError as e:\n            logger.warning(f\"Agent {agent_id} not found for Code Server request\")\n            return JSONResponse(\n                status_code=404,\n                content={\"error\": f\"Agent {agent_id} not found or expired\"}\n            )\n\n        except Exception as e:\n            logger.exception(f\"Error handling Code Server request for agent {agent_id}: {str(e)}\")\n            return JSONResponse(\n                status_code=500,\n                content={\"error\": \"Internal server error\"}\n            )\n    \n    def _is_websocket_request(self, request: Request) -> bool:\n        \"\"\"检查是否是WebSocket升级请求\"\"\"\n        connection = request.headers.get(\"connection\", \"\").lower()\n        upgrade = request.headers.get(\"upgrade\", \"\").lower()\n        return \"upgrade\" in connection and upgrade == \"websocket\"\n    \n    async def _handle_http_proxy(self, request: Request, target_base_url: str) -> Response:\n        \"\"\"处理HTTP请求代理\n        \n        Args:\n            request: 原始请求\n            target_base_url: 目标服务的基础URL\n            \n        Returns:\n            代理响应\n        \"\"\"\n        # 获取原始路径（不使用urljoin，直接拼接）\n        request_path = str(request.url.path)\n        request_query = str(request.url.query) if request.url.query else \"\"\n        \n        # 确保target_base_url不以斜杠结尾，request_path以斜杠开头\n        target_base_clean = target_base_url.rstrip('/')\n        request_path_clean = request_path if request_path.startswith('/') else '/' + request_path\n        \n        # 直接拼接URL，避免urljoin的路径替换问题\n        target_url = target_base_clean + request_path_clean\n        if request_query:\n            target_url += f\"?{request_query}\"\n        \n        # 添加详细的调试日志\n        logger.info(f\"Proxying {request.method} request:\")\n        logger.info(f\"  Original path: {request_path}\")\n        logger.info(f\"  Target base: {target_base_url}\")\n        logger.info(f\"  Final URL: {target_url}\")\n        \n        # 准备请求头 - 保留大部分头信息，只移除可能导致问题的头\n        headers = dict(request.headers)\n        \n        # 移除可能导致冲突的头\n        headers_to_remove = [\n            \"host\",  # 避免host头冲突\n            \"referer\",\n            \"content-length\",  # httpx会自动设置\n            \"transfer-encoding\",  # httpx会自动处理\n        ]\n        \n        for header in headers_to_remove:\n            headers.pop(header, None)\n            headers.pop(header.lower(), None)  # 确保大小写都处理\n            headers.pop(header.upper(), None)\n        \n        # 保留重要的头信息，包括但不限于：\n        # - cookies (Cookie)\n        # - authorization (Authorization) \n        # - content-type (Content-Type)\n        # - accept-* 系列头\n        # - user-agent (User-Agent)\n        # - referer (Referer)\n        # - cache-control (Cache-Control)\n        # - if-* 条件头\n        \n        logger.debug(f\"Forwarding headers: {list(headers.keys())}\")\n        \n        # 读取请求体\n        body = await request.body() if request.method in [\"POST\", \"PUT\", \"PATCH\"] else None\n        \n        try:\n            # 发送代理请求\n            response = await self.client.request(\n                method=request.method,\n                url=target_url,\n                headers=headers,\n                content=body,\n                follow_redirects=False\n            )\n            \n            logger.debug(f\"Proxy response: {response.status_code} for {target_url}\")\n            \n            # 准备响应头\n            response_headers = dict(response.headers)\n            # 移除可能导致问题的头\n            response_headers.pop(\"content-encoding\", None)\n            response_headers.pop(\"transfer-encoding\", None)\n            \n            # 处理流式响应\n            if response.headers.get(\"content-type\", \"\").startswith(\"text/\") or \\\n               response.headers.get(\"content-type\", \"\").startswith(\"application/json\"):\n                # 对于文本内容，直接返回\n                content = response.content\n                return Response(\n                    content=content,\n                    status_code=response.status_code,\n                    headers=response_headers\n                )\n            else:\n                # 对于其他内容（如二进制文件），使用流式响应\n                async def stream_response():\n                    async for chunk in response.aiter_bytes():\n                        yield chunk\n                \n                return StreamingResponse(\n                    stream_response(),\n                    status_code=response.status_code,\n                    headers=response_headers\n                )\n                \n        except httpx.RequestError as e:\n            logger.error(f\"Proxy request failed for {target_url}: {str(e)}\")\n            return JSONResponse(\n                status_code=502,\n                content={\"error\": \"Proxy request failed\"}\n            )\n        except Exception as e:\n            logger.exception(f\"Unexpected error in HTTP proxy for {target_url}: {str(e)}\")\n            return JSONResponse(\n                status_code=500,\n                content={\"error\": \"Internal proxy error\"}\n            ) ",
      "methods": [
        "<module>.CodeServerSubdomainMiddleware.__init__",
        "<module>.CodeServerSubdomainMiddleware.__del__",
        "<module>.CodeServerSubdomainMiddleware.dispatch",
        "<module>.CodeServerSubdomainMiddleware._extract_agent_id_from_subdomain",
        "<module>.CodeServerSubdomainMiddleware._handle_code_server_request",
        "<module>.CodeServerSubdomainMiddleware._is_websocket_request",
        "<module>.CodeServerSubdomainMiddleware._handle_http_proxy"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/services/user_context.py",
      "name": "UserContext",
      "qualname": "<module>.UserContext",
      "source": "class UserContext:\n    \"\"\"User context manager for the current request.\"\"\"\n    \n    @staticmethod\n    async def get_current_user_info(request: Request) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get the current user information from OAuth2 headers.\n        \n        Args:\n            request: The FastAPI request\n            \n        Returns:\n            User information dictionary or None\n        \"\"\"\n        # 从请求头中获取用户信息\n        user_info = await OAuth2Service.get_current_user(request)\n        \n        if user_info:\n            # 存储在上下文变量中\n            current_user_context.set(user_info)\n            return user_info\n        \n        return None\n    \n    @staticmethod\n    async def get_current_user(request: Request) -> Optional[User]:\n        \"\"\"\n        Get the current user model from the database/store.\n        \n        Args:\n            request: The FastAPI request\n            \n        Returns:\n            User model or None\n        \"\"\"\n        user_info = await UserContext.get_current_user_info(request)\n        \n        if not user_info:\n            return None\n        \n        # 从用户服务获取或创建用户\n        user_repository = get_user_repository()\n        user_service = UserService(user_repository)\n        user = await user_service.get_or_create_user(user_info)\n        \n        # 存储在上下文变量中\n        current_user_model.set(user)\n        \n        return user\n    \n    @staticmethod\n    def get_current_user_id() -> Optional[str]:\n        \"\"\"\n        Get the current user ID from context.\n        \n        Returns:\n            User ID or None\n        \"\"\"\n        user_info = current_user_context.get()\n        if user_info:\n            return user_info.get(\"user_id\")\n        return None\n    \n    @staticmethod\n    def get_user_model() -> Optional[User]:\n        \"\"\"\n        Get the current user model from context.\n        \n        Returns:\n            User model or None\n        \"\"\"\n        return current_user_model.get()\n",
      "methods": [
        "<module>.UserContext.get_current_user_info",
        "<module>.UserContext.get_current_user",
        "<module>.UserContext.get_current_user_id",
        "<module>.UserContext.get_user_model"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/services/agent.py",
      "name": "AgentService",
      "qualname": "<module>.AgentService",
      "source": "class AgentService:\n    def __init__(self):\n        logger.info(\"Initializing AgentService\")\n        # 初始化事件订阅管理器\n        self.event_subscription_manager = get_event_subscription_manager()\n        \n        # 初始化事件订阅领域服务\n        self.event_subscription_domain_service = EventSubscriptionDomainService(\n            broadcast_repository=self.event_subscription_manager.broadcast_repository,\n            stream_repository=self.event_subscription_manager.stream_repository,\n            event_subscription_manager=self.event_subscription_manager  # 传递底层管理器\n        )\n        \n        # 初始化会话服务\n        conversation_repository = MemoryConversationRepository()\n        conversation_service = ConversationService(conversation_repository)\n        \n        # 初始化用户服务\n        user_repository = MemoryUserRepository()\n        user_service = UserService(user_repository)\n        \n        # 根据配置选择使用哪种Agent领域服务实现\n        logger.info(\"Using AgentDomainServiceWithRepository (repository pattern)\")\n        agent_context_repository = get_agent_context_repository()\n        self.agent_domain_service = AgentDomainService(\n            agent_context_repository=agent_context_repository,\n            conversation_service=conversation_service,\n            event_subscription_service=self.event_subscription_domain_service,\n            user_service=user_service\n        )\n        \n        self.settings = get_settings()\n        self.llm = OpenAILLM()\n        self.audio_llm = SiliconflowAudioLLM()\n        self.image_llm = OpenAIImageLLM()\n        self.video_llm = GeminiVideoLLM()\n        self.reason_llm = DeepSeekReasonLLM()\n        self.search_engine: SearchEngineInterface = create_search_engine()\n\n    async def create_agent(self, request: Optional[CreateAgentRequest] = None) -> Agent:\n        \"\"\"\n        Create a new agent.\n        \n        Args:\n            request: Optional request containing agent configuration\n            \n        Returns:\n            Agent: The created agent\n        \"\"\"\n        logger.info(\"Creating new agent\")\n        \n        # 初始化请求\n        if request is None:\n            request = CreateAgentRequest()\n            \n        # 获取当前用户ID\n        user_id = UserContext.get_current_user_id()\n        logger.info(f\"Creating agent for user: {user_id}\")\n        \n        # 获取flow_id\n        flow_id = request.flow_id\n        logger.info(f\"Using flow type: {flow_id}\")\n        \n        # 验证flow_id是否有效\n        available_flows = self.agent_domain_service.get_available_flows()\n        valid_flow_ids = [flow[\"flow_id\"] for flow in available_flows]\n        if flow_id not in valid_flow_ids:\n            raise ValueError(f\"无效的flow类型: {flow_id}. 可用的flow类型: {valid_flow_ids}\")\n        \n        # 获取环境变量\n        environment_variables = request.environment_variables\n        if environment_variables:\n            logger.info(f\"Received {len(environment_variables)} environment variables\")\n        \n        # 首先创建Agent实例以获取agent_id\n        # 创建环境变量领域模型（如果有）\n        environment = None\n        if environment_variables:\n            environment = Environment.from_dict(\n                variables=environment_variables,\n                user_id=user_id\n            )\n        \n        # 创建Agent实例，获取agent_id\n        agent = Agent(\n            planner_memory=Memory(),\n            execution_memory=Memory(),\n            model_name=self.settings.model_name,\n            temperature=self.settings.temperature,\n            max_tokens=self.settings.max_tokens,\n            user_id=user_id,\n            environment=environment\n        )\n        \n        agent_id = agent.id\n        logger.info(f\"Generated agent ID: {agent_id}\")\n        \n        # 使用agent_id作为沙箱ID，获取或创建沙箱（支持持久化存储卷）\n        sandbox = await SandboxFactory.get_or_create_sandbox(\n            sandbox_id=agent_id,\n            user_id=user_id,\n            environment_variables=environment_variables\n        )\n        cdp_url = sandbox.get_cdp_url()\n        logger.info(f\"Got or created sandbox with CDP URL: {cdp_url}\")\n        \n        browser = PlaywrightBrowser(self.llm, cdp_url)\n        logger.info(\"Initialized Playwright browser\")\n        \n        # 使用异步方法\n        final_agent = await self.agent_domain_service.initialize_agent(\n            agent=agent,\n            llm=self.llm, \n            image_llm=self.image_llm,\n            audio_llm=self.audio_llm,\n            video_llm=self.video_llm,\n            reason_llm=self.reason_llm,\n            sandbox=sandbox, \n            browser=browser, \n            search_engine=self.search_engine,\n            flow_id=flow_id\n        )\n        \n        logger.info(f\"Agent created successfully with ID: {agent_id}, user ID: {user_id}, flow: {flow_id}\")\n        return final_agent\n\n    async def get_agent(self, agent_id: str) -> Optional[Agent]:\n        logger.info(f\"Retrieving agent with ID: {agent_id}\")\n        agent = await self.agent_domain_service.get_agent(agent_id)\n        \n        if agent:\n            logger.info(f\"Agent found: {agent_id}\")\n        else:\n            logger.warning(f\"Agent not found: {agent_id}\")\n        return agent\n\n    def _to_sse_event(self, event: AgentEvent) -> Generator[SSEEvent, None, None]:\n        if isinstance(event, (PlanCreatedEvent, PlanUpdatedEvent, PlanCompletedEvent)):\n            if isinstance(event, PlanCreatedEvent):\n                if event.plan.title:\n                    yield TitleSSEEvent(data=TitleData(title=event.plan.title))\n                yield MessageSSEEvent(data=MessageData(content=event.plan.message))\n            if len(event.plan.steps) > 0:\n                \"\"\"\n                if event.issubplan == True: \n                    yield PlanSSEEvent(data=PlanData(steps=[StepData(\n                        status=step.status,\n                        id=step.id, \n                        description=step.description\n                    ) for step in event.plan.steps]))\n                elif event.issuperplan == True: \n                    yield PlanSSEEvent(data=PlanData(steps=[StepData(\n                        status=step.status,\n                        id=step.id, \n                        description=step.description\n                    ) for step in event.plan.steps]))\n                else: \n                    yield PlanSSEEvent(data=PlanData(steps=[StepData(\n                        status=step.status,\n                        id=step.id, \n                        description=step.description\n                    ) for step in event.plan.steps]))\n                \"\"\"\n                print('DEBUG: issuperplan:', getattr(event, 'issuperplan', None), 'issubplan:', getattr(event, 'issubplan', None))\n                yield PlanSSEEvent(data=PlanData(\n                    steps=[StepData(\n                        status=step.status,\n                        id=step.id,\n                        description=step.description\n                    ) for step in event.plan.steps],\n                    issuperplan=getattr(event, 'issuperplan', False),\n                    issubplan=getattr(event, 'issubplan', False)\n                ))\n        elif isinstance(event, ReportEvent):\n            yield MessageSSEEvent(data=MessageData(content=event.message))\n        elif isinstance(event, ToolCallingEvent):\n            if event.tool_name in [\"message_notify_user\"]:\n                yield MessageSSEEvent(data=MessageData(content=event.function_args[\"text\"]))\n            elif event.function_name in [\"message_done\", \"message_request_clarification\"]:\n                yield MessageSSEEvent(data=MessageData(content=event.function_args[\"text\"]))\n            elif event.function_name in [\"message_deliver_artifact\"]:\n                yield ToolSSEEvent(data=ToolData(\n                    name=\"message\",\n                    status=\"calling\",\n                    function=event.function_name,\n                    args=event.function_args\n                ))\n            elif event.tool_name in [\"browser\", \"file\", \"shell\", \"message\", \"audio\", \"image\", \"video\", \"reasoning\"]:\n                yield ToolSSEEvent(data=ToolData(\n                    name=event.tool_name,\n                    status=\"calling\",\n                    function=event.function_name,\n                    args=event.function_args\n                ))\n        elif isinstance(event, ToolCalledEvent):\n            if event.tool_name in [\"search\"]:\n                yield ToolSSEEvent(data=ToolData(\n                    name=event.tool_name,\n                    function=event.function_name,\n                    args=event.function_args,\n                    status=\"called\",\n                    result=event.function_result\n                ))\n        elif isinstance(event, (StepStartedEvent, StepCompletedEvent, StepFailedEvent)):\n            yield StepSSEEvent(data=StepData(\n                status=event.step.status,\n                id=event.step.id,\n                description=event.step.description\n            ))\n            if event.step.error:\n                yield ErrorSSEEvent(data=ErrorData(error=event.step.error))\n            if event.step.result:\n                yield MessageSSEEvent(data=MessageData(content=event.step.result))\n        elif isinstance(event, DoneEvent):\n            yield DoneSSEEvent(data=BaseData())\n        elif isinstance(event, ErrorEvent):\n            yield ErrorSSEEvent(data=ErrorData(error=event.error))\n        elif isinstance(event, UserInputEvent):\n            yield UserInputSSEEvent(data=UserInputData(content=event.message, file_ids=event.file_ids))\n\n        #print('SSE OUT:', json.dumps(PlanSSEEvent(...).dict(), ensure_ascii=False))\n\n    async def destroy_agent(self, agent_id: str) -> bool:\n        \"\"\"Destroy the specified Agent and its associated sandbox\n        \n        Args:\n            agent_id: Agent ID\n            \n        Returns:\n            Whether the destruction was successful\n        \"\"\"\n        logger.info(f\"Attempting to destroy agent: {agent_id}\")\n        try:\n            # Destroy Agent resources through the domain service\n            result = await self.agent_domain_service.close_agent(agent_id)\n            if result:\n                logger.info(f\"Agent destroyed successfully: {agent_id}\")\n            else:\n                logger.warning(f\"Failed to destroy agent: {agent_id}\")\n            return result\n        except Exception as e:\n            logger.error(f\"Error destroying agent {agent_id}: {str(e)}\")\n            return False\n\n    async def close(self):\n        logger.info(\"Closing all agents and cleaning up resources\")\n        # Clean up all Agents and their associated sandboxes\n        await self.agent_domain_service.close_all()\n        logger.info(\"All agents closed successfully\")\n\n    async def agent_exists(self, agent_id: str) -> bool:\n        \"\"\"Check if agent exists\"\"\"\n        return await self.agent_domain_service.has_agent(agent_id)\n\n    async def shell_view(self, agent_id: str, session_id: str) -> ShellViewResponse:\n        \"\"\"View shell session output\n        \n        Args:\n            agent_id: Agent ID\n            session_id: Shell session ID\n            \n        Returns:\n            APIResponse: Response entity containing shell output\n            \n        Raises:\n            ResourceNotFoundError: When Agent or Sandbox does not exist\n            OperationError: When a server error occurs during execution\n        \"\"\"\n        logger.info(f\"Viewing shell output for agent {agent_id} in session {session_id}\")\n        \n        if not await self.agent_exists(agent_id):\n            logger.warning(f\"Agent not found: {agent_id}\")\n            raise NotFoundError(f\"Agent not found: {agent_id}\")\n        \n        sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n\n        if not sandbox:\n            logger.warning(f\"Sandbox not found: {agent_id}\")\n            raise NotFoundError(f\"Sandbox not found: {agent_id}\")\n            \n        result = await sandbox.view_shell(session_id)\n        return ShellViewResponse(**result.data)\n\n    async def get_vnc_url(self, agent_id: str) -> str:\n        \"\"\"Get the VNC URL for the Agent sandbox\n        \n        Args:\n            agent_id: Agent ID\n            \n        Returns:\n            str: Sandbox host address\n            \n        Raises:\n            NotFoundError: When Agent or Sandbox does not exist\n        \"\"\"\n        logger.info(f\"Getting sandbox host for agent {agent_id}\")\n        \n        if not await self.agent_exists(agent_id):\n            logger.warning(f\"Agent not found: {agent_id}\")\n            raise NotFoundError(f\"Agent not found: {agent_id}\")\n        \n        sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n        \n        if not sandbox:\n            logger.warning(f\"Sandbox not found: {agent_id}\")\n            raise NotFoundError(f\"Sandbox not found: {agent_id}\")\n        \n        return sandbox.get_vnc_url()\n    \n    async def get_code_server_url(self, agent_id: str) -> str:\n        \"\"\"Get the Code Server URL for the Agent sandbox\n        \n        Args:\n            agent_id: Agent ID\n\n        Returns:\n            str: Code Server URL\n            \n        Raises:\n            NotFoundError: When Agent or Sandbox does not exist\n        \"\"\"\n        logger.info(f\"Getting code server URL for agent {agent_id}\")\n\n        if not await self.agent_exists(agent_id):\n            logger.warning(f\"Agent not found: {agent_id}\")\n            raise NotFoundError(f\"Agent not found: {agent_id}\")\n        \n        sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n\n        if not sandbox:\n            logger.warning(f\"Sandbox not found: {agent_id}\")\n            raise NotFoundError(f\"Sandbox not found: {agent_id}\")\n\n        return sandbox.get_code_server_url()\n    \n    async def get_code_server_subdomain_url(self, agent_id: str) -> str:\n        \"\"\"Get the Code Server subdomain URL for the Agent\n        \n        Args:\n            agent_id: Agent ID\n            \n        Returns:\n            str: Code Server subdomain URL\n            \n        Raises:\n            NotFoundError: When Agent does not exist\n        \"\"\"\n        logger.info(f\"Getting code server subdomain URL for agent {agent_id}\")\n        \n        if not await self.agent_exists(agent_id):\n            logger.warning(f\"Agent not found: {agent_id}\")\n            raise NotFoundError(f\"Agent not found: {agent_id}\")\n        \n        # 构建子域名URL - 开发环境使用HTTP，生产环境使用HTTPS\n        protocol = \"http\" if \"localhost\" in self.settings.code_server_origin else \"https\"\n        port_suffix = \":8000\" if \"localhost\" in self.settings.code_server_origin else \"\"\n        subdomain_url = f\"{protocol}://code-{agent_id}.{self.settings.code_server_origin}{port_suffix}\"\n        logger.info(f\"Generated code server subdomain URL: {subdomain_url}\")\n        return subdomain_url\n\n    async def file_view(self, agent_id: str, path: str) -> FileViewResponse:\n        \"\"\"View file content\n        \n        Args:\n            agent_id: Agent ID\n            path: File path\n            \n        Returns:\n            FileViewResponse: File content\n        \"\"\"\n        logger.info(f\"[DEBUG 2] 开始查看文件 {path} for agent {agent_id}\")\n        \n        # Verify agent exists\n        if not await self.agent_exists(agent_id):\n            logger.error(f\"[DEBUG 2] Agent {agent_id} not found when viewing file\")\n            raise NotFoundError(f\"Agent {agent_id} not found\")\n        \n        # Get sandbox and view file\n        sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n        \n        if sandbox is None:\n            logger.error(f\"[DEBUG 2] Sandbox not found for agent {agent_id}\")\n            raise NotFoundError(f\"Sandbox not found for agent {agent_id}\")\n        \n        logger.info(f\"[DEBUG 2] 调用sandbox.file_read读取文件: {path}\")\n        result = await sandbox.file_read(path)\n        logger.info(f\"[DEBUG 2] 文件读取结果: success={result.success}, message={result.message}\")\n        logger.info(f\"[DEBUG 2] 文件数据: {result.data}\")\n        \n        if not result.success:\n            logger.error(f\"[DEBUG 2] Failed to view file {path}: {result.message}\")\n            raise OperationError(f\"Failed to view file: {result.message}\")\n        \n        content = result.data.get(\"content\", \"\")\n        logger.info(f\"[DEBUG 2] 提取的文件内容: type={type(content)}, is_none={content is None}, length={len(str(content)) if content is not None else 'N/A'}\")\n        \n        if content is None:\n            logger.error(f\"[DEBUG 2] 文件内容为None! 文件路径: {path}, 原始数据: {result.data}\")\n            content = \"\"  # 设置为空字符串而不是None\n        \n        return FileViewResponse(content=content, file=path)\n\n    async def list_files(self, agent_id: str, path: str = \"/home/ubuntu\") -> FileListResponse:\n        \"\"\"列出沙盒中的文件\n        \n        Args:\n            agent_id: Agent ID\n            path: 目录路径，默认为/home/ubuntu\n            \n        Returns:\n            FileListResponse: 文件列表\n        \"\"\"\n        logger.info(f\"Listing files in {path} for agent {agent_id}\")\n        \n        # 确保路径不为空\n        if not path or path.strip() == \"\":\n            path = \"/home/ubuntu\"\n            logger.info(f\"Empty path provided, using default: {path}\")\n        \n        # 验证agent是否存在\n        if not await self.agent_exists(agent_id):\n            logger.error(f\"Agent {agent_id} not found when listing files\")\n            raise NotFoundError(f\"Agent {agent_id} not found\")\n        \n        # 获取沙盒并列出文件\n        sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n        \n        if sandbox is None:\n            logger.error(f\"Sandbox not found for agent {agent_id}\")\n            raise NotFoundError(f\"Sandbox not found for agent {agent_id}\")\n        \n        try:\n            # 使用shell命令列出文件（临时实现）\n            command = f\"cd {path} && ls -l --time-style=long-iso | tail -n +2\"\n            logger.debug(f\"Executing command: {command}\")\n            result = await sandbox.exec_command(\"list_files_session\", \"/home/ubuntu\", command)\n            \n            if not result.success:\n                logger.error(f\"Failed to list files in {path}: {result.message}\")\n                raise OperationError(f\"Failed to list files: {result.message}\")\n            \n            output = result.data.get(\"output\", \"\")\n            logger.debug(f\"Command output: {output[:200]}...\")\n            \n            # 解析输出文本为文件列表\n            items = []\n            for line in output.strip().split(\"\\n\"):\n                if not line.strip():\n                    continue\n                \n                try:\n                    parts = line.split()\n                    if len(parts) < 8:\n                        continue\n                    \n                    permissions = parts[0]\n                    is_dir = permissions.startswith(\"d\")\n                    size = int(parts[4])\n                    modified_date = f\"{parts[5]} {parts[6]}\"\n                    name = \" \".join(parts[7:])\n                    \n                    # 排除 \".\" 和 \"..\" 目录\n                    if name in [\".\", \"..\"]:\n                        continue\n                    \n                    # 构建完整路径\n                    full_path = f\"{path}/{name}\" if path.endswith(\"/\") else f\"{path}/{name}\"\n                    \n                    items.append(FileListItem(\n                        name=name,\n                        path=full_path,\n                        size=size,\n                        is_dir=is_dir,\n                        modified_time=modified_date\n                    ))\n                except Exception as e:\n                    logger.warning(f\"Error parsing file list entry '{line}': {str(e)}\")\n            \n            logger.info(f\"Listed {len(items)} files in {path}\")\n            return FileListResponse(\n                current_path=path,\n                items=items\n            )\n        except Exception as e:\n            logger.exception(f\"Error listing files in {path}: {str(e)}\")\n            raise OperationError(f\"Failed to list files: {str(e)}\")\n\n    async def download_file(self, agent_id: str, file_path: str) -> Tuple[bytes, str, str]:\n        \"\"\"Download a file from sandbox\n        \n        Args:\n            agent_id: Agent ID\n            file_path: File path\n            \n        Returns:\n            Tuple[bytes, str]: File content and filename\n        \"\"\"\n        logger.info(f\"Downloading file from agent {agent_id}, file path: {file_path}\")\n        \n        # 检查Agent是否存在\n        if not await self.agent_exists(agent_id):\n            logger.warning(f\"Agent not found: {agent_id}\")\n            raise NotFoundError(f\"Agent not found: {agent_id}\")\n        \n        # 获取沙箱实例\n        sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n        \n        if not sandbox:\n            logger.warning(f\"Sandbox not found: {agent_id}\")\n            raise NotFoundError(f\"Sandbox not found: {agent_id}\")\n        \n        try:\n            # 从沙箱下载文件\n            content = await sandbox.file_download(file_path)\n            \n            # 推断文件类型\n            filename = os.path.basename(file_path)\n            content_type = self._guess_content_type(filename)\n            \n            logger.info(f\"File downloaded successfully: {file_path}\")\n            return content, filename, content_type\n            \n        except FileNotFoundError as e:\n            logger.warning(f\"File not found in sandbox: {file_path}\")\n            raise NotFoundError(str(e))\n        except PermissionError as e:\n            logger.warning(f\"Permission denied for file: {file_path}\")\n            raise PermissionDeniedError(str(e))\n        except Exception as e:\n            logger.error(f\"Error downloading file: {str(e)}\")\n            raise OperationError(f\"Error downloading file: {str(e)}\")\n    \n    def _guess_content_type(self, filename: str) -> str:\n        \"\"\"\n        根据文件名推断内容类型\n        \n        Args:\n            filename: 文件名\n            \n        Returns:\n            内容类型\n        \"\"\"\n        import mimetypes\n        \n        # 确保mimetypes已初始化\n        mimetypes.init()\n        \n        # 获取文件扩展名并推断内容类型\n        content_type, _ = mimetypes.guess_type(filename)\n        \n        # 如果无法推断，返回通用二进制流类型\n        if content_type is None:\n            content_type = \"application/octet-stream\"\n            \n        return content_type\n    \n    async def delete_conversation_history(self, agent_id: str) -> bool:\n        \"\"\"删除会话历史\"\"\"\n        logger.info(f\"Deleting conversation history for agent {agent_id}\")\n        return await self.agent_domain_service.delete_conversation_history(agent_id)\n    \n    async def list_conversations(self, user_id: Optional[str] = None, limit: int = 50, offset: int = 0):\n        \"\"\"列出会话历史\"\"\"\n        logger.info(f\"Listing conversations for user {user_id}\")\n        return await self.agent_domain_service.list_conversations(user_id, limit, offset)\n\n    async def get_event_stream(self, agent_id: str, from_sequence: int = 1) -> AsyncGenerator[SSEEvent, None]:\n        \"\"\"\n        获取Agent的事件流，支持断连重连\n        \n        Args:\n            agent_id: Agent ID\n            from_sequence: 从指定序号开始获取事件\n            \n        Returns:\n            SSE事件流\n        \"\"\"\n        logger.info(f\"Starting event stream for agent {agent_id} from sequence {from_sequence}\")\n        \n        # 检查Agent是否存在\n        if not await self.agent_exists(agent_id):\n            logger.error(f\"Agent {agent_id} not found\")\n            yield ErrorSSEEvent(data=ErrorData(error=\"Agent not found\"))\n            return\n        \n        try:\n            # 获取事件流\n            async for event in self.event_subscription_domain_service.get_event_stream(agent_id, from_sequence):\n                # 转换为SSE事件\n                for sse_event in self._to_sse_event(event):\n                    yield sse_event\n                    \n        except Exception as e:\n            logger.error(f\"Error in event stream for agent {agent_id}: {str(e)}\")\n            yield ErrorSSEEvent(data=ErrorData(error=f\"Event stream error: {str(e)}\"))\n\n    async def send_message(self, agent_id: str, message: str, timestamp: int = 0, file_ids: List[str] = None) -> bool:\n        \"\"\"\n        发送消息到Agent（不返回事件流）\n        \n        这个方法只负责将消息放入Agent的处理队列，不返回事件流。\n        客户端需要通过get_event_stream方法来接收事件。\n        \n        Args:\n            agent_id: Agent ID\n            message: 用户消息\n            timestamp: 消息时间戳\n            file_ids: 文件ID列表，可选\n            \n        Returns:\n            是否成功将消息放入队列\n        \"\"\"\n        logger.info(f\"Sending message to agent {agent_id}: {message[:50]}...\")\n        \n        # 检查Agent是否存在\n        if not await self.agent_exists(agent_id):\n            logger.error(f\"Agent {agent_id} not found\")\n            raise NotFoundError(f\"Agent {agent_id} not found\")\n        \n        try:\n            sandbox = await SandboxFactory.get_or_create_sandbox(agent_id)\n            # 使用领域层的send_message方法\n            return await self.agent_domain_service.send_message(agent_id, message, sandbox, timestamp, file_ids)\n                \n        except AgentNotRunningError as e:\n            # 尝试从仓储恢复\n            logger.info(f\"Agent {agent_id} exists in repository but not in runtime, attempting to restore...\")\n            try:\n                # 尝试从仓储恢复Agent\n                restored_agent = await self.load_agent_from_repository(agent_id)\n                if restored_agent:\n                    logger.info(f\"Successfully restored Agent {agent_id} from repository\")\n                    # 重新尝试发送消息\n                    return await self.agent_domain_service.send_message(agent_id, message, sandbox, timestamp, file_ids)\n                else:\n                    logger.error(f\"Failed to restore Agent {agent_id} from repository\")\n                    raise NotFoundError(f\"Agent {agent_id} could not be restored\")\n            except Exception as restore_error:\n                logger.error(f\"Error restoring Agent {agent_id}: {str(restore_error)}\")\n                raise OperationError(f\"Failed to restore Agent {agent_id}: {str(restore_error)}\")\n\n        except RuntimeError as e:\n            # 领域层抛出的RuntimeError转换为OperationError\n            logger.error(f\"Failed to send message: {str(e)}\")\n            raise OperationError(str(e))\n        except Exception as e:\n            logger.error(f\"Unexpected error sending message to agent {agent_id}: {str(e)}\")\n            raise OperationError(f\"Failed to send message: {str(e)}\")\n\n    def get_available_flows(self) -> List[Dict[str, str]]:\n        \"\"\"\n        获取所有可用的flow类型\n        \n        Returns:\n            List[Dict[str, str]]: 包含所有可用flow类型的列表\n        \"\"\"\n        return self.agent_domain_service.get_available_flows()\n\n    # Agent上下文管理相关方法（仅在使用repository模式时可用）\n    async def list_agent_contexts(self, user_id: Optional[str] = None, status: Optional[str] = None, \n                                 limit: int = 50, offset: int = 0):\n        \"\"\"\n        列出Agent上下文（仅在使用repository模式时可用）\n        \n        Args:\n            user_id: 用户ID，可选\n            status: 状态过滤，可选\n            limit: 限制数量\n            offset: 偏移量\n            \n        Returns:\n            Agent上下文列表\n        \"\"\"\n        return await self.agent_domain_service.list_agent_contexts(user_id, status, limit, offset)\n    \n    async def get_agent_context(self, agent_id: str):\n        \"\"\"\n        获取Agent上下文（仅在使用repository模式时可用）\n        \n        Args:\n            agent_id: Agent ID\n            \n        Returns:\n            Agent上下文或None\n        \"\"\"\n        return await self.agent_domain_service.get_agent_context(agent_id)\n    \n    async def update_agent_status(self, agent_id: str, status: str) -> bool:\n        \"\"\"\n        更新Agent状态（仅在使用repository模式时可用）\n        \n        Args:\n            agent_id: Agent ID\n            status: 新状态\n            \n        Returns:\n            是否更新成功\n        \"\"\"\n        return await self.agent_domain_service.update_agent_status(agent_id, status)\n    \n    async def load_agent_from_repository(self, agent_id: str) -> Optional[Agent]:\n        \"\"\"\n        从仓储加载Agent并恢复运行时上下文（仅在使用repository模式时可用）\n        \n        Args:\n            agent_id: Agent ID\n            \n        Returns:\n            加载的Agent或None\n        \"\"\"\n        try:\n            # 创建沙盒\n            sandbox = await SandboxFactory.get_or_create_sandbox(\n                sandbox_id=agent_id,\n                user_id=None,  # 从上下文中获取\n                environment_variables=None\n            )\n            cdp_url = sandbox.get_cdp_url()\n            browser = PlaywrightBrowser(self.llm, cdp_url)\n            \n            return await self.agent_domain_service.load_agent_from_repository(\n                agent_id=agent_id,\n                llm=self.llm,\n                audio_llm=self.audio_llm,\n                image_llm=self.image_llm,\n                video_llm=self.video_llm,\n                reason_llm=self.reason_llm,\n                sandbox=sandbox,\n                browser=browser,\n                search_engine=self.search_engine\n            )\n        except Exception as e:\n            logger.error(f\"Failed to load agent {agent_id} from repository: {str(e)}\")\n            return None\n\n    async def cleanup_inactive_subscriptions(self, timeout_minutes: int = 30) -> int:\n        \"\"\"\n        清理不活跃的订阅\n        \n        Args:\n            timeout_minutes: 超时时间（分钟）\n            \n        Returns:\n            清理的订阅数量\n        \"\"\"\n        agent_contexts = await self.agent_domain_service.list_agent_contexts()\n        for agent_context in agent_contexts:\n            try:\n                if agent_context.status != \"running\":\n                    await self.event_subscription_domain_service.cleanup_inactive_subscribers(agent_context.agent_id, timeout_minutes)\n            except Exception as e:\n                logger.error(f\"Failed to cleanup inactive subscribers for agent {agent_context.agent_id}: {str(e)}\")\n                continue\n        return len(agent_contexts)\n",
      "methods": [
        "<module>.AgentService.__init__",
        "<module>.AgentService.create_agent",
        "<module>.AgentService.get_agent",
        "<module>.AgentService._to_sse_event",
        "<module>.AgentService.destroy_agent",
        "<module>.AgentService.close",
        "<module>.AgentService.agent_exists",
        "<module>.AgentService.shell_view",
        "<module>.AgentService.get_vnc_url",
        "<module>.AgentService.get_code_server_url",
        "<module>.AgentService.get_code_server_subdomain_url",
        "<module>.AgentService.file_view",
        "<module>.AgentService.list_files",
        "<module>.AgentService.download_file",
        "<module>.AgentService._guess_content_type",
        "<module>.AgentService.delete_conversation_history",
        "<module>.AgentService.list_conversations",
        "<module>.AgentService.get_event_stream",
        "<module>.AgentService.send_message",
        "<module>.AgentService.get_available_flows",
        "<module>.AgentService.list_agent_contexts",
        "<module>.AgentService.get_agent_context",
        "<module>.AgentService.update_agent_status",
        "<module>.AgentService.load_agent_from_repository",
        "<module>.AgentService.cleanup_inactive_subscriptions"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/services/event_subscription_service.py",
      "name": "EventSubscriptionApplicationService",
      "qualname": "<module>.EventSubscriptionApplicationService",
      "source": "class EventSubscriptionApplicationService:\n    \"\"\"事件订阅应用服务 - 纯发布订阅模式\"\"\"\n\n    def __init__(self, event_subscription_domain_service: EventSubscriptionDomainService):\n        self.domain_service = event_subscription_domain_service\n\n    async def get_event_stream(self, request: EventStreamRequest) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"获取事件流用例\"\"\"\n        logger.info(f\"Starting event stream for agent {request.agent_id} from sequence {request.from_sequence}\")\n        \n        async for event in self.domain_service.get_event_stream(\n            agent_id=request.agent_id,\n            from_sequence=request.from_sequence\n        ):\n            yield event\n\n    async def broadcast_event(self, agent_id: str, event: AgentEvent) -> int:\n        \"\"\"广播事件用例\"\"\"\n        return await self.domain_service.broadcast_event(agent_id, event)\n\n    async def get_agent_subscription_count(self, agent_id: str) -> int:\n        \"\"\"获取Agent活跃订阅者数量用例\"\"\"\n        return await self.domain_service.get_agent_subscription_count(agent_id)\n\n    async def cleanup_agent_streams(self, agent_id: str) -> bool:\n        \"\"\"清理Agent事件流用例\"\"\"\n        logger.info(f\"Cleaning up streams for agent {agent_id}\")\n        return await self.domain_service.cleanup_agent_streams(agent_id)\n\n    async def cleanup_inactive_subscribers(self, agent_id: str, timeout_minutes: int = 30) -> int:\n        \"\"\"清理不活跃订阅者用例\"\"\"\n        logger.info(f\"Cleaning up inactive subscribers for agent {agent_id} older than {timeout_minutes} minutes\")\n        return await self.domain_service.cleanup_inactive_subscribers(agent_id, timeout_minutes) ",
      "methods": [
        "<module>.EventSubscriptionApplicationService.__init__",
        "<module>.EventSubscriptionApplicationService.get_event_stream",
        "<module>.EventSubscriptionApplicationService.broadcast_event",
        "<module>.EventSubscriptionApplicationService.get_agent_subscription_count",
        "<module>.EventSubscriptionApplicationService.cleanup_agent_streams",
        "<module>.EventSubscriptionApplicationService.cleanup_inactive_subscribers"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "CreateAgentRequest",
      "qualname": "<module>.CreateAgentRequest",
      "source": "class CreateAgentRequest(BaseModel):\n    \"\"\"Request model for creating an agent.\"\"\"\n    \n    flow_id: str = Field(\n        default=\"plan_act\",\n        description=\"要使用的flow类型ID\",\n        example=\"plan_act\"\n    )\n    \n    environment_variables: Optional[Dict[str, str]] = Field(\n        default_factory=dict,\n        description=\"要传递到沙盒环境的环境变量\",\n        example={\"PYTHON_PATH\": \"/usr/local/bin/python\", \"NODE_ENV\": \"production\"}\n    )\n    \n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"flow_id\": \"plan_act\",\n                \"environment_variables\": {\n                    \"PYTHON_PATH\": \"/usr/local/bin/python\",\n                    \"NODE_ENV\": \"production\"\n                }\n            }\n        }\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "Config",
      "qualname": "<module>.CreateAgentRequest.Config",
      "source": "    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"flow_id\": \"plan_act\",\n                \"environment_variables\": {\n                    \"PYTHON_PATH\": \"/usr/local/bin/python\",\n                    \"NODE_ENV\": \"production\"\n                }\n            }\n        }\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "FileViewRequest",
      "qualname": "<module>.FileViewRequest",
      "source": "class FileViewRequest(BaseModel):\n    file: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "ShellViewRequest",
      "qualname": "<module>.ShellViewRequest",
      "source": "class ShellViewRequest(BaseModel):\n    \"\"\"Request model for viewing shell state.\"\"\"\n    \n    session_id: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "FileDownloadRequest",
      "qualname": "<module>.FileDownloadRequest",
      "source": "class FileDownloadRequest(BaseModel):\n    \"\"\"请求模型，用于从沙箱下载文件\"\"\"\n    file: str = Field(..., description=\"沙箱中的文件路径\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "FileUploadResponse",
      "qualname": "<module>.FileUploadResponse",
      "source": "class FileUploadResponse(BaseModel):\n    \"\"\"响应模型，用于文件上传后返回文件ID和相关信息\"\"\"\n    id: str\n    filename: str\n    path: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "FileListRequest",
      "qualname": "<module>.FileListRequest",
      "source": "class FileListRequest(BaseModel):\n    \"\"\"请求模型，用于列出沙箱中的文件\"\"\"\n    path: Optional[str] = Field(\n        default=\"/home/ubuntu\",\n        description=\"要列出文件的目录路径\",\n        examples=[\"/home/ubuntu\", \"/home/ubuntu/project\", \"/etc\"]\n    )\n\n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"path\": \"/home/ubuntu\"\n            }\n        }\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "Config",
      "qualname": "<module>.FileListRequest.Config",
      "source": "    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"path\": \"/home/ubuntu\"\n            }\n        }\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "ReplayConversationRequest",
      "qualname": "<module>.ReplayConversationRequest",
      "source": "class ReplayConversationRequest(BaseModel):\n    \"\"\"重放会话请求模型\"\"\"\n    from_sequence: int = Field(default=1, ge=1, description=\"从第几个事件开始重放\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "ListConversationsRequest",
      "qualname": "<module>.ListConversationsRequest",
      "source": "class ListConversationsRequest(BaseModel):\n    \"\"\"列出会话请求模型\"\"\"\n    user_id: Optional[str] = Field(default=None, description=\"用户ID，用于过滤\")\n    limit: int = Field(default=50, ge=1, le=100, description=\"每页数量\")\n    offset: int = Field(default=0, ge=0, description=\"偏移量\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "SendMessageRequest",
      "qualname": "<module>.SendMessageRequest",
      "source": "class SendMessageRequest(BaseModel):\n    \"\"\"发送消息请求模型（用于分离的消息发送接口）\"\"\"\n    \n    message: str = Field(..., description=\"消息内容\")\n    timestamp: int = Field(default_factory=lambda: int(time.time()), description=\"消息时间戳\")\n    file_ids: Optional[List[str]] = Field(\n        default_factory=list,\n        description=\"附件文件ID列表，这些文件将被自动传输到沙盒中的/home/ubuntu目录\",\n        example=[\"f8e7d456-9c1a-4b5e-8e7d-456f9c1a4b5e\"]\n    )\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "ListAgentContextsRequest",
      "qualname": "<module>.ListAgentContextsRequest",
      "source": "class ListAgentContextsRequest(BaseModel):\n    \"\"\"列出Agent上下文请求模型\"\"\"\n    user_id: Optional[str] = Field(default=None, description=\"用户ID，用于过滤\")\n    status: Optional[str] = Field(default=None, description=\"状态过滤\")\n    limit: int = Field(default=50, ge=1, le=100, description=\"每页数量\")\n    offset: int = Field(default=0, ge=0, description=\"偏移量\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "UpdateAgentStatusRequest",
      "qualname": "<module>.UpdateAgentStatusRequest",
      "source": "class UpdateAgentStatusRequest(BaseModel):\n    \"\"\"更新Agent状态请求模型\"\"\"\n    status: str = Field(..., description=\"新状态\", example=\"active\")\n    \n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"status\": \"active\"\n            }\n        }",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/request.py",
      "name": "Config",
      "qualname": "<module>.UpdateAgentStatusRequest.Config",
      "source": "    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"status\": \"active\"\n            }\n        }",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/environment.py",
      "name": "EnvironmentVariablesSchema",
      "qualname": "<module>.EnvironmentVariablesSchema",
      "source": "class EnvironmentVariablesSchema(BaseModel):\n    \"\"\"Schema for environment variables in API requests and responses.\"\"\"\n    \n    variables: Dict[str, str] = Field(\n        default_factory=dict,\n        description=\"环境变量键值对，用于传递到沙盒容器\",\n        example={\"PYTHON_PATH\": \"/usr/local/bin/python\", \"NODE_ENV\": \"production\"}\n    )\n    \n    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"variables\": {\n                    \"PYTHON_PATH\": \"/usr/local/bin/python\",\n                    \"NODE_ENV\": \"production\",\n                    \"DEBUG\": \"true\"\n                }\n            }\n        } ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/environment.py",
      "name": "Config",
      "qualname": "<module>.EnvironmentVariablesSchema.Config",
      "source": "    class Config:\n        json_schema_extra = {\n            \"example\": {\n                \"variables\": {\n                    \"PYTHON_PATH\": \"/usr/local/bin/python\",\n                    \"NODE_ENV\": \"production\",\n                    \"DEBUG\": \"true\"\n                }\n            }\n        } ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "APIResponse",
      "qualname": "<module>.APIResponse",
      "source": "class APIResponse(BaseModel, Generic[T]):\n    code: int = 0\n    msg: str = \"success\"\n    data: Optional[T] = None \n\n    @staticmethod\n    def success(data: Optional[T] = None, msg: str = \"success\") -> \"APIResponse[T]\":\n        return APIResponse(code=0, msg=msg, data=data)\n\n    @staticmethod\n    def error(code: int, msg: str) -> \"APIResponse[T]\":\n        return APIResponse(code=code, msg=msg, data=None)\n",
      "methods": [
        "<module>.APIResponse.success",
        "<module>.APIResponse.error"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "AgentResponse",
      "qualname": "<module>.AgentResponse",
      "source": "class AgentResponse(BaseModel):\n    agent_id: str\n    status: str = \"created\"\n    message: str = \"Agent created successfully\" \n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "ConsoleRecord",
      "qualname": "<module>.ConsoleRecord",
      "source": "class ConsoleRecord(BaseModel):\n    ps1: str\n    command: str\n    output: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "ShellViewResponse",
      "qualname": "<module>.ShellViewResponse",
      "source": "class ShellViewResponse(BaseModel):\n    output: str\n    session_id: str\n    console: Optional[List[ConsoleRecord]] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "FileViewResponse",
      "qualname": "<module>.FileViewResponse",
      "source": "class FileViewResponse(BaseModel):\n    \"\"\"File view response model\"\"\"\n    content: str\n    file: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "FileDownloadResponse",
      "qualname": "<module>.FileDownloadResponse",
      "source": "class FileDownloadResponse(BaseModel):\n    \"\"\"文件下载响应模型\"\"\"\n    filename: str\n    content_type: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "FileListItem",
      "qualname": "<module>.FileListItem",
      "source": "class FileListItem(BaseModel):\n    \"\"\"文件列表项模型\"\"\"\n    name: str\n    path: str\n    size: int\n    is_dir: bool\n    modified_time: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "FileListResponse",
      "qualname": "<module>.FileListResponse",
      "source": "class FileListResponse(BaseModel):\n    \"\"\"文件列表响应模型\"\"\"\n    current_path: str\n    items: List[FileListItem]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "ConversationEventResponse",
      "qualname": "<module>.ConversationEventResponse",
      "source": "class ConversationEventResponse(BaseModel):\n    \"\"\"会话事件响应模型\"\"\"\n    id: str\n    agent_id: str\n    event_type: str\n    event_data: Dict[str, Any]\n    timestamp: datetime\n    sequence: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "ConversationHistoryResponse",
      "qualname": "<module>.ConversationHistoryResponse",
      "source": "class ConversationHistoryResponse(BaseModel):\n    \"\"\"会话历史响应模型\"\"\"\n    agent_id: str\n    user_id: Optional[str] = None\n    flow_id: str\n    title: Optional[str] = None  # 会话标题\n    created_at: datetime\n    updated_at: datetime\n    events: List[ConversationEventResponse]\n    total_events: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "ConversationListResponse",
      "qualname": "<module>.ConversationListResponse",
      "source": "class ConversationListResponse(BaseModel):\n    \"\"\"会话列表响应模型\"\"\"\n    conversations: List[ConversationHistoryResponse]\n    total: int\n    limit: int\n    offset: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/response.py",
      "name": "SendMessageResponse",
      "qualname": "<module>.SendMessageResponse",
      "source": "class SendMessageResponse(BaseModel):\n    \"\"\"发送消息响应模型\"\"\"\n    \n    success: bool = Field(..., description=\"是否发送成功\")\n    message_id: Optional[str] = Field(None, description=\"消息ID\")\n    timestamp: int = Field(..., description=\"消息时间戳\")\n    queued: bool = Field(default=True, description=\"消息是否已加入处理队列\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "BaseData",
      "qualname": "<module>.BaseData",
      "source": "class BaseData(BaseModel):\n    timestamp: int = Field(default_factory=lambda: int(time.time()))\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "MessageData",
      "qualname": "<module>.MessageData",
      "source": "class MessageData(BaseData):\n    content: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "ToolData",
      "qualname": "<module>.ToolData",
      "source": "class ToolData(BaseData):\n    name: str\n    function: str\n    args: Dict[str, Any]\n    result: Optional[Any] = None\n    status: Literal[\"calling\", \"called\"]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "StepData",
      "qualname": "<module>.StepData",
      "source": "class StepData(BaseData):\n    status: ExecutionStatus\n    id: str\n    description: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "PlanData",
      "qualname": "<module>.PlanData",
      "source": "class PlanData(BaseData):\n    steps: List[StepData]\n    issuperplan: bool = False\n    issubplan: bool = False\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "ErrorData",
      "qualname": "<module>.ErrorData",
      "source": "class ErrorData(BaseData):\n    error: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "TitleData",
      "qualname": "<module>.TitleData",
      "source": "class TitleData(BaseData):\n    title: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "UserInputData",
      "qualname": "<module>.UserInputData",
      "source": "class UserInputData(BaseData):\n    content: str\n    file_ids: List[str]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "SSEEvent",
      "qualname": "<module>.SSEEvent",
      "source": "class SSEEvent(BaseModel):\n    event: str\n    data: Optional[Union[str, BaseData]]\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "MessageSSEEvent",
      "qualname": "<module>.MessageSSEEvent",
      "source": "class MessageSSEEvent(SSEEvent):\n    event: Literal[\"message\"] = \"message\"\n    data: MessageData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "ToolSSEEvent",
      "qualname": "<module>.ToolSSEEvent",
      "source": "class ToolSSEEvent(SSEEvent):\n    event: Literal[\"tool\"] = \"tool\"\n    data: ToolData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "DoneSSEEvent",
      "qualname": "<module>.DoneSSEEvent",
      "source": "class DoneSSEEvent(SSEEvent):\n    event: Literal[\"done\"] = \"done\"\n    data: BaseData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "ErrorSSEEvent",
      "qualname": "<module>.ErrorSSEEvent",
      "source": "class ErrorSSEEvent(SSEEvent):\n    event: Literal[\"error\"] = \"error\"\n    data: ErrorData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "StepSSEEvent",
      "qualname": "<module>.StepSSEEvent",
      "source": "class StepSSEEvent(SSEEvent):\n    event: Literal[\"step\"] = \"step\"\n    data: StepData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "TitleSSEEvent",
      "qualname": "<module>.TitleSSEEvent",
      "source": "class TitleSSEEvent(SSEEvent):\n    event: Literal[\"title\"] = \"title\"\n    data: TitleData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "PlanSSEEvent",
      "qualname": "<module>.PlanSSEEvent",
      "source": "class PlanSSEEvent(SSEEvent):\n    event: Literal[\"plan\"] = \"plan\"\n    data: PlanData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event.py",
      "name": "UserInputSSEEvent",
      "qualname": "<module>.UserInputSSEEvent",
      "source": "class UserInputSSEEvent(SSEEvent):\n    event: Literal[\"user_input\"] = \"user_input\"\n    data: UserInputData\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "UserFileSchema",
      "qualname": "<module>.UserFileSchema",
      "source": "class UserFileSchema(BaseModel):\n    \"\"\"Schema for user file.\"\"\"\n    \n    id: str\n    filename: str\n    path: str\n    created_at: datetime\n    updated_at: datetime\n    metadata: Dict[str, Any] = {}\n    \n    class Config:\n        from_attributes = True\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "Config",
      "qualname": "<module>.UserFileSchema.Config",
      "source": "    class Config:\n        from_attributes = True\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "UserFileMetadataSchema",
      "qualname": "<module>.UserFileMetadataSchema",
      "source": "class UserFileMetadataSchema(BaseModel):\n    \"\"\"Schema for user file metadata.\"\"\"\n    \n    id: str\n    filename: str\n    path: str\n    metadata: Dict[str, Any] = {}\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "UserTaskSchema",
      "qualname": "<module>.UserTaskSchema",
      "source": "class UserTaskSchema(BaseModel):\n    \"\"\"Schema for user task.\"\"\"\n    \n    id: str\n    agent_id: str\n    title: str\n    status: str\n    created_at: datetime\n    completed_at: Optional[datetime] = None\n    metadata: Dict[str, Any] = {}\n    \n    class Config:\n        from_attributes = True\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "Config",
      "qualname": "<module>.UserTaskSchema.Config",
      "source": "    class Config:\n        from_attributes = True\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "UserSchema",
      "qualname": "<module>.UserSchema",
      "source": "class UserSchema(BaseModel):\n    \"\"\"Schema for user information.\"\"\"\n    \n    id: str\n    email: str\n    name: Optional[str] = None\n    groups: List[str] = []\n    created_at: datetime\n    last_login: datetime\n    \n    class Config:\n        from_attributes = True\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/user.py",
      "name": "Config",
      "qualname": "<module>.UserSchema.Config",
      "source": "    class Config:\n        from_attributes = True\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event_subscription.py",
      "name": "CreateEventSubscriptionRequest",
      "qualname": "<module>.CreateEventSubscriptionRequest",
      "source": "class CreateEventSubscriptionRequest(BaseModel):\n    \"\"\"创建事件订阅请求\"\"\"\n    agent_id: str = Field(..., description=\"Agent ID\")\n    from_sequence: int = Field(default=1, description=\"从指定序号开始订阅事件\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event_subscription.py",
      "name": "EventSubscriptionResponse",
      "qualname": "<module>.EventSubscriptionResponse",
      "source": "class EventSubscriptionResponse(BaseModel):\n    \"\"\"事件订阅响应\"\"\"\n    subscription_id: str = Field(..., description=\"订阅ID\")\n    agent_id: str = Field(..., description=\"Agent ID\") \n    from_sequence: int = Field(..., description=\"起始序号\")\n    created_at: datetime = Field(..., description=\"创建时间\")\n    is_active: bool = Field(..., description=\"是否活跃\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event_subscription.py",
      "name": "EventSubscriptionHeartbeatRequest",
      "qualname": "<module>.EventSubscriptionHeartbeatRequest",
      "source": "class EventSubscriptionHeartbeatRequest(BaseModel):\n    \"\"\"事件订阅心跳请求\"\"\"\n    subscription_id: str = Field(..., description=\"订阅ID\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/event_subscription.py",
      "name": "EventStreamRequest",
      "qualname": "<module>.EventStreamRequest",
      "source": "class EventStreamRequest(BaseModel):\n    \"\"\"事件流请求\"\"\"\n    agent_id: str = Field(..., description=\"Agent ID\")\n    from_sequence: int = Field(default=1, description=\"从指定序号开始\")\n    subscription_id: Optional[str] = Field(None, description=\"订阅ID（用于心跳更新）\") ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "APIException",
      "qualname": "<module>.APIException",
      "source": "class APIException(HTTPException):\n    def __init__(\n        self,\n        code: int,\n        msg: str,\n        status_code: int = 400,\n        headers: Optional[Dict[str, Any]] = None,\n    ):\n        self.code = code\n        self.msg = msg\n        super().__init__(status_code=status_code, detail=msg, headers=headers)\n",
      "methods": [
        "<module>.APIException.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "NotFoundError",
      "qualname": "<module>.NotFoundError",
      "source": "class NotFoundError(APIException):\n    def __init__(self, msg: str = \"Resource not found\"):\n        super().__init__(code=404, msg=msg, status_code=404)\n",
      "methods": [
        "<module>.NotFoundError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "BadRequestError",
      "qualname": "<module>.BadRequestError",
      "source": "class BadRequestError(APIException):\n    def __init__(self, msg: str = \"Bad request parameters\"):\n        super().__init__(code=400, msg=msg, status_code=400)\n",
      "methods": [
        "<module>.BadRequestError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "ServerError",
      "qualname": "<module>.ServerError",
      "source": "class ServerError(APIException):\n    def __init__(self, msg: str = \"Internal server error\"):\n        super().__init__(code=500, msg=msg, status_code=500)\n",
      "methods": [
        "<module>.ServerError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "UnauthorizedError",
      "qualname": "<module>.UnauthorizedError",
      "source": "class UnauthorizedError(APIException):\n    def __init__(self, msg: str = \"Unauthorized\"):\n        super().__init__(code=401, msg=msg, status_code=401) \n",
      "methods": [
        "<module>.UnauthorizedError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "FileNotFoundError",
      "qualname": "<module>.FileNotFoundError",
      "source": "class FileNotFoundError(APIException):\n    def __init__(self, msg: str = \"File not found\"):\n        super().__init__(code=404, msg=msg, status_code=404)\n",
      "methods": [
        "<module>.FileNotFoundError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "PermissionDeniedError",
      "qualname": "<module>.PermissionDeniedError",
      "source": "class PermissionDeniedError(APIException):\n    def __init__(self, msg: str = \"Permission denied\"):\n        super().__init__(code=403, msg=msg, status_code=403)\n",
      "methods": [
        "<module>.PermissionDeniedError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/application/schemas/exceptions.py",
      "name": "OperationError",
      "qualname": "<module>.OperationError",
      "source": "class OperationError(APIException):\n    def __init__(self, msg: str = \"Operation failed\"):\n        super().__init__(code=400, msg=msg, status_code=400)\n",
      "methods": [
        "<module>.OperationError.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/logging.py",
      "name": "SuperPlannerFilter",
      "qualname": "<module>.SuperPlannerFilter",
      "source": "class SuperPlannerFilter(logging.Filter):\n    \"\"\"只允许super_planner相关的日志通过\"\"\"\n    def filter(self, record):\n        # 添加调试信息\n        print(f\"Filtering log: {record.name}, level: {record.levelname}, message: {record.getMessage()}\")\n        return record.name.startswith('super_planner.')\n",
      "methods": [
        "<module>.SuperPlannerFilter.filter"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/logging.py",
      "name": "ComponentLoggerFilter",
      "qualname": "<module>.ComponentLoggerFilter",
      "source": "class ComponentLoggerFilter(logging.Filter):\n    \"\"\"更灵活的组件日志过滤器\"\"\"\n    def __init__(self, show_sub_planners: bool = True, show_super_planner: bool = True):\n        super().__init__()\n        self.show_sub_planners = show_sub_planners\n        self.show_super_planner = show_super_planner\n    \n    def filter(self, record):\n        # 根据配置决定是否显示super_planner相关日志\n        if self.show_super_planner and record.name.startswith('super_planner'):\n            return True\n        \n        # 根据配置决定是否显示sub_planner相关日志\n        # if (record.name.startswith('sub_planner_interface.') or \n        #     record.name.startswith('sub_planner_agent.') or\n        #     record.name.startswith('sub_planner_flow.')):\n        if self.show_sub_planners and record.name.startswith('sub_planner'):\n            return True\n        \n        return False\n",
      "methods": [
        "<module>.ComponentLoggerFilter.__init__",
        "<module>.ComponentLoggerFilter.filter"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/config.py",
      "name": "Settings",
      "qualname": "<module>.Settings",
      "source": "class Settings(BaseSettings):\n\n    # Bypass\n    bypass_oauth2: bool = False\n    \n    # Database configuration\n    database_type: str = \"sqlite\"  # 可选值: memory, sqlite\n    database_url: str = \"sqlite+aiosqlite:///./data/ai_manus.db\"\n    database_echo: bool = False  # 是否打印SQL语句\n    database_pool_size: int = 10\n    database_max_overflow: int = 20\n    \n    # Model provider configuration\n    api_key: str | None = None\n    api_base: str = \"https://api.deepseek.com/v1\"\n    \n    # Model configuration\n    model_name: str = \"deepseek-chat\"\n    temperature: float = 0.7\n    max_tokens: int = 2000\n\n    # Image model configuration\n    image_api_key: str | None = None\n    image_api_base: str = \"https://api.openai.com/v1\"\n    image_model_name: str = \"dall-e-3\"\n\n    # Audio model configuration\n    audio_api_key: str | None = None\n    audio_api_base: str = \"https://api.siliconflow.cn/v1\"\n    audio_model_name: str = \"FunAudioLLM/SenseVoiceSmall\"\n    \n    # Video model configuration\n    video_api_key: str | None = None\n    video_api_base: str = \"https://generativelanguage.googleapis.com\"\n    video_model_name: str = \"gemini-2.5-flash-preview-05-20\"\n    \n    # Reasoning model configuration\n    reason_api_key: str | None = None\n    reason_api_base: str = \"https://api.deepseek.com/v1\"\n    reason_model_name: str = \"o3\"\n    \n    # Docker configuration\n    docker_host_url: str | None = None  # 远程Docker API地址，如\"tcp://192.168.1.100:2375\"\n    docker_timeout: int | None = 120  # Docker API超时时间(秒)\n    docker_tls_verify: bool = False  # 是否验证TLS证书\n    docker_cert_path: str | None = None  # TLS证书路径\n    \n    # Sandbox configuration\n    sandbox_remote_address: str | None = None  # 远程沙盒服务地址（供远程Docker使用）\n    sandbox_image: str | None = None\n    sandbox_name_prefix: str | None = None\n    sandbox_ttl_minutes: int | None = 30\n    sandbox_network: str | None = None  # Docker network bridge name\n    sandbox_chrome_args: str | None = \"\"\n    sandbox_https_proxy: str | None = None\n    sandbox_http_proxy: str | None = None\n    sandbox_no_proxy: str | None = None\n    \n    # Sandbox security configuration\n    sandbox_run_as_user: int = 0  # 允许root用户（0）\n    sandbox_run_as_group: int = 0  # 允许root组（0）\n    sandbox_fs_group: int = 1000  # 文件系统组ID保持1000\n    sandbox_allow_privilege_escalation: bool = True  # 允许权限提升（sudo需要）\n    sandbox_read_only_root_filesystem: bool = False  # 允许写入根文件系统\n    \n    # Kubernetes configuration\n    use_kubernetes: bool = False  # 是否使用Kubernetes沙箱\n    k8s_namespace: str | None = None  # Kubernetes命名空间\n    k8s_release_name: str | None = None  # Helm Release名称，用于构造ServiceAccount名称\n    k8s_service_type: str = \"ClusterIP\"  # Kubernetes服务类型（ClusterIP或NodePort）\n    k8s_node_selector: str | None = None  # Kubernetes节点选择器（JSON格式）\n    k8s_resources_limits_cpu: str | None = None  # CPU限制，如\"500m\"\n    k8s_resources_limits_memory: str | None = None  # 内存限制，如\"512Mi\"\n    k8s_resources_requests_cpu: str | None = None  # CPU请求，如\"100m\"\n    k8s_resources_requests_memory: str | None = None  # 内存请求，如\"128Mi\"\n    \n    # 持久化存储卷配置\n    k8s_enable_persistent_volume: bool = True  # 是否启用持久化存储卷\n    k8s_pvc_size: str = \"10Gi\"  # PVC大小，如\"10Gi\"\n    k8s_storage_class: str | None = None  # 存储类名称，None表示使用默认存储类\n    k8s_volume_mount_path: str = \"/home/ubuntu\"  # 存储卷挂载路径\n    \n    # Docker持久化存储卷配置\n    docker_enable_persistent_volume: bool = True  # 是否启用Docker持久化存储卷\n    docker_volume_mount_path: str = \"/home/ubuntu\"  # Docker存储卷挂载路径\n    \n    # Search engine configuration\n    search_engine_type: str = \"searxng\"  # 可选值: google, searxng\n    google_search_api_key: str | None = None\n    google_search_engine_id: str | None = None\n    searxng_url: str | None = None\n    \n    # Code Server configuration\n    code_server_origin: str = \"localhost.betterspace.top\"  # 主域名\n    code_server_subdomain_pattern: str = \"code-{agent_id}\"  # 子域名模式\n    \n    # Logging configuration\n    log_level: str = \"INFO\"\n    \n    class Config:\n        env_file = \".env\"\n        env_file_encoding = \"utf-8\"\n        \n    def validate(self):\n        if not self.api_key:\n            raise ValueError(\"API key is required\")\n",
      "methods": [
        "<module>.Settings.validate"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/config.py",
      "name": "Config",
      "qualname": "<module>.Settings.Config",
      "source": "    class Config:\n        env_file = \".env\"\n        env_file_encoding = \"utf-8\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/browser/playwright_browser.py",
      "name": "PlaywrightBrowser",
      "qualname": "<module>.PlaywrightBrowser",
      "source": "class PlaywrightBrowser:\n    \"\"\"Playwright client that provides specific implementation of browser operations\"\"\"\n    \n    def __init__(self, llm: LLM, cdp_url: str):\n        self.browser: Optional[Browser] = None\n        self.page: Optional[Page] = None\n        self.playwright = None\n        self.llm = llm\n        self.settings = get_settings()\n        self.cdp_url = cdp_url\n        \n    async def initialize(self):\n        \"\"\"Initialize and ensure resources are available\"\"\"\n        # Add retry logic\n        max_retries = 1\n        retry_delay = 1  # Initial wait 1 second\n        for attempt in range(max_retries):\n            try:\n                self.playwright = await async_playwright().start()\n                # Connect to existing Chrome instance\n                self.browser = await self.playwright.chromium.connect_over_cdp(self.cdp_url)\n                # Get all contexts\n                contexts = self.browser.contexts\n                if contexts and len(contexts[0].pages) == 1:\n                    # Check if it's the initial page (by URL)\n                    page = contexts[0].pages[0]\n                    page_url = await page.evaluate(\"window.location.href\")\n                    if (\n                        page_url == \"about:blank\" or \n                        page_url == \"chrome://newtab/\" or \n                        page_url == \"chrome://new-tab-page/\" or \n                        not page_url\n                    ):\n                        # Only use it when it's the initial page and only one tab\n                        self.page = page\n                    else:\n                        # Not the initial page, create a new page\n                        self.page = await contexts[0].new_page()\n                else:\n                    # Create a new page in other cases\n                    context = contexts[0] if contexts else await self.browser.new_context()\n                    self.page = await context.new_page()\n                return True\n            except Exception as e:\n                # Clean up failed resources\n                await self.cleanup()\n                \n                # Return error if maximum retry count is reached\n                if attempt == max_retries - 1:\n                    logger.error(f\"Initialization failed (retried {max_retries} times): {e}\")\n                    return False\n                \n                # Otherwise increase waiting time (exponential backoff strategy)\n                retry_delay = min(retry_delay * 2, 10)  # Maximum wait 10 seconds\n                logger.warning(f\"Initialization failed, will retry in {retry_delay} seconds: {e}\")\n                await asyncio.sleep(retry_delay)\n\n    async def cleanup(self):\n        \"\"\"Clean up Playwright resources, first close all tabs, then close the browser\"\"\"\n        try:\n            # If browser exists, first close all tabs\n            if self.browser:\n                # Get all contexts\n                contexts = self.browser.contexts\n                if contexts:\n                    for context in contexts:\n                        # Get all pages in the context\n                        pages = context.pages\n                        # Close all pages\n                        for page in pages:\n                            # Avoid closing self.page multiple times\n                            if page != self.page or (self.page and not self.page.is_closed()):\n                                await page.close()\n            \n            # Ensure the current page is closed (if it exists and is not closed)\n            if self.page and not self.page.is_closed():\n                await self.page.close()\n                \n            # Close the browser\n            if self.browser:\n                await self.browser.close()\n                \n            # Stop playwright\n            if self.playwright:\n                await self.playwright.stop()\n                \n        except Exception as e:\n            logger.error(f\"Error occurred when cleaning up resources: {e}\")\n        finally:\n            # Reset references\n            self.page = None\n            self.browser = None\n            self.playwright = None\n\n    async def _ensure_browser(self):\n        \"\"\"Ensure the browser is started\"\"\"\n        if not self.browser or not self.page:\n            if not await self.initialize():\n                raise Exception(\"Unable to initialize browser resources\")\n    \n    async def _ensure_page(self):\n        \"\"\"Ensure the page is created and update to the current active tab (rightmost tab)\"\"\"\n        await self._ensure_browser()\n        if not self.page:\n            self.page = await self.browser.new_page()\n        else:\n            # Get all contexts\n            contexts = self.browser.contexts\n            if contexts:\n                # Get all pages in the current context\n                current_context = contexts[0]\n                pages = current_context.pages\n                \n                if pages:\n                    # Get the rightmost tab (usually the most recently opened page)\n                    rightmost_page = pages[-1]\n                    \n                    # Update if the current page is not the rightmost tab\n                    if self.page != rightmost_page:\n                        # Update to the rightmost tab\n                        self.page = rightmost_page\n    \n    async def wait_for_page_load(self, timeout: int = 15) -> bool:\n        \"\"\"Wait for the page to finish loading, waiting up to the specified timeout\n        \n        Args:\n            timeout: Maximum wait time (seconds), default is 15 seconds\n            \n        Returns:\n            bool: Whether successfully waited for the page to load completely\n        \"\"\"\n        await self._ensure_page()\n        \n        start_time = asyncio.get_event_loop().time()\n        check_interval = 2  # Check every 5 seconds\n        \n        while asyncio.get_event_loop().time() - start_time < timeout:\n            # Check if the page has completely loaded\n            is_loaded = await self.page.evaluate(\"\"\"() => {\n                return document.readyState === 'complete';\n            }\"\"\")\n            \n            if is_loaded:\n                return True\n                \n            # Wait for a while before checking again\n            await asyncio.sleep(check_interval)\n        \n        # Timeout, page loading not completed\n        return False\n    \n    async def _extract_content(self) -> Dict[str, Any]:\n        \"\"\"Extract content from the current page\"\"\"\n\n        # Execute JavaScript to get elements in the viewport    \n        visible_content = await self.page.evaluate(\"\"\"() => {\n            const visibleElements = [];\n            const viewportHeight = window.innerHeight;\n            const viewportWidth = window.innerWidth;\n            \n            // Get all potentially relevant elements\n            const elements = document.querySelectorAll('body *');\n            \n            for (const element of elements) {\n                // Check if the element is in the viewport and visible\n                const rect = element.getBoundingClientRect();\n                \n                // Element must have some dimensions\n                if (rect.width === 0 || rect.height === 0) continue;\n                \n                // Element must be within the viewport\n                if (\n                    rect.bottom < 0 || \n                    rect.top > viewportHeight ||\n                    rect.right < 0 || \n                    rect.left > viewportWidth\n                ) continue;\n                \n                // Check if the element is visible (not hidden by CSS)\n                const style = window.getComputedStyle(element);\n                if (\n                    style.display === 'none' || \n                    style.visibility === 'hidden' || \n                    style.opacity === '0'\n                ) continue;\n                \n                // If it's a text node or meaningful element, add it to the results\n                if (\n                    element.innerText || \n                    element.tagName === 'IMG' || \n                    element.tagName === 'INPUT' || \n                    element.tagName === 'BUTTON'\n                ) {\n                    visibleElements.push(element.outerHTML);\n                }\n            }\n            \n            // Build HTML containing these visible elements\n            return '<div>' + visibleElements.join('') + '</div>';\n        }\"\"\")\n\n        \n        # Convert to Markdown\n        markdown_content = markdownify(visible_content)\n\n        max_content_length = min(50000, len(markdown_content))\n        response = await self.llm.ask([{\n            \"role\": \"system\",\n            \"content\": \"You are a professional web page information extraction assistant. Please extract all information from the current page content and convert it to Markdown format.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": markdown_content[:max_content_length]\n        }\n        ])\n        \n        return response.content\n    \n    async def view_page(self) -> ToolResult:\n        \"\"\"View visible elements within the current page's viewport and convert to Markdown format\"\"\"\n        await self._ensure_page()\n        \n        # Wait for the page to load completely, maximum wait 15 seconds\n        await self.wait_for_page_load()\n        \n        # First update the interactive elements cache\n        interactive_elements = await self._extract_interactive_elements()\n        \n        return ToolResult(\n            success=True,\n            data={\n                \"interactive_elements\": interactive_elements,\n                \"content\": await self._extract_content(),\n            }\n        )\n    \n    async def _extract_interactive_elements(self) -> List[str]:\n        \"\"\"Return a list of visible interactive elements on the page, formatted as index:<tag>text</tag>\"\"\"\n        await self._ensure_page()\n        \n        # Clear the current page's cache to ensure we always get the latest list of elements\n        self.page.interactive_elements_cache = []\n        \n        # Execute JavaScript to get interactive elements in the viewport\n        interactive_elements = await self.page.evaluate(\"\"\"() => {\n            const interactiveElements = [];\n            const viewportHeight = window.innerHeight;\n            const viewportWidth = window.innerWidth;\n            \n            // Get all potentially relevant interactive elements\n            const elements = document.querySelectorAll('button, a, input, textarea, select, [role=\"button\"], [tabindex]:not([tabindex=\"-1\"])');\n            \n            let validElementIndex = 0; // For generating consecutive indices\n            \n            for (let i = 0; i < elements.length; i++) {\n                const element = elements[i];\n                // Check if the element is in the viewport and visible\n                const rect = element.getBoundingClientRect();\n                \n                // Element must have some dimensions\n                if (rect.width === 0 || rect.height === 0) continue;\n                \n                // Element must be within the viewport\n                if (\n                    rect.bottom < 0 || \n                    rect.top > viewportHeight ||\n                    rect.right < 0 || \n                    rect.left > viewportWidth\n                ) continue;\n                \n                // Check if the element is visible (not hidden by CSS)\n                const style = window.getComputedStyle(element);\n                if (\n                    style.display === 'none' || \n                    style.visibility === 'hidden' || \n                    style.opacity === '0'\n                ) continue;\n                \n                \n                // Get element type and text\n                let tagName = element.tagName.toLowerCase();\n                let text = '';\n                \n                if (element.value && ['input', 'textarea', 'select'].includes(tagName)) {\n                    text = element.value;\n                    \n                    // Add label and placeholder information for input elements\n                    if (tagName === 'input') {\n                        // Get associated label text\n                        let labelText = '';\n                        if (element.id) {\n                            const label = document.querySelector(`label[for=\"${element.id}\"]`);\n                            if (label) {\n                                labelText = label.innerText.trim();\n                            }\n                        }\n                        \n                        // Look for parent or sibling label\n                        if (!labelText) {\n                            const parentLabel = element.closest('label');\n                            if (parentLabel) {\n                                labelText = parentLabel.innerText.trim().replace(element.value, '').trim();\n                            }\n                        }\n                        \n                        // Add label information\n                        if (labelText) {\n                            text = `[Label: ${labelText}] ${text}`;\n                        }\n                        \n                        // Add placeholder information\n                        if (element.placeholder) {\n                            text = `${text} [Placeholder: ${element.placeholder}]`;\n                        }\n                    }\n                } else if (element.innerText) {\n                    text = element.innerText.trim().replace(/\\\\s+/g, ' ');\n                } else if (element.alt) { // For image buttons\n                    text = element.alt;\n                } else if (element.title) { // For elements with title\n                    text = element.title;\n                } else if (element.placeholder) { // For placeholder text\n                    text = `[Placeholder: ${element.placeholder}]`;\n                } else if (element.type) { // For input type\n                    text = `[${element.type}]`;\n                    \n                    // Add label and placeholder information for text-less input elements\n                    if (tagName === 'input') {\n                        // Get associated label text\n                        let labelText = '';\n                        if (element.id) {\n                            const label = document.querySelector(`label[for=\"${element.id}\"]`);\n                            if (label) {\n                                labelText = label.innerText.trim();\n                            }\n                        }\n                        \n                        // Look for parent or sibling label\n                        if (!labelText) {\n                            const parentLabel = element.closest('label');\n                            if (parentLabel) {\n                                labelText = parentLabel.innerText.trim();\n                            }\n                        }\n                        \n                        // Add label information\n                        if (labelText) {\n                            text = `[Label: ${labelText}] ${text}`;\n                        }\n                        \n                        // Add placeholder information\n                        if (element.placeholder) {\n                            text = `${text} [Placeholder: ${element.placeholder}]`;\n                        }\n                    }\n                } else {\n                    text = '[No text]';\n                }\n                \n                // Maximum limit on text length to keep it clear\n                if (text.length > 100) {\n                    text = text.substring(0, 97) + '...';\n                }\n                \n                // Only add data-manus-id attribute to elements that meet the conditions\n                element.setAttribute('data-manus-id', `manus-element-${validElementIndex}`);\n                                                        \n                // Build selector - using only data-manus-id\n                const selector = `[data-manus-id=\"manus-element-${validElementIndex}\"]`;\n                \n                // Add element information to the array\n                interactiveElements.push({\n                    index: validElementIndex,  // Use consecutive index\n                    tag: tagName,\n                    text: text,\n                    selector: selector\n                });\n                \n                validElementIndex++; // Increment valid element counter\n            }\n            \n            return interactiveElements;\n        }\"\"\")\n        \n        # Update cache\n        self.page.interactive_elements_cache = interactive_elements\n        \n        # Format element information in specified format\n        formatted_elements = []\n        for el in interactive_elements:\n            formatted_elements.append(f\"{el['index']}:<{el['tag']}>{el['text']}</{el['tag']}>\")\n        \n        return formatted_elements\n    \n    async def navigate(self, url: str, timeout: Optional[int] = 15000) -> ToolResult:\n        \"\"\"Navigate to the specified URL\n        \n        Args:\n            url: URL to navigate to\n            timeout: Navigation timeout (milliseconds), default is 60 seconds\n        \"\"\"\n        await self._ensure_page()\n        try:\n            # Clear cache as the page is about to change\n            self.page.interactive_elements_cache = []\n            try:\n                await self.page.goto(url, timeout=timeout)\n            except Exception as e:\n                logger.warning(f\"Failed to navigate to {url}: {str(e)}\")\n            return ToolResult(\n                success=True,\n                data={\n                    \"interactive_elements\": await self._extract_interactive_elements(),\n                }\n            )\n        except Exception as e:\n            return ToolResult(success=False, message=f\"Failed to navigate to {url}: {str(e)}\")\n    \n    async def restart(self, url: str) -> ToolResult:\n        \"\"\"Restart the browser and navigate to the specified URL\"\"\"\n        await self.cleanup()\n        return await self.navigate(url)\n\n    \n    async def _get_element_by_index(self, index: int) -> Optional[Any]:\n        \"\"\"Get element by index using data-manus-id selector\n        \n        Args:\n            index: Element index\n            \n        Returns:\n            The found element, or None if not found\n        \"\"\"\n        # Check if there are cached elements\n        if not hasattr(self.page, 'interactive_elements_cache') or not self.page.interactive_elements_cache or index >= len(self.page.interactive_elements_cache):\n            return None\n        \n        # Use data-manus-id selector\n        selector = f'[data-manus-id=\"manus-element-{index}\"]'\n        return await self.page.query_selector(selector)\n    \n    async def click(\n        self,\n        index: Optional[int] = None,\n        coordinate_x: Optional[float] = None,\n        coordinate_y: Optional[float] = None\n    ) -> ToolResult:\n        \"\"\"Click an element\"\"\"\n        await self._ensure_page()\n        if coordinate_x is not None and coordinate_y is not None:\n            await self.page.mouse.click(coordinate_x, coordinate_y)\n        elif index is not None:\n            try:\n                element = await self._get_element_by_index(index)\n                if not element:\n                    return ToolResult(success=False, message=f\"Cannot find interactive element with index {index}\")\n                \n                # Check if the element is visible\n                is_visible = await self.page.evaluate(\"\"\"(element) => {\n                    if (!element) return false;\n                    const rect = element.getBoundingClientRect();\n                    const style = window.getComputedStyle(element);\n                    return !(\n                        rect.width === 0 || \n                        rect.height === 0 || \n                        style.display === 'none' || \n                        style.visibility === 'hidden' || \n                        style.opacity === '0'\n                    );\n                }\"\"\", element)\n                \n                if not is_visible:\n                    # Try to scroll to the element position\n                    await self.page.evaluate(\"\"\"(element) => {\n                        if (element) {\n                            element.scrollIntoView({behavior: 'smooth', block: 'center'});\n                        }\n                    }\"\"\", element)\n                    # Wait for the element to become visible\n                    await asyncio.sleep(1)\n                \n                # Try to click the element\n                await element.click(timeout=5000)\n            except Exception as e:\n                return ToolResult(success=False, message=f\"Failed to click element: {str(e)}\")\n        return ToolResult(success=True)\n    \n    async def input(\n        self,\n        text: str,\n        press_enter: bool,\n        index: Optional[int] = None,\n        coordinate_x: Optional[float] = None,\n        coordinate_y: Optional[float] = None\n    ) -> ToolResult:\n        \"\"\"Input text\"\"\"\n        await self._ensure_page()\n        if coordinate_x is not None and coordinate_y is not None:\n            await self.page.mouse.click(coordinate_x, coordinate_y)\n            await self.page.keyboard.type(text)\n        elif index is not None:\n            try:\n                element = await self._get_element_by_index(index)\n                if not element:\n                    return ToolResult(success=False, message=f\"Cannot find interactive element with index {index}\")\n                \n                # Try to use fill() method, but catch possible errors\n                try:\n                    await element.fill(\"\")\n                    await element.type(text)\n                except Exception as e:\n                    # If fill() fails, use type() method directly\n                    await element.click()\n                    await self.page.keyboard.type(text)\n            except Exception as e:\n                return ToolResult(success=False, message=f\"Failed to input text: {str(e)}\")\n        \n        if press_enter:\n            await self.page.keyboard.press(\"Enter\")\n        return ToolResult(success=True)\n    \n    async def move_mouse(\n        self,\n        coordinate_x: float,\n        coordinate_y: float\n    ) -> ToolResult:\n        \"\"\"Move the mouse\"\"\"\n        await self._ensure_page()\n        await self.page.mouse.move(coordinate_x, coordinate_y)\n        return ToolResult(success=True)\n    \n    async def press_key(self, key: str) -> ToolResult:\n        \"\"\"Simulate key press\"\"\"\n        await self._ensure_page()\n        await self.page.keyboard.press(key)\n        return ToolResult(success=True)\n    \n    async def select_option(\n        self,\n        index: int,\n        option: int\n    ) -> ToolResult:\n        \"\"\"Select dropdown option\"\"\"\n        await self._ensure_page()\n        try:\n            element = await self._get_element_by_index(index)\n            if not element:\n                return ToolResult(success=False, message=f\"Cannot find selector element with index {index}\")\n            \n            # Try to select the option\n            await element.select_option(index=option)\n            return ToolResult(success=True)\n        except Exception as e:\n            return ToolResult(success=False, message=f\"Failed to select option: {str(e)}\")\n    \n    async def scroll_up(\n        self,\n        to_top: Optional[bool] = None\n    ) -> ToolResult:\n        \"\"\"Scroll up\"\"\"\n        await self._ensure_page()\n        if to_top:\n            await self.page.evaluate(\"window.scrollTo(0, 0)\")\n        else:\n            await self.page.evaluate(\"window.scrollBy(0, -window.innerHeight)\")\n        return ToolResult(success=True)\n    \n    async def scroll_down(\n        self,\n        to_bottom: Optional[bool] = None\n    ) -> ToolResult:\n        \"\"\"Scroll down\"\"\"\n        await self._ensure_page()\n        if to_bottom:\n            await self.page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n        else:\n            await self.page.evaluate(\"window.scrollBy(0, window.innerHeight)\")\n        return ToolResult(success=True)\n    \n    async def console_exec(self, javascript: str) -> ToolResult:\n        \"\"\"Execute JavaScript code\"\"\"\n        await self._ensure_page()\n        result = await self.page.evaluate(javascript)\n        return ToolResult(success=True, data={\"result\": result})\n    \n    async def console_view(self, max_lines: Optional[int] = None) -> ToolResult:\n        \"\"\"View console output\"\"\"\n        await self._ensure_page()\n        logs = await self.page.evaluate(\"\"\"() => {\n            return window.console.logs || [];\n        }\"\"\")\n        if max_lines is not None:\n            logs = logs[-max_lines:]\n        return ToolResult(success=True, data={\"logs\": logs})\n",
      "methods": [
        "<module>.PlaywrightBrowser.__init__",
        "<module>.PlaywrightBrowser.initialize",
        "<module>.PlaywrightBrowser.cleanup",
        "<module>.PlaywrightBrowser._ensure_browser",
        "<module>.PlaywrightBrowser._ensure_page",
        "<module>.PlaywrightBrowser.wait_for_page_load",
        "<module>.PlaywrightBrowser._extract_content",
        "<module>.PlaywrightBrowser.view_page",
        "<module>.PlaywrightBrowser._extract_interactive_elements",
        "<module>.PlaywrightBrowser.navigate",
        "<module>.PlaywrightBrowser.restart",
        "<module>.PlaywrightBrowser._get_element_by_index",
        "<module>.PlaywrightBrowser.click",
        "<module>.PlaywrightBrowser.input",
        "<module>.PlaywrightBrowser.move_mouse",
        "<module>.PlaywrightBrowser.press_key",
        "<module>.PlaywrightBrowser.select_option",
        "<module>.PlaywrightBrowser.scroll_up",
        "<module>.PlaywrightBrowser.scroll_down",
        "<module>.PlaywrightBrowser.console_exec",
        "<module>.PlaywrightBrowser.console_view"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/conversation/memory_repository.py",
      "name": "MemoryConversationRepository",
      "qualname": "<module>.MemoryConversationRepository",
      "source": "class MemoryConversationRepository(ConversationRepository):\n    \"\"\"对话仓储内存实现\"\"\"\n    \n    async def save_history(self, history: ConversationHistory) -> None:\n        \"\"\"保存会话历史\"\"\"\n        conversation_data_store.histories[history.agent_id] = history\n        \n        # 更新用户会话索引\n        if history.user_id not in conversation_data_store.user_histories_index:\n            conversation_data_store.user_histories_index[history.user_id] = []\n            \n        if history.agent_id not in conversation_data_store.user_histories_index[history.user_id]:\n            conversation_data_store.user_histories_index[history.user_id].append(history.agent_id)\n            \n        logger.debug(f\"保存会话历史: {history.agent_id}, 用户: {history.user_id}\")\n    \n    async def get_history(self, agent_id: str) -> Optional[ConversationHistory]:\n        \"\"\"获取会话历史\"\"\"\n        return conversation_data_store.histories.get(agent_id)\n    \n    async def add_event(self, agent_id: str, event_type: str, event_data: dict) -> ConversationEvent:\n        \"\"\"添加事件到会话历史\"\"\"\n        # 获取会话历史\n        history = await self.get_history(agent_id)\n        if not history:\n            logger.error(f\"未找到会话历史: {agent_id}\")\n            raise ValueError(f\"会话历史不存在: {agent_id}\")\n        \n        # 确保事件表中有该agent_id的条目\n        if agent_id not in conversation_data_store.events:\n            conversation_data_store.events[agent_id] = {}\n        \n        # 计算事件序号\n        next_sequence = max(conversation_data_store.events[agent_id].keys(), default=0) + 1\n        \n        # 创建事件\n        event = ConversationEvent(\n            id=f\"{agent_id}_{next_sequence}\",\n            agent_id=agent_id,\n            event_type=event_type,\n            event_data=event_data,\n            sequence=next_sequence,\n            timestamp=datetime.now()\n        )\n        \n        # 保存事件到事件表\n        conversation_data_store.events[agent_id][next_sequence] = event\n        \n        # 将事件添加到会话历史的events列表中\n        history.events.append(event)\n        \n        # 更新会话历史的最后更新时间\n        history.updated_at = datetime.now()\n        await self.save_history(history)\n        \n        logger.debug(f\"添加事件: {event.id}, 类型: {event_type}, 序号: {next_sequence}\")\n        return event\n    \n    async def get_events_from_sequence(self, agent_id: str, from_sequence: int = 1) -> List[ConversationEvent]:\n        \"\"\"获取从指定序号开始的事件\"\"\"\n        if agent_id not in conversation_data_store.events:\n            return []\n        \n        events = conversation_data_store.events[agent_id]\n        return [events[seq] for seq in sorted(events.keys()) if seq >= from_sequence]\n    \n    async def delete_history(self, agent_id: str) -> bool:\n        \"\"\"删除会话历史\"\"\"\n        # 获取会话历史\n        history = conversation_data_store.histories.pop(agent_id, None)\n        if not history:\n            logger.warning(f\"未找到要删除的会话历史: {agent_id}\")\n            return False\n        \n        # 从用户会话索引中移除\n        if history.user_id in conversation_data_store.user_histories_index:\n            if agent_id in conversation_data_store.user_histories_index[history.user_id]:\n                conversation_data_store.user_histories_index[history.user_id].remove(agent_id)\n        \n        # 删除事件\n        conversation_data_store.events.pop(agent_id, None)\n        \n        logger.info(f\"删除会话历史: {agent_id}, 用户: {history.user_id}\")\n        return True\n    \n    async def list_histories(self, user_id: str, limit: int = 50, offset: int = 0) -> List[ConversationHistory]:\n        \"\"\"列出会话历史（支持按用户过滤）\"\"\"\n        result = []\n        \n        # 获取用户关联的所有agent_id\n        agent_ids = conversation_data_store.user_histories_index.get(user_id, [])\n        \n        # 计算分页\n        end_idx = min(offset + limit, len(agent_ids))\n        paged_agent_ids = agent_ids[offset:end_idx]\n        \n        # 获取对应的会话历史\n        for agent_id in paged_agent_ids:\n            history = conversation_data_store.histories.get(agent_id)\n            if history:\n                result.append(history)\n        \n        # 按更新时间排序（最新的在前）\n        result.sort(key=lambda h: h.updated_at, reverse=True)\n        \n        return result ",
      "methods": [
        "<module>.MemoryConversationRepository.save_history",
        "<module>.MemoryConversationRepository.get_history",
        "<module>.MemoryConversationRepository.add_event",
        "<module>.MemoryConversationRepository.get_events_from_sequence",
        "<module>.MemoryConversationRepository.delete_history",
        "<module>.MemoryConversationRepository.list_histories"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/conversation/sqlite_repository.py",
      "name": "SQLiteConversationRepository",
      "qualname": "<module>.SQLiteConversationRepository",
      "source": "class SQLiteConversationRepository:\n    \"\"\"会话仓储SQLite实现 - 使用全局DatabaseManager\"\"\"\n\n    def __init__(self, engine: AsyncEngine):\n        \"\"\"初始化会话仓储\n        \n        Args:\n            engine: 可选的数据库引擎，如果不提供则使用默认引擎\n        \"\"\"\n        self.engine = engine\n        self._agent_locks = collections.defaultdict(asyncio.Lock)\n    \n    def _orm_to_domain_event(self, event_orm: ConversationEventORM) -> ConversationEvent:\n        \"\"\"将事件ORM模型转换为领域模型\"\"\"\n        return ConversationEvent(\n            id=event_orm.id,\n            agent_id=event_orm.agent_id,\n            event_type=event_orm.event_type,\n            event_data=event_orm.event_data,\n            timestamp=event_orm.timestamp,\n            sequence=event_orm.sequence\n        )\n    \n    def _domain_to_orm_event(self, event: ConversationEvent) -> ConversationEventORM:\n        \"\"\"将事件领域模型转换为ORM模型\"\"\"\n        return ConversationEventORM(\n            id=event.id,\n            agent_id=event.agent_id,\n            sequence=event.sequence,\n            event_type=event.event_type,\n            event_data=event.event_data,\n            timestamp=event.timestamp\n        )\n    \n    def _orm_to_domain_history(self, history_orm: ConversationHistoryORM) -> ConversationHistory:\n        \"\"\"将历史ORM模型转换为领域模型\"\"\"\n        events = []\n        if history_orm.events:\n            events = [self._orm_to_domain_event(event_orm) for event_orm in history_orm.events]\n            # 按序号排序\n            events.sort(key=lambda e: e.sequence)\n        \n        return ConversationHistory(\n            agent_id=history_orm.agent_id,\n            user_id=history_orm.user_id,\n            flow_id=history_orm.flow_id,\n            title=history_orm.title,\n            created_at=history_orm.created_at,\n            updated_at=history_orm.updated_at,\n            events=events\n        )\n    \n    def _domain_to_orm_history(self, history: ConversationHistory) -> ConversationHistoryORM:\n        \"\"\"将历史领域模型转换为ORM模型\"\"\"\n        return ConversationHistoryORM(\n            agent_id=history.agent_id,\n            user_id=history.user_id,\n            flow_id=history.flow_id,\n            title=history.title,\n            created_at=history.created_at,\n            updated_at=history.updated_at\n        )\n    \n    async def save_history(self, history: ConversationHistory) -> None:\n        \"\"\"保存会话历史\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 检查会话历史是否已存在\n                stmt = select(ConversationHistoryORM).where(ConversationHistoryORM.agent_id == history.agent_id)\n                result = await session.execute(stmt)\n                existing_history = result.scalar_one_or_none()\n                \n                if existing_history:\n                    # 更新现有会话历史\n                    existing_history.user_id = history.user_id\n                    existing_history.flow_id = history.flow_id\n                    existing_history.title = history.title\n                    existing_history.updated_at = history.updated_at\n                else:\n                    # 创建新会话历史\n                    history_orm = self._domain_to_orm_history(history)\n                    session.add(history_orm)\n                \n                await session.commit()\n                logger.debug(f\"保存会话历史: {history.agent_id}, 用户: {history.user_id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"保存会话历史失败: {history.agent_id}, 错误: {str(e)}\")\n                raise\n    \n    async def get_history(self, agent_id: str) -> Optional[ConversationHistory]:\n        \"\"\"获取会话历史\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(ConversationHistoryORM).options(\n                selectinload(ConversationHistoryORM.events)\n            ).where(ConversationHistoryORM.agent_id == agent_id)\n            result = await session.execute(stmt)\n            history_orm = result.scalar_one_or_none()\n            \n            if history_orm:\n                return self._orm_to_domain_history(history_orm)\n            return None\n    \n    async def add_event(self, agent_id: str, event_type: str, event_data: dict) -> ConversationEvent:\n        \"\"\"添加事件到会话历史 - 使用重试机制处理并发\"\"\"\n        max_retries = 10\n        for attempt in range(max_retries):\n            async with get_session(self.engine) as session:\n                try:\n                    async with self._agent_locks[agent_id]:\n                        # 在事务中获取序号并插入\n                        max_sequence_stmt = select(func.max(ConversationEventORM.sequence)).where(\n                            ConversationEventORM.agent_id == agent_id\n                        )\n                        max_sequence_result = await session.execute(max_sequence_stmt)\n                        current_max_sequence = max_sequence_result.scalar_one_or_none()\n                        \n                        next_sequence = (current_max_sequence or 0) + 1\n                        \n                        event = ConversationEvent(\n                            id=str(uuid.uuid4()),\n                            agent_id=agent_id,\n                            event_type=event_type,\n                            event_data=event_data,\n                            timestamp=datetime.now(),\n                            sequence=next_sequence\n                        )\n                        \n                        event_orm = self._domain_to_orm_event(event)\n                        session.add(event_orm)\n                        \n                        await session.commit()\n                        return event\n                    \n                except IntegrityError as e:\n                    await session.rollback()\n                    logger.exception(f\"添加事件失败: {agent_id}, 错误: {str(e)}\")\n                    if attempt < max_retries - 1:\n                        # 短暂等待后重试\n                        await asyncio.sleep(0.01 * (2 ** attempt))  # 指数退避\n                        continue\n                    else:\n                        logger.error(f\"添加事件失败，已达最大重试次数: {agent_id}\")\n                        raise\n                except Exception as e:\n                    await session.rollback()\n                    logger.error(f\"添加事件失败: {agent_id}, 错误: {str(e)}\")\n                    raise\n    \n    async def get_events_from_sequence(self, agent_id: str, from_sequence: int = 1) -> List[ConversationEvent]:\n        \"\"\"获取从指定序号开始的事件\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(ConversationEventORM).where(\n                ConversationEventORM.agent_id == agent_id,\n                ConversationEventORM.sequence >= from_sequence\n            ).order_by(ConversationEventORM.sequence)\n\n            result = await session.execute(stmt)\n            event_orms = result.scalars().all()\n            \n            return [self._orm_to_domain_event(event_orm) for event_orm in event_orms]\n    \n    async def delete_history(self, agent_id: str) -> bool:\n        \"\"\"删除会话历史\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 先删除相关事件\n                stmt_delete_events = delete(ConversationEventORM).where(ConversationEventORM.agent_id == agent_id)\n                await session.execute(stmt_delete_events)\n                \n                # 再删除会话历史\n                stmt_delete_history = delete(ConversationHistoryORM).where(ConversationHistoryORM.agent_id == agent_id)\n                result = await session.execute(stmt_delete_history)\n                \n                await session.commit()\n                \n                deleted_count = result.rowcount\n                if deleted_count > 0:\n                    logger.debug(f\"删除会话历史: {agent_id}\")\n                    return True\n                else:\n                    logger.warning(f\"未找到要删除的会话历史: {agent_id}\")\n                    return False\n                    \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"删除会话历史失败: {agent_id}, 错误: {str(e)}\")\n                raise\n    \n    async def list_histories(self, user_id: str, limit: int = 50, offset: int = 0) -> List[ConversationHistory]:\n        \"\"\"列出会话历史（支持按用户过滤）\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(ConversationHistoryORM).where(ConversationHistoryORM.user_id == user_id)\n            \n            stmt = stmt.order_by(\n                ConversationHistoryORM.updated_at.desc()\n            ).limit(limit).offset(offset)\n            \n            result = await session.execute(stmt)\n            history_orms = result.scalars().all()\n            \n            # 注意：这里不加载事件，只返回会话历史基本信息\n            histories = []\n            for history_orm in history_orms:\n                history = ConversationHistory(\n                    agent_id=history_orm.agent_id,\n                    user_id=history_orm.user_id,\n                    flow_id=history_orm.flow_id,\n                    title=history_orm.title,\n                    created_at=history_orm.created_at,\n                    updated_at=history_orm.updated_at,\n                    events=[]  # 不加载事件，提升性能\n                )\n                histories.append(history)\n            \n            return histories ",
      "methods": [
        "<module>.SQLiteConversationRepository.__init__",
        "<module>.SQLiteConversationRepository._orm_to_domain_event",
        "<module>.SQLiteConversationRepository._domain_to_orm_event",
        "<module>.SQLiteConversationRepository._orm_to_domain_history",
        "<module>.SQLiteConversationRepository._domain_to_orm_history",
        "<module>.SQLiteConversationRepository.save_history",
        "<module>.SQLiteConversationRepository.get_history",
        "<module>.SQLiteConversationRepository.add_event",
        "<module>.SQLiteConversationRepository.get_events_from_sequence",
        "<module>.SQLiteConversationRepository.delete_history",
        "<module>.SQLiteConversationRepository.list_histories"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/memory_repository.py",
      "name": "MemoryEventBuffer",
      "qualname": "<module>.MemoryEventBuffer",
      "source": "class MemoryEventBuffer:\n    \"\"\"内存版本的事件缓冲实现\"\"\"\n    \n    def __init__(self, agent_id: str, max_size: int = EventBuffer.DEFAULT_MAX_SIZE):\n        self.agent_id = agent_id\n        self.max_size = max_size\n        self.events: List[AgentEvent] = []\n        self._current_sequence: int = 0\n\n    def add_event(self, event: AgentEvent) -> int:\n        \"\"\"添加事件到缓冲区，返回序号\"\"\"\n        self._current_sequence += 1\n        \n        # 如果缓冲区满了，移除最老的事件\n        if len(self.events) >= self.max_size:\n            self.events.pop(0)\n        \n        self.events.append(event)\n        return self._current_sequence\n\n    def get_events_from_sequence(self, from_sequence: int) -> List[AgentEvent]:\n        \"\"\"获取指定序号之后的事件\"\"\"\n        if from_sequence <= 0:\n            return self.events.copy()\n        \n        # 计算起始位置\n        start_index = max(0, from_sequence - (self._current_sequence - len(self.events) + 1))\n        return self.events[start_index:]\n\n    def has_done_event_as_last(self) -> bool:\n        \"\"\"检查最后一个事件是否是DoneEvent\"\"\"\n        if not self.events:\n            return False\n        return isinstance(self.events[-1], DoneEvent)\n\n    def clear(self) -> None:\n        \"\"\"清空缓冲区\"\"\"\n        self.events.clear()\n\n    @property\n    def current_sequence(self) -> int:\n        \"\"\"获取当前序号\"\"\"\n        return self._current_sequence\n",
      "methods": [
        "<module>.MemoryEventBuffer.__init__",
        "<module>.MemoryEventBuffer.add_event",
        "<module>.MemoryEventBuffer.get_events_from_sequence",
        "<module>.MemoryEventBuffer.has_done_event_as_last",
        "<module>.MemoryEventBuffer.clear",
        "<module>.MemoryEventBuffer.current_sequence"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/memory_repository.py",
      "name": "MemoryEventBroadcastRepository",
      "qualname": "<module>.MemoryEventBroadcastRepository",
      "source": "class MemoryEventBroadcastRepository(EventBroadcastRepository):\n    \"\"\"内存版本的事件广播仓储\"\"\"\n\n    def __init__(self):\n        self._broadcasters: Dict[str, AgentEventBroadcaster] = {}\n        logger.info(\"MemoryEventBroadcastRepository initialized\")\n\n    def _create_broadcaster(self, agent_id: str) -> AgentEventBroadcaster:\n        \"\"\"创建新的广播器，使用内存版本的事件缓冲\"\"\"\n        event_buffer = MemoryEventBuffer(agent_id)\n        return AgentEventBroadcaster(\n            agent_id=agent_id,\n            event_buffer=event_buffer\n        )\n\n    async def save_broadcaster(self, broadcaster: AgentEventBroadcaster) -> None:\n        \"\"\"保存广播器\"\"\"\n        self._broadcasters[broadcaster.agent_id] = broadcaster\n        logger.debug(f\"Saved broadcaster for agent {broadcaster.agent_id}\")\n\n    async def get_broadcaster(self, agent_id: str) -> Optional[AgentEventBroadcaster]:\n        \"\"\"获取广播器\"\"\"\n        return self._broadcasters.get(agent_id)\n\n    async def update_broadcaster(self, broadcaster: AgentEventBroadcaster) -> bool:\n        \"\"\"更新广播器\"\"\"\n        if broadcaster.agent_id not in self._broadcasters:\n            return False\n        \n        self._broadcasters[broadcaster.agent_id] = broadcaster\n        logger.debug(f\"Updated broadcaster for agent {broadcaster.agent_id}\")\n        return True\n\n    async def delete_broadcaster(self, agent_id: str) -> bool:\n        \"\"\"删除广播器\"\"\"\n        broadcaster = self._broadcasters.pop(agent_id, None)\n        if broadcaster:\n            logger.debug(f\"Deleted broadcaster for agent {agent_id}\")\n            return True\n        return False\n",
      "methods": [
        "<module>.MemoryEventBroadcastRepository.__init__",
        "<module>.MemoryEventBroadcastRepository._create_broadcaster",
        "<module>.MemoryEventBroadcastRepository.save_broadcaster",
        "<module>.MemoryEventBroadcastRepository.get_broadcaster",
        "<module>.MemoryEventBroadcastRepository.update_broadcaster",
        "<module>.MemoryEventBroadcastRepository.delete_broadcaster"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/memory_repository.py",
      "name": "MemoryEventStreamRepository",
      "qualname": "<module>.MemoryEventStreamRepository",
      "source": "class MemoryEventStreamRepository(EventStreamRepository):\n    \"\"\"内存版本的事件流仓储 - 发布订阅模式\"\"\"\n\n    def __init__(self, broadcast_repository: MemoryEventBroadcastRepository):\n        self.broadcast_repository = broadcast_repository\n        logger.info(\"MemoryEventStreamRepository initialized with pub-sub pattern\")\n\n    async def get_events_from_sequence(self, agent_id: str, from_sequence: int = 1) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"从指定序号开始获取事件流（包含历史事件和实时事件）\"\"\"\n        logger.info(f\"Starting event stream for agent {agent_id} from sequence {from_sequence}\")\n        \n        # 1. 首先检查是否有广播器，如果有的话检查是否已经有DoneEvent作为最后一个事件\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if broadcaster and broadcaster.event_buffer.has_done_event_as_last():\n            # 如果最后一个事件是DoneEvent，只获取历史事件然后结束\n            logger.info(f\"Agent {agent_id} already has DoneEvent as last event, returning only buffered events\")\n            buffered_events = await self.get_buffered_events(agent_id, from_sequence)\n            for event in buffered_events:\n                yield event\n            return\n        \n        # 2. 获取缓冲区中的历史事件 (不提前终止，即使遇到DoneEvent)\n        buffered_events = await self.get_buffered_events(agent_id, from_sequence)\n        for event in buffered_events:\n            yield event\n        \n        # 3. 创建订阅者并注册到广播器\n        subscriber = EventSubscriber.create(agent_id)\n        await self._register_subscriber(agent_id, subscriber)\n        \n        try:\n            # 4. 持续从订阅者的队列中获取实时事件\n            while True:\n                try:\n                    # 使用超时来避免无限阻塞，同时更新活动时间\n                    event = await asyncio.wait_for(subscriber.event_queue.get(), timeout=30.0)\n                    subscriber.update_activity()\n                    yield event\n                    subscriber.event_queue.task_done()\n                    \n                    # 检查是否是DoneEvent，如果是则结束事件流\n                    if isinstance(event, DoneEvent):\n                        logger.info(f\"Received DoneEvent for agent {agent_id}, terminating event stream\")\n                        return\n                        \n                except asyncio.TimeoutError:\n                    # 超时时更新活动时间，保持连接活跃\n                    subscriber.update_activity()\n                    continue\n        except asyncio.CancelledError:\n            logger.info(f\"Event stream for agent {agent_id} was cancelled\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error in event stream for agent {agent_id}: {str(e)}\")\n            raise\n        finally:\n            # 5. 清理：注销订阅者\n            await self._unregister_subscriber(agent_id, subscriber.subscriber_id)\n\n    async def _register_subscriber(self, agent_id: str, subscriber: EventSubscriber) -> None:\n        \"\"\"注册订阅者到广播器\"\"\"\n        # 获取或创建广播器\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if not broadcaster:\n            broadcaster = self.broadcast_repository._create_broadcaster(agent_id)\n            await self.broadcast_repository.save_broadcaster(broadcaster)\n        \n        # 添加订阅者\n        broadcaster.add_subscriber(subscriber)\n        await self.broadcast_repository.update_broadcaster(broadcaster)\n        \n        logger.debug(f\"Registered subscriber {subscriber.subscriber_id} for agent {agent_id}\")\n\n    async def _unregister_subscriber(self, agent_id: str, subscriber_id: str) -> None:\n        \"\"\"从广播器中注销订阅者\"\"\"\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if broadcaster:\n            broadcaster.remove_subscriber(subscriber_id)\n            await self.broadcast_repository.update_broadcaster(broadcaster)\n            logger.debug(f\"Unregistered subscriber {subscriber_id} for agent {agent_id}\")\n\n    async def get_buffered_events(self, agent_id: str, from_sequence: int = 1) -> List[AgentEvent]:\n        \"\"\"获取缓冲区中的事件\"\"\"\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if not broadcaster:\n            return []\n        \n        return broadcaster.event_buffer.get_events_from_sequence(from_sequence)\n\n    async def notify_new_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"通知新事件 - 通过广播器分发给所有订阅者\"\"\"\n        # 获取或创建广播器\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if not broadcaster:\n            broadcaster = self.broadcast_repository._create_broadcaster(agent_id)\n            await self.broadcast_repository.save_broadcaster(broadcaster)\n        \n        # 广播事件\n        broadcaster.broadcast_event(event)\n        await self.broadcast_repository.update_broadcaster(broadcaster)\n        \n        logger.debug(f\"Broadcasted event to {broadcaster.get_active_subscriber_count()} subscribers for agent {agent_id}\")\n\n    async def cleanup_agent_stream(self, agent_id: str) -> None:\n        \"\"\"清理agent的事件流\"\"\"\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if broadcaster:\n            # 停用所有订阅者\n            for subscriber in broadcaster.subscribers.values():\n                subscriber.deactivate()\n            # 清空订阅者列表\n            broadcaster.subscribers.clear()\n            await self.broadcast_repository.update_broadcaster(broadcaster)\n            logger.debug(f\"Cleaned up event stream for agent {agent_id}\")\n",
      "methods": [
        "<module>.MemoryEventStreamRepository.__init__",
        "<module>.MemoryEventStreamRepository.get_events_from_sequence",
        "<module>.MemoryEventStreamRepository._register_subscriber",
        "<module>.MemoryEventStreamRepository._unregister_subscriber",
        "<module>.MemoryEventStreamRepository.get_buffered_events",
        "<module>.MemoryEventStreamRepository.notify_new_event",
        "<module>.MemoryEventStreamRepository.cleanup_agent_stream"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/memory_repository.py",
      "name": "MemoryEventSubscriptionManager",
      "qualname": "<module>.MemoryEventSubscriptionManager",
      "source": "class MemoryEventSubscriptionManager:\n    \"\"\"内存版本的事件订阅管理器 - 纯发布订阅模式\"\"\"\n\n    def __init__(self):\n        self.broadcast_repository = MemoryEventBroadcastRepository()\n        self.stream_repository = MemoryEventStreamRepository(self.broadcast_repository)\n        logger.info(\"MemoryEventSubscriptionManager initialized with pure pub-sub pattern\")\n\n    async def notify_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"通知新事件 - 直接通过流仓储的广播机制分发\"\"\"\n        await self.stream_repository.notify_new_event(agent_id, event)\n\n    async def cleanup_agent(self, agent_id: str) -> None:\n        \"\"\"清理agent相关的所有订阅资源\"\"\"\n        # 清理流（包括所有订阅者）\n        await self.stream_repository.cleanup_agent_stream(agent_id)\n        \n        # 清理广播器\n        await self.broadcast_repository.delete_broadcaster(agent_id) ",
      "methods": [
        "<module>.MemoryEventSubscriptionManager.__init__",
        "<module>.MemoryEventSubscriptionManager.notify_event",
        "<module>.MemoryEventSubscriptionManager.cleanup_agent"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/sqlite_repository.py",
      "name": "SQLiteEventBuffer",
      "qualname": "<module>.SQLiteEventBuffer",
      "source": "class SQLiteEventBuffer:\n    \"\"\"SQLite版本的事件缓冲实现 - 数据库持久化缓冲\"\"\"\n    \n    def __init__(self, agent_id: str, max_size: int = EventBuffer.DEFAULT_MAX_SIZE, engine: AsyncEngine = None):\n        self.agent_id = agent_id\n        self.max_size = max_size\n        self.engine = engine\n        self._current_sequence: int = 0\n        # 内存缓存，用于快速访问最近的事件\n        self._memory_cache: List[AgentEvent] = []\n\n    def _create_event_from_data(self, event_type: str, event_data: dict) -> Optional[AgentEvent]:\n        \"\"\"根据事件类型和数据创建具体的事件对象\"\"\"\n        try:\n            if event_type == \"message\":\n                return MessageEvent(**event_data)\n            elif event_type == \"error\":\n                return ErrorEvent(**event_data)\n            elif event_type == \"pause\":\n                return PauseEvent(**event_data)\n            elif event_type == \"tool_calling\":\n                return ToolCallingEvent(**event_data)\n            elif event_type == \"tool_called\":\n                return ToolCalledEvent(**event_data)\n            elif event_type == \"report\":\n                return ReportEvent(**event_data)\n            elif event_type == \"user_input\":\n                return UserInputEvent(**event_data)\n            elif event_type == \"done\":\n                return DoneEvent(**event_data)\n            elif event_type == \"plan_created\":\n                return PlanCreatedEvent(**event_data)\n            elif event_type == \"plan_updated\":\n                return PlanUpdatedEvent(**event_data)\n            elif event_type == \"plan_completed\":\n                return PlanCompletedEvent(**event_data)\n            elif event_type == \"step_started\":\n                return StepStartedEvent(**event_data)\n            elif event_type == \"step_completed\":\n                return StepCompletedEvent(**event_data)\n            elif event_type == \"step_failed\":\n                return StepFailedEvent(**event_data)\n            else:\n                # 对于未知类型，创建基础AgentEvent\n                return AgentEvent(type=event_type)\n        except Exception as e:\n            logger.warning(f\"Failed to create event from data: {event_type}, {event_data}, error: {str(e)}\")\n            return None\n\n    async def _load_events_from_db(self) -> None:\n        \"\"\"从数据库加载事件到内存缓存\"\"\"\n        logger.debug(f\"[SQLiteEventBuffer] _load_events_from_db 开始 - agent_id: {self.agent_id}\")\n        \n        if not self.engine:\n            logger.debug(f\"[SQLiteEventBuffer] 没有数据库引擎，跳过加载 - agent_id: {self.agent_id}\")\n            return\n            \n        try:\n            logger.debug(f\"[SQLiteEventBuffer] 创建数据库会话 - agent_id: {self.agent_id}\")\n            async with get_readonly_session(self.engine) as session:\n                logger.debug(f\"[SQLiteEventBuffer] 数据库会话已创建，开始查询事件 - agent_id: {self.agent_id}\")\n                \n                # 获取最新的事件，按序号排序\n                stmt = select(BufferedEventORM).where(\n                    BufferedEventORM.agent_id == self.agent_id\n                ).order_by(BufferedEventORM.sequence.desc()).limit(self.max_size)\n                \n                logger.debug(f\"[SQLiteEventBuffer] 执行查询语句 - agent_id: {self.agent_id}, max_size: {self.max_size}\")\n                result = await session.execute(stmt)\n                buffered_events = result.scalars().all()\n                \n                logger.debug(f\"[SQLiteEventBuffer] 查询到 {len(buffered_events)} 个事件 - agent_id: {self.agent_id}\")\n                \n                # 按序号正序排列\n                buffered_events = sorted(buffered_events, key=lambda x: x.sequence)\n                \n                # 转换为领域事件对象\n                self._memory_cache = []\n                for buffered_event_orm in buffered_events:\n                    logger.debug(f\"[SQLiteEventBuffer] 转换事件 - agent_id: {self.agent_id}, sequence: {buffered_event_orm.sequence}, type: {buffered_event_orm.event_type}\")\n                    event = self._create_event_from_data(\n                        buffered_event_orm.event_type, \n                        buffered_event_orm.event_data\n                    )\n                    if event:\n                        self._memory_cache.append(event)\n                    else:\n                        logger.warning(f\"[SQLiteEventBuffer] 事件转换失败 - agent_id: {self.agent_id}, sequence: {buffered_event_orm.sequence}\")\n                \n                # 更新当前序号\n                if buffered_events:\n                    self._current_sequence = max(event.sequence for event in buffered_events)\n                    logger.debug(f\"[SQLiteEventBuffer] 更新当前序号 - agent_id: {self.agent_id}, current_sequence: {self._current_sequence}\")\n                else:\n                    logger.debug(f\"[SQLiteEventBuffer] 没有事件，保持当前序号 - agent_id: {self.agent_id}, current_sequence: {self._current_sequence}\")\n                    \n                logger.debug(f\"[SQLiteEventBuffer] _load_events_from_db 完成 - agent_id: {self.agent_id}, 加载了 {len(self._memory_cache)} 个事件\")\n                \n        except Exception as e:\n            logger.error(f\"[SQLiteEventBuffer] _load_events_from_db 异常 - agent_id: {self.agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    # 同步接口（用于向后兼容）\n    def add_event(self, event: AgentEvent) -> int:\n        \"\"\"添加事件到缓冲区，返回序号（同步版本，仅更新内存缓存）\"\"\"\n        if not self.engine:\n            # 如果没有数据库引擎，回退到内存模式\n            return self._add_event_memory_only(event)\n        \n        # 对于有数据库引擎的情况，只更新内存缓存，数据库操作需要调用异步版本\n        self._current_sequence += 1\n        \n        if len(self._memory_cache) >= self.max_size:\n            self._memory_cache.pop(0)\n        \n        self._memory_cache.append(event)\n        logger.debug(f\"Added event to memory cache for agent {self.agent_id}, sequence: {self._current_sequence}\")\n        return self._current_sequence\n\n    async def add_event_async(self, event: AgentEvent) -> int:\n        \"\"\"添加事件到缓冲区，同时保存到数据库（异步版本）\"\"\"\n        logger.debug(f\"[SQLiteEventBuffer] add_event_async 开始 - agent_id: {self.agent_id}, event_type: {event.type}\")\n        \n        if not self.engine:\n            logger.debug(f\"[SQLiteEventBuffer] 没有数据库引擎，使用内存模式 - agent_id: {self.agent_id}\")\n            # 如果没有数据库引擎，回退到内存模式\n            return self._add_event_memory_only(event)\n        \n        self._current_sequence += 1\n        sequence = self._current_sequence\n        logger.debug(f\"[SQLiteEventBuffer] 分配序号 - agent_id: {self.agent_id}, sequence: {sequence}\")\n        \n        try:\n            logger.debug(f\"[SQLiteEventBuffer] 创建数据库会话 - agent_id: {self.agent_id}\")\n            async with get_session(self.engine) as session:\n                logger.debug(f\"[SQLiteEventBuffer] 数据库会话已创建 - agent_id: {self.agent_id}\")\n                \n                try:\n                    # 1. 保存事件到数据库\n                    event_id = str(uuid.uuid4())\n                    logger.debug(f\"[SQLiteEventBuffer] 创建BufferedEventORM - agent_id: {self.agent_id}, event_id: {event_id}, sequence: {sequence}\")\n                    \n                    buffered_event_orm = BufferedEventORM(\n                        id=event_id,\n                        agent_id=self.agent_id,\n                        sequence=sequence,\n                        event_type=event.type,\n                        event_data=event.model_dump(),\n                        timestamp=datetime.now()\n                    )\n                    session.add(buffered_event_orm)\n                    logger.debug(f\"[SQLiteEventBuffer] BufferedEventORM已添加到会话 - agent_id: {self.agent_id}\")\n                    \n                    # 2. 如果缓冲区满了，删除最老的事件\n                    event_count = await self._get_event_count(session)\n                    logger.debug(f\"[SQLiteEventBuffer] 当前事件数量: {event_count}, 最大容量: {self.max_size} - agent_id: {self.agent_id}\")\n                    \n                    if event_count >= self.max_size:\n                        logger.debug(f\"[SQLiteEventBuffer] 缓冲区已满，删除最老事件 - agent_id: {self.agent_id}\")\n                        await self._remove_oldest_event(session)\n                        logger.debug(f\"[SQLiteEventBuffer] 最老事件已删除 - agent_id: {self.agent_id}\")\n                    \n                    logger.debug(f\"[SQLiteEventBuffer] 提交数据库事务 - agent_id: {self.agent_id}\")\n                    await session.commit()\n                    logger.debug(f\"[SQLiteEventBuffer] 数据库事务已提交 - agent_id: {self.agent_id}\")\n                    \n                    # 3. 更新内存缓存\n                    if len(self._memory_cache) >= self.max_size:\n                        removed_event = self._memory_cache.pop(0)\n                        logger.debug(f\"[SQLiteEventBuffer] 从内存缓存移除最老事件 - agent_id: {self.agent_id}, removed_type: {removed_event.type}\")\n                    \n                    self._memory_cache.append(event)\n                    logger.debug(f\"[SQLiteEventBuffer] 事件已添加到内存缓存 - agent_id: {self.agent_id}, cache_size: {len(self._memory_cache)}\")\n                    \n                    logger.debug(f\"[SQLiteEventBuffer] add_event_async 成功完成 - agent_id: {self.agent_id}, sequence: {sequence}\")\n                    return sequence\n                    \n                except Exception as e:\n                    logger.error(f\"[SQLiteEventBuffer] 数据库操作异常，回滚事务 - agent_id: {self.agent_id}, 错误: {str(e)}\", exc_info=True)\n                    await session.rollback()\n                    raise\n                    \n        except Exception as e:\n            logger.error(f\"[SQLiteEventBuffer] add_event_async 失败 - agent_id: {self.agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    def _add_event_memory_only(self, event: AgentEvent) -> int:\n        \"\"\"仅内存模式添加事件（回退方案）\"\"\"\n        self._current_sequence += 1\n        \n        if len(self._memory_cache) >= self.max_size:\n            self._memory_cache.pop(0)\n        \n        self._memory_cache.append(event)\n        return self._current_sequence\n\n    async def _get_event_count(self, session: AsyncSession) -> int:\n        \"\"\"获取当前agent的事件数量\"\"\"\n        logger.debug(f\"[SQLiteEventBuffer] _get_event_count 开始 - agent_id: {self.agent_id}\")\n        \n        try:\n            stmt = select(func.count(BufferedEventORM.id)).where(\n                BufferedEventORM.agent_id == self.agent_id\n            )\n            logger.debug(f\"[SQLiteEventBuffer] 执行计数查询 - agent_id: {self.agent_id}\")\n            result = await session.execute(stmt)\n            count = result.scalar() or 0\n            logger.debug(f\"[SQLiteEventBuffer] _get_event_count 完成 - agent_id: {self.agent_id}, count: {count}\")\n            return count\n        except Exception as e:\n            logger.error(f\"[SQLiteEventBuffer] _get_event_count 异常 - agent_id: {self.agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    async def _remove_oldest_event(self, session: AsyncSession) -> None:\n        \"\"\"删除最老的事件\"\"\"\n        logger.debug(f\"[SQLiteEventBuffer] _remove_oldest_event 开始 - agent_id: {self.agent_id}\")\n        \n        try:\n            # 获取最小序号的事件\n            stmt = select(BufferedEventORM.sequence).where(\n                BufferedEventORM.agent_id == self.agent_id\n            ).order_by(BufferedEventORM.sequence.asc()).limit(1)\n            \n            logger.debug(f\"[SQLiteEventBuffer] 查询最老事件序号 - agent_id: {self.agent_id}\")\n            result = await session.execute(stmt)\n            oldest_sequence = result.scalar()\n            \n            if oldest_sequence is not None:\n                logger.debug(f\"[SQLiteEventBuffer] 找到最老事件序号: {oldest_sequence} - agent_id: {self.agent_id}\")\n                # 删除最老的事件\n                delete_stmt = delete(BufferedEventORM).where(\n                    BufferedEventORM.agent_id == self.agent_id,\n                    BufferedEventORM.sequence == oldest_sequence\n                )\n                result = await session.execute(delete_stmt)\n                deleted_count = result.rowcount\n                logger.debug(f\"[SQLiteEventBuffer] _remove_oldest_event 完成 - agent_id: {self.agent_id}, deleted_count: {deleted_count}\")\n            else:\n                logger.warning(f\"[SQLiteEventBuffer] 没有找到最老事件 - agent_id: {self.agent_id}\")\n                \n        except Exception as e:\n            logger.error(f\"[SQLiteEventBuffer] _remove_oldest_event 异常 - agent_id: {self.agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    # 同步接口（用于向后兼容）\n    def get_events_from_sequence(self, from_sequence: int) -> List[AgentEvent]:\n        \"\"\"获取指定序号之后的事件（同步版本，仅从内存缓存获取）\"\"\"\n        return self._get_events_from_sequence_memory(from_sequence)\n\n    async def get_events_from_sequence_async(self, from_sequence: int) -> List[AgentEvent]:\n        \"\"\"获取指定序号之后的事件（异步版本，从数据库获取）\"\"\"\n        if not self.engine:\n            # 如果没有数据库引擎，使用内存缓存\n            return self._get_events_from_sequence_memory(from_sequence)\n        \n        async with get_readonly_session(self.engine) as session:\n            # 从数据库获取事件\n            stmt = select(BufferedEventORM).where(\n                BufferedEventORM.agent_id == self.agent_id,\n                BufferedEventORM.sequence >= from_sequence\n            ).order_by(BufferedEventORM.sequence.asc())\n            \n            result = await session.execute(stmt)\n            buffered_events = result.scalars().all()\n            \n            # 转换为领域事件对象\n            events = []\n            for buffered_event_orm in buffered_events:\n                event = self._create_event_from_data(\n                    buffered_event_orm.event_type,\n                    buffered_event_orm.event_data\n                )\n                if event:\n                    events.append(event)\n            \n            return events\n\n    def _get_events_from_sequence_memory(self, from_sequence: int) -> List[AgentEvent]:\n        \"\"\"从内存缓存获取指定序号之后的事件（回退方案）\"\"\"\n        if from_sequence <= 0:\n            return self._memory_cache.copy()\n        \n        # 计算起始位置\n        start_index = max(0, from_sequence - (self._current_sequence - len(self._memory_cache) + 1))\n        return self._memory_cache[start_index:]\n\n    # 同步接口（用于向后兼容）\n    def has_done_event_as_last(self) -> bool:\n        \"\"\"检查最后一个事件是否是DoneEvent（同步版本，仅检查内存缓存）\"\"\"\n        if not self._memory_cache:\n            return False\n        return isinstance(self._memory_cache[-1], DoneEvent)\n\n    async def has_done_event_as_last_async(self) -> bool:\n        \"\"\"检查最后一个事件是否是DoneEvent（异步版本，检查数据库）\"\"\"\n        if not self.engine:\n            # 如果没有数据库引擎，检查内存缓存\n            if not self._memory_cache:\n                return False\n            return isinstance(self._memory_cache[-1], DoneEvent)\n        \n        async with get_readonly_session(self.engine) as session:\n            # 获取最新的事件\n            stmt = select(BufferedEventORM).where(\n                BufferedEventORM.agent_id == self.agent_id\n            ).order_by(BufferedEventORM.sequence.desc()).limit(1)\n            \n            result = await session.execute(stmt)\n            latest_event_orm = result.scalar_one_or_none()\n            \n            if not latest_event_orm:\n                return False\n            \n            # 检查是否是DoneEvent\n            return latest_event_orm.event_type == \"done\"\n\n    async def clear_async(self) -> None:\n        \"\"\"清空缓冲区（异步版本，清空数据库和内存缓存）\"\"\"\n        if not self.engine:\n            # 如果没有数据库引擎，只清空内存缓存\n            self._memory_cache.clear()\n            return\n        \n        async with get_session(self.engine) as session:\n            try:\n                # 删除数据库中的所有事件\n                stmt = delete(BufferedEventORM).where(\n                    BufferedEventORM.agent_id == self.agent_id\n                )\n                await session.execute(stmt)\n                await session.commit()\n                \n                # 清空内存缓存\n                self._memory_cache.clear()\n                \n                logger.debug(f\"Cleared buffer for agent {self.agent_id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to clear buffer for agent {self.agent_id}: {str(e)}\")\n                raise\n\n    def clear(self) -> None:\n        \"\"\"清空缓冲区（同步版本，仅清空内存缓存）\"\"\"\n        self._memory_cache.clear()\n        logger.debug(f\"Cleared memory cache for agent {self.agent_id}\")\n\n    @property\n    def current_sequence(self) -> int:\n        \"\"\"获取当前序号\"\"\"\n        return self._current_sequence\n\n    @property\n    def events(self) -> List[AgentEvent]:\n        \"\"\"获取内存缓存中的事件（用于兼容性）\"\"\"\n        return self._memory_cache.copy()\n\n    async def initialize(self) -> None:\n        \"\"\"初始化缓冲区，从数据库加载事件\"\"\"\n        logger.debug(f\"[SQLiteEventBuffer] initialize 开始 - agent_id: {self.agent_id}\")\n        \n        if self.engine:\n            logger.debug(f\"[SQLiteEventBuffer] 有数据库引擎，开始加载事件 - agent_id: {self.agent_id}\")\n            await self._load_events_from_db()\n            logger.debug(f\"[SQLiteEventBuffer] initialize 完成 - agent_id: {self.agent_id}, 内存缓存大小: {len(self._memory_cache)}\")\n        else:\n            logger.debug(f\"[SQLiteEventBuffer] 没有数据库引擎，跳过初始化 - agent_id: {self.agent_id}\")\n",
      "methods": [
        "<module>.SQLiteEventBuffer.__init__",
        "<module>.SQLiteEventBuffer._create_event_from_data",
        "<module>.SQLiteEventBuffer._load_events_from_db",
        "<module>.SQLiteEventBuffer.add_event",
        "<module>.SQLiteEventBuffer.add_event_async",
        "<module>.SQLiteEventBuffer._add_event_memory_only",
        "<module>.SQLiteEventBuffer._get_event_count",
        "<module>.SQLiteEventBuffer._remove_oldest_event",
        "<module>.SQLiteEventBuffer.get_events_from_sequence",
        "<module>.SQLiteEventBuffer.get_events_from_sequence_async",
        "<module>.SQLiteEventBuffer._get_events_from_sequence_memory",
        "<module>.SQLiteEventBuffer.has_done_event_as_last",
        "<module>.SQLiteEventBuffer.has_done_event_as_last_async",
        "<module>.SQLiteEventBuffer.clear_async",
        "<module>.SQLiteEventBuffer.clear",
        "<module>.SQLiteEventBuffer.current_sequence",
        "<module>.SQLiteEventBuffer.events",
        "<module>.SQLiteEventBuffer.initialize"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/sqlite_repository.py",
      "name": "SQLiteEventBroadcastRepository",
      "qualname": "<module>.SQLiteEventBroadcastRepository",
      "source": "class SQLiteEventBroadcastRepository(EventBroadcastRepository):\n    \"\"\"SQLite版本的事件广播仓储\"\"\"\n\n    def __init__(self, engine: AsyncEngine):\n        \"\"\"初始化事件广播仓储\n        \n        Args:\n            engine: 数据库引擎\n        \"\"\"\n        self.engine = engine\n\n    def _create_broadcaster(self, agent_id: str) -> AgentEventBroadcaster:\n        \"\"\"创建新的广播器，使用SQLite版本的事件缓冲\"\"\"\n        event_buffer = SQLiteEventBuffer(agent_id, engine=self.engine)\n        return AgentEventBroadcaster(\n            agent_id=agent_id,\n            event_buffer=event_buffer\n        )\n\n    async def _orm_to_domain_broadcaster(self, broadcaster_orm: EventBroadcasterORM) -> AgentEventBroadcaster:\n        \"\"\"将广播器ORM模型转换为领域模型\"\"\"\n        logger.debug(f\"[SQLiteEventBroadcastRepository] _orm_to_domain_broadcaster 开始 - agent_id: {broadcaster_orm.agent_id}\")\n        \n        try:\n            # 创建事件缓冲区\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 创建SQLiteEventBuffer - agent_id: {broadcaster_orm.agent_id}, max_size: {broadcaster_orm.max_buffer_size}\")\n            event_buffer = SQLiteEventBuffer(\n                agent_id=broadcaster_orm.agent_id,\n                max_size=broadcaster_orm.max_buffer_size,\n                engine=self.engine\n            )\n            event_buffer._current_sequence = broadcaster_orm.current_sequence\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 设置当前序号 - agent_id: {broadcaster_orm.agent_id}, current_sequence: {broadcaster_orm.current_sequence}\")\n            \n            # 初始化缓冲区（从数据库加载事件）\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 初始化事件缓冲区 - agent_id: {broadcaster_orm.agent_id}\")\n            await event_buffer.initialize()\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 事件缓冲区初始化完成 - agent_id: {broadcaster_orm.agent_id}\")\n            \n            broadcaster = AgentEventBroadcaster(\n                agent_id=broadcaster_orm.agent_id,\n                subscribers={},  # 订阅者不持久化，每次重启都是新的\n                event_buffer=event_buffer\n            )\n            \n            logger.debug(f\"[SQLiteEventBroadcastRepository] _orm_to_domain_broadcaster 完成 - agent_id: {broadcaster_orm.agent_id}\")\n            return broadcaster\n            \n        except Exception as e:\n            logger.error(f\"[SQLiteEventBroadcastRepository] _orm_to_domain_broadcaster 异常 - agent_id: {broadcaster_orm.agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    def _domain_to_orm_broadcaster(self, broadcaster: AgentEventBroadcaster) -> EventBroadcasterORM:\n        \"\"\"将广播器领域模型转换为ORM模型\"\"\"\n        return EventBroadcasterORM(\n            agent_id=broadcaster.agent_id,\n            current_sequence=broadcaster.event_buffer.current_sequence,\n            max_buffer_size=broadcaster.event_buffer.max_size,\n            updated_at=datetime.now()\n        )\n\n    async def save_broadcaster(self, broadcaster: AgentEventBroadcaster) -> None:\n        \"\"\"保存广播器。假定调用者已处理并发和锁定。\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 检查广播器是否已存在\n                stmt = select(EventBroadcasterORM).where(EventBroadcasterORM.agent_id == broadcaster.agent_id)\n                result = await session.execute(stmt)\n                existing_broadcaster_orm = result.scalar_one_or_none()\n                \n                if existing_broadcaster_orm:\n                    # 更新现有广播器\n                    existing_broadcaster_orm.current_sequence = broadcaster.event_buffer.current_sequence\n                    existing_broadcaster_orm.max_buffer_size = broadcaster.event_buffer.max_size\n                    existing_broadcaster_orm.updated_at = datetime.now()\n                    logger.debug(f\"保存广播器时发现已存在，执行更新: {broadcaster.agent_id}\")\n                else:\n                    # 创建新广播器\n                    broadcaster_orm = self._domain_to_orm_broadcaster(broadcaster)\n                    session.add(broadcaster_orm)\n                    logger.debug(f\"保存新的广播器: {broadcaster.agent_id}\")\n                \n                await session.commit()\n                \n            except IntegrityError as e:\n                await session.rollback()\n                logger.error(f\"保存广播器时发生IntegrityError: {broadcaster.agent_id}, 错误: {str(e)}\")\n                raise\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"保存广播器失败: {broadcaster.agent_id}, 错误: {str(e)}\")\n                raise\n\n    async def create_broadcaster_if_not_exists(self, agent_id: str) -> None:\n        \"\"\"\n        原子性地创建新的广播器数据库条目（如果尚不存在）。\n        使用 SQLite 的 INSERT ... ON CONFLICT DO NOTHING。\n        \"\"\"\n        logger.debug(f\"[SQLiteEventBroadcastRepository] create_broadcaster_if_not_exists 开始 - agent_id: {agent_id}\")\n        \n        broadcaster_orm_values = {\n            \"agent_id\": agent_id,\n            \"current_sequence\": 0,\n            \"max_buffer_size\": EventBuffer.DEFAULT_MAX_SIZE, \n            \"created_at\": datetime.now(),\n            \"updated_at\": datetime.now()\n        }\n        \n        logger.debug(f\"[SQLiteEventBroadcastRepository] 准备插入广播器数据 - agent_id: {agent_id}, values: {broadcaster_orm_values}\")\n        \n        # 构造 INSERT ... ON CONFLICT DO NOTHING 语句\n        stmt = sqlite_insert(EventBroadcasterORM).values(broadcaster_orm_values)\n        stmt = stmt.on_conflict_do_nothing(\n            index_elements=['agent_id']\n        )\n        \n        logger.debug(f\"[SQLiteEventBroadcastRepository] SQL语句已构造 - agent_id: {agent_id}\")\n\n        try:\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 创建数据库会话 - agent_id: {agent_id}\")\n            async with get_session(self.engine) as session:\n                logger.debug(f\"[SQLiteEventBroadcastRepository] 数据库会话已创建 - agent_id: {agent_id}\")\n                \n                try:\n                    logger.debug(f\"[SQLiteEventBroadcastRepository] 执行INSERT ... ON CONFLICT DO NOTHING - agent_id: {agent_id}\")\n                    result = await session.execute(stmt)\n                    logger.debug(f\"[SQLiteEventBroadcastRepository] INSERT执行完成 - agent_id: {agent_id}, rowcount: {result.rowcount}\")\n                    \n                    logger.debug(f\"[SQLiteEventBroadcastRepository] 提交事务 - agent_id: {agent_id}\")\n                    await session.commit()\n                    logger.debug(f\"[SQLiteEventBroadcastRepository] 事务已提交 - agent_id: {agent_id}\")\n                    \n                    # 验证插入结果\n                    logger.debug(f\"[SQLiteEventBroadcastRepository] 验证插入结果 - agent_id: {agent_id}\")\n                    verify_stmt = select(EventBroadcasterORM).where(EventBroadcasterORM.agent_id == agent_id)\n                    verify_result = await session.execute(verify_stmt)\n                    verify_broadcaster = verify_result.scalar_one_or_none()\n                    \n                    if verify_broadcaster:\n                        logger.debug(f\"[SQLiteEventBroadcastRepository] 验证成功：广播器已存在 - agent_id: {agent_id}, current_sequence: {verify_broadcaster.current_sequence}\")\n                    else:\n                        logger.error(f\"[SQLiteEventBroadcastRepository] 验证失败：广播器不存在 - agent_id: {agent_id}\")\n                    \n                    logger.debug(f\"[SQLiteEventBroadcastRepository] create_broadcaster_if_not_exists 成功完成 - agent_id: {agent_id}\")\n                    \n                except Exception as e:\n                    logger.error(f\"[SQLiteEventBroadcastRepository] 数据库操作异常，回滚事务 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n                    await session.rollback()\n                    raise\n                    \n        except Exception as e:\n            logger.error(f\"[SQLiteEventBroadcastRepository] create_broadcaster_if_not_exists 失败 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    async def get_broadcaster(self, agent_id: str) -> Optional[AgentEventBroadcaster]:\n        \"\"\"获取广播器\"\"\"\n        logger.debug(f\"[SQLiteEventBroadcastRepository] get_broadcaster 开始 - agent_id: {agent_id}\")\n        \n        # 先获取ORM对象\n        broadcaster_orm = None\n        try:\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 创建数据库会话 - agent_id: {agent_id}\")\n            async with get_readonly_session(self.engine) as session:\n                logger.debug(f\"[SQLiteEventBroadcastRepository] 数据库会话已创建，查询广播器 - agent_id: {agent_id}\")\n                stmt = select(EventBroadcasterORM).where(EventBroadcasterORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                broadcaster_orm = result.scalar_one_or_none()\n                \n                if broadcaster_orm:\n                    logger.debug(f\"[SQLiteEventBroadcastRepository] 找到广播器ORM - agent_id: {agent_id}, current_sequence: {broadcaster_orm.current_sequence}\")\n                else:\n                    logger.debug(f\"[SQLiteEventBroadcastRepository] 未找到广播器ORM - agent_id: {agent_id}\")\n                    \n        except Exception as e:\n            logger.error(f\"[SQLiteEventBroadcastRepository] 查询广播器ORM异常 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n            \n        # 在session外部进行转换，避免嵌套session问题\n        if broadcaster_orm:\n            logger.debug(f\"[SQLiteEventBroadcastRepository] 开始转换ORM到领域模型 - agent_id: {agent_id}\")\n            try:\n                broadcaster = await self._orm_to_domain_broadcaster(broadcaster_orm)\n                logger.debug(f\"[SQLiteEventBroadcastRepository] get_broadcaster 成功完成 - agent_id: {agent_id}\")\n                return broadcaster\n            except Exception as e:\n                logger.error(f\"[SQLiteEventBroadcastRepository] 转换ORM到领域模型异常 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n                raise\n        else:\n            logger.debug(f\"[SQLiteEventBroadcastRepository] get_broadcaster 返回None - agent_id: {agent_id}\")\n            return None\n\n    async def update_broadcaster(self, broadcaster: AgentEventBroadcaster) -> bool:\n        \"\"\"更新广播器\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = select(EventBroadcasterORM).where(EventBroadcasterORM.agent_id == broadcaster.agent_id)\n                result = await session.execute(stmt)\n                existing_broadcaster = result.scalar_one_or_none()\n                \n                if not existing_broadcaster:\n                    return False\n                \n                # 更新广播器信息\n                existing_broadcaster.current_sequence = broadcaster.event_buffer.current_sequence\n                existing_broadcaster.max_buffer_size = broadcaster.event_buffer.max_size\n                existing_broadcaster.updated_at = datetime.now()\n                \n                await session.commit()\n                logger.debug(f\"更新广播器: {broadcaster.agent_id}\")\n                return True\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"更新广播器失败: {broadcaster.agent_id}, 错误: {str(e)}\")\n                raise\n\n    async def delete_broadcaster(self, agent_id: str) -> bool:\n        \"\"\"删除广播器\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 先删除缓冲事件（由于外键约束，会自动级联删除）\n                stmt_delete_events = delete(BufferedEventORM).where(BufferedEventORM.agent_id == agent_id)\n                await session.execute(stmt_delete_events)\n                \n                # 再删除广播器\n                stmt_delete_broadcaster = delete(EventBroadcasterORM).where(EventBroadcasterORM.agent_id == agent_id)\n                result = await session.execute(stmt_delete_broadcaster)\n                \n                await session.commit()\n                \n                deleted_count = result.rowcount\n                if deleted_count > 0:\n                    logger.debug(f\"删除广播器: {agent_id}\")\n                    return True\n                return False\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"删除广播器失败: {agent_id}, 错误: {str(e)}\")\n                raise\n",
      "methods": [
        "<module>.SQLiteEventBroadcastRepository.__init__",
        "<module>.SQLiteEventBroadcastRepository._create_broadcaster",
        "<module>.SQLiteEventBroadcastRepository._orm_to_domain_broadcaster",
        "<module>.SQLiteEventBroadcastRepository._domain_to_orm_broadcaster",
        "<module>.SQLiteEventBroadcastRepository.save_broadcaster",
        "<module>.SQLiteEventBroadcastRepository.create_broadcaster_if_not_exists",
        "<module>.SQLiteEventBroadcastRepository.get_broadcaster",
        "<module>.SQLiteEventBroadcastRepository.update_broadcaster",
        "<module>.SQLiteEventBroadcastRepository.delete_broadcaster"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/sqlite_repository.py",
      "name": "SQLiteEventStreamRepository",
      "qualname": "<module>.SQLiteEventStreamRepository",
      "source": "class SQLiteEventStreamRepository(EventStreamRepository):\n    \"\"\"SQLite版本的事件流仓储 - 数据库持久化订阅者\"\"\"\n\n    def __init__(self, broadcast_repository: SQLiteEventBroadcastRepository):\n        self.broadcast_repository = broadcast_repository\n        self.engine = broadcast_repository.engine\n        logger.debug(\"SQLiteEventStreamRepository initialized with database-persisted subscribers\")\n\n    async def get_events_from_sequence(self, agent_id: str, from_sequence: int = 1) -> AsyncGenerator[AgentEvent, None]:\n        \"\"\"从指定序号开始获取事件流（包含历史事件和实时事件）\"\"\"\n        logger.debug(f\"Starting event stream for agent {agent_id} from sequence {from_sequence}\")\n        \n        # 1. 首先检查是否有广播器，如果有的话检查是否已经有DoneEvent作为最后一个事件\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if broadcaster and await broadcaster.event_buffer.has_done_event_as_last_async():\n            # 如果最后一个事件是DoneEvent，只获取历史事件然后结束\n            logger.debug(f\"Agent {agent_id} already has DoneEvent as last event, returning only buffered events\")\n            buffered_events = await self.get_buffered_events(agent_id, from_sequence)\n            for event in buffered_events:\n                yield event\n            return\n        \n        # 2. 获取缓冲区中的历史事件\n        buffered_events = await self.get_buffered_events(agent_id, from_sequence)\n        current_sequence = from_sequence\n        for event in buffered_events:\n            yield event\n            current_sequence += 1\n        \n        # 3. 创建订阅者并注册到数据库\n        subscriber = EventSubscriber.create(agent_id)\n        await self._register_subscriber_db(agent_id, subscriber)\n        \n        try:\n            # 4. 轮询获取新事件（基于数据库的实时事件流）\n            last_check_sequence = current_sequence - 1\n            consecutive_empty_checks = 0\n            max_consecutive_empty_checks = 10  # 最多连续10次空检查后增加轮询间隔\n            \n            while True:\n                try:\n                    # 更新订阅者活动时间\n                    await self._update_subscriber_activity(subscriber.subscriber_id)\n                    \n                    # 从数据库获取新事件\n                    new_events = await self.get_buffered_events(agent_id, last_check_sequence + 1)\n                    \n                    if new_events:\n                        consecutive_empty_checks = 0\n                        for event in new_events:\n                            yield event\n                            last_check_sequence += 1\n                            \n                            # 检查是否是DoneEvent，如果是则结束事件流\n                            if isinstance(event, DoneEvent):\n                                logger.debug(f\"Received DoneEvent for agent {agent_id}, terminating event stream\")\n                                return\n                    else:\n                        consecutive_empty_checks += 1\n                    \n                    # 动态调整轮询间隔：如果连续多次没有新事件，增加轮询间隔\n                    if consecutive_empty_checks < max_consecutive_empty_checks:\n                        poll_interval = 1.0  # 1秒\n                    else:\n                        poll_interval = 5.0  # 5秒\n                    \n                    # 等待一段时间再次检查\n                    await asyncio.sleep(poll_interval)\n                    \n                except asyncio.CancelledError:\n                    logger.debug(f\"Event stream for agent {agent_id} was cancelled\")\n                    raise\n                except Exception as e:\n                    logger.error(f\"Error polling events for agent {agent_id}: {str(e)}\")\n                    # 发生错误时等待一段时间再重试\n                    await asyncio.sleep(2.0)\n                    \n        except asyncio.CancelledError:\n            logger.debug(f\"Event stream for agent {agent_id} was cancelled\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error in event stream for agent {agent_id}: {str(e)}\")\n            raise\n        finally:\n            # 5. 清理：注销订阅者\n            await self._unregister_subscriber_db(subscriber.subscriber_id)\n\n    async def _register_subscriber_db(self, agent_id: str, subscriber: EventSubscriber) -> None:\n        \"\"\"在数据库中注册订阅者\"\"\"\n        logger.debug(f\"[SQLiteEventStreamRepository] _register_subscriber_db 开始 - agent_id: {agent_id}, subscriber_id: {subscriber.subscriber_id}\")\n        \n        try:\n            async with get_session(self.engine) as session:\n                logger.debug(f\"[SQLiteEventStreamRepository] 数据库会话已创建 - subscriber_id: {subscriber.subscriber_id}\")\n                \n                try:\n                    subscriber_orm = EventSubscriberORM(\n                        subscriber_id=subscriber.subscriber_id,\n                        agent_id=agent_id,\n                        created_at=subscriber.created_at,\n                        last_activity=subscriber.last_activity,\n                        is_active=\"true\",\n                        heartbeat_timeout_seconds=300\n                    )\n                    session.add(subscriber_orm)\n                    logger.debug(f\"[SQLiteEventStreamRepository] EventSubscriberORM已添加到会话 - subscriber_id: {subscriber.subscriber_id}\")\n                    \n                    await session.commit()\n                    logger.debug(f\"[SQLiteEventStreamRepository] _register_subscriber_db 成功完成 - subscriber_id: {subscriber.subscriber_id}\")\n                    \n                except Exception as e:\n                    logger.error(f\"[SQLiteEventStreamRepository] 数据库操作异常，回滚事务 - subscriber_id: {subscriber.subscriber_id}, 错误: {str(e)}\", exc_info=True)\n                    await session.rollback()\n                    raise\n                    \n        except Exception as e:\n            logger.error(f\"[SQLiteEventStreamRepository] _register_subscriber_db 失败 - subscriber_id: {subscriber.subscriber_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    async def _unregister_subscriber_db(self, subscriber_id: str) -> None:\n        \"\"\"从数据库中注销订阅者\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = delete(EventSubscriberORM).where(EventSubscriberORM.subscriber_id == subscriber_id)\n                await session.execute(stmt)\n                await session.commit()\n                logger.debug(f\"Unregistered subscriber {subscriber_id} from database\")\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to unregister subscriber {subscriber_id}: {str(e)}\")\n                raise\n\n    async def _update_subscriber_activity(self, subscriber_id: str) -> None:\n        \"\"\"更新订阅者活动时间\"\"\"\n        logger.debug(f\"[SQLiteEventStreamRepository] _update_subscriber_activity 开始 - subscriber_id: {subscriber_id}\")\n        \n        try:\n            async with get_session(self.engine) as session:\n                logger.debug(f\"[SQLiteEventStreamRepository] 数据库会话已创建 - subscriber_id: {subscriber_id}\")\n                \n                try:\n                    stmt = select(EventSubscriberORM).where(EventSubscriberORM.subscriber_id == subscriber_id)\n                    result = await session.execute(stmt)\n                    subscriber_orm = result.scalar_one_or_none()\n                    \n                    if subscriber_orm:\n                        old_activity = subscriber_orm.last_activity\n                        subscriber_orm.last_activity = datetime.now()\n                        logger.debug(f\"[SQLiteEventStreamRepository] 更新活动时间 - subscriber_id: {subscriber_id}, old: {old_activity}, new: {subscriber_orm.last_activity}\")\n                        await session.commit()\n                        logger.debug(f\"[SQLiteEventStreamRepository] _update_subscriber_activity 成功完成 - subscriber_id: {subscriber_id}\")\n                    else:\n                        logger.warning(f\"[SQLiteEventStreamRepository] 订阅者不存在 - subscriber_id: {subscriber_id}\")\n                        \n                except Exception as e:\n                    logger.error(f\"[SQLiteEventStreamRepository] 数据库操作异常，回滚事务 - subscriber_id: {subscriber_id}, 错误: {str(e)}\", exc_info=True)\n                    await session.rollback()\n                    raise\n                    \n        except Exception as e:\n            logger.error(f\"[SQLiteEventStreamRepository] _update_subscriber_activity 失败 - subscriber_id: {subscriber_id}, 错误: {str(e)}\", exc_info=True)\n\n    async def get_buffered_events(self, agent_id: str, from_sequence: int = 1) -> List[AgentEvent]:\n        \"\"\"获取缓冲区中的事件\"\"\"\n        broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n        if not broadcaster:\n            return []\n        \n        return await broadcaster.event_buffer.get_events_from_sequence_async(from_sequence)\n\n    async def notify_new_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"通知数据库中的活跃订阅者新事件（基于轮询的实现）\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 清理过期的订阅者\n                current_time = datetime.now()\n                \n                # 获取该agent的所有活跃订阅者\n                stmt = select(EventSubscriberORM).where(\n                    EventSubscriberORM.agent_id == agent_id,\n                    EventSubscriberORM.is_active == \"true\"\n                )\n                result = await session.execute(stmt)\n                active_subscribers = result.scalars().all()\n                \n                # 检查并清理过期的订阅者\n                inactive_subscriber_ids = []\n                \n                for subscriber_orm in active_subscribers:\n                    # 检查是否超时（默认5分钟）\n                    timeout_delta = timedelta(seconds=subscriber_orm.heartbeat_timeout_seconds)\n                    if current_time - subscriber_orm.last_activity > timeout_delta:\n                        inactive_subscriber_ids.append(subscriber_orm.subscriber_id)\n                        subscriber_orm.is_active = \"false\"\n                        logger.debug(f\"Marking subscriber {subscriber_orm.subscriber_id} as inactive due to timeout\")\n                \n                # 提交不活跃状态更新\n                if inactive_subscriber_ids:\n                    await session.commit()\n                \n                # 记录活跃订阅者数量（在轮询模式下，订阅者会自己获取新事件）\n                active_count = len([s for s in active_subscribers if s.subscriber_id not in inactive_subscriber_ids])\n                logger.debug(f\"Event {event.type} available for {active_count} active subscribers of agent {agent_id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to process event notification for agent {agent_id}: {str(e)}\")\n                raise\n\n    async def cleanup_agent_stream(self, agent_id: str) -> None:\n        \"\"\"清理agent的事件流\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 删除该agent的所有订阅者\n                stmt = delete(EventSubscriberORM).where(EventSubscriberORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                await session.commit()\n                \n                deleted_count = result.rowcount\n                logger.debug(f\"Cleaned up {deleted_count} subscribers for agent {agent_id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to cleanup agent stream for {agent_id}: {str(e)}\")\n                raise\n\n    async def get_active_subscribers(self, agent_id: str) -> List[EventSubscriber]:\n        \"\"\"获取指定agent的活跃订阅者\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(EventSubscriberORM).where(\n                EventSubscriberORM.agent_id == agent_id,\n                EventSubscriberORM.is_active == \"true\"\n            )\n            result = await session.execute(stmt)\n            subscriber_orms = result.scalars().all()\n            \n            # 转换为领域模型\n            subscribers = []\n            for subscriber_orm in subscriber_orms:\n                # 注意：这里创建的EventSubscriber没有event_queue，因为队列不能持久化\n                # 实际使用时需要重新创建队列或使用其他机制\n                subscriber = EventSubscriber(\n                    subscriber_id=subscriber_orm.subscriber_id,\n                    agent_id=subscriber_orm.agent_id,\n                    event_queue=asyncio.Queue(maxsize=100),  # 重新创建队列\n                    created_at=subscriber_orm.created_at,\n                    last_activity=subscriber_orm.last_activity,\n                    is_active=subscriber_orm.is_active == \"true\"\n                )\n                subscribers.append(subscriber)\n            \n            return subscribers\n\n    async def cleanup_expired_subscribers(self) -> None:\n        \"\"\"清理过期的订阅者\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                current_time = datetime.now()\n                \n                # 查找所有活跃但可能过期的订阅者\n                stmt = select(EventSubscriberORM).where(EventSubscriberORM.is_active == \"true\")\n                result = await session.execute(stmt)\n                active_subscribers = result.scalars().all()\n                \n                expired_count = 0\n                for subscriber_orm in active_subscribers:\n                    timeout_delta = timedelta(seconds=subscriber_orm.heartbeat_timeout_seconds)\n                    if current_time - subscriber_orm.last_activity > timeout_delta:\n                        subscriber_orm.is_active = \"false\"\n                        expired_count += 1\n                \n                if expired_count > 0:\n                    await session.commit()\n                    logger.debug(f\"Marked {expired_count} subscribers as expired\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to cleanup expired subscribers: {str(e)}\")\n                raise\n",
      "methods": [
        "<module>.SQLiteEventStreamRepository.__init__",
        "<module>.SQLiteEventStreamRepository.get_events_from_sequence",
        "<module>.SQLiteEventStreamRepository._register_subscriber_db",
        "<module>.SQLiteEventStreamRepository._unregister_subscriber_db",
        "<module>.SQLiteEventStreamRepository._update_subscriber_activity",
        "<module>.SQLiteEventStreamRepository.get_buffered_events",
        "<module>.SQLiteEventStreamRepository.notify_new_event",
        "<module>.SQLiteEventStreamRepository.cleanup_agent_stream",
        "<module>.SQLiteEventStreamRepository.get_active_subscribers",
        "<module>.SQLiteEventStreamRepository.cleanup_expired_subscribers"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/event_subscription/sqlite_repository.py",
      "name": "SQLiteEventSubscriptionManager",
      "qualname": "<module>.SQLiteEventSubscriptionManager",
      "source": "class SQLiteEventSubscriptionManager:\n    \"\"\"SQLite版本的事件订阅管理器 - 数据库持久化订阅者\"\"\"\n\n    def __init__(self, engine: AsyncEngine):\n        \"\"\"初始化事件订阅管理器\n        \n        Args:\n            engine: 数据库引擎\n        \"\"\"\n        self.broadcast_repository = SQLiteEventBroadcastRepository(engine)\n        self.stream_repository = SQLiteEventStreamRepository(self.broadcast_repository)\n        self._agent_locks = collections.defaultdict(asyncio.Lock) # 恢复锁\n        self.engine = engine\n        logger.debug(\"SQLiteEventSubscriptionManager initialized with database-persisted subscribers\")\n\n    async def notify_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"通知新事件 - 通过流仓储的数据库机制分发，并确保操作的原子性。\"\"\"\n        logger.debug(f\"[SQLiteEventSubscriptionManager] notify_event 开始 - agent_id: {agent_id}, event_type: {event.type}\")\n        \n        try:\n            logger.debug(f\"[SQLiteEventSubscriptionManager] 尝试获取agent锁 - agent_id: {agent_id}\")\n            async with self._agent_locks[agent_id]:\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 成功获得agent锁 - agent_id: {agent_id}\")\n                \n                # 1. 获取或创建广播器 (在锁的保护下)\n                #    这一步会确保 broadcaster 对象是最新的，并且数据库条目存在。\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤1：开始获取或创建广播器 - agent_id: {agent_id}\")\n                try:\n                    broadcaster = await self.get_or_create_broadcaster_nolock_internal(agent_id)\n                    logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤1成功：广播器已获取 - agent_id: {agent_id}, current_sequence: {broadcaster.event_buffer.current_sequence}\")\n                except Exception as e:\n                    logger.error(f\"[SQLiteEventSubscriptionManager] 步骤1失败：获取或创建广播器异常 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n                    raise\n                \n                # 2. 添加事件到缓冲区（序号由缓冲区内部管理，使用异步版本进行数据库持久化）\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤2：开始添加事件到缓冲区 - agent_id: {agent_id}, event_type: {event.type}\")\n                try:\n                    sequence = await broadcaster.event_buffer.add_event_async(event)\n                    logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤2成功：事件已添加到缓冲区 - agent_id: {agent_id}, sequence: {sequence}\")\n                except Exception as e:\n                    logger.error(f\"[SQLiteEventSubscriptionManager] 步骤2失败：添加事件到缓冲区异常 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n                    raise\n                \n                # 3. 更新广播器到数据库\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤3：开始更新广播器到数据库 - agent_id: {agent_id}\")\n                try:\n                    await self.broadcast_repository.update_broadcaster(broadcaster)\n                    logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤3成功：广播器已更新到数据库 - agent_id: {agent_id}\")\n                except Exception as e:\n                    logger.error(f\"[SQLiteEventSubscriptionManager] 步骤3失败：更新广播器到数据库异常 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n                    raise\n                \n                # 4. 通知数据库中的订阅者 (由 stream_repository 处理)\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤4：开始通知订阅者 - agent_id: {agent_id}\")\n                try:\n                    await self.stream_repository.notify_new_event(agent_id, event)\n                    logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤4成功：订阅者已通知 - agent_id: {agent_id}\")\n                except Exception as e:\n                    logger.error(f\"[SQLiteEventSubscriptionManager] 步骤4失败：通知订阅者异常 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n                    raise\n                \n                logger.debug(f\"[SQLiteEventSubscriptionManager] notify_event 成功完成 - agent_id: {agent_id}, sequence: {sequence}\")\n                \n        except Exception as e:\n            logger.error(f\"[SQLiteEventSubscriptionManager] notify_event 失败 - agent_id: {agent_id}, event_type: {event.type}, 错误: {str(e)}\", exc_info=True)\n            raise\n\n    async def cleanup_agent(self, agent_id: str) -> None:\n        \"\"\"清理agent相关的所有订阅资源\"\"\"\n        # 清理流（包括所有订阅者）\n        await self.stream_repository.cleanup_agent_stream(agent_id)\n        \n        # 清理广播器（包括数据库中的历史数据）\n        await self.broadcast_repository.delete_broadcaster(agent_id)\n    \n    # 以下方法用于测试和调试\n    async def get_or_create_broadcaster(self, agent_id: str) -> AgentEventBroadcaster:\n        \"\"\"获取或创建广播器 - 使用原子化的数据库操作和应用层锁。\"\"\"\n        async with self._agent_locks[agent_id]: # 恢复锁的使用\n            return await self.get_or_create_broadcaster_nolock_internal(agent_id)\n\n    async def get_or_create_broadcaster_nolock_internal(self, agent_id: str) -> AgentEventBroadcaster:\n        \"\"\"获取或创建广播器的内部无锁版本，假定调用者已获取锁。\"\"\"\n        logger.debug(f\"[SQLiteEventSubscriptionManager] get_or_create_broadcaster_nolock_internal 开始 - agent_id: {agent_id}\")\n        \n        # 1. 首先尝试获取，这通常会成功，除非是首次为 agent_id 创建\n        logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤1：尝试获取现有广播器 - agent_id: {agent_id}\")\n        try:\n            broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n            if broadcaster:\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤1成功：找到现有广播器 - agent_id: {agent_id}, current_sequence: {broadcaster.event_buffer.current_sequence}\")\n                return broadcaster\n            else:\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤1结果：未找到现有广播器 - agent_id: {agent_id}\")\n        except Exception as e:\n            logger.error(f\"[SQLiteEventSubscriptionManager] 步骤1异常：获取现有广播器失败 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n            # 继续执行创建流程\n        \n        logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤2：需要创建新广播器 - agent_id: {agent_id}\")\n        \n        # 2. 如果获取不到，调用原子化的创建方法来确保数据库记录存在\n        logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤2.1：调用create_broadcaster_if_not_exists - agent_id: {agent_id}\")\n        try:\n            await self.broadcast_repository.create_broadcaster_if_not_exists(agent_id)\n            logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤2.1成功：create_broadcaster_if_not_exists 完成 - agent_id: {agent_id}\")\n        except Exception as e:\n            logger.error(f\"[SQLiteEventSubscriptionManager] 步骤2.1异常：create_broadcaster_if_not_exists 失败 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n        \n        # 3. 再次获取广播器\n        logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤3：再次尝试获取广播器 - agent_id: {agent_id}\")\n        try:\n            broadcaster = await self.broadcast_repository.get_broadcaster(agent_id)\n            if not broadcaster:\n                logger.error(f\"[SQLiteEventSubscriptionManager] 步骤3失败：创建并尝试获取广播器后仍然失败 - agent_id: {agent_id}\")\n                \n                # 额外的调试信息：检查数据库状态\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 调试：检查数据库中的广播器记录 - agent_id: {agent_id}\")\n                try:\n                    async with get_readonly_session(self.engine) as session:\n                        debug_stmt = select(EventBroadcasterORM).where(EventBroadcasterORM.agent_id == agent_id)\n                        debug_result = await session.execute(debug_stmt)\n                        debug_broadcaster = debug_result.scalar_one_or_none()\n                        \n                        if debug_broadcaster:\n                            logger.debug(f\"[SQLiteEventSubscriptionManager] 调试：数据库中存在广播器记录 - agent_id: {agent_id}, current_sequence: {debug_broadcaster.current_sequence}\")\n                        else:\n                            logger.error(f\"[SQLiteEventSubscriptionManager] 调试：数据库中不存在广播器记录 - agent_id: {agent_id}\")\n                except Exception as debug_e:\n                    logger.error(f\"[SQLiteEventSubscriptionManager] 调试查询失败 - agent_id: {agent_id}, 错误: {str(debug_e)}\", exc_info=True)\n                \n                raise RuntimeError(f\"Failed to get broadcaster for {agent_id} after ensuring it exists in DB.\")\n            else:\n                logger.debug(f\"[SQLiteEventSubscriptionManager] 步骤3成功：获取到广播器 - agent_id: {agent_id}, current_sequence: {broadcaster.event_buffer.current_sequence}\")\n        except RuntimeError:\n            raise\n        except Exception as e:\n            logger.error(f\"[SQLiteEventSubscriptionManager] 步骤3异常：再次获取广播器失败 - agent_id: {agent_id}, 错误: {str(e)}\", exc_info=True)\n            raise\n        \n        logger.debug(f\"[SQLiteEventSubscriptionManager] get_or_create_broadcaster_nolock_internal 成功完成 - agent_id: {agent_id}, current_sequence: {broadcaster.event_buffer.current_sequence}\")\n        return broadcaster\n    \n    async def broadcast_event(self, agent_id: str, event: AgentEvent) -> None:\n        \"\"\"广播事件\"\"\"\n        await self.notify_event(agent_id, event)\n    \n    async def get_buffered_events(self, agent_id: str, from_sequence: int = 1) -> List[AgentEvent]:\n        \"\"\"获取缓冲事件\"\"\"\n        return await self.stream_repository.get_buffered_events(agent_id, from_sequence)\n    \n    async def create_subscription(self, subscription: EventSubscriber) -> None:\n        \"\"\"创建订阅\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                subscriber_orm = EventSubscriberORM(\n                    subscriber_id=subscription.subscriber_id,\n                    agent_id=subscription.agent_id,\n                    created_at=subscription.created_at,\n                    last_activity=subscription.last_activity,\n                    is_active=\"true\" if subscription.is_active else \"false\",\n                    heartbeat_timeout_seconds=300\n                )\n                session.add(subscriber_orm)\n                await session.commit()\n                logger.debug(f\"Created subscription {subscription.subscriber_id} for agent {subscription.agent_id}\")\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to create subscription {subscription.subscriber_id}: {str(e)}\")\n                raise\n    \n    async def get_subscription(self, subscription_id: str) -> Optional[EventSubscriber]:\n        \"\"\"获取订阅\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(EventSubscriberORM).where(EventSubscriberORM.subscriber_id == subscription_id)\n            result = await session.execute(stmt)\n            subscriber_orm = result.scalar_one_or_none()\n            \n            if subscriber_orm:\n                return EventSubscriber(\n                    subscriber_id=subscriber_orm.subscriber_id,\n                    agent_id=subscriber_orm.agent_id,\n                    event_queue=asyncio.Queue(maxsize=100),  # 重新创建队列\n                    created_at=subscriber_orm.created_at,\n                    last_activity=subscriber_orm.last_activity,\n                    is_active=subscriber_orm.is_active == \"true\"\n                )\n            return None\n    \n    async def update_subscription_heartbeat(self, subscription_id: str, heartbeat: datetime) -> None:\n        \"\"\"更新订阅心跳\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = select(EventSubscriberORM).where(EventSubscriberORM.subscriber_id == subscription_id)\n                result = await session.execute(stmt)\n                subscriber_orm = result.scalar_one_or_none()\n                \n                if subscriber_orm:\n                    subscriber_orm.last_activity = heartbeat\n                    await session.commit()\n                    logger.debug(f\"Updated heartbeat for subscription {subscription_id}\")\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to update heartbeat for subscription {subscription_id}: {str(e)}\")\n                raise\n    \n    async def delete_subscription(self, subscription_id: str) -> None:\n        \"\"\"删除订阅\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = delete(EventSubscriberORM).where(EventSubscriberORM.subscriber_id == subscription_id)\n                result = await session.execute(stmt)\n                await session.commit()\n                \n                if result.rowcount > 0:\n                    logger.debug(f\"Deleted subscription {subscription_id}\")\n                else:\n                    logger.warning(f\"Subscription {subscription_id} not found for deletion\")\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Failed to delete subscription {subscription_id}: {str(e)}\")\n                raise\n    \n    async def get_active_subscriptions(self, agent_id: str) -> List[EventSubscriber]:\n        \"\"\"获取活跃订阅\"\"\"\n        return await self.stream_repository.get_active_subscribers(agent_id)\n    \n    async def cleanup_expired_subscriptions(self) -> None:\n        \"\"\"清理过期订阅\"\"\"\n        await self.stream_repository.cleanup_expired_subscribers()\n    \n    async def get_subscription_count(self, agent_id: str) -> int:\n        \"\"\"获取订阅数量\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(func.count(EventSubscriberORM.subscriber_id)).where(\n                EventSubscriberORM.agent_id == agent_id,\n                EventSubscriberORM.is_active == \"true\"\n            )\n            result = await session.execute(stmt)\n            return result.scalar() or 0\n    \n    async def _update_broadcaster_buffer_size(self, agent_id: str, buffer_size: int) -> None:\n        \"\"\"更新广播器缓冲区大小（测试辅助方法）\"\"\"\n        broadcaster = await self.get_or_create_broadcaster(agent_id)\n        broadcaster.event_buffer.max_size = buffer_size\n        await self.broadcast_repository.update_broadcaster(broadcaster) ",
      "methods": [
        "<module>.SQLiteEventSubscriptionManager.__init__",
        "<module>.SQLiteEventSubscriptionManager.notify_event",
        "<module>.SQLiteEventSubscriptionManager.cleanup_agent",
        "<module>.SQLiteEventSubscriptionManager.get_or_create_broadcaster",
        "<module>.SQLiteEventSubscriptionManager.get_or_create_broadcaster_nolock_internal",
        "<module>.SQLiteEventSubscriptionManager.broadcast_event",
        "<module>.SQLiteEventSubscriptionManager.get_buffered_events",
        "<module>.SQLiteEventSubscriptionManager.create_subscription",
        "<module>.SQLiteEventSubscriptionManager.get_subscription",
        "<module>.SQLiteEventSubscriptionManager.update_subscription_heartbeat",
        "<module>.SQLiteEventSubscriptionManager.delete_subscription",
        "<module>.SQLiteEventSubscriptionManager.get_active_subscriptions",
        "<module>.SQLiteEventSubscriptionManager.cleanup_expired_subscriptions",
        "<module>.SQLiteEventSubscriptionManager.get_subscription_count",
        "<module>.SQLiteEventSubscriptionManager._update_broadcaster_buffer_size"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/search/searxng_search.py",
      "name": "SearXNGSearchEngine",
      "qualname": "<module>.SearXNGSearchEngine",
      "source": "class SearXNGSearchEngine(SearchEngineInterface):\n    \"\"\"SearXNG API based search engine implementation\"\"\"\n    \n    def __init__(self, base_url: str):\n        \"\"\"Initialize SearXNG search engine\n        \n        Args:\n            base_url: SearXNG instance URL (e.g., \"https://searx.example.org\")\n        \"\"\"\n        self.base_url = base_url\n        self.search_endpoint = f\"{self.base_url}/search\"\n        # google,google scholar,arxiv,wikipedia\n        self.engines = [\"google\", \"google scholar\", \"arxiv\", \"wikipedia\"]\n        \n    async def search(\n        self, \n        query: str, \n        date_range: Optional[str] = None\n    ) -> ToolResult:\n        \"\"\"Search web pages using SearXNG\n        \n        Args:\n            query: Search query\n            date_range: (Optional) Time range filter for search results\n            \n        Returns:\n            Search results\n        \"\"\"\n        params = {\n            \"q\": query,\n            \"format\": \"json\",\n            \"engines\": \",\".join(self.engines)\n        }\n        \n        # Add time range filter if specified\n        if date_range and date_range != \"all\":\n            # Convert date_range to the format used by SearXNG\n            date_mapping = {\n                \"past_hour\": \"hour\",\n                \"past_day\": \"day\", \n                \"past_week\": \"week\",\n                \"past_month\": \"month\",\n                \"past_year\": \"year\"\n            }\n            if date_range in date_mapping:\n                params[\"time_range\"] = date_mapping[date_range]\n        \n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(self.search_endpoint, params=params)\n                response.raise_for_status()\n                data = response.json()\n                \n                # Process search results\n                search_results = []\n                if \"results\" in data:\n                    for item in data[\"results\"]:\n                        search_results.append({\n                            \"title\": item.get(\"title\", \"\"),\n                            \"link\": item.get(\"url\", \"\"),\n                            \"snippet\": item.get(\"content\", \"\"),\n                        })\n                \n                # Build return result\n                results = {\n                    \"query\": query,\n                    \"date_range\": date_range,\n                    \"search_info\": {\n                        \"time\": data.get(\"search_time\", 0),\n                        \"engines\": data.get(\"engines\", [])\n                    },\n                    \"results\": search_results,\n                    \"total_results\": len(search_results)\n                }\n                \n                return ToolResult(success=True, data=results)\n                \n        except Exception as e:\n            logger.error(f\"SearXNG Search API call failed: {e}\")\n            return ToolResult(\n                success=False,\n                message=f\"SearXNG Search API call failed: {e}\",\n                data={\n                    \"query\": query,\n                    \"date_range\": date_range,\n                    \"results\": []\n                }\n            )\n",
      "methods": [
        "<module>.SearXNGSearchEngine.__init__",
        "<module>.SearXNGSearchEngine.search"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/search/search_engine_interface.py",
      "name": "SearchEngineInterface",
      "qualname": "<module>.SearchEngineInterface",
      "source": "class SearchEngineInterface(Protocol):\n    \"\"\"Interface for search engine implementations\"\"\"\n    \n    @abstractmethod\n    async def search(\n        self, \n        query: str, \n        date_range: Optional[str] = None\n    ) -> ToolResult:\n        \"\"\"Search web pages using search engine\n        \n        Args:\n            query: Search query\n            date_range: (Optional) Time range filter for search results\n            \n        Returns:\n            Search results wrapped in ToolResult\n        \"\"\"\n        pass ",
      "methods": [
        "<module>.SearchEngineInterface.search"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/search/google_search.py",
      "name": "GoogleSearchEngine",
      "qualname": "<module>.GoogleSearchEngine",
      "source": "class GoogleSearchEngine(SearchEngineInterface):\n    \"\"\"Google API based search engine implementation\"\"\"\n    \n    def __init__(self, api_key: str, cx: str):\n        \"\"\"Initialize Google search engine\n        \n        Args:\n            api_key: Google Custom Search API key\n            cx: Google Search Engine ID\n        \"\"\"\n        self.api_key = api_key\n        self.cx = cx\n        self.base_url = \"https://www.googleapis.com/customsearch/v1\"\n        \n    async def search(\n        self, \n        query: str, \n        date_range: Optional[str] = None\n    ) -> ToolResult:\n        \"\"\"Search web pages using Google API\n        \n        Args:\n            query: Search query, Google search style, use 3-5 keywords\n            date_range: (Optional) Time range filter for search results\n            \n        Returns:\n            Search results\n        \"\"\"\n        params = {\n            \"key\": self.api_key,\n            \"cx\": self.cx,\n            \"q\": query\n        }\n        \n        # Add time range filter\n        if date_range and date_range != \"all\":\n            # Convert date_range to time range parameters supported by Google API\n            # For example: via dateRestrict parameter (d[number]: day, w[number]: week, m[number]: month, y[number]: year)\n            date_mapping = {\n                \"past_hour\": \"d1\",\n                \"past_day\": \"d1\", \n                \"past_week\": \"w1\",\n                \"past_month\": \"m1\",\n                \"past_year\": \"y1\"\n            }\n            if date_range in date_mapping:\n                params[\"dateRestrict\"] = date_mapping[date_range]\n        \n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(self.base_url, params=params)\n                response.raise_for_status()\n                data = response.json()\n                \n                # Process search results\n                search_results = []\n                if \"items\" in data:\n                    for item in data[\"items\"]:\n                        search_results.append({\n                            \"title\": item.get(\"title\", \"\"),\n                            \"link\": item.get(\"link\", \"\"),\n                            \"snippet\": item.get(\"snippet\", \"\"),\n                        })\n                \n                # Build return result\n                results = {\n                    \"query\": query,\n                    \"date_range\": date_range,\n                    \"search_info\": data.get(\"searchInformation\", {}),\n                    \"results\": search_results,\n                    \"total_results\": data.get(\"searchInformation\", {}).get(\"totalResults\", \"0\")\n                }\n                \n                return ToolResult(success=True, data=results)\n                \n        except Exception as e:\n            logger.error(f\"Google Search API call failed: {e}\")\n            return ToolResult(\n                success=False,\n                message=f\"Google Search API call failed: {e}\",\n                data={\n                    \"query\": query,\n                    \"date_range\": date_range,\n                    \"results\": []\n                }\n            )\n",
      "methods": [
        "<module>.GoogleSearchEngine.__init__",
        "<module>.GoogleSearchEngine.search"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/user/memory_repository.py",
      "name": "UserDataStore",
      "qualname": "<module>.UserDataStore",
      "source": "class UserDataStore:\n    \"\"\"用户数据存储\"\"\"\n\n    def __init__(self):\n        # 用户表: user_id -> User\n        self.users: Dict[str, User] = {}\n        # 用户邮箱索引: email -> user_id\n        self.email_index: Dict[str, str] = {}\n        # 任务表: task_id -> UserTask\n        self.tasks: Dict[str, UserTask] = {}\n        # 用户任务索引: user_id -> [task_id]\n        self.user_tasks_index: Dict[str, List[str]] = {}\n        # 文件表: file_id -> UserFile\n        self.files: Dict[str, UserFile] = {}\n        # 用户文件索引: user_id -> [file_id]\n        self.user_files_index: Dict[str, List[str]] = {}\n",
      "methods": [
        "<module>.UserDataStore.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/user/memory_repository.py",
      "name": "ConversationDataStore",
      "qualname": "<module>.ConversationDataStore",
      "source": "class ConversationDataStore:\n    \"\"\"对话数据存储\"\"\"\n\n    def __init__(self):\n        # 会话历史表: agent_id -> ConversationHistory\n        self.histories: Dict[str, ConversationHistory] = {}\n        # 事件表: (agent_id, sequence) -> ConversationEvent\n        self.events: Dict[str, Dict[int, ConversationEvent]] = {}\n        # 用户会话索引: user_id -> [agent_id]\n        self.user_histories_index: Dict[str, List[str]] = {}\n",
      "methods": [
        "<module>.ConversationDataStore.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/user/memory_repository.py",
      "name": "AgentContextDataStore",
      "qualname": "<module>.AgentContextDataStore",
      "source": "class AgentContextDataStore:\n    \"\"\"Agent上下文数据存储\"\"\"\n\n    def __init__(self):\n        # Agent上下文表: agent_id -> AgentContext\n        self.contexts: Dict[str, 'AgentContext'] = {}\n        # 用户Agent索引: user_id -> [agent_id]\n        self.user_agents_index: Dict[str, List[str]] = {}\n        # 状态索引: status -> [agent_id]\n        self.status_index: Dict[str, List[str]] = {}\n        # 沙盒索引: sandbox_id -> agent_id\n        self.sandbox_index: Dict[str, str] = {}\n",
      "methods": [
        "<module>.AgentContextDataStore.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/user/memory_repository.py",
      "name": "MemoryUserRepository",
      "qualname": "<module>.MemoryUserRepository",
      "source": "class MemoryUserRepository:\n    \"\"\"用户仓储内存实现\"\"\"\n    \n    async def save_user(self, user: User) -> None:\n        \"\"\"保存用户\"\"\"\n        user_data_store.users[user.id] = user\n        \n        # 更新邮箱索引\n        if user.email:\n            user_data_store.email_index[user.email] = user.id\n            \n        logger.debug(f\"保存用户: {user.id}\")\n    \n    async def get_user(self, user_id: str) -> Optional[User]:\n        \"\"\"通过ID获取用户\"\"\"\n        return user_data_store.users.get(user_id)\n    \n    async def get_user_by_email(self, email: str) -> Optional[User]:\n        \"\"\"通过邮箱获取用户\"\"\"\n        user_id = user_data_store.email_index.get(email)\n        if user_id:\n            return user_data_store.users.get(user_id)\n        return None\n    \n    async def save_task(self, task: UserTask) -> None:\n        \"\"\"保存用户任务\"\"\"\n        user_data_store.tasks[task.id] = task\n        \n        # 更新用户任务索引\n        if task.user_id not in user_data_store.user_tasks_index:\n            user_data_store.user_tasks_index[task.user_id] = []\n            \n        if task.id not in user_data_store.user_tasks_index[task.user_id]:\n            user_data_store.user_tasks_index[task.user_id].append(task.id)\n            \n        logger.debug(f\"保存用户任务: {task.id}, 用户: {task.user_id}\")\n    \n    async def get_task(self, task_id: str) -> Optional[UserTask]:\n        \"\"\"通过ID获取任务\"\"\"\n        return user_data_store.tasks.get(task_id)\n    \n    async def get_user_tasks(self, user_id: str) -> List[UserTask]:\n        \"\"\"获取用户所有任务\"\"\"\n        task_ids = user_data_store.user_tasks_index.get(user_id, [])\n        return [user_data_store.tasks[task_id] for task_id in task_ids \n                if task_id in user_data_store.tasks]\n    \n    async def save_file(self, file: UserFile) -> None:\n        \"\"\"保存用户文件\"\"\"\n        user_data_store.files[file.id] = file\n        \n        # 更新用户文件索引\n        if file.user_id not in user_data_store.user_files_index:\n            user_data_store.user_files_index[file.user_id] = []\n            \n        if file.id not in user_data_store.user_files_index[file.user_id]:\n            user_data_store.user_files_index[file.user_id].append(file.id)\n            \n        logger.debug(f\"保存用户文件: {file.id}, 用户: {file.user_id}\")\n    \n    async def get_file(self, file_id: str) -> Optional[UserFile]:\n        \"\"\"通过ID获取文件\"\"\"\n        return user_data_store.files.get(file_id)\n    \n    async def get_user_files(self, user_id: str) -> List[UserFile]:\n        \"\"\"获取用户所有文件\"\"\"\n        file_ids = user_data_store.user_files_index.get(user_id, [])\n        return [user_data_store.files[file_id] for file_id in file_ids \n                if file_id in user_data_store.files]\n",
      "methods": [
        "<module>.MemoryUserRepository.save_user",
        "<module>.MemoryUserRepository.get_user",
        "<module>.MemoryUserRepository.get_user_by_email",
        "<module>.MemoryUserRepository.save_task",
        "<module>.MemoryUserRepository.get_task",
        "<module>.MemoryUserRepository.get_user_tasks",
        "<module>.MemoryUserRepository.save_file",
        "<module>.MemoryUserRepository.get_file",
        "<module>.MemoryUserRepository.get_user_files"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/user/sqlite_repository.py",
      "name": "SQLiteUserRepository",
      "qualname": "<module>.SQLiteUserRepository",
      "source": "class SQLiteUserRepository(UserRepository):\n    \"\"\"用户仓储SQLite实现\"\"\"\n    \n    def __init__(self, engine: AsyncEngine):\n        \"\"\"初始化用户仓储\n        \n        Args:\n            engine: 数据库引擎\n        \"\"\"\n        self.engine = engine\n    \n    def _orm_to_domain_user(self, user_orm: UserORM) -> User:\n        \"\"\"将ORM模型转换为领域模型\"\"\"\n        return User(\n            id=user_orm.id,\n            email=user_orm.email,\n            name=user_orm.name,\n            groups=user_orm.groups or [],\n            created_at=user_orm.created_at,\n            last_login=user_orm.last_login\n        )\n    \n    def _domain_to_orm_user(self, user: User) -> UserORM:\n        \"\"\"将领域模型转换为ORM模型\"\"\"\n        return UserORM(\n            id=user.id,\n            email=user.email,\n            name=user.name,\n            groups=user.groups,\n            created_at=user.created_at,\n            last_login=user.last_login\n        )\n    \n    def _orm_to_domain_task(self, task_orm: UserTaskORM) -> UserTask:\n        \"\"\"将任务ORM模型转换为领域模型\"\"\"\n        return UserTask(\n            id=task_orm.id,\n            user_id=task_orm.user_id,\n            agent_id=task_orm.agent_id,\n            title=task_orm.title,\n            status=task_orm.status,\n            created_at=task_orm.created_at,\n            completed_at=task_orm.completed_at,\n            metadata=task_orm.meta_data or {}\n        )\n    \n    def _domain_to_orm_task(self, task: UserTask) -> UserTaskORM:\n        \"\"\"将任务领域模型转换为ORM模型\"\"\"\n        return UserTaskORM(\n            id=task.id,\n            user_id=task.user_id,\n            agent_id=task.agent_id,\n            title=task.title,\n            status=task.status,\n            created_at=task.created_at,\n            completed_at=task.completed_at,\n            meta_data=task.metadata\n        )\n    \n    def _orm_to_domain_file(self, file_orm: UserFileORM) -> UserFile:\n        \"\"\"将文件ORM模型转换为领域模型\"\"\"\n        return UserFile(\n            id=file_orm.id,\n            user_id=file_orm.user_id,\n            filename=file_orm.filename,\n            path=file_orm.path,\n            created_at=file_orm.created_at,\n            updated_at=file_orm.updated_at,\n            metadata=file_orm.meta_data or {}\n        )\n    \n    def _domain_to_orm_file(self, file: UserFile) -> UserFileORM:\n        \"\"\"将文件领域模型转换为ORM模型\"\"\"\n        return UserFileORM(\n            id=file.id,\n            user_id=file.user_id,\n            filename=file.filename,\n            path=file.path,\n            created_at=file.created_at,\n            updated_at=file.updated_at,\n            meta_data=file.metadata\n        )\n    \n    async def save_user(self, user: User) -> None:\n        \"\"\"保存用户\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 检查用户是否已存在\n                stmt = select(UserORM).where(UserORM.id == user.id)\n                result = await session.execute(stmt)\n                existing_user = result.scalar_one_or_none()\n                \n                if existing_user:\n                    # 更新现有用户\n                    existing_user.email = user.email\n                    existing_user.name = user.name\n                    existing_user.groups = user.groups\n                    existing_user.last_login = user.last_login\n                else:\n                    # 创建新用户\n                    user_orm = self._domain_to_orm_user(user)\n                    session.add(user_orm)\n                \n                await session.commit()\n                logger.debug(f\"保存用户: {user.id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"保存用户失败: {user.id}, 错误: {str(e)}\")\n                raise\n    \n    async def get_user(self, user_id: str) -> Optional[User]:\n        \"\"\"通过ID获取用户\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(UserORM).where(UserORM.id == user_id)\n            result = await session.execute(stmt)\n            user_orm = result.scalar_one_or_none()\n            \n            if user_orm:\n                return self._orm_to_domain_user(user_orm)\n            return None\n    \n    async def get_user_by_email(self, email: str) -> Optional[User]:\n        \"\"\"通过邮箱获取用户\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(UserORM).where(UserORM.email == email)\n            result = await session.execute(stmt)\n            user_orm = result.scalar_one_or_none()\n            \n            if user_orm:\n                return self._orm_to_domain_user(user_orm)\n            return None\n    \n    async def save_task(self, task: UserTask) -> None:\n        \"\"\"保存用户任务\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 检查任务是否已存在\n                stmt = select(UserTaskORM).where(UserTaskORM.id == task.id)\n                result = await session.execute(stmt)\n                existing_task = result.scalar_one_or_none()\n                \n                if existing_task:\n                    # 更新现有任务\n                    existing_task.title = task.title\n                    existing_task.status = task.status\n                    existing_task.completed_at = task.completed_at\n                    existing_task.meta_data = task.metadata\n                else:\n                    # 创建新任务\n                    task_orm = self._domain_to_orm_task(task)\n                    session.add(task_orm)\n                \n                await session.commit()\n                logger.debug(f\"保存用户任务: {task.id}, 用户: {task.user_id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"保存用户任务失败: {task.id}, 错误: {str(e)}\")\n                raise\n    \n    async def get_task(self, task_id: str) -> Optional[UserTask]:\n        \"\"\"通过ID获取任务\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(UserTaskORM).where(UserTaskORM.id == task_id)\n            result = await session.execute(stmt)\n            task_orm = result.scalar_one_or_none()\n            \n            if task_orm:\n                return self._orm_to_domain_task(task_orm)\n            return None\n    \n    async def get_user_tasks(self, user_id: str) -> List[UserTask]:\n        \"\"\"获取用户所有任务\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(UserTaskORM).where(UserTaskORM.user_id == user_id).order_by(UserTaskORM.created_at.desc())\n            result = await session.execute(stmt)\n            task_orms = result.scalars().all()\n            \n            return [self._orm_to_domain_task(task_orm) for task_orm in task_orms]\n    \n    async def save_file(self, file: UserFile) -> None:\n        \"\"\"保存用户文件\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 检查文件是否已存在\n                stmt = select(UserFileORM).where(UserFileORM.id == file.id)\n                result = await session.execute(stmt)\n                existing_file = result.scalar_one_or_none()\n                \n                if existing_file:\n                    # 更新现有文件\n                    existing_file.filename = file.filename\n                    existing_file.path = file.path\n                    existing_file.updated_at = file.updated_at\n                    existing_file.meta_data = file.metadata\n                else:\n                    # 创建新文件\n                    file_orm = self._domain_to_orm_file(file)\n                    session.add(file_orm)\n                \n                await session.commit()\n                logger.debug(f\"保存用户文件: {file.id}, 用户: {file.user_id}\")\n                \n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"保存用户文件失败: {file.id}, 错误: {str(e)}\")\n                raise\n    \n    async def get_file(self, file_id: str) -> Optional[UserFile]:\n        \"\"\"通过ID获取文件\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(UserFileORM).where(UserFileORM.id == file_id)\n            result = await session.execute(stmt)\n            file_orm = result.scalar_one_or_none()\n            \n            if file_orm:\n                return self._orm_to_domain_file(file_orm)\n            return None\n    \n    async def get_user_files(self, user_id: str) -> List[UserFile]:\n        \"\"\"获取用户所有文件\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            stmt = select(UserFileORM).where(UserFileORM.user_id == user_id).order_by(UserFileORM.created_at.desc())\n            result = await session.execute(stmt)\n            file_orms = result.scalars().all()\n            \n            return [self._orm_to_domain_file(file_orm) for file_orm in file_orms] ",
      "methods": [
        "<module>.SQLiteUserRepository.__init__",
        "<module>.SQLiteUserRepository._orm_to_domain_user",
        "<module>.SQLiteUserRepository._domain_to_orm_user",
        "<module>.SQLiteUserRepository._orm_to_domain_task",
        "<module>.SQLiteUserRepository._domain_to_orm_task",
        "<module>.SQLiteUserRepository._orm_to_domain_file",
        "<module>.SQLiteUserRepository._domain_to_orm_file",
        "<module>.SQLiteUserRepository.save_user",
        "<module>.SQLiteUserRepository.get_user",
        "<module>.SQLiteUserRepository.get_user_by_email",
        "<module>.SQLiteUserRepository.save_task",
        "<module>.SQLiteUserRepository.get_task",
        "<module>.SQLiteUserRepository.get_user_tasks",
        "<module>.SQLiteUserRepository.save_file",
        "<module>.SQLiteUserRepository.get_file",
        "<module>.SQLiteUserRepository.get_user_files"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/agent_context/memory_repository.py",
      "name": "MemoryAgentContextRepository",
      "qualname": "<module>.MemoryAgentContextRepository",
      "source": "class MemoryAgentContextRepository:\n    \"\"\"Agent上下文仓储内存实现\"\"\"\n    \n    async def save_context(self, context: AgentContext) -> None:\n        \"\"\"保存Agent上下文\"\"\"\n        agent_id = context.agent_id\n        user_id = context.agent.user_id\n        status = context.status\n        sandbox_id = context.sandbox_id\n        \n        # 保存上下文\n        agent_context_data_store.contexts[agent_id] = context\n        \n        # 更新用户Agent索引\n        if user_id:\n            if user_id not in agent_context_data_store.user_agents_index:\n                agent_context_data_store.user_agents_index[user_id] = []\n            if agent_id not in agent_context_data_store.user_agents_index[user_id]:\n                agent_context_data_store.user_agents_index[user_id].append(agent_id)\n        \n        # 更新状态索引\n        if status not in agent_context_data_store.status_index:\n            agent_context_data_store.status_index[status] = []\n        if agent_id not in agent_context_data_store.status_index[status]:\n            agent_context_data_store.status_index[status].append(agent_id)\n        \n        # 更新沙盒索引\n        if sandbox_id:\n            agent_context_data_store.sandbox_index[sandbox_id] = agent_id\n        \n        logger.debug(f\"保存Agent上下文: {agent_id}, 用户: {user_id}, 状态: {status}\")\n    \n    async def get_context(self, agent_id: str) -> Optional[AgentContext]:\n        \"\"\"通过agent_id获取Agent上下文\"\"\"\n        return agent_context_data_store.contexts.get(agent_id)\n    \n    async def update_context(self, context: AgentContext) -> None:\n        \"\"\"更新Agent上下文\"\"\"\n        agent_id = context.agent_id\n        old_context = agent_context_data_store.contexts.get(agent_id)\n        \n        if not old_context:\n            logger.warning(f\"尝试更新不存在的Agent上下文: {agent_id}\")\n            return\n        \n        # 如果状态发生变化，需要更新状态索引\n        if old_context.status != context.status:\n            # 从旧状态索引中移除\n            if old_context.status in agent_context_data_store.status_index:\n                if agent_id in agent_context_data_store.status_index[old_context.status]:\n                    agent_context_data_store.status_index[old_context.status].remove(agent_id)\n            \n            # 添加到新状态索引\n            if context.status not in agent_context_data_store.status_index:\n                agent_context_data_store.status_index[context.status] = []\n            if agent_id not in agent_context_data_store.status_index[context.status]:\n                agent_context_data_store.status_index[context.status].append(agent_id)\n        \n        # 如果沙盒ID发生变化，需要更新沙盒索引\n        if old_context.sandbox_id != context.sandbox_id:\n            # 移除旧的沙盒索引\n            if old_context.sandbox_id and old_context.sandbox_id in agent_context_data_store.sandbox_index:\n                del agent_context_data_store.sandbox_index[old_context.sandbox_id]\n            \n            # 添加新的沙盒索引\n            if context.sandbox_id:\n                agent_context_data_store.sandbox_index[context.sandbox_id] = agent_id\n        \n        # 更新上下文\n        context.updated_at = datetime.now()\n        agent_context_data_store.contexts[agent_id] = context\n        \n        logger.debug(f\"更新Agent上下文: {agent_id}\")\n    \n    async def delete_context(self, agent_id: str) -> bool:\n        \"\"\"删除Agent上下文\"\"\"\n        context = agent_context_data_store.contexts.pop(agent_id, None)\n        if not context:\n            logger.warning(f\"未找到要删除的Agent上下文: {agent_id}\")\n            return False\n        \n        user_id = context.agent.user_id\n        status = context.status\n        sandbox_id = context.sandbox_id\n        \n        # 从用户Agent索引中移除\n        if user_id and user_id in agent_context_data_store.user_agents_index:\n            if agent_id in agent_context_data_store.user_agents_index[user_id]:\n                agent_context_data_store.user_agents_index[user_id].remove(agent_id)\n        \n        # 从状态索引中移除\n        if status in agent_context_data_store.status_index:\n            if agent_id in agent_context_data_store.status_index[status]:\n                agent_context_data_store.status_index[status].remove(agent_id)\n        \n        # 从沙盒索引中移除\n        if sandbox_id and sandbox_id in agent_context_data_store.sandbox_index:\n            del agent_context_data_store.sandbox_index[sandbox_id]\n        \n        logger.info(f\"删除Agent上下文: {agent_id}, 用户: {user_id}\")\n        return True\n    \n    async def list_contexts(self, user_id: Optional[str] = None, status: Optional[str] = None, \n                           limit: int = 50, offset: int = 0) -> List[AgentContext]:\n        \"\"\"列出Agent上下文（支持按用户和状态过滤）\"\"\"\n        result = []\n        \n        # 根据过滤条件获取agent_id列表\n        if user_id and status:\n            # 同时按用户和状态过滤\n            user_agents = set(agent_context_data_store.user_agents_index.get(user_id, []))\n            status_agents = set(agent_context_data_store.status_index.get(status, []))\n            agent_ids = list(user_agents.intersection(status_agents))\n        elif user_id:\n            # 只按用户过滤\n            agent_ids = agent_context_data_store.user_agents_index.get(user_id, [])\n        elif status:\n            # 只按状态过滤\n            agent_ids = agent_context_data_store.status_index.get(status, [])\n        else:\n            # 不过滤，获取所有\n            agent_ids = list(agent_context_data_store.contexts.keys())\n        \n        # 计算分页\n        end_idx = min(offset + limit, len(agent_ids))\n        paged_agent_ids = agent_ids[offset:end_idx]\n        \n        # 获取对应的上下文\n        for agent_id in paged_agent_ids:\n            context = agent_context_data_store.contexts.get(agent_id)\n            if context:\n                result.append(context)\n        \n        # 按更新时间排序（最新的在前）\n        result.sort(key=lambda c: c.updated_at, reverse=True)\n        \n        return result\n    \n    async def get_contexts_by_user(self, user_id: str) -> List[AgentContext]:\n        \"\"\"获取指定用户的所有Agent上下文\"\"\"\n        agent_ids = agent_context_data_store.user_agents_index.get(user_id, [])\n        result = []\n        \n        for agent_id in agent_ids:\n            context = agent_context_data_store.contexts.get(agent_id)\n            if context:\n                result.append(context)\n        \n        # 按更新时间排序（最新的在前）\n        result.sort(key=lambda c: c.updated_at, reverse=True)\n        \n        return result\n    \n    async def get_contexts_by_status(self, status: str) -> List[AgentContext]:\n        \"\"\"获取指定状态的所有Agent上下文\"\"\"\n        agent_ids = agent_context_data_store.status_index.get(status, [])\n        result = []\n        \n        for agent_id in agent_ids:\n            context = agent_context_data_store.contexts.get(agent_id)\n            if context:\n                result.append(context)\n        \n        # 按更新时间排序（最新的在前）\n        result.sort(key=lambda c: c.updated_at, reverse=True)\n        \n        return result\n    \n    async def update_status(self, agent_id: str, status: str) -> bool:\n        \"\"\"更新Agent状态\"\"\"\n        context = agent_context_data_store.contexts.get(agent_id)\n        if not context:\n            logger.warning(f\"未找到Agent上下文: {agent_id}\")\n            return False\n        \n        old_status = context.status\n        context.update_status(status)\n        \n        # 更新状态索引\n        if old_status != status:\n            # 从旧状态索引中移除\n            if old_status in agent_context_data_store.status_index:\n                if agent_id in agent_context_data_store.status_index[old_status]:\n                    agent_context_data_store.status_index[old_status].remove(agent_id)\n            \n            # 添加到新状态索引\n            if status not in agent_context_data_store.status_index:\n                agent_context_data_store.status_index[status] = []\n            if agent_id not in agent_context_data_store.status_index[status]:\n                agent_context_data_store.status_index[status].append(agent_id)\n        \n        logger.debug(f\"更新Agent状态: {agent_id}, {old_status} -> {status}\")\n        return True\n    \n    async def update_last_message(self, agent_id: str, message: str, timestamp: Optional[int] = None) -> bool:\n        \"\"\"更新最后消息\"\"\"\n        context = agent_context_data_store.contexts.get(agent_id)\n        if not context:\n            logger.warning(f\"未找到Agent上下文: {agent_id}\")\n            return False\n        \n        context.update_last_message(message, timestamp)\n        logger.debug(f\"更新Agent最后消息: {agent_id}\")\n        return True\n    \n    async def set_sandbox_id(self, agent_id: str, sandbox_id: str) -> bool:\n        \"\"\"设置沙盒ID\"\"\"\n        context = agent_context_data_store.contexts.get(agent_id)\n        if not context:\n            logger.warning(f\"未找到Agent上下文: {agent_id}\")\n            return False\n        \n        old_sandbox_id = context.sandbox_id\n        context.set_sandbox_id(sandbox_id)\n        \n        # 更新沙盒索引\n        if old_sandbox_id and old_sandbox_id in agent_context_data_store.sandbox_index:\n            del agent_context_data_store.sandbox_index[old_sandbox_id]\n        \n        agent_context_data_store.sandbox_index[sandbox_id] = agent_id\n        \n        logger.debug(f\"设置Agent沙盒ID: {agent_id}, {sandbox_id}\")\n        return True\n    \n    async def context_exists(self, agent_id: str) -> bool:\n        \"\"\"检查Agent上下文是否存在\"\"\"\n        return agent_id in agent_context_data_store.contexts ",
      "methods": [
        "<module>.MemoryAgentContextRepository.save_context",
        "<module>.MemoryAgentContextRepository.get_context",
        "<module>.MemoryAgentContextRepository.update_context",
        "<module>.MemoryAgentContextRepository.delete_context",
        "<module>.MemoryAgentContextRepository.list_contexts",
        "<module>.MemoryAgentContextRepository.get_contexts_by_user",
        "<module>.MemoryAgentContextRepository.get_contexts_by_status",
        "<module>.MemoryAgentContextRepository.update_status",
        "<module>.MemoryAgentContextRepository.update_last_message",
        "<module>.MemoryAgentContextRepository.set_sandbox_id",
        "<module>.MemoryAgentContextRepository.context_exists"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/agent_context/sqlite_repository.py",
      "name": "SQLiteAgentContextRepository",
      "qualname": "<module>.SQLiteAgentContextRepository",
      "source": "class SQLiteAgentContextRepository:\n    \"\"\"Agent上下文仓储SQLite实现\"\"\"\n\n    def __init__(self, engine: AsyncEngine):\n        \"\"\"初始化Agent上下文仓储\n        \n        Args:\n            engine: 数据库引擎\n        \"\"\"\n        self.engine = engine\n    \n    def _orm_to_domain(self, context_orm: AgentContextORM) -> AgentContext:\n        \"\"\"将ORM模型转换为领域模型\"\"\"\n        # 反序列化Agent数据\n        agent_data = context_orm.agent_data\n        agent = Agent(\n            id=agent_data.get(\"id\"),\n            planner_memory=Memory.from_dict(agent_data.get(\"planner_memory\", {})),\n            execution_memory=Memory.from_dict(agent_data.get(\"execution_memory\", {})),\n            model_name=agent_data.get(\"model_name\"),\n            temperature=agent_data.get(\"temperature\", 0.7),\n            max_tokens=agent_data.get(\"max_tokens\"),\n            user_id=agent_data.get(\"user_id\"),\n            environment=agent_data.get(\"environment\")\n        )\n        \n        return AgentContext(\n            agent_id=context_orm.agent_id,\n            agent=agent,\n            flow_id=context_orm.flow_id,\n            sandbox_id=context_orm.sandbox_id,\n            status=context_orm.status,\n            last_message=context_orm.last_message,\n            last_message_time=context_orm.last_message_time,\n            created_at=context_orm.created_at,\n            updated_at=context_orm.updated_at,\n            meta_data=context_orm.meta_data or {}\n        )\n    \n    def _domain_to_orm(self, context: AgentContext) -> AgentContextORM:\n        \"\"\"将领域模型转换为ORM模型\"\"\"\n        # 序列化Agent数据\n        agent_data = {\n            \"id\": context.agent.id,\n            \"planner_memory\": context.agent.planner_memory.to_dict(),\n            \"execution_memory\": context.agent.execution_memory.to_dict(),\n            \"model_name\": context.agent.model_name,\n            \"temperature\": context.agent.temperature,\n            \"max_tokens\": context.agent.max_tokens,\n            \"user_id\": context.agent.user_id,\n            \"environment\": context.agent.environment.to_dict() if context.agent.environment else None\n        }\n        \n        return AgentContextORM(\n            agent_id=context.agent_id,\n            user_id=context.agent.user_id,\n            flow_id=context.flow_id,\n            sandbox_id=context.sandbox_id,\n            status=context.status,\n            last_message=context.last_message,\n            last_message_time=context.last_message_time,\n            created_at=context.created_at,\n            updated_at=context.updated_at,\n            meta_data=context.meta_data,\n            agent_data=agent_data\n        )\n    \n    async def save_context(self, context: AgentContext) -> None:\n        \"\"\"保存Agent上下文\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                context_orm = self._domain_to_orm(context)\n                session.add(context_orm)\n                await session.commit()\n                logger.debug(f\"保存Agent上下文: {context.agent_id}, 用户: {context.agent.user_id}\")\n            except IntegrityError as e:\n                await session.rollback()\n                logger.error(f\"保存Agent上下文失败，可能已存在: {context.agent_id}, 错误: {str(e)}\")\n                raise ValueError(f\"Agent上下文已存在: {context.agent_id}\")\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"保存Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def get_context(self, agent_id: str) -> Optional[AgentContext]:\n        \"\"\"通过agent_id获取Agent上下文\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM).where(AgentContextORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                context_orm = result.scalar_one_or_none()\n                \n                if context_orm:\n                    return self._orm_to_domain(context_orm)\n                return None\n            except Exception as e:\n                logger.error(f\"获取Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def update_context(self, context: AgentContext) -> None:\n        \"\"\"更新Agent上下文\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                # 查找现有记录\n                stmt = select(AgentContextORM).where(AgentContextORM.agent_id == context.agent_id)\n                result = await session.execute(stmt)\n                existing_orm = result.scalar_one_or_none()\n                \n                if not existing_orm:\n                    logger.warning(f\"尝试更新不存在的Agent上下文: {context.agent_id}\")\n                    return\n                \n                # 更新字段\n                context.updated_at = datetime.now()\n                updated_orm = self._domain_to_orm(context)\n                \n                existing_orm.user_id = updated_orm.user_id\n                existing_orm.flow_id = updated_orm.flow_id\n                existing_orm.sandbox_id = updated_orm.sandbox_id\n                existing_orm.status = updated_orm.status\n                existing_orm.last_message = updated_orm.last_message\n                existing_orm.last_message_time = updated_orm.last_message_time\n                existing_orm.updated_at = updated_orm.updated_at\n                existing_orm.meta_data = updated_orm.meta_data\n                existing_orm.agent_data = updated_orm.agent_data\n                \n                await session.commit()\n                logger.debug(f\"更新Agent上下文: {context.agent_id}\")\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"更新Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def delete_context(self, agent_id: str) -> bool:\n        \"\"\"删除Agent上下文\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = delete(AgentContextORM).where(AgentContextORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                await session.commit()\n                \n                deleted_count = result.rowcount\n                if deleted_count > 0:\n                    logger.debug(f\"删除Agent上下文: {agent_id}\")\n                    return True\n                else:\n                    logger.warning(f\"未找到要删除的Agent上下文: {agent_id}\")\n                    return False\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"删除Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def list_contexts(self, user_id: Optional[str] = None, status: Optional[str] = None, \n                           limit: int = 50, offset: int = 0) -> List[AgentContext]:\n        \"\"\"列出Agent上下文（支持按用户和状态过滤）\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM)\n                \n                # 添加过滤条件\n                conditions = []\n                if user_id:\n                    conditions.append(AgentContextORM.user_id == user_id)\n                if status:\n                    conditions.append(AgentContextORM.status == status)\n                \n                if conditions:\n                    stmt = stmt.where(and_(*conditions))\n                \n                # 添加排序和分页\n                stmt = stmt.order_by(AgentContextORM.updated_at.desc()).offset(offset).limit(limit)\n                \n                result = await session.execute(stmt)\n                context_orms = result.scalars().all()\n                \n                return [self._orm_to_domain(orm) for orm in context_orms]\n            except Exception as e:\n                logger.error(f\"列出Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def get_contexts_by_user(self, user_id: str) -> List[AgentContext]:\n        \"\"\"获取指定用户的所有Agent上下文\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM).where(\n                    AgentContextORM.user_id == user_id\n                ).order_by(AgentContextORM.updated_at.desc())\n                \n                result = await session.execute(stmt)\n                context_orms = result.scalars().all()\n                \n                return [self._orm_to_domain(orm) for orm in context_orms]\n            except Exception as e:\n                logger.error(f\"获取用户Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def get_contexts_by_status(self, status: str) -> List[AgentContext]:\n        \"\"\"获取指定状态的所有Agent上下文\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM).where(\n                    AgentContextORM.status == status\n                ).order_by(AgentContextORM.updated_at.desc())\n                \n                result = await session.execute(stmt)\n                context_orms = result.scalars().all()\n                \n                return [self._orm_to_domain(orm) for orm in context_orms]\n            except Exception as e:\n                logger.error(f\"获取状态Agent上下文时发生错误: {str(e)}\")\n                raise\n    \n    async def update_status(self, agent_id: str, status: str) -> bool:\n        \"\"\"更新Agent状态\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM).where(AgentContextORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                context_orm = result.scalar_one_or_none()\n                \n                if not context_orm:\n                    logger.warning(f\"未找到Agent上下文: {agent_id}\")\n                    return False\n                \n                context_orm.status = status\n                context_orm.updated_at = datetime.now()\n                \n                await session.commit()\n                logger.debug(f\"更新Agent状态: {agent_id}, {status}\")\n                return True\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"更新Agent状态时发生错误: {str(e)}\")\n                raise\n    \n    async def update_last_message(self, agent_id: str, message: str, timestamp: Optional[int] = None) -> bool:\n        \"\"\"更新最后消息\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM).where(AgentContextORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                context_orm = result.scalar_one_or_none()\n                \n                if not context_orm:\n                    logger.warning(f\"未找到Agent上下文: {agent_id}\")\n                    return False\n                \n                context_orm.last_message = message\n                context_orm.last_message_time = timestamp\n                context_orm.updated_at = datetime.now()\n                \n                await session.commit()\n                logger.debug(f\"更新Agent最后消息: {agent_id}\")\n                return True\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"更新Agent最后消息时发生错误: {str(e)}\")\n                raise\n    \n    async def set_sandbox_id(self, agent_id: str, sandbox_id: str) -> bool:\n        \"\"\"设置沙盒ID\"\"\"\n        async with get_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM).where(AgentContextORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                context_orm = result.scalar_one_or_none()\n                \n                if not context_orm:\n                    logger.warning(f\"未找到Agent上下文: {agent_id}\")\n                    return False\n                \n                context_orm.sandbox_id = sandbox_id\n                context_orm.updated_at = datetime.now()\n                \n                await session.commit()\n                logger.debug(f\"设置Agent沙盒ID: {agent_id}, {sandbox_id}\")\n                return True\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"设置Agent沙盒ID时发生错误: {str(e)}\")\n                raise \n    \n    async def context_exists(self, agent_id: str) -> bool:\n        \"\"\"检查Agent上下文是否存在\"\"\"\n        async with get_readonly_session(self.engine) as session:\n            try:\n                stmt = select(AgentContextORM.agent_id).where(AgentContextORM.agent_id == agent_id)\n                result = await session.execute(stmt)\n                return result.scalar_one_or_none() is not None\n            except Exception as e:\n                logger.error(f\"检查Agent上下文存在性时发生错误: {str(e)}\")\n                raise ",
      "methods": [
        "<module>.SQLiteAgentContextRepository.__init__",
        "<module>.SQLiteAgentContextRepository._orm_to_domain",
        "<module>.SQLiteAgentContextRepository._domain_to_orm",
        "<module>.SQLiteAgentContextRepository.save_context",
        "<module>.SQLiteAgentContextRepository.get_context",
        "<module>.SQLiteAgentContextRepository.update_context",
        "<module>.SQLiteAgentContextRepository.delete_context",
        "<module>.SQLiteAgentContextRepository.list_contexts",
        "<module>.SQLiteAgentContextRepository.get_contexts_by_user",
        "<module>.SQLiteAgentContextRepository.get_contexts_by_status",
        "<module>.SQLiteAgentContextRepository.update_status",
        "<module>.SQLiteAgentContextRepository.update_last_message",
        "<module>.SQLiteAgentContextRepository.set_sandbox_id",
        "<module>.SQLiteAgentContextRepository.context_exists"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/auth/oauth2.py",
      "name": "OAuth2Service",
      "qualname": "<module>.OAuth2Service",
      "source": "class OAuth2Service:\n    \"\"\"Service for handling OAuth2 authentication and user information.\"\"\"\n    \n    # OAuth2 Proxy header names\n    USER_HEADER = \"X-Auth-Request-User\"\n    EMAIL_HEADER = \"X-Auth-Request-Email\"\n    GROUPS_HEADER = \"X-Auth-Request-Groups\"\n    \n    # 开发模式默认用户\n    DEFAULT_DEV_USER = {\n        \"user_id\": \"dev_user\",\n        \"email\": \"dev@example.com\",\n        \"groups\": [],\n        \"is_authenticated\": True\n    }\n    \n    @classmethod\n    async def get_current_user(cls, request: Request) -> Optional[Dict[Any, Any]]:\n        \"\"\"\n        Extract user information from OAuth2 Proxy headers.\n        \n        Args:\n            request: The incoming FastAPI request\n            \n        Returns:\n            A dictionary containing user information or None if no user information is found\n        \"\"\"\n        # 在开发模式下返回默认用户信息\n        if get_settings().bypass_oauth2:\n            logger.debug(\"Using development mode, bypassing OAuth2 authentication\")\n            return cls.DEFAULT_DEV_USER\n            \n        headers = request.headers\n        \n        user_id = headers.get(cls.USER_HEADER)\n        email = headers.get(cls.EMAIL_HEADER)\n        groups = headers.get(cls.GROUPS_HEADER, \"\").split(\",\") if headers.get(cls.GROUPS_HEADER) else []\n        \n        if not user_id and not email:\n            logger.warning(\"No user information found in request headers\")\n            return None\n        \n        logger.debug(f\"Extracted user information: user_id={user_id}, email={email}\")\n        \n        return {\n            \"user_id\": user_id,\n            \"email\": email,\n            \"groups\": groups,\n            \"is_authenticated\": bool(user_id or email)\n        }\n",
      "methods": [
        "<module>.OAuth2Service.get_current_user"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/sandbox/sandbox_factory.py",
      "name": "SandboxFactory",
      "qualname": "<module>.SandboxFactory",
      "source": "class SandboxFactory:\n    \"\"\"沙箱工厂类，根据配置创建相应的沙箱实例\"\"\"\n    @staticmethod\n    async def get_or_create_sandbox(sandbox_id: str, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None) -> SandboxInterface:\n        \"\"\"获取或创建沙箱实例，支持持久化存储卷\n        \n        Args:\n            sandbox_id: 沙箱ID，用作容器名和存储卷名的一部分\n            user_id: 可选的用户ID\n            environment_variables: 可选的环境变量字典\n            \n        Returns:\n            沙箱实例\n        \"\"\"\n        settings = get_settings()\n        \n        if settings.use_kubernetes:\n            return await K8sSandbox.get_or_create(sandbox_id, user_id, environment_variables)\n        else:\n            return await DockerSandbox.get_or_create(sandbox_id, user_id, environment_variables) ",
      "methods": [
        "<module>.SandboxFactory.get_or_create_sandbox"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/sandbox/sandbox_interface.py",
      "name": "SandboxInterface",
      "qualname": "<module>.SandboxInterface",
      "source": "class SandboxInterface(Protocol):\n    \"\"\"抽象沙箱接口，定义所有沙箱必须实现的方法\"\"\"    \n    @staticmethod\n    @abstractmethod\n    async def get_or_create(sandbox_id: str, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None) -> 'SandboxInterface':\n        \"\"\"获取或创建沙箱实例，支持持久化存储卷\n        \n        Args:\n            sandbox_id: 沙箱ID，用作容器名和存储卷名的一部分\n            user_id: 可选的用户ID\n            environment_variables: 可选的环境变量字典\n            \n        Returns:\n            沙箱实例\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def get_cdp_url(self) -> str:\n        \"\"\"获取Chrome调试协议URL\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_vnc_url(self) -> str:\n        \"\"\"获取VNC URL\"\"\"\n        pass\n    \n    @abstractmethod\n    def get_code_server_url(self) -> str:\n        \"\"\"获取Code Server URL\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_status(self) -> ToolResult:\n        \"\"\"获取沙箱状态，检查所有服务是否正常运行\"\"\"\n        pass\n\n    async def ensure_status(self) -> ToolResult:\n        \"\"\"确保沙箱状态正常\"\"\"\n        retry = 5\n        interval = 2\n        for _ in range(retry):\n            status = await self.get_status()\n            if status.success:\n                return status\n            await asyncio.sleep(interval)\n        return ToolResult(success=False, message=\"沙箱状态检查失败\")\n    \n    @abstractmethod\n    async def exec_command(self, session_id: str, exec_dir: str, command: str) -> ToolResult:\n        \"\"\"执行命令\"\"\"\n        pass\n    \n    @abstractmethod\n    async def view_shell(self, session_id: str) -> ToolResult:\n        \"\"\"查看shell输出\"\"\"\n        pass\n    \n    @abstractmethod\n    async def wait_for_process(self, session_id: str, seconds: Optional[int] = None) -> ToolResult:\n        \"\"\"等待进程完成\"\"\"\n        pass\n    \n    @abstractmethod\n    async def write_to_process(self, session_id: str, input_text: str, press_enter: bool = True) -> ToolResult:\n        \"\"\"向进程写入输入\"\"\"\n        pass\n    \n    @abstractmethod\n    async def kill_process(self, session_id: str) -> ToolResult:\n        \"\"\"终止进程\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_write(self, file: str, content: str, append: bool = False, \n                       leading_newline: bool = False, trailing_newline: bool = False, \n                       sudo: bool = False) -> ToolResult:\n        \"\"\"写入文件内容\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_read(self, file: str, start_line: int = None, \n                      end_line: int = None, sudo: bool = False) -> ToolResult:\n        \"\"\"读取文件内容\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_exists(self, path: str) -> ToolResult:\n        \"\"\"检查文件是否存在\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_delete(self, path: str) -> ToolResult:\n        \"\"\"删除文件\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_list(self, path: str) -> ToolResult:\n        \"\"\"列出目录内容\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_replace(self, file: str, old_str: str, new_str: str, sudo: bool = False) -> ToolResult:\n        \"\"\"替换文件中的字符串\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_search(self, file: str, regex: str, sudo: bool = False) -> ToolResult:\n        \"\"\"在文件内容中搜索\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_find(self, path: str, glob_pattern: str) -> ToolResult:\n        \"\"\"按名称模式查找文件\"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_upload(self, file_path: str, content: bytes, make_executable: bool = False) -> ToolResult:\n        \"\"\"\n        上传二进制文件内容到沙箱\n        \n        Args:\n            file_path: 在沙箱中的目标文件路径\n            content: 文件二进制内容\n            make_executable: 是否将文件设置为可执行\n            \n        Returns:\n            上传结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def file_download(self, file_path: str) -> bytes:\n        \"\"\"\n        从沙箱下载文件的二进制内容\n        \n        Args:\n            file_path: 沙箱中的文件路径\n            \n        Returns:\n            文件的二进制内容\n            \n        Raises:\n            FileNotFoundError: 当文件不存在时\n            PermissionError: 当权限不足时\n            Exception: 其他错误\n        \"\"\"\n        pass\n    \n    # MCP服务管理相关方法\n    @abstractmethod\n    async def mcp_install(self, pkg: str, lang: str, args: Optional[list] = None) -> ToolResult:\n        \"\"\"\n        安装并启动MCP服务器\n        \n        Args:\n            pkg: MCP包名称\n            lang: 编程语言类型 (\"python\" 或 \"node\")\n            args: 可选的启动参数列表\n            \n        Returns:\n            安装结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def mcp_uninstall(self, pkg: str) -> ToolResult:\n        \"\"\"\n        停止并卸载MCP服务器\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            卸载结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def mcp_list_servers(self) -> ToolResult:\n        \"\"\"\n        列出所有已安装的MCP服务器\n        \n        Returns:\n            服务器列表结果，包含各服务器的状态信息\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def mcp_health_check(self, pkg: str) -> ToolResult:\n        \"\"\"\n        检查MCP服务器健康状态\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            健康状态结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def mcp_proxy_request(self, pkg: str, request: Dict) -> ToolResult:\n        \"\"\"\n        代理JSON-RPC请求到MCP服务器\n        \n        Args:\n            pkg: 目标MCP服务器包名\n            request: JSON-RPC请求数据\n            \n        Returns:\n            服务器响应结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def mcp_get_capabilities(self, pkg: str) -> ToolResult:\n        \"\"\"\n        获取MCP服务器能力信息\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            服务器能力信息结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def mcp_shutdown_all(self) -> ToolResult:\n        \"\"\"\n        关闭所有MCP服务器\n        \n        Returns:\n            关闭操作结果\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def close(self):\n        \"\"\"关闭连接，清理资源\"\"\"\n        pass ",
      "methods": [
        "<module>.SandboxInterface.get_or_create",
        "<module>.SandboxInterface.get_cdp_url",
        "<module>.SandboxInterface.get_vnc_url",
        "<module>.SandboxInterface.get_code_server_url",
        "<module>.SandboxInterface.get_status",
        "<module>.SandboxInterface.ensure_status",
        "<module>.SandboxInterface.exec_command",
        "<module>.SandboxInterface.view_shell",
        "<module>.SandboxInterface.wait_for_process",
        "<module>.SandboxInterface.write_to_process",
        "<module>.SandboxInterface.kill_process",
        "<module>.SandboxInterface.file_write",
        "<module>.SandboxInterface.file_read",
        "<module>.SandboxInterface.file_exists",
        "<module>.SandboxInterface.file_delete",
        "<module>.SandboxInterface.file_list",
        "<module>.SandboxInterface.file_replace",
        "<module>.SandboxInterface.file_search",
        "<module>.SandboxInterface.file_find",
        "<module>.SandboxInterface.file_upload",
        "<module>.SandboxInterface.file_download",
        "<module>.SandboxInterface.mcp_install",
        "<module>.SandboxInterface.mcp_uninstall",
        "<module>.SandboxInterface.mcp_list_servers",
        "<module>.SandboxInterface.mcp_health_check",
        "<module>.SandboxInterface.mcp_proxy_request",
        "<module>.SandboxInterface.mcp_get_capabilities",
        "<module>.SandboxInterface.mcp_shutdown_all",
        "<module>.SandboxInterface.close"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/sandbox/k8s_sandbox.py",
      "name": "K8sSandbox",
      "qualname": "<module>.K8sSandbox",
      "source": "class K8sSandbox(SandboxInterface):\n    def __init__(self, ip: str = None, pod_name: str = None, namespace: str = None, pod_ip: str = None, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None):\n        \"\"\"初始化Kubernetes沙箱和API交互客户端\n        \n        Args:\n            ip: 沙箱服务地址（Service名称或IP）\n            pod_name: Kubernetes Pod名称\n            namespace: Kubernetes命名空间\n            pod_ip: Pod的实际IP地址（用于Chrome CDP）\n            user_id: 用户ID\n            environment_variables: 环境变量字典\n        \"\"\"\n        self.client = httpx.AsyncClient(timeout=600)\n        self.ip = ip\n        self.pod_name = pod_name\n        self.namespace = namespace\n        self.pod_ip = pod_ip or ip  # 如果没有提供pod_ip，则使用ip\n        self.user_id = user_id\n        self.environment_variables = environment_variables or {}\n        self.base_url = f\"http://{self.ip}:8080\"\n        self.vnc_url = f\"ws://{self.ip}:5901\"\n        # Chrome CDP需要使用Pod IP\n        self.cdp_url = f\"http://{self.pod_ip}:9222\"\n        # Code Server URL\n        self.code_server_url = f\"http://{self.ip}:8443\"\n\n    @staticmethod\n    async def get_or_create(sandbox_id: str, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None) -> 'K8sSandbox':\n        \"\"\"获取或创建K8s沙箱，支持持久化存储卷\n        \n        Args:\n            sandbox_id: 沙箱ID，用作Pod名和PVC名\n            user_id: 可选的用户ID\n            environment_variables: 可选的环境变量字典\n            \n        Returns:\n            K8sSandbox实例\n        \"\"\"\n        return await asyncio.to_thread(K8sSandbox._get_or_create_task, sandbox_id, user_id, environment_variables)\n    \n    @staticmethod\n    def _get_or_create_task(sandbox_id: str, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None) -> 'K8sSandbox':\n        \"\"\"获取或创建K8s沙箱的同步实现\n        \n        Args:\n            sandbox_id: 沙箱ID，用作Pod名和PVC名\n            user_id: 可选的用户ID\n            environment_variables: 可选的环境变量字典\n            \n        Returns:\n            K8sSandbox实例\n        \"\"\"\n        settings = get_settings()\n        \n        # 使用sandbox_id作为Pod名和PVC名\n        pod_name = f\"{settings.sandbox_name_prefix}-{sandbox_id}\"\n        pvc_name = f\"{settings.sandbox_name_prefix}-pvc-{sandbox_id}\"\n        \n        try:\n            # 创建Kubernetes客户端\n            config.load_incluster_config()\n            v1 = client.CoreV1Api()\n            \n            # 检查Pod是否已存在且正在运行\n            try:\n                existing_pod = v1.read_namespaced_pod(name=pod_name, namespace=settings.k8s_namespace)\n                if existing_pod.status.phase == 'Running':\n                    logger.info(f\"Found existing running pod: {pod_name}\")\n                    \n                    # 获取Pod IP\n                    pod_ip = existing_pod.status.pod_ip\n                    \n                    return K8sSandbox(\n                        pod_name=pod_name,\n                        ip=pod_ip,\n                        user_id=user_id,\n                        environment_variables=environment_variables\n                    )\n                else:\n                    # Pod存在但未运行，删除它\n                    logger.info(f\"Found non-running pod {pod_name}, deleting it\")\n                    v1.delete_namespaced_pod(name=pod_name, namespace=settings.k8s_namespace)\n                    # 等待Pod删除完成\n                    import time\n                    time.sleep(5)\n            except client.exceptions.ApiException as e:\n                if e.status == 404:\n                    # Pod不存在，继续创建新Pod\n                    logger.info(f\"Pod {pod_name} not found, creating new one\")\n                else:\n                    raise\n            \n            # 确保PVC存在\n            try:\n                existing_pvc = v1.read_namespaced_persistent_volume_claim(name=pvc_name, namespace=settings.k8s_namespace)\n                logger.info(f\"Found existing PVC: {pvc_name}\")\n            except client.exceptions.ApiException as e:\n                if e.status == 404:\n                    # 创建新的PVC\n                    pvc_spec = client.V1PersistentVolumeClaimSpec(\n                        access_modes=['ReadWriteOnce'],\n                        resources=client.V1ResourceRequirements(\n                            requests={'storage': settings.k8s_pvc_size or '10Gi'}\n                        )\n                    )\n                    \n                    if settings.k8s_storage_class:\n                        pvc_spec.storage_class_name = settings.k8s_storage_class\n                    \n                    pvc = client.V1PersistentVolumeClaim(\n                        metadata=client.V1ObjectMeta(name=pvc_name),\n                        spec=pvc_spec\n                    )\n                    \n                    v1.create_namespaced_persistent_volume_claim(\n                        namespace=settings.k8s_namespace,\n                        body=pvc\n                    )\n                    logger.info(f\"Created new PVC: {pvc_name}\")\n                else:\n                    raise\n\n            # 准备环境变量\n            env_vars = [\n                client.V1EnvVar(name=\"SERVICE_TIMEOUT_MINUTES\", value=str(settings.sandbox_ttl_minutes)),\n                client.V1EnvVar(name=\"CHROME_ARGS\", value=settings.sandbox_chrome_args),\n                client.V1EnvVar(name=\"HTTPS_PROXY\", value=settings.sandbox_https_proxy),\n                client.V1EnvVar(name=\"HTTP_PROXY\", value=settings.sandbox_http_proxy),\n                client.V1EnvVar(name=\"NO_PROXY\", value=settings.sandbox_no_proxy)\n            ]\n            \n            # 添加用户ID到环境变量\n            if user_id:\n                env_vars.append(client.V1EnvVar(name=\"USER_ID\", value=user_id))\n                logger.info(f\"Setting USER_ID={user_id} for sandbox pod\")\n            \n            # 添加自定义环境变量\n            if environment_variables:\n                for key, value in environment_variables.items():\n                    env_vars.append(client.V1EnvVar(name=key, value=value))\n                logger.info(f\"Adding {len(environment_variables)} custom environment variables to sandbox pod\")\n\n            # 创建Pod规格\n            container = client.V1Container(\n                name=\"sandbox\",\n                image=settings.sandbox_image,\n                env=env_vars,\n                ports=[\n                    client.V1ContainerPort(container_port=8080, name=\"api\"),\n                    client.V1ContainerPort(container_port=5901, name=\"vnc\"),\n                    client.V1ContainerPort(container_port=9222, name=\"cdp\"),\n                    client.V1ContainerPort(container_port=8443, name=\"code-server\")\n                ],\n                volume_mounts=[\n                    client.V1VolumeMount(\n                        name=\"workspace\",\n                        mount_path=\"/home/ubuntu\"\n                    )\n                ]\n            )\n            \n            # 添加资源限制\n            if settings.k8s_cpu_limit or settings.k8s_memory_limit:\n                limits = {}\n                requests = {}\n                \n                if settings.k8s_cpu_limit:\n                    limits['cpu'] = settings.k8s_cpu_limit\n                if settings.k8s_memory_limit:\n                    limits['memory'] = settings.k8s_memory_limit\n                if settings.k8s_cpu_request:\n                    requests['cpu'] = settings.k8s_cpu_request\n                if settings.k8s_memory_request:\n                    requests['memory'] = settings.k8s_memory_request\n                \n                container.resources = client.V1ResourceRequirements(\n                    limits=limits if limits else None,\n                    requests=requests if requests else None\n                )\n\n            pod_spec = client.V1PodSpec(\n                containers=[container],\n                volumes=[\n                    client.V1Volume(\n                        name=\"workspace\",\n                        persistent_volume_claim=client.V1PersistentVolumeClaimVolumeSource(\n                            claim_name=pvc_name\n                        )\n                    )\n                ],\n                restart_policy=\"Never\"  # 不自动重启，保持持久化\n            )\n\n            pod = client.V1Pod(\n                metadata=client.V1ObjectMeta(\n                    name=pod_name,\n                    labels={\"app\": \"ai-manus-sandbox\", \"sandbox-id\": sandbox_id}\n                ),\n                spec=pod_spec\n            )\n\n            # 创建Pod\n            v1.create_namespaced_pod(namespace=settings.k8s_namespace, body=pod)\n            logger.info(f\"Created new pod: {pod_name} with PVC: {pvc_name}\")\n\n            # 等待Pod运行\n            timeout = 300  # 5分钟超时\n            start_time = time.time()\n            \n            while time.time() - start_time < timeout:\n                try:\n                    pod_status = v1.read_namespaced_pod(name=pod_name, namespace=settings.k8s_namespace)\n                    if pod_status.status.phase == 'Running':\n                        pod_ip = pod_status.status.pod_ip\n                        logger.info(f\"Pod {pod_name} is running with IP: {pod_ip}\")\n                        \n                        return K8sSandbox(\n                            pod_name=pod_name,\n                            ip=pod_ip,\n                            user_id=user_id,\n                            environment_variables=environment_variables\n                        )\n                    elif pod_status.status.phase == 'Failed':\n                        raise Exception(f\"Pod {pod_name} failed to start\")\n                    \n                    time.sleep(2)\n                except client.exceptions.ApiException:\n                    time.sleep(2)\n            \n            raise Exception(f\"Timeout waiting for pod {pod_name} to start\")\n            \n        except Exception as e:\n            logger.exception(f\"Failed to get or create K8s sandbox: {str(e)}\")\n            raise Exception(f\"Failed to get or create K8s sandbox: {str(e)}\")\n    \n    def get_cdp_url(self) -> str:\n        \"\"\"获取Chrome调试协议URL\n        \n        Returns:\n            Chrome调试协议URL\n        \"\"\"\n        return self.cdp_url\n\n    def get_vnc_url(self) -> str:\n        \"\"\"获取VNC URL\n        \n        Returns:\n            VNC URL\n        \"\"\"\n        return self.vnc_url\n    \n    def get_code_server_url(self) -> str:\n        \"\"\"获取Code Server URL\n        \n        Returns:\n            Code Server URL\n        \"\"\"\n        return self.code_server_url\n    \n    async def get_status(self) -> ToolResult:\n        \"\"\"获取沙箱状态\n        \n        Returns:\n            ToolResult: 包含沙箱服务状态的工具结果\n        \"\"\"\n        try:\n            response = await self.client.get(f\"{self.base_url}/api/v1/supervisor/status\")\n            return ToolResult(**response.json())\n        except Exception as e:\n            return ToolResult(success=False, message=f\"获取沙箱状态失败: {str(e)}\")\n    \n    async def exec_command(self, session_id: str, exec_dir: str, command: str) -> ToolResult:\n        \"\"\"执行命令\n        \n        Args:\n            session_id: 会话ID\n            exec_dir: 执行目录\n            command: 命令\n            \n        Returns:\n            执行结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/exec\",\n            json={\n                \"id\": session_id,\n                \"exec_dir\": exec_dir,\n                \"command\": command\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def view_shell(self, session_id: str) -> ToolResult:\n        \"\"\"查看shell输出\n        \n        Args:\n            session_id: 会话ID\n            \n        Returns:\n            Shell输出\n        \"\"\"\n        try:\n            # 设置超时时间为10秒，防止请求卡住\n            async with httpx.AsyncClient(timeout=10.0) as client:\n                response = await client.post(\n                    f\"{self.base_url}/api/v1/shell/view\",\n                    json={\"id\": session_id}\n                )\n                return ToolResult(**response.json())\n        except httpx.TimeoutException:\n            logger.warning(f\"视图Shell请求超时 - session_id: {session_id}\")\n            return ToolResult(success=False, message=\"请求超时，可能是因为Shell会话处理了大量输出\")\n        except httpx.RemoteProtocolError as e:\n            logger.error(f\"远程协议错误 - session_id: {session_id}, 错误: {str(e)}\")\n            return ToolResult(success=False, message=f\"连接错误: {str(e)}\")\n        except Exception as e:\n            logger.exception(f\"查看Shell输出时出错 - session_id: {session_id}\")\n            return ToolResult(success=False, message=f\"查看Shell输出失败: {str(e)}\")\n\n    async def wait_for_process(self, session_id: str, seconds: Optional[int] = None) -> ToolResult:\n        \"\"\"等待进程完成\n        \n        Args:\n            session_id: 会话ID\n            seconds: 超时时间（秒）\n            \n        Returns:\n            等待结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/wait\",\n            json={\n                \"id\": session_id,\n                \"seconds\": seconds\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def write_to_process(self, session_id: str, input_text: str, press_enter: bool = True) -> ToolResult:\n        \"\"\"向进程写入输入\n        \n        Args:\n            session_id: 会话ID\n            input_text: 输入文本\n            press_enter: 是否按回车键\n            \n        Returns:\n            写入结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/write\",\n            json={\n                \"id\": session_id,\n                \"input\": input_text,\n                \"press_enter\": press_enter\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def kill_process(self, session_id: str) -> ToolResult:\n        \"\"\"终止进程\n        \n        Args:\n            session_id: 会话ID\n            \n        Returns:\n            终止结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/kill\",\n            json={\"id\": session_id}\n        )\n        return ToolResult(**response.json())\n\n    async def file_write(self, file: str, content: str, append: bool = False, \n                        leading_newline: bool = False, trailing_newline: bool = False, \n                        sudo: bool = False) -> ToolResult:\n        \"\"\"写入文件内容\n        \n        Args:\n            file: 文件路径\n            content: 内容\n            append: 是否追加内容\n            leading_newline: 是否在内容前添加换行符\n            trailing_newline: 是否在内容后添加换行符\n            sudo: 是否使用sudo权限\n            \n        Returns:\n            写入结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/write\",\n            json={\n                \"file\": file,\n                \"content\": content,\n                \"append\": append,\n                \"leading_newline\": leading_newline,\n                \"trailing_newline\": trailing_newline,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_read(self, file: str, start_line: int = None, \n                        end_line: int = None, sudo: bool = False) -> ToolResult:\n        \"\"\"读取文件内容\n        \n        Args:\n            file: 文件路径\n            start_line: 开始行号\n            end_line: 结束行号\n            sudo: 是否使用sudo权限\n            \n        Returns:\n            文件内容\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/read\",\n            json={\n                \"file\": file,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n        \n    async def file_exists(self, path: str) -> ToolResult:\n        \"\"\"检查文件是否存在\n        \n        Args:\n            path: 文件路径\n            \n        Returns:\n            文件是否存在\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/exists\",\n            json={\"path\": path}\n        )\n        return ToolResult(**response.json())\n        \n    async def file_delete(self, path: str) -> ToolResult:\n        \"\"\"删除文件\n        \n        Args:\n            path: 文件路径\n            \n        Returns:\n            删除结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/delete\",\n            json={\"path\": path}\n        )\n        return ToolResult(**response.json())\n        \n    async def file_list(self, path: str) -> ToolResult:\n        \"\"\"列出目录内容\n        \n        Args:\n            path: 目录路径\n            \n        Returns:\n            目录内容列表\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/list\",\n            json={\"path\": path}\n        )\n        return ToolResult(**response.json())\n\n    async def file_replace(self, file: str, old_str: str, new_str: str, sudo: bool = False) -> ToolResult:\n        \"\"\"替换文件中的字符串\n        \n        Args:\n            file: 文件路径\n            old_str: 要替换的字符串\n            new_str: 替换为的字符串\n            sudo: 是否使用sudo权限\n            \n        Returns:\n            替换结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/replace\",\n            json={\n                \"file\": file,\n                \"old_str\": old_str,\n                \"new_str\": new_str,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_search(self, file: str, regex: str, sudo: bool = False) -> ToolResult:\n        \"\"\"在文件内容中搜索\n        \n        Args:\n            file: 文件路径\n            regex: 正则表达式\n            sudo: 是否使用sudo权限\n            \n        Returns:\n            搜索结果\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/search\",\n            json={\n                \"file\": file,\n                \"regex\": regex,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_find(self, path: str, glob_pattern: str) -> ToolResult:\n        \"\"\"按名称模式查找文件\n        \n        Args:\n            path: 搜索目录路径\n            glob_pattern: Glob匹配模式\n            \n        Returns:\n            找到的文件列表\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/find\",\n            json={\n                \"path\": path,\n                \"glob\": glob_pattern\n            }\n        )\n        return ToolResult(**response.json())\n        \n    async def file_upload(self, file_path: str, content: bytes, make_executable: bool = False) -> ToolResult:\n        \"\"\"\n        上传二进制文件内容到沙箱\n        \n        Args:\n            file_path: 在沙箱中的目标文件路径\n            content: 文件二进制内容\n            make_executable: 是否将文件设置为可执行\n            \n        Returns:\n            上传结果\n        \"\"\"\n        # 使用multipart/form-data上传二进制内容\n        import io\n        import aiohttp\n        from aiohttp import FormData\n        \n        form = FormData()\n        form.add_field('file', \n                       io.BytesIO(content),\n                       filename=os.path.basename(file_path))\n        form.add_field('path', file_path)\n        form.add_field('make_executable', str(make_executable).lower())\n        \n        async with aiohttp.ClientSession() as session:\n            async with session.post(f\"{self.base_url}/api/v1/file/upload\", data=form) as response:\n                result_json = await response.json()\n                return ToolResult(**result_json)\n                \n    async def file_download(self, file_path: str) -> bytes:\n        \"\"\"\n        从沙箱下载文件的二进制内容\n        \n        Args:\n            file_path: 沙箱中的文件路径\n            \n        Returns:\n            文件的二进制内容\n            \n        Raises:\n            FileNotFoundError: 当文件不存在时\n            PermissionError: 当权限不足时\n            Exception: 其他错误\n        \"\"\"\n        import aiohttp\n        \n        # 首先检查文件是否存在\n        result = await self.file_exists(file_path)\n        if not result.success or not result.data.get(\"exists\", False):\n            raise FileNotFoundError(f\"文件在沙箱中不存在: {file_path}\")\n        \n        # 发起下载请求\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"{self.base_url}/api/v1/file/download\",\n                json={\"path\": file_path}\n            ) as response:\n                if response.status == 200:\n                    return await response.read()\n                elif response.status == 404:\n                    raise FileNotFoundError(f\"文件在沙箱中不存在: {file_path}\")\n                elif response.status == 403:\n                    raise PermissionError(f\"没有权限访问文件: {file_path}\")\n                else:\n                    error_text = await response.text()\n                    raise Exception(f\"下载文件失败 ({response.status}): {error_text}\")\n\n    @staticmethod\n    async def _resolve_hostname_to_ip(hostname: str) -> str:\n        \"\"\"将主机名解析为IP地址\n        \n        Args:\n            hostname: 要解析的主机名\n            \n        Returns:\n            解析的IP地址，或如果解析失败，则为None\n        \"\"\"\n        try:\n            # 首先检查主机名是否已经是IP地址格式\n            try:\n                socket.inet_pton(socket.AF_INET, hostname)\n                # 如果解析成功，则是IPv4地址格式，直接返回\n                return hostname\n            except OSError:\n                # 不是有效的IP地址格式，继续进行DNS解析\n                pass\n                \n            # 使用socket.getaddrinfo进行DNS解析\n            addr_info = socket.getaddrinfo(hostname, None, family=socket.AF_INET)\n            # 返回找到的第一个IPv4地址\n            if addr_info and len(addr_info) > 0:\n                return addr_info[0][4][0]  # Return sockaddr[0] from (family, type, proto, canonname, sockaddr), which is the IP address\n            return None\n        except Exception as e:\n            # 记录错误并在失败时返回None\n            logger.error(f\"解析主机名失败 {hostname}: {str(e)}\")\n            return None\n\n    async def close(self):\n        \"\"\"关闭连接和清理资源\"\"\"\n        try:\n            # 清理Kubernetes资源\n            await self.cleanup()\n        except Exception as e:\n            logger.error(f\"在close过程中清理Kubernetes资源失败: {str(e)}\")\n        \n        # 关闭HTTP客户端\n        if self.client:\n            await self.client.aclose()\n    \n    async def cleanup(self):\n        \"\"\"清理Kubernetes资源\"\"\"\n        if not self.pod_name or not self.namespace:\n            return\n            \n        try:\n            # 加载Kubernetes配置\n            try:\n                # 尝试从集群内部加载配置\n                config.load_incluster_config()\n            except config.config_exception.ConfigException:\n                # 如果失败，尝试从kubeconfig文件加载\n                config.load_kube_config()\n            \n            # 创建Kubernetes API客户端\n            v1 = client.CoreV1Api()\n            \n            # 删除Pod和Service\n            v1.delete_namespaced_pod(name=self.pod_name, namespace=self.namespace)\n            v1.delete_namespaced_service(name=self.pod_name, namespace=self.namespace)\n            \n            logger.info(f\"清理了Kubernetes资源: pod={self.pod_name}, namespace={self.namespace}\")\n        except Exception as e:\n            logger.error(f\"清理Kubernetes资源失败: {str(e)}\")\n\n    # MCP服务管理相关方法\n    async def mcp_install(self, pkg: str, lang: str, args: Optional[list] = None) -> ToolResult:\n        \"\"\"\n        安装并启动MCP服务器\n        \n        Args:\n            pkg: MCP包名称\n            lang: 编程语言类型 (\"python\" 或 \"node\")\n            args: 可选的启动参数列表\n            \n        Returns:\n            安装结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/mcp/install\",\n            json={\n                \"pkg\": pkg,\n                \"lang\": lang,\n                \"args\": args\n            }\n        )\n\n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # status, message\n            return ToolResult(\n                success=response_data[\"status\"] == \"ok\",\n                message=response_data[\"message\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_uninstall(self, pkg: str) -> ToolResult:\n        \"\"\"\n        停止并卸载MCP服务器\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            卸载结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.delete(\n            f\"{self.base_url}/api/v1/mcp/uninstall/{pkg}\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # status, message\n            return ToolResult(\n                success=response_data[\"status\"] == \"ok\",\n                message=response_data[\"message\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_list_servers(self) -> ToolResult:\n        \"\"\"\n        列出所有已安装的MCP服务器\n        \n        Returns:\n            服务器列表结果，包含各服务器的状态信息\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.get(\n            f\"{self.base_url}/api/v1/mcp/list\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # servers\n            return ToolResult(\n                success=True,\n                data=response_data[\"servers\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_health_check(self, pkg: str) -> ToolResult:\n        \"\"\"\n        检查MCP服务器健康状态\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            健康检查结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.get(\n            f\"{self.base_url}/api/v1/mcp/health/{pkg}\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # pkg, alive, uptime\n            return ToolResult(\n                success=True,\n                data=response_data\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_proxy_request(self, pkg: str, request: Dict) -> ToolResult:\n        \"\"\"\n        向MCP服务器发送代理请求\n        \n        Args:\n            pkg: MCP包名称\n            request: 请求内容字典\n            \n        Returns:\n            代理请求结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/mcp/proxy/{pkg}\",\n            json=request\n        )\n        \n        # 对于proxy请求，处理原始响应内容\n        if response.status_code < 400:\n            try:\n                response_data = response.json()\n                return ToolResult(\n                    success=True,\n                    message=\"MCP proxy request completed\",\n                    data=response_data\n                )\n            except Exception:\n                # 如果不是JSON，返回原始内容\n                return ToolResult(\n                    success=True,\n                    message=\"MCP proxy request completed\",\n                    data={\"content\": response.text}\n                )\n        else:\n            return ToolResult(\n                success=False,\n                message=f\"MCP proxy request failed with status {response.status_code}\",\n                data={\"status_code\": response.status_code, \"content\": response.text}\n            )\n    \n    async def mcp_get_capabilities(self, pkg: str) -> ToolResult:\n        \"\"\"\n        获取MCP服务器的能力信息\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            服务器能力信息\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.get(\n            f\"{self.base_url}/api/v1/mcp/capabilities/{pkg}\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # pkg, tools_count, tools\n            return ToolResult(\n                success=True,\n                data=response_data\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_shutdown_all(self) -> ToolResult:\n        \"\"\"\n        关闭所有MCP服务器\n        \n        Returns:\n            关闭操作结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/mcp/shutdown\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # status, message\n            return ToolResult(\n                success=response_data[\"status\"] == \"ok\",\n                message=response_data[\"message\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n",
      "methods": [
        "<module>.K8sSandbox.__init__",
        "<module>.K8sSandbox.get_or_create",
        "<module>.K8sSandbox._get_or_create_task",
        "<module>.K8sSandbox.get_cdp_url",
        "<module>.K8sSandbox.get_vnc_url",
        "<module>.K8sSandbox.get_code_server_url",
        "<module>.K8sSandbox.get_status",
        "<module>.K8sSandbox.exec_command",
        "<module>.K8sSandbox.view_shell",
        "<module>.K8sSandbox.wait_for_process",
        "<module>.K8sSandbox.write_to_process",
        "<module>.K8sSandbox.kill_process",
        "<module>.K8sSandbox.file_write",
        "<module>.K8sSandbox.file_read",
        "<module>.K8sSandbox.file_exists",
        "<module>.K8sSandbox.file_delete",
        "<module>.K8sSandbox.file_list",
        "<module>.K8sSandbox.file_replace",
        "<module>.K8sSandbox.file_search",
        "<module>.K8sSandbox.file_find",
        "<module>.K8sSandbox.file_upload",
        "<module>.K8sSandbox.file_download",
        "<module>.K8sSandbox._resolve_hostname_to_ip",
        "<module>.K8sSandbox.close",
        "<module>.K8sSandbox.cleanup",
        "<module>.K8sSandbox.mcp_install",
        "<module>.K8sSandbox.mcp_uninstall",
        "<module>.K8sSandbox.mcp_list_servers",
        "<module>.K8sSandbox.mcp_health_check",
        "<module>.K8sSandbox.mcp_proxy_request",
        "<module>.K8sSandbox.mcp_get_capabilities",
        "<module>.K8sSandbox.mcp_shutdown_all"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/sandbox/docker_sandbox.py",
      "name": "DockerSandbox",
      "qualname": "<module>.DockerSandbox",
      "source": "class DockerSandbox(SandboxInterface):\n    def __init__(\n            self, \n            container_name: str, \n            ip: str = None, \n            api_server_port: int = 8080, \n            vnc_port: int = 5901, \n            cdp_port: int = 9222, \n            code_server_port: int = 8443,\n            user_id: Optional[str] = None, \n            environment_variables: Optional[Dict[str, str]] = None\n        ):\n        \"\"\"Initialize Docker sandbox and API interaction client\"\"\"\n        self.container_name = container_name\n        self.client = httpx.AsyncClient(timeout=600)\n        self.ip = ip\n        self.base_url = f\"http://{self.ip}:{api_server_port}\"\n        self.vnc_url = f\"ws://{self.ip}:{vnc_port}\"\n        self.cdp_url = f\"http://{self.ip}:{cdp_port}\"\n        self.code_server_url = f\"http://{self.ip}:{code_server_port}\"\n        self.user_id = user_id\n        self.environment_variables = environment_variables or {}\n\n    @staticmethod\n    def _create_docker_client(settings):\n        \"\"\"创建Docker客户端连接\n        \n        支持本地和远程Docker主机连接，支持TLS认证\n        优先使用配置中的设置，如果未配置则尝试使用环境变量\n        \n        Args:\n            settings: 应用配置\n            \n        Returns:\n            Docker客户端实例\n        \"\"\"\n        # 检查是否使用远程Docker主机\n        docker_url = settings.docker_host_url\n        \n        # 如果未配置docker_host_url，但存在DOCKER_HOST环境变量，则使用环境变量\n        if not docker_url and os.environ.get('DOCKER_HOST'):\n            docker_url = os.environ.get('DOCKER_HOST')\n            logger.info(f\"Using DOCKER_HOST from environment: {docker_url}\")\n            \n        if docker_url:\n            # 连接到远程Docker主机\n            docker_client = docker.DockerClient(\n                base_url=docker_url, \n                timeout=settings.docker_timeout or 120\n            )\n            logger.info(f\"Connected to remote Docker host: {docker_url}\")\n        else:\n            # 使用from_env()从环境变量中读取配置连接到Docker\n            docker_client = docker.from_env()\n            logger.info(\"Connected to local Docker host using environment configuration\")\n            \n        # 测试docker连接是否正常\n        try:\n            docker_client.ping()\n            logger.info(\"Docker connection test passed\")\n        except Exception as e:\n            logger.error(f\"Docker connection test failed: {str(e)}\")\n            raise Exception(f\"Docker connection test failed: {str(e)}\")\n        return docker_client\n\n    @staticmethod\n    async def get_or_create(sandbox_id: str, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None) -> 'DockerSandbox':\n        \"\"\"获取或创建Docker沙箱，支持持久化存储卷\n        \n        Args:\n            sandbox_id: 沙箱ID，用作容器名和存储卷名\n            user_id: 可选的用户ID\n            environment_variables: 可选的环境变量字典\n            \n        Returns:\n            DockerSandbox实例\n        \"\"\"\n        return await asyncio.to_thread(DockerSandbox._get_or_create_task, sandbox_id, user_id, environment_variables)\n    \n    @staticmethod\n    def _get_or_create_task(sandbox_id: str, user_id: Optional[str] = None, environment_variables: Optional[Dict[str, str]] = None) -> 'DockerSandbox':\n        \"\"\"获取或创建Docker沙箱的同步实现\n        \n        Args:\n            sandbox_id: 沙箱ID，用作容器名和存储卷名\n            user_id: 可选的用户ID\n            environment_variables: 可选的环境变量字典\n            \n        Returns:\n            DockerSandbox实例\n        \"\"\"\n        settings = get_settings()\n        \n        # 使用sandbox_id作为容器名和存储卷名\n        container_name = f\"{settings.sandbox_name_prefix}-{sandbox_id}\"\n        volume_name = f\"{settings.sandbox_name_prefix}-vol-{sandbox_id}\"\n        \n        try:\n            # 创建Docker客户端\n            docker_client = DockerSandbox._create_docker_client(settings)\n            \n            # 判断是否为远程Docker\n            is_remote_docker = settings.docker_host_url or os.environ.get('DOCKER_HOST')\n            \n            # 检查容器是否已存在且正在运行\n            try:\n                existing_container = docker_client.containers.get(container_name)\n                if existing_container.status == 'running':\n                    logger.info(f\"Found existing running container: {container_name}\")\n                    \n                    # 获取容器IP地址\n                    existing_container.reload()\n                    network_settings = existing_container.attrs['NetworkSettings']\n                    ip_address = network_settings['IPAddress']\n                    \n                    # 如果默认网络没有IP，尝试从其他网络获取IP\n                    if not ip_address and 'Networks' in network_settings:\n                        networks = network_settings['Networks']\n                        for network_name, network_config in networks.items():\n                            if 'IPAddress' in network_config and network_config['IPAddress']:\n                                ip_address = network_config['IPAddress']\n                                break\n                    \n                    # 对于远程Docker，使用配置的远程地址\n                    if is_remote_docker and settings.sandbox_remote_address:\n                        # 获取端口映射\n                        ports = existing_container.attrs['NetworkSettings']['Ports']\n                        api_server_port = int(ports['8080/tcp'][0]['HostPort']) if ports.get('8080/tcp') else 8080\n                        vnc_port = int(ports['5901/tcp'][0]['HostPort']) if ports.get('5901/tcp') else 5901\n                        cdp_port = int(ports['9222/tcp'][0]['HostPort']) if ports.get('9222/tcp') else 9222\n                        code_server_port = int(ports['8443/tcp'][0]['HostPort']) if ports.get('8443/tcp') else 8443\n\n                        return DockerSandbox(\n                            container_name=container_name,\n                            ip=settings.sandbox_remote_address,\n                            api_server_port=api_server_port,\n                            vnc_port=vnc_port,\n                            cdp_port=cdp_port,\n                            code_server_port=code_server_port,\n                            user_id=user_id,\n                            environment_variables=environment_variables\n                        )\n                    \n                    return DockerSandbox(\n                        container_name=container_name,\n                        ip=ip_address,\n                        user_id=user_id,\n                        environment_variables=environment_variables\n                    )\n                else:\n                    # 容器存在但未运行，删除它\n                    logger.info(f\"Found stopped container {container_name}, removing it\")\n                    existing_container.remove(force=True)\n            except docker.errors.NotFound:\n                # 容器不存在，继续创建新容器\n                logger.info(f\"Container {container_name} not found, creating new one\")\n                pass\n            \n            # 确保存储卷存在\n            try:\n                volume = docker_client.volumes.get(volume_name)\n                logger.info(f\"Found existing volume: {volume_name}\")\n            except docker.errors.NotFound:\n                # 创建新的存储卷\n                volume = docker_client.volumes.create(\n                    name=volume_name,\n                    driver='local'\n                )\n                logger.info(f\"Created new volume: {volume_name}\")\n\n            # 准备环境变量\n            env_vars = {\n                \"SERVICE_TIMEOUT_MINUTES\": settings.sandbox_ttl_minutes,\n                \"CHROME_ARGS\": settings.sandbox_chrome_args,\n                \"HTTPS_PROXY\": settings.sandbox_https_proxy,\n                \"HTTP_PROXY\": settings.sandbox_http_proxy,\n                \"NO_PROXY\": settings.sandbox_no_proxy\n            }\n            \n            # 添加用户ID到环境变量\n            if user_id:\n                env_vars[\"USER_ID\"] = user_id\n                logger.info(f\"Setting USER_ID={user_id} for sandbox container\")\n            \n            # 添加自定义环境变量\n            if environment_variables:\n                for key, value in environment_variables.items():\n                    env_vars[key] = value\n                logger.info(f\"Adding {len(environment_variables)} custom environment variables to sandbox container\")\n\n            # 准备容器配置\n            container_config = {\n                \"image\": settings.sandbox_image,\n                \"name\": container_name,\n                \"detach\": True,\n                # 自动删除容器但保留命名卷，以便持久化数据\n                \"remove\": True,\n                \"environment\": env_vars,\n                \"volumes\": {\n                    volume_name: {\n                        'bind': '/home/ubuntu',\n                        'mode': 'rw'\n                    }\n                }\n            }\n\n            if is_remote_docker:\n                port_range = range(30720, 40730)\n                api_server_port = random.choice(port_range)\n                vnc_port = random.choice(port_range)\n                cdp_port = random.choice(port_range)\n                code_server_port = random.choice(port_range)\n                container_config[\"ports\"] = {\n                    \"8080\": {\n                        \"HostPort\": api_server_port\n                    },\n                    \"5901\": {\n                        \"HostPort\": vnc_port\n                    },\n                    \"9222\": {\n                        \"HostPort\": cdp_port\n                    },\n                    \"8443\": {\n                        \"HostPort\": code_server_port\n                    }\n                }\n            \n            # 添加网络配置\n            if settings.sandbox_network:\n                container_config[\"network\"] = settings.sandbox_network\n            \n            # 创建容器\n            container = docker_client.containers.run(**container_config)\n            logger.info(f\"Created new container: {container_name} with volume: {volume_name}\")\n            \n            # 获取容器IP地址\n            container.reload()\n            network_settings = container.attrs['NetworkSettings']\n            ip_address = network_settings['IPAddress']\n            \n            # 如果默认网络没有IP，尝试从其他网络获取IP\n            if not ip_address and 'Networks' in network_settings:\n                networks = network_settings['Networks']\n                for network_name, network_config in networks.items():\n                    if 'IPAddress' in network_config and network_config['IPAddress']:\n                        ip_address = network_config['IPAddress']\n                        break\n            \n            # 对于远程Docker，使用配置的远程地址\n            if is_remote_docker and settings.sandbox_remote_address:\n                logger.info(f\"Using configured remote sandbox address: {settings.sandbox_remote_address}\")\n                return DockerSandbox(\n                    container_name=container_name,\n                    ip=settings.sandbox_remote_address,\n                    api_server_port=api_server_port,\n                    vnc_port=vnc_port,\n                    cdp_port=cdp_port,\n                    code_server_port=code_server_port,\n                    user_id=user_id,\n                    environment_variables=environment_variables\n                )\n            \n            # 创建并返回DockerSandbox实例\n            return DockerSandbox(\n                container_name=container_name,\n                ip=ip_address,\n                user_id=user_id,\n                environment_variables=environment_variables\n            )\n            \n        except Exception as e:\n            logger.exception(f\"Failed to get or create Docker sandbox: {str(e)}\")\n            raise Exception(f\"Failed to get or create Docker sandbox: {str(e)}\")\n    \n    def get_cdp_url(self) -> str:\n        return self.cdp_url\n\n    def get_vnc_url(self) -> str:\n        return self.vnc_url\n\n    def get_code_server_url(self) -> str:\n        return self.code_server_url\n\n    async def get_status(self) -> ToolResult:\n        \"\"\"获取沙箱状态\n        \n        返回沙箱中各服务的运行状态\n        \n        Returns:\n            ToolResult: 包含沙箱服务状态的工具结果\n        \"\"\"\n        try:\n            response = await self.client.get(f\"{self.base_url}/api/v1/supervisor/status\")\n            return ToolResult(**response.json())\n        except Exception as e:\n            return ToolResult(success=False, message=f\"获取沙箱状态失败: {str(e)}\")\n\n    async def exec_command(self, session_id: str, exec_dir: str, command: str) -> ToolResult:\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/exec\",\n            json={\n                \"id\": session_id,\n                \"exec_dir\": exec_dir,\n                \"command\": command\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def view_shell(self, session_id: str) -> ToolResult:\n        try:\n            # 设置超时时间为10秒，防止请求卡住\n            async with httpx.AsyncClient(timeout=10.0) as client:\n                response = await client.post(\n                    f\"{self.base_url}/api/v1/shell/view\",\n                    json={\"id\": session_id}\n                )\n                return ToolResult(**response.json())\n        except httpx.TimeoutException:\n            logger.warning(f\"视图Shell请求超时 - session_id: {session_id}\")\n            return ToolResult(success=False, message=\"请求超时，可能是因为Shell会话处理了大量输出\")\n        except httpx.RemoteProtocolError as e:\n            logger.error(f\"远程协议错误 - session_id: {session_id}, 错误: {str(e)}\")\n            return ToolResult(success=False, message=f\"连接错误: {str(e)}\")\n        except Exception as e:\n            logger.exception(f\"查看Shell输出时出错 - session_id: {session_id}\")\n            return ToolResult(success=False, message=f\"查看Shell输出失败: {str(e)}\")\n\n    async def wait_for_process(self, session_id: str, seconds: Optional[int] = None) -> ToolResult:\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/wait\",\n            json={\n                \"id\": session_id,\n                \"seconds\": seconds\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def write_to_process(self, session_id: str, input_text: str, press_enter: bool = True) -> ToolResult:\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/write\",\n            json={\n                \"id\": session_id,\n                \"input\": input_text,\n                \"press_enter\": press_enter\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def kill_process(self, session_id: str) -> ToolResult:\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/shell/kill\",\n            json={\"id\": session_id}\n        )\n        return ToolResult(**response.json())\n\n    async def file_write(self, file: str, content: str, append: bool = False, \n                        leading_newline: bool = False, trailing_newline: bool = False, \n                        sudo: bool = False) -> ToolResult:\n        \"\"\"Write content to file\n        \n        Args:\n            file: File path\n            content: Content to write\n            append: Whether to append content\n            leading_newline: Whether to add newline before content\n            trailing_newline: Whether to add newline after content\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            Result of write operation\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/write\",\n            json={\n                \"file\": file,\n                \"content\": content,\n                \"append\": append,\n                \"leading_newline\": leading_newline,\n                \"trailing_newline\": trailing_newline,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_read(self, file: str, start_line: int = None, \n                        end_line: int = None, sudo: bool = False) -> ToolResult:\n        \"\"\"Read file content\n        \n        Args:\n            file: File path\n            start_line: Start line number\n            end_line: End line number\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            File content\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/read\",\n            json={\n                \"file\": file,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n        \n    async def file_exists(self, path: str) -> ToolResult:\n        \"\"\"Check if file exists\n        \n        Args:\n            path: File path\n            \n        Returns:\n            Whether file exists\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/exists\",\n            json={\"path\": path}\n        )\n        return ToolResult(**response.json())\n        \n    async def file_delete(self, path: str) -> ToolResult:\n        \"\"\"Delete file\n        \n        Args:\n            path: File path\n            \n        Returns:\n            Result of delete operation\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/delete\",\n            json={\"path\": path}\n        )\n        return ToolResult(**response.json())\n        \n    async def file_list(self, path: str) -> ToolResult:\n        \"\"\"List directory contents\n        \n        Args:\n            path: Directory path\n            \n        Returns:\n            List of directory contents\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/list\",\n            json={\"path\": path}\n        )\n        return ToolResult(**response.json())\n\n    async def file_replace(self, file: str, old_str: str, new_str: str, sudo: bool = False) -> ToolResult:\n        \"\"\"Replace string in file\n        \n        Args:\n            file: File path\n            old_str: String to replace\n            new_str: String to replace with\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            Result of replace operation\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/replace\",\n            json={\n                \"file\": file,\n                \"old_str\": old_str,\n                \"new_str\": new_str,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_search(self, file: str, regex: str, sudo: bool = False) -> ToolResult:\n        \"\"\"Search in file content\n        \n        Args:\n            file: File path\n            regex: Regular expression\n            sudo: Whether to use sudo privileges\n            \n        Returns:\n            Search results\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/search\",\n            json={\n                \"file\": file,\n                \"regex\": regex,\n                \"sudo\": sudo\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_find(self, path: str, glob_pattern: str) -> ToolResult:\n        \"\"\"Find files by name pattern\n        \n        Args:\n            path: Search directory path\n            glob_pattern: Glob match pattern\n            \n        Returns:\n            List of found files\n        \"\"\"\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/file/find\",\n            json={\n                \"path\": path,\n                \"glob\": glob_pattern\n            }\n        )\n        return ToolResult(**response.json())\n\n    async def file_upload(self, file_path: str, content: bytes, make_executable: bool = False) -> ToolResult:\n        \"\"\"\n        上传二进制文件内容到沙箱\n        \n        Args:\n            file_path: 在沙箱中的目标文件路径\n            content: 文件二进制内容\n            make_executable: 是否将文件设置为可执行\n            \n        Returns:\n            上传结果\n        \"\"\"\n        await self.ensure_status()\n        # 使用multipart/form-data上传二进制内容\n        import io\n        import aiohttp\n        from aiohttp import FormData\n        \n        form = FormData()\n        form.add_field('file', \n                       io.BytesIO(content),\n                       filename=os.path.basename(file_path))\n        form.add_field('path', file_path)\n        form.add_field('make_executable', str(make_executable).lower())\n        \n        async with aiohttp.ClientSession() as session:\n            async with session.post(f\"{self.base_url}/api/v1/file/upload\", data=form) as response:\n                result_json = await response.json()\n                return ToolResult(**result_json)\n                \n    async def file_download(self, file_path: str) -> bytes:\n        \"\"\"\n        从沙箱下载文件的二进制内容\n        \n        Args:\n            file_path: 沙箱中的文件路径\n            \n        Returns:\n            文件的二进制内容\n            \n        Raises:\n            FileNotFoundError: 当文件不存在时\n            PermissionError: 当权限不足时\n            Exception: 其他错误\n        \"\"\"\n        import aiohttp\n        \n        # 首先检查文件是否存在\n        result = await self.file_exists(file_path)\n        if not result.success or not result.data.get(\"exists\", False):\n            raise FileNotFoundError(f\"文件在沙箱中不存在: {file_path}\")\n        \n        # 发起下载请求\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"{self.base_url}/api/v1/file/download\",\n                json={\"path\": file_path}\n            ) as response:\n                if response.status == 200:\n                    return await response.read()\n                elif response.status == 404:\n                    raise FileNotFoundError(f\"文件在沙箱中不存在: {file_path}\")\n                elif response.status == 403:\n                    raise PermissionError(f\"没有权限访问文件: {file_path}\")\n                else:\n                    error_text = await response.text()\n                    raise Exception(f\"下载文件失败 ({response.status}): {error_text}\")\n\n    @staticmethod\n    async def _resolve_hostname_to_ip(hostname: str) -> str:\n        \"\"\"Resolve hostname to IP address\n        \n        Args:\n            hostname: Hostname to resolve\n            \n        Returns:\n            Resolved IP address, or None if resolution fails\n        \"\"\"\n        try:\n            # First check if hostname is already in IP address format\n            try:\n                socket.inet_pton(socket.AF_INET, hostname)\n                # If successfully parsed, it's an IPv4 address format, return directly\n                return hostname\n            except OSError:\n                # Not a valid IP address format, proceed with DNS resolution\n                pass\n                \n            # Use socket.getaddrinfo for DNS resolution\n            addr_info = socket.getaddrinfo(hostname, None, family=socket.AF_INET)\n            # Return the first IPv4 address found\n            if addr_info and len(addr_info) > 0:\n                return addr_info[0][4][0]  # Return sockaddr[0] from (family, type, proto, canonname, sockaddr), which is the IP address\n            return None\n        except Exception as e:\n            # Log error and return None on failure\n            logger.error(f\"Failed to resolve hostname {hostname}: {str(e)}\")\n            return None\n\n    async def close(self):\n        \"\"\"关闭连接和清理资源\"\"\"\n        try:\n            # 清理Docker容器\n            settings = get_settings()\n            try:\n                # 创建Docker客户端\n                docker_client = self._create_docker_client(settings)\n                \n                # 尝试查找匹配IP的容器\n                containers = docker_client.containers.list(\n                    filters={\"name\": self.container_name}\n                )\n                \n                for container in containers:\n                    container.stop()\n                    try:\n                        container.remove(force=True)\n                    except Exception as e:\n                        logger.error(f\"Failed to remove container {container.name}: {str(e)}\")\n            except Exception as e:\n                logger.error(f\"清理Docker容器时出错: {str(e)}\")\n        except Exception as e:\n            logger.error(f\"关闭沙箱连接时出错: {str(e)}\")\n        \n        # 关闭HTTP客户端\n        if self.client:\n            await self.client.aclose()\n\n    # MCP服务管理相关方法\n    async def mcp_install(self, pkg: str, lang: str, args: Optional[list] = None) -> ToolResult:\n        \"\"\"\n        安装并启动MCP服务器\n        \n        Args:\n            pkg: MCP包名称\n            lang: 编程语言类型 (\"python\" 或 \"node\")\n            args: 可选的启动参数列表\n            \n        Returns:\n            安装结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/mcp/install\",\n            json={\n                \"pkg\": pkg,\n                \"lang\": lang,\n                \"args\": args\n            }\n        )\n\n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # status, message\n            return ToolResult(\n                success=response_data[\"status\"] == \"ok\",\n                message=response_data[\"message\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_uninstall(self, pkg: str) -> ToolResult:\n        \"\"\"\n        停止并卸载MCP服务器\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            卸载结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.delete(\n            f\"{self.base_url}/api/v1/mcp/uninstall/{pkg}\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # status, message\n            return ToolResult(\n                success=response_data[\"status\"] == \"ok\",\n                message=response_data[\"message\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_list_servers(self) -> ToolResult:\n        \"\"\"\n        列出所有已安装的MCP服务器\n        \n        Returns:\n            服务器列表结果，包含各服务器的状态信息\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.get(\n            f\"{self.base_url}/api/v1/mcp/list\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # servers\n            return ToolResult(\n                success=True,\n                data=response_data[\"servers\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_health_check(self, pkg: str) -> ToolResult:\n        \"\"\"\n        检查MCP服务器健康状态\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            健康检查结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.get(\n            f\"{self.base_url}/api/v1/mcp/health/{pkg}\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # pkg, alive, uptime\n            return ToolResult(\n                success=True,\n                data=response_data\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_proxy_request(self, pkg: str, request: Dict) -> ToolResult:\n        \"\"\"\n        向MCP服务器发送代理请求\n        \n        Args:\n            pkg: MCP包名称\n            request: 请求内容字典\n            \n        Returns:\n            代理请求结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/mcp/proxy/{pkg}\",\n            json=request\n        )\n        \n        # 对于proxy请求，处理原始响应内容\n        if response.status_code < 400:\n            try:\n                response_data = response.json()\n                return ToolResult(\n                    success=True,\n                    message=\"MCP proxy request completed\",\n                    data=response_data\n                )\n            except Exception:\n                # 如果不是JSON，返回原始内容\n                return ToolResult(\n                    success=True,\n                    message=\"MCP proxy request completed\",\n                    data={\"content\": response.text}\n                )\n        else:\n            return ToolResult(\n                success=False,\n                message=f\"MCP proxy request failed with status {response.status_code}\",\n                data={\"status_code\": response.status_code, \"content\": response.text}\n            )\n    \n    async def mcp_get_capabilities(self, pkg: str) -> ToolResult:\n        \"\"\"\n        获取MCP服务器的能力信息\n        \n        Args:\n            pkg: MCP包名称\n            \n        Returns:\n            服务器能力信息\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.get(\n            f\"{self.base_url}/api/v1/mcp/capabilities/{pkg}\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # pkg, tools_count, tools\n            return ToolResult(\n                success=True,\n                data=response_data\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n    \n    async def mcp_shutdown_all(self) -> ToolResult:\n        \"\"\"\n        关闭所有MCP服务器\n        \n        Returns:\n            关闭操作结果\n        \"\"\"\n        await self.ensure_status()\n        response = await self.client.post(\n            f\"{self.base_url}/api/v1/mcp/shutdown\"\n        )\n        \n        if response.status_code == 200:\n            # 转换沙箱返回格式为ToolResult格式\n            response_data = response.json()\n            # status, message\n            return ToolResult(\n                success=response_data[\"status\"] == \"ok\",\n                message=response_data[\"message\"]\n            )\n        else:\n            return ToolResult(\n                success=False,\n                message=response.text\n            )\n",
      "methods": [
        "<module>.DockerSandbox.__init__",
        "<module>.DockerSandbox._create_docker_client",
        "<module>.DockerSandbox.get_or_create",
        "<module>.DockerSandbox._get_or_create_task",
        "<module>.DockerSandbox.get_cdp_url",
        "<module>.DockerSandbox.get_vnc_url",
        "<module>.DockerSandbox.get_code_server_url",
        "<module>.DockerSandbox.get_status",
        "<module>.DockerSandbox.exec_command",
        "<module>.DockerSandbox.view_shell",
        "<module>.DockerSandbox.wait_for_process",
        "<module>.DockerSandbox.write_to_process",
        "<module>.DockerSandbox.kill_process",
        "<module>.DockerSandbox.file_write",
        "<module>.DockerSandbox.file_read",
        "<module>.DockerSandbox.file_exists",
        "<module>.DockerSandbox.file_delete",
        "<module>.DockerSandbox.file_list",
        "<module>.DockerSandbox.file_replace",
        "<module>.DockerSandbox.file_search",
        "<module>.DockerSandbox.file_find",
        "<module>.DockerSandbox.file_upload",
        "<module>.DockerSandbox.file_download",
        "<module>.DockerSandbox._resolve_hostname_to_ip",
        "<module>.DockerSandbox.close",
        "<module>.DockerSandbox.mcp_install",
        "<module>.DockerSandbox.mcp_uninstall",
        "<module>.DockerSandbox.mcp_list_servers",
        "<module>.DockerSandbox.mcp_health_check",
        "<module>.DockerSandbox.mcp_proxy_request",
        "<module>.DockerSandbox.mcp_get_capabilities",
        "<module>.DockerSandbox.mcp_shutdown_all"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/llm/audio_llm.py",
      "name": "SiliconflowAudioLLM",
      "qualname": "<module>.SiliconflowAudioLLM",
      "source": "class SiliconflowAudioLLM:\n    def __init__(self):\n        settings = get_settings()\n        self.headers = {\n            \"Authorization\": f\"Bearer {settings.audio_api_key}\",\n        }\n        self.client = httpx.AsyncClient(\n            base_url=settings.audio_api_base,\n            headers=self.headers,\n            timeout=60.0  # 增加超时时间，因为音频处理可能需要更长时间\n        )\n        \n        self.model_name = settings.audio_model_name\n        logger.info(f\"Initialized Audio LLM with model: {self.model_name}\")\n    \n    def _convert_audio_to_mp3(self, audio_data: bytes, original_filename: str) -> bytes:\n        \"\"\"将音频数据转换为MP3格式\"\"\"\n        try:\n            # 从文件扩展名推断音频格式\n            file_extension = Path(original_filename).suffix.lower().lstrip('.')\n            \n            # 如果已经是mp3格式，直接返回\n            if file_extension == 'mp3':\n                logger.info(\"Audio is already in MP3 format\")\n                return audio_data\n            \n            # 支持的音频格式映射\n            format_mapping = {\n                'wav': 'wav',\n                'mp3': 'mp3',\n                'flac': 'flac',\n                'aac': 'aac',\n                'm4a': 'mp4',\n                'ogg': 'ogg',\n                'wma': 'asf',\n                'aiff': 'aiff',\n                'au': 'au',\n                'mp4': 'mp4',\n                'webm': 'webm',\n                '3gp': '3gp',\n                'amr': 'amr'\n            }\n            \n            # 如果格式不在映射中，尝试自动检测\n            audio_format = format_mapping.get(file_extension, file_extension)\n            \n            logger.info(f\"Converting audio from {file_extension} to mp3, original size: {len(audio_data)} bytes\")\n            \n            # 使用临时文件处理音频转换\n            with tempfile.NamedTemporaryFile(suffix=f'.{file_extension}', delete=False) as temp_input:\n                temp_input.write(audio_data)\n                temp_input.flush()\n                temp_input_path = temp_input.name\n            \n            try:\n                # 加载音频文件\n                try:\n                    audio = AudioSegment.from_file(temp_input_path, format=audio_format)\n                except Exception as e:\n                    logger.warning(f\"Failed to load with format {audio_format}, trying auto-detection: {e}\")\n                    # 如果指定格式失败，尝试让pydub自动检测\n                    audio = AudioSegment.from_file(temp_input_path)\n                \n                # 转换为MP3格式并保存到临时文件\n                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_output:\n                    temp_output_path = temp_output.name\n                \n                # 导出为MP3\n                audio.export(temp_output_path, format=\"mp3\", bitrate=\"128k\")\n                \n                # 读取转换后的MP3数据\n                with open(temp_output_path, 'rb') as f:\n                    mp3_data = f.read()\n                    \n                logger.info(f\"Successfully converted audio to MP3, size: {len(mp3_data)} bytes\")\n                return mp3_data\n                \n            finally:\n                # 清理临时文件\n                try:\n                    import os\n                    os.unlink(temp_input_path)\n                    if 'temp_output_path' in locals():\n                        os.unlink(temp_output_path)\n                except Exception as cleanup_error:\n                    logger.warning(f\"Failed to cleanup temp files: {cleanup_error}\")\n                \n        except Exception as e:\n            logger.exception(f\"Error converting audio to MP3: {str(e)}\")\n            # 如果转换失败，返回原始数据（可能已经是MP3或兼容格式）\n            logger.warning(\"Conversion failed, using original audio data\")\n            return audio_data\n    \n    async def audio_to_text(self, audio_file: bytes, filename: str) -> str:\n        \"\"\"将音频文件转换为文本\"\"\"\n        response = None\n        try:\n            # 转换音频为MP3格式\n            mp3_data = self._convert_audio_to_mp3(audio_file, filename)\n            \n            # 生成MP3文件名\n            mp3_filename = Path(filename).stem + '.mp3'\n            \n            logger.info(f\"Sending audio transcription request for file: {mp3_filename}, size: {len(mp3_data)} bytes\")\n            \n            # 准备表单数据\n            files = {\n                \"file\": (mp3_filename, mp3_data, \"audio/mp3\")\n            }\n            \n            data = {\n                \"model\": self.model_name,\n            }\n            \n            # 发送请求到音频转录接口\n            response = await self.client.post(\n                \"/audio/transcriptions\",\n                files=files,\n                data=data\n            )\n            \n            # 检查响应状态\n            if response.status_code != 200:\n                logger.error(f\"API request failed with status {response.status_code}: {response.text}\")\n                raise Exception(f\"API request failed: {response.status_code}\")\n            \n            json_data = response.json()\n            \n            # 检查响应数据\n            if \"text\" not in json_data:\n                logger.error(f\"Unexpected response format: {json_data}\")\n                raise Exception(\"Invalid response format from API\")\n            \n            transcribed_text = json_data[\"text\"]\n            logger.info(f\"Successfully transcribed audio, text length: {len(transcribed_text)}\")\n            \n            return transcribed_text\n            \n        except Exception as e:\n            error_msg = f\"Error in audio transcription: {str(e)}\"\n            if response:\n                error_msg += f\" Response: {response.text if hasattr(response, 'text') else 'No response text'}\"\n            logger.exception(error_msg)\n            raise Exception(error_msg)\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.client.aclose()\n",
      "methods": [
        "<module>.SiliconflowAudioLLM.__init__",
        "<module>.SiliconflowAudioLLM._convert_audio_to_mp3",
        "<module>.SiliconflowAudioLLM.audio_to_text",
        "<module>.SiliconflowAudioLLM.__aenter__",
        "<module>.SiliconflowAudioLLM.__aexit__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/llm/video_llm.py",
      "name": "GeminiVideoLLM",
      "qualname": "<module>.GeminiVideoLLM",
      "source": "class GeminiVideoLLM:\n    \"\"\"基于Gemini API的视频分析服务\"\"\"\n    \n    def __init__(self):\n        settings = get_settings()\n        self.api_key = settings.video_api_key\n        self.api_base = settings.video_api_base\n        self.model_name = settings.video_model_name\n        \n        if not self.api_key:\n            raise ValueError(\"Video API key is required\")\n        \n        self.client = httpx.AsyncClient(\n            timeout=300.0  # 视频处理需要更长时间\n        )\n        \n        logger.info(f\"Initialized Video LLM with model: {self.model_name}\")\n    \n    async def upload_file_to_gemini(self, file_path: str) -> str:\n        \"\"\"上传文件到Gemini API并返回文件URI\"\"\"\n        try:\n            # 检查文件是否存在\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"文件不存在: {file_path}\")\n            \n            # 获取文件MIME类型\n            mime_type, _ = mimetypes.guess_type(file_path)\n            if not mime_type:\n                mime_type = \"video/mp4\"  # 默认为mp4\n            \n            logger.info(f\"正在上传文件: {file_path}, 类型: {mime_type}\")\n            \n            # 读取文件\n            with open(file_path, 'rb') as f:\n                file_data = f.read()\n            \n            # 准备上传请求\n            upload_url = f\"{self.api_base}/upload/v1beta/files?key={self.api_key}\"\n            \n            # 第一步：开始上传\n            headers = {\n                'X-Goog-Upload-Protocol': 'resumable',\n                'X-Goog-Upload-Command': 'start',\n                'X-Goog-Upload-Header-Content-Length': str(len(file_data)),\n                'X-Goog-Upload-Header-Content-Type': mime_type,\n                'Content-Type': 'application/json'\n            }\n            \n            metadata = {\n                'file': {\n                    'display_name': os.path.basename(file_path)\n                }\n            }\n            \n            response = await self.client.post(upload_url, headers=headers, json=metadata)\n            \n            if response.status_code != 200:\n                logger.error(f\"开始上传失败: {response.status_code}, {response.text}\")\n                raise Exception(f\"API request failed: {response.status_code}\")\n            \n            # 获取上传URL\n            upload_session_url = response.headers.get('X-Goog-Upload-URL')\n            if not upload_session_url:\n                raise Exception(\"未获取到上传URL\")\n            \n            # 第二步：上传文件数据\n            upload_headers = {\n                'Content-Length': str(len(file_data)),\n                'X-Goog-Upload-Offset': '0',\n                'X-Goog-Upload-Command': 'upload, finalize'\n            }\n            \n            upload_response = await self.client.post(\n                upload_session_url, \n                headers=upload_headers, \n                content=file_data\n            )\n            \n            if upload_response.status_code != 200:\n                logger.error(f\"文件上传失败: {upload_response.status_code}, {upload_response.text}\")\n                raise Exception(f\"File upload failed: {upload_response.status_code}\")\n            \n            # 解析响应获取文件URI\n            file_info = upload_response.json()\n            file_uri = file_info.get('file', {}).get('uri')\n            \n            if file_uri:\n                logger.info(f\"文件上传成功! URI: {file_uri}\")\n                return file_uri\n            else:\n                raise Exception(\"上传成功但未获取到文件URI\")\n                \n        except Exception as e:\n            logger.exception(f\"上传文件时出错: {e}\")\n            raise\n    \n    async def analyze_video_with_gemini_api(self, file_uri: str, query: str) -> str:\n        \"\"\"使用Gemini API分析视频\"\"\"\n        try:\n            url = f\"{self.api_base}/v1beta/models/{self.model_name}:generateContent?key={self.api_key}\"\n            \n            headers = {\n                'Content-Type': 'application/json'\n            }\n            \n            data = {\n                \"contents\": [\n                    {\n                        \"parts\": [\n                            {\n                                \"fileData\": {\n                                    \"mimeType\": \"video/mp4\",\n                                    \"fileUri\": file_uri\n                                }\n                            },\n                            {\n                                \"text\": query\n                            }\n                        ]\n                    }\n                ]\n            }\n            \n            logger.info(\"正在分析视频内容...\")\n            response = await self.client.post(url, headers=headers, json=data)\n            \n            if response.status_code == 200:\n                result = response.json()\n                \n                if 'candidates' in result and len(result['candidates']) > 0:\n                    content = result['candidates'][0]['content']['parts'][0]['text']\n                    return content\n                else:\n                    logger.error(\"API返回了空结果\")\n                    raise Exception(\"API返回了空结果\")\n            else:\n                logger.error(f\"API请求失败: {response.status_code}, {response.text}\")\n                raise Exception(f\"API request failed: {response.status_code}\")\n                \n        except Exception as e:\n            logger.exception(f\"分析视频时出错: {e}\")\n            raise\n    \n    async def video_to_text(self, video_uri: str) -> str:\n        \"\"\"将视频转换为文本描述\"\"\"\n        query = \"请详细描述这个视频的内容，包括视觉元素、动作、场景等。\"\n        return await self.analyze_video_with_gemini_api(video_uri, query)\n    \n    async def ask_video(self, video_uri: str, query: str) -> str:\n        \"\"\"对视频进行问答分析\"\"\"\n        return await self.analyze_video_with_gemini_api(video_uri, query)\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.client.aclose()\n",
      "methods": [
        "<module>.GeminiVideoLLM.__init__",
        "<module>.GeminiVideoLLM.upload_file_to_gemini",
        "<module>.GeminiVideoLLM.analyze_video_with_gemini_api",
        "<module>.GeminiVideoLLM.video_to_text",
        "<module>.GeminiVideoLLM.ask_video",
        "<module>.GeminiVideoLLM.__aenter__",
        "<module>.GeminiVideoLLM.__aexit__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/llm/reason_llm.py",
      "name": "DeepSeekReasonLLM",
      "qualname": "<module>.DeepSeekReasonLLM",
      "source": "class DeepSeekReasonLLM:\n    \"\"\"基于DeepSeek Reasoner的深度推理服务\"\"\"\n    \n    def __init__(self):\n        settings = get_settings()\n        self.api_key = settings.reason_api_key\n        self.api_base = settings.reason_api_base\n        self.model_name = settings.reason_model_name\n        \n        if not self.api_key:\n            raise ValueError(\"Reason API key is required\")\n        \n        self.client = AsyncOpenAI(\n            api_key=settings.reason_api_key,\n            base_url=settings.reason_api_base\n        )\n        \n        logger.info(f\"Initialized Reason LLM with model: {self.model_name}\")\n    \n    async def deep_reasoning(self, problem: str, context: Optional[str] = None) -> str:\n        \"\"\"\n        进行深度推理分析\n        \n        Args:\n            problem: 需要推理的问题\n            context: 可选的上下文信息\n            \n        Returns:\n            推理结果\n        \"\"\"\n        try:\n            # 构建推理提示词\n            messages = [\n                {\"role\": \"system\", \"content\": \"你是一个有用的AI助手。请回答用户的问题。/think\"},\n                {\"role\": \"user\", \"content\": f\"问题: {problem}\\n上下文: {context}\"},\n            ]\n            \n            # 调用API\n            response = await self.client.chat.completions.create(\n                model=self.model_name,\n                temperature=0.0,\n                max_tokens=8000,\n                messages=messages,\n                extra_body={\"enable_thinking\": False},\n                # response_format=response_format,\n            )\n            \n            return response.choices[0].message\n            \n        except Exception as e:\n            logger.exception(f\"深度推理失败: {e}\")\n            raise\n",
      "methods": [
        "<module>.DeepSeekReasonLLM.__init__",
        "<module>.DeepSeekReasonLLM.deep_reasoning"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/llm/openai_llm.py",
      "name": "OpenAILLM",
      "qualname": "<module>.OpenAILLM",
      "source": "class OpenAILLM:\n    def __init__(self):\n        settings = get_settings()\n        self.client = AsyncOpenAI(\n            api_key=settings.api_key,\n            base_url=settings.api_base\n        )\n        \n        self.model_name = settings.model_name\n        self.temperature = settings.temperature\n        self.max_tokens = settings.max_tokens\n        logger.info(f\"Initialized OpenAI LLM with model: {self.model_name}\")\n    \n    async def ask(self, messages: List[Dict[str, str]], \n                            tools: Optional[List[Dict[str, Any]]] = None,\n                            response_format: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"Send chat request to OpenAI API\"\"\"\n        # [DEBUG 3] 验证消息格式\n        logger.info(f\"[DEBUG 3] 准备发送到OpenAI API，消息数量: {len(messages)}\")\n        for i, msg in enumerate(messages):\n            content = msg.get('content')\n            role = msg.get('role')\n            logger.info(f\"[DEBUG 3] 消息 {i}: role={role}, content_type={type(content)}, content_is_none={content is None}\")\n            if content is None:\n                logger.error(f\"[DEBUG 3] 检测到消息 {i} content为None! 完整消息: {msg}\")\n                # 修复None content\n                msg['content'] = \"\"\n                logger.info(f\"[DEBUG 3] 已将消息 {i} 的None content修复为空字符串\")\n            elif not isinstance(content, str):\n                logger.warning(f\"[DEBUG 3] 消息 {i} content不是字符串: {type(content)}, 值: {content}\")\n                msg['content'] = str(content)\n                logger.info(f\"[DEBUG 3] 已将消息 {i} content转换为字符串\")\n        \n        response = None\n        try:\n            if tools:\n                logger.debug(f\"Sending request to OpenAI with tools, model: {self.model_name}\")\n                response = await self.client.chat.completions.create(\n                    model=self.model_name,\n                    temperature=self.temperature,\n                    max_tokens=self.max_tokens,\n                    messages=messages,\n                    tools=tools,\n                    # response_format=response_format,\n                )\n            else:\n                logger.debug(f\"Sending request to OpenAI without tools, model: {self.model_name}\")\n                response = await self.client.chat.completions.create(\n                    model=self.model_name,\n                    temperature=self.temperature,\n                    max_tokens=self.max_tokens,\n                    messages=messages,\n                    # response_format=response_format\n                )\n            logger.info(f\"OpenAI response: {response}\")\n            return response.choices[0].message\n        except Exception as e:\n            logger.error(f\"[DEBUG 3] OpenAI API调用失败: {str(e)}\")\n            logger.error(f\"[DEBUG 3] 发送的消息详情: {messages}\")\n            raise\n",
      "methods": [
        "<module>.OpenAILLM.__init__",
        "<module>.OpenAILLM.ask"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/external/llm/openai_llm.py",
      "name": "OpenAIImageLLM",
      "qualname": "<module>.OpenAIImageLLM",
      "source": "class OpenAIImageLLM(OpenAILLM):\n    def __init__(self):\n        settings = get_settings()\n        self.client = AsyncOpenAI(\n            api_key=settings.image_api_key,\n            base_url=settings.image_api_base\n        )\n        \n        self.model_name = settings.image_model_name\n        self.temperature = settings.temperature\n        self.max_tokens = settings.max_tokens\n        logger.info(f\"Initialized OpenAI Image LLM with model: {self.model_name}\")\n",
      "methods": [
        "<module>.OpenAIImageLLM.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/tasks/cleanup_task.py",
      "name": "SubscriptionCleanupTask",
      "qualname": "<module>.SubscriptionCleanupTask",
      "source": "class SubscriptionCleanupTask:\n    \"\"\"订阅清理后台任务\"\"\"\n\n    def __init__(self, agent_service: AgentService, cleanup_interval_minutes: int = 30, timeout_minutes: int = 60):\n        self.agent_service = agent_service\n        self.cleanup_interval_minutes = cleanup_interval_minutes\n        self.timeout_minutes = timeout_minutes\n        self.task: Optional[asyncio.Task] = None\n        self.running = False\n\n    async def start(self) -> None:\n        \"\"\"启动清理任务\"\"\"\n        if self.running:\n            logger.warning(\"Cleanup task is already running\")\n            return\n\n        self.running = True\n        self.task = asyncio.create_task(self._cleanup_loop())\n        logger.info(f\"Started subscription cleanup task with interval {self.cleanup_interval_minutes} minutes\")\n\n    async def stop(self) -> None:\n        \"\"\"停止清理任务\"\"\"\n        if not self.running:\n            return\n\n        self.running = False\n        if self.task:\n            self.task.cancel()\n            try:\n                await self.task\n            except asyncio.CancelledError:\n                pass\n            self.task = None\n\n        logger.info(\"Stopped subscription cleanup task\")\n\n    async def _cleanup_loop(self) -> None:\n        \"\"\"清理循环\"\"\"\n        try:\n            while self.running:\n                try:\n                    # 执行清理\n                    cleaned_count = await self.agent_service.cleanup_inactive_subscriptions(self.timeout_minutes)\n                    if cleaned_count > 0:\n                        logger.info(f\"Cleaned up {cleaned_count} inactive subscriptions\")\n\n                    # 等待下次清理\n                    await asyncio.sleep(self.cleanup_interval_minutes * 60)\n\n                except Exception as e:\n                    logger.error(f\"Error in cleanup task: {str(e)}\")\n                    # 出错后等待一段时间再重试\n                    await asyncio.sleep(60)\n\n        except asyncio.CancelledError:\n            logger.info(\"Cleanup task was cancelled\")\n            raise\n        except Exception as e:\n            logger.error(f\"Cleanup task failed: {str(e)}\")\n        finally:\n            self.running = False\n",
      "methods": [
        "<module>.SubscriptionCleanupTask.__init__",
        "<module>.SubscriptionCleanupTask.start",
        "<module>.SubscriptionCleanupTask.stop",
        "<module>.SubscriptionCleanupTask._cleanup_loop"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "JSONType",
      "qualname": "<module>.JSONType",
      "source": "class JSONType(TypeDecorator):\n    \"\"\"JSON类型装饰器，用于存储JSON数据\"\"\"\n    impl = VARCHAR\n    cache_ok = True\n\n    def process_bind_param(self, value, dialect):\n        if value is not None:\n            return safe_json_dumps(value)\n        return value\n\n    def process_result_value(self, value, dialect):\n        if value is not None:\n            return json.loads(value)\n        return value\n",
      "methods": [
        "<module>.JSONType.process_bind_param",
        "<module>.JSONType.process_result_value"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "UserORM",
      "qualname": "<module>.UserORM",
      "source": "class UserORM(Base):\n    \"\"\"用户ORM模型\"\"\"\n    __tablename__ = \"users\"\n    \n    id = Column(String(255), primary_key=True)\n    email = Column(String(255), unique=True, nullable=False, index=True)\n    name = Column(String(255), nullable=True)\n    groups = Column(JSONType, default=list)\n    created_at = Column(DateTime, default=datetime.now)\n    last_login = Column(DateTime, default=datetime.now)\n    \n    # 关联关系\n    tasks = relationship(\"UserTaskORM\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n    files = relationship(\"UserFileORM\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "UserTaskORM",
      "qualname": "<module>.UserTaskORM",
      "source": "class UserTaskORM(Base):\n    \"\"\"用户任务ORM模型\"\"\"\n    __tablename__ = \"user_tasks\"\n    \n    id = Column(String(255), primary_key=True)\n    user_id = Column(String(255), ForeignKey(\"users.id\"), nullable=False, index=True)\n    agent_id = Column(String(255), nullable=False)\n    title = Column(String(500), nullable=False)\n    status = Column(String(50), nullable=False)\n    created_at = Column(DateTime, default=datetime.now)\n    completed_at = Column(DateTime, nullable=True)\n    meta_data = Column(JSONType, default=dict)\n    \n    # 关联关系\n    user = relationship(\"UserORM\", back_populates=\"tasks\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "UserFileORM",
      "qualname": "<module>.UserFileORM",
      "source": "class UserFileORM(Base):\n    \"\"\"用户文件ORM模型\"\"\"\n    __tablename__ = \"user_files\"\n    \n    id = Column(String(255), primary_key=True)\n    user_id = Column(String(255), ForeignKey(\"users.id\"), nullable=False, index=True)\n    filename = Column(String(500), nullable=False)\n    path = Column(String(1000), nullable=False)\n    created_at = Column(DateTime, default=datetime.now)\n    updated_at = Column(DateTime, default=datetime.now)\n    meta_data = Column(JSONType, default=dict)\n    \n    # 关联关系\n    user = relationship(\"UserORM\", back_populates=\"files\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "ConversationHistoryORM",
      "qualname": "<module>.ConversationHistoryORM",
      "source": "class ConversationHistoryORM(Base):\n    \"\"\"会话历史ORM模型\"\"\"\n    __tablename__ = \"conversation_histories\"\n    \n    agent_id = Column(String(255), primary_key=True)\n    user_id = Column(String(255), nullable=True, index=True)\n    flow_id = Column(String(255), nullable=False, default=\"plan_act\")\n    title = Column(String(500), nullable=True)\n    created_at = Column(DateTime, default=datetime.now)\n    updated_at = Column(DateTime, default=datetime.now)\n    \n    # 关联关系\n    events = relationship(\"ConversationEventORM\", back_populates=\"history\", cascade=\"all, delete-orphan\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "ConversationEventORM",
      "qualname": "<module>.ConversationEventORM",
      "source": "class ConversationEventORM(Base):\n    \"\"\"会话事件ORM模型\"\"\"\n    __tablename__ = \"conversation_events\"\n    \n    id = Column(String(255), primary_key=True)\n    agent_id = Column(String(255), ForeignKey(\"conversation_histories.agent_id\"), nullable=False)\n    event_type = Column(String(100), nullable=False)\n    event_data = Column(JSONType, nullable=False)\n    timestamp = Column(DateTime, default=datetime.now)\n    sequence = Column(Integer, nullable=False)\n    \n    # 关联关系\n    history = relationship(\"ConversationHistoryORM\", back_populates=\"events\")\n    \n    # 复合索引和唯一约束\n    __table_args__ = (\n        Index('idx_agent_sequence', 'agent_id', 'sequence'),\n        Index('idx_agent_timestamp', 'agent_id', 'timestamp'),\n        UniqueConstraint('agent_id', 'sequence', name='uq_agent_sequence'),\n    )\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "EventBroadcasterORM",
      "qualname": "<module>.EventBroadcasterORM",
      "source": "class EventBroadcasterORM(Base):\n    \"\"\"事件广播器ORM模型\"\"\"\n    __tablename__ = \"event_broadcasters\"\n    \n    agent_id = Column(String(255), primary_key=True)\n    current_sequence = Column(Integer, default=0)\n    max_buffer_size = Column(Integer, default=1000)\n    created_at = Column(DateTime, default=datetime.now)\n    updated_at = Column(DateTime, default=datetime.now)\n    \n    # 关联关系\n    buffered_events = relationship(\"BufferedEventORM\", back_populates=\"broadcaster\", cascade=\"all, delete-orphan\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "BufferedEventORM",
      "qualname": "<module>.BufferedEventORM",
      "source": "class BufferedEventORM(Base):\n    \"\"\"缓冲事件ORM模型\"\"\"\n    __tablename__ = \"buffered_events\"\n    \n    id = Column(String(255), primary_key=True)\n    agent_id = Column(String(255), ForeignKey(\"event_broadcasters.agent_id\"), nullable=False)\n    sequence = Column(Integer, nullable=False)\n    event_type = Column(String(100), nullable=False)\n    event_data = Column(JSONType, nullable=False)\n    timestamp = Column(DateTime, default=datetime.now)\n    \n    # 关联关系\n    broadcaster = relationship(\"EventBroadcasterORM\", back_populates=\"buffered_events\")\n    \n    # 复合索引\n    __table_args__ = (\n        Index('idx_agent_sequence_buffered', 'agent_id', 'sequence'),\n    )\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "EventSubscriberORM",
      "qualname": "<module>.EventSubscriberORM",
      "source": "class EventSubscriberORM(Base):\n    \"\"\"事件订阅者ORM模型\"\"\"\n    __tablename__ = \"event_subscribers\"\n    \n    subscriber_id = Column(String(255), primary_key=True)\n    agent_id = Column(String(255), nullable=False, index=True)\n    created_at = Column(DateTime, default=datetime.now)\n    last_activity = Column(DateTime, default=datetime.now)\n    is_active = Column(String(10), default=\"true\")  # 使用字符串存储布尔值\n    heartbeat_timeout_seconds = Column(Integer, default=300)  # 5分钟超时\n    \n    # 复合索引\n    __table_args__ = (\n        Index('idx_agent_active', 'agent_id', 'is_active'),\n        Index('idx_last_activity', 'last_activity'),\n    )\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/models.py",
      "name": "AgentContextORM",
      "qualname": "<module>.AgentContextORM",
      "source": "class AgentContextORM(Base):\n    \"\"\"Agent上下文ORM模型\"\"\"\n    __tablename__ = \"agent_contexts\"\n    \n    agent_id = Column(String(255), primary_key=True)\n    user_id = Column(String(255), nullable=True, index=True)\n    flow_id = Column(String(255), nullable=False, default=\"plan_act\")\n    sandbox_id = Column(String(255), nullable=True, index=True)\n    status = Column(String(50), nullable=False, default=\"created\", index=True)\n    last_message = Column(Text, nullable=True)\n    last_message_time = Column(Integer, nullable=True)\n    created_at = Column(DateTime, default=datetime.now)\n    updated_at = Column(DateTime, default=datetime.now)\n    meta_data = Column(JSONType, default=dict)\n    \n    # Agent模型数据（序列化存储）\n    agent_data = Column(JSONType, nullable=False)\n    \n    # 复合索引\n    __table_args__ = (\n        Index('idx_user_status', 'user_id', 'status'),\n        Index('idx_status_updated', 'status', 'updated_at'),\n        Index('idx_user_updated', 'user_id', 'updated_at'),\n    ) ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/backend/app/infrastructure/database/connection.py",
      "name": "DatabaseManager",
      "qualname": "<module>.DatabaseManager",
      "source": "class DatabaseManager:\n    \"\"\"数据库管理器 - 单例模式管理engine和session\"\"\"\n    \n    _instance: Optional['DatabaseManager'] = None\n    _engine: Optional[AsyncEngine] = None\n    _session_maker: dict[str, async_sessionmaker] = {}\n    _readonly_session_maker: dict[str, async_sessionmaker] = {}\n    \n    def __new__(cls) -> 'DatabaseManager':\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n    \n    def get_engine(self) -> AsyncEngine:\n        \"\"\"获取数据库引擎（单例）\"\"\"\n        if self._engine is None:\n            settings = get_settings()\n            self._engine = create_async_engine(\n                settings.database_url, \n                echo=False,\n                # 连接池配置\n                pool_size=10,\n                max_overflow=20,\n                pool_pre_ping=True,\n                pool_recycle=3600\n            )\n            logger.info(\"数据库引擎已创建\")\n        return self._engine\n    \n    async def get_session_maker(self, engine: AsyncEngine) -> async_sessionmaker:\n        \"\"\"获取读写session maker（单例）\"\"\"\n        if engine not in self._session_maker:\n            self._session_maker[engine] = async_sessionmaker(\n                engine,\n                class_=AsyncSession,\n                expire_on_commit=False\n            )\n        return self._session_maker[engine]\n    \n    async def get_readonly_session_maker(self, engine: AsyncEngine) -> async_sessionmaker:\n        \"\"\"获取只读session maker（单例）\"\"\"\n        if engine not in self._readonly_session_maker:\n            self._readonly_session_maker[engine] = async_sessionmaker(\n                engine,\n                class_=AsyncSession,\n                expire_on_commit=False,\n                # 只读会话配置\n                autoflush=False,  # 禁用自动刷新\n                autocommit=False  # 禁用自动提交\n            )\n        return self._readonly_session_maker[engine]\n    \n    async def close(self):\n        \"\"\"关闭数据库连接\"\"\"\n        if self._engine:\n            await self._engine.dispose()\n            self._engine = None\n            self._session_maker = {}\n            self._readonly_session_maker = {}\n            logger.info(\"数据库连接已关闭\")\n",
      "methods": [
        "<module>.DatabaseManager.__new__",
        "<module>.DatabaseManager.get_engine",
        "<module>.DatabaseManager.get_session_maker",
        "<module>.DatabaseManager.get_readonly_session_maker",
        "<module>.DatabaseManager.close"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileReadResult",
      "qualname": "<module>.FileReadResult",
      "source": "class FileReadResult(BaseModel):\n    \"\"\"File read result\"\"\"\n    content: str = Field(..., description=\"File content\")\n    file: str = Field(..., description=\"Path of the read file\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileWriteResult",
      "qualname": "<module>.FileWriteResult",
      "source": "class FileWriteResult(BaseModel):\n    \"\"\"File write result\"\"\"\n    file: str = Field(..., description=\"Path of the written file\")\n    bytes_written: int = Field(..., description=\"Number of bytes written\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileReplaceResult",
      "qualname": "<module>.FileReplaceResult",
      "source": "class FileReplaceResult(BaseModel):\n    \"\"\"File replace result\"\"\"\n    file: str = Field(..., description=\"Path of the modified file\")\n    replaced_count: int = Field(..., description=\"Number of replacements made\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileSearchResult",
      "qualname": "<module>.FileSearchResult",
      "source": "class FileSearchResult(BaseModel):\n    \"\"\"File search result\"\"\"\n    file: str = Field(..., description=\"Path of the searched file\")\n    matches: List[str] = Field(..., description=\"Lines matched\")\n    line_numbers: List[int] = Field(..., description=\"Line numbers with matches\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileFindResult",
      "qualname": "<module>.FileFindResult",
      "source": "class FileFindResult(BaseModel):\n    \"\"\"File find result\"\"\"\n    path: str = Field(..., description=\"Path that was searched\")\n    files: List[str] = Field(..., description=\"Files found\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileUploadResponse",
      "qualname": "<module>.FileUploadResponse",
      "source": "class FileUploadResponse(BaseModel):\n    \"\"\"File upload response\"\"\"\n    file: str = Field(..., description=\"Absolute path of the uploaded file\")\n    size: int = Field(..., description=\"Size of the uploaded file in bytes\")\n    is_executable: bool = Field(False, description=\"Whether the file is executable\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/file.py",
      "name": "FileExistsResult",
      "qualname": "<module>.FileExistsResult",
      "source": "class FileExistsResult(BaseModel):\n    \"\"\"File exists result\"\"\"\n    path: str = Field(..., description=\"Path of the checked file\")\n    exists: bool = Field(..., description=\"Whether the file exists\")\n    is_file: Optional[bool] = Field(None, description=\"Whether it is a file (if exists)\")\n    is_dir: Optional[bool] = Field(None, description=\"Whether it is a directory (if exists)\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ConsoleRecord",
      "qualname": "<module>.ConsoleRecord",
      "source": "class ConsoleRecord(BaseModel):\n    \"\"\"Shell command console record model\"\"\"\n    ps1: str = Field(..., description=\"Command prompt\")\n    command: str = Field(..., description=\"Executed command\")\n    output: str = Field(default=\"\", description=\"Command output\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ShellTask",
      "qualname": "<module>.ShellTask",
      "source": "class ShellTask(BaseModel):\n    \"\"\"Shell task model\"\"\"\n    id: str = Field(..., description=\"Task unique identifier\")\n    command: str = Field(..., description=\"Executed command\")\n    status: str = Field(..., description=\"Task status\")\n    created_at: str = Field(..., description=\"Task creation time\")\n    output: Optional[str] = Field(None, description=\"Task output\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ShellCommandResult",
      "qualname": "<module>.ShellCommandResult",
      "source": "class ShellCommandResult(BaseModel):\n    \"\"\"Shell command execution result model\"\"\"\n    session_id: str = Field(..., description=\"Shell session ID\")\n    command: str = Field(..., description=\"Executed command\")\n    status: str = Field(..., description=\"Command execution status\")\n    returncode: Optional[int] = Field(None, description=\"Process return code, only has value when status is completed\")\n    output: Optional[str] = Field(None, description=\"Command execution output, only has value when status is completed\")\n    console: Optional[List[ConsoleRecord]] = Field(None, description=\"Console command records\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ShellViewResult",
      "qualname": "<module>.ShellViewResult",
      "source": "class ShellViewResult(BaseModel):\n    \"\"\"Shell session content view result model\"\"\"\n    output: str = Field(..., description=\"Shell session output content\")\n    session_id: str = Field(..., description=\"Shell session ID\")\n    console: Optional[List[ConsoleRecord]] = Field(None, description=\"Console command records\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ShellWaitResult",
      "qualname": "<module>.ShellWaitResult",
      "source": "class ShellWaitResult(BaseModel):\n    \"\"\"Process wait result model\"\"\"\n    returncode: int = Field(..., description=\"Process return code\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ShellWriteResult",
      "qualname": "<module>.ShellWriteResult",
      "source": "class ShellWriteResult(BaseModel):\n    \"\"\"Process input write result model\"\"\"\n    status: str = Field(..., description=\"Write status\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/shell.py",
      "name": "ShellKillResult",
      "qualname": "<module>.ShellKillResult",
      "source": "class ShellKillResult(BaseModel):\n    \"\"\"Process termination result model\"\"\"\n    status: str = Field(..., description=\"Process status\")\n    returncode: int = Field(..., description=\"Process return code\") ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/supervisor.py",
      "name": "ProcessInfo",
      "qualname": "<module>.ProcessInfo",
      "source": "class ProcessInfo(BaseModel):\n    \"\"\"Process information model\"\"\"\n    name: str = Field(..., description=\"Process name\")\n    group: str = Field(..., description=\"Process group\")\n    description: str = Field(..., description=\"Process description\")\n    start: int = Field(..., description=\"Start timestamp\")\n    stop: int = Field(..., description=\"Stop timestamp\")\n    now: int = Field(..., description=\"Current timestamp\")\n    state: int = Field(..., description=\"State code\")\n    statename: str = Field(..., description=\"State name\")\n    spawnerr: str = Field(..., description=\"Spawn error\")\n    exitstatus: int = Field(..., description=\"Exit status code\")\n    logfile: str = Field(..., description=\"Log file\")\n    stdout_logfile: str = Field(..., description=\"Standard output log file\")\n    stderr_logfile: str = Field(..., description=\"Standard error log file\")\n    pid: int = Field(..., description=\"Process ID\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/supervisor.py",
      "name": "SupervisorActionResult",
      "qualname": "<module>.SupervisorActionResult",
      "source": "class SupervisorActionResult(BaseModel):\n    \"\"\"Supervisor operation result model\"\"\"\n    status: str = Field(..., description=\"Operation status\")\n    result: Optional[List[str]] = Field(None, description=\"Operation result\")\n    stop_result: Optional[List[str]] = Field(None, description=\"Stop result\")\n    start_result: Optional[List[str]] = Field(None, description=\"Start result\")\n    shutdown_result: Optional[List[str]] = Field(None, description=\"Shutdown result\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/supervisor.py",
      "name": "SupervisorTimeout",
      "qualname": "<module>.SupervisorTimeout",
      "source": "class SupervisorTimeout(BaseModel):\n    \"\"\"Supervisor timeout model\"\"\"\n    status: Optional[str] = Field(None, description=\"Timeout setting status\")\n    active: bool = Field(False, description=\"Whether timeout is active\")\n    shutdown_time: Optional[str] = Field(None, description=\"Shutdown time\")\n    timeout_minutes: Optional[float] = Field(None, description=\"Timeout duration (minutes)\")\n    remaining_seconds: Optional[float] = Field(None, description=\"Remaining seconds\") ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "Language",
      "qualname": "<module>.Language",
      "source": "class Language(str, Enum):\n    \"\"\"Supported MCP server languages\"\"\"\n    PYTHON = \"python\"\n    NODE = \"node\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpInstallRequest",
      "qualname": "<module>.McpInstallRequest",
      "source": "class McpInstallRequest(BaseModel):\n    \"\"\"Request model for installing MCP server\"\"\"\n    pkg: str = Field(..., description=\"Package name from PyPI or npm\")\n    lang: Language = Field(default=Language.PYTHON, description=\"Programming language\")\n    args: Optional[List[str]] = Field(default=None, description=\"Additional installation arguments\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpInstallResponse",
      "qualname": "<module>.McpInstallResponse",
      "source": "class McpInstallResponse(BaseModel):\n    \"\"\"Response model for MCP server installation\"\"\"\n    status: Literal[\"ok\", \"error\"] = Field(..., description=\"Installation status\")\n    message: Optional[str] = Field(None, description=\"Additional message\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpServerInfo",
      "qualname": "<module>.McpServerInfo",
      "source": "class McpServerInfo(BaseModel):\n    \"\"\"Information about an MCP server\"\"\"\n    pkg: str = Field(..., description=\"Package name\")\n    lang: Language = Field(..., description=\"Programming language\")\n    alive: bool = Field(..., description=\"Whether the server is alive\")\n    pid: Optional[int] = Field(None, description=\"Process ID\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpListResponse",
      "qualname": "<module>.McpListResponse",
      "source": "class McpListResponse(BaseModel):\n    \"\"\"Response model for listing MCP servers\"\"\"\n    servers: List[McpServerInfo] = Field(..., description=\"List of MCP servers\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpUninstallResponse",
      "qualname": "<module>.McpUninstallResponse",
      "source": "class McpUninstallResponse(BaseModel):\n    \"\"\"Response model for uninstalling MCP server\"\"\"\n    status: str = Field(..., description=\"Uninstallation status\")\n    message: Optional[str] = Field(None, description=\"Additional message\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpProxyResponse",
      "qualname": "<module>.McpProxyResponse",
      "source": "class McpProxyResponse(BaseModel):\n    \"\"\"Response model for MCP proxy requests\"\"\"\n    content: bytes = Field(..., description=\"Raw response content\")\n    media_type: str = Field(default=\"application/json\", description=\"Media type\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/models/mcp.py",
      "name": "McpHealthResponse",
      "qualname": "<module>.McpHealthResponse",
      "source": "class McpHealthResponse(BaseModel):\n    \"\"\"Response model for MCP server health check\"\"\"\n    pkg: str = Field(..., description=\"Package name\")\n    alive: bool = Field(..., description=\"Whether the server is alive\")\n    uptime: Optional[float] = Field(None, description=\"Server uptime in seconds\") ",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/file.py",
      "name": "FileService",
      "qualname": "<module>.FileService",
      "source": "class FileService:\n    \"\"\"File Operation Service\"\"\"\n\n    async def read_file(self, file: str, start_line: Optional[int] = None, \n                 end_line: Optional[int] = None, sudo: bool = False) -> FileReadResult:\n        \"\"\"\n        Asynchronously read file content\n        \n        Args:\n            file: Absolute file path\n            start_line: Starting line (0-based)\n            end_line: Ending line (not included)\n            sudo: Whether to use sudo privileges\n        \"\"\"\n        # Check if file exists\n        if not os.path.exists(file) and not sudo:\n            # 返回可读错误文本而不是抛异常\n            return FileReadResult(content=f\"File does not exist: {file}\", file=file)\n\n        # Helper: hex preview for binary files (first N bytes)\n        def hex_preview(data: bytes, limit: int = 256) -> str:\n            head = data[:limit]\n            hex_str = binascii.hexlify(head).decode(\"ascii\")\n            grouped = \" \".join(hex_str[i:i+2] for i in range(0, len(hex_str), 2))\n            note = \"\\n...[truncated hex preview]...\" if len(data) > limit else \"\"\n            return f\"[binary file detected; showing first {len(head)} bytes in hex]\\n{grouped}{note}\"\n\n        # Helper: attempt robust decoding using charset-normalizer\n        def robust_decode(data: bytes) -> str:\n            try:\n                matches = cn_from_bytes(data)\n                best = matches.best() if hasattr(matches, \"best\") else None\n                if best and getattr(best, \"encoding\", None):\n                    encoding = best.encoding\n                    try:\n                        return data.decode(encoding)\n                    except Exception:\n                        # Fallback to replace if strict decoding fails\n                        return data.decode(encoding, errors=\"replace\")\n            except Exception:\n                # If detection fails, continue to common fallbacks\n                pass\n\n            # 4) As a last resort, decode with replacement to avoid exceptions\n            return hex_preview(data)\n\n        try:\n            raw: bytes\n            if sudo:\n                # Read with sudo (bytes)\n                command = f\"sudo cat '{file}'\"\n                process = await asyncio.create_subprocess_shell(\n                    command,\n                    stdout=asyncio.subprocess.PIPE,\n                    stderr=asyncio.subprocess.PIPE\n                )\n                stdout, stderr = await process.communicate()\n                if process.returncode != 0:\n                    # Return a readable message rather than throwing generic 500\n                    return FileReadResult(content=f\"Failed to read file: {stderr.decode(errors='replace')}\", file=file)\n                raw = stdout\n            else:\n                # Asynchronously read file bytes to avoid UnicodeDecodeError\n                def read_file_bytes():\n                    try:\n                        with open(file, 'rb') as f:\n                            return f.read()\n                    except Exception as e:\n                        return str(e).encode()\n                raw = await asyncio.to_thread(read_file_bytes)\n\n            # Decide how to present content\n            content = robust_decode(raw)\n\n            # Process line range on decoded content\n            if start_line is not None or end_line is not None:\n                lines = content.splitlines()\n                start = start_line if start_line is not None else 0\n                end = end_line if end_line is not None else len(lines)\n                content = '\\n'.join(lines[start:end])\n\n            return FileReadResult(\n                content=content,\n                file=file\n            )\n        except Exception as e:\n            # Fallback: never explode with 500 due to decoding; return readable error text\n            safe_message = f\"Failed to read file safely: {str(e)}\"\n            return FileReadResult(content=safe_message, file=file)\n\n    async def write_file(self, file: str, content: str, append: bool = False,\n                  leading_newline: bool = False, trailing_newline: bool = False,\n                  sudo: bool = False) -> FileWriteResult:\n        \"\"\"\n        Asynchronously write file content\n        \n        Args:\n            file: Absolute file path\n            content: Content to write\n            append: Whether to append mode\n            leading_newline: Whether to add a leading newline\n            trailing_newline: Whether to add a trailing newline\n            sudo: Whether to use sudo privileges\n        \"\"\"\n        try:\n            # Prepare content\n            if leading_newline:\n                content = '\\n' + content\n            if trailing_newline:\n                content = content + '\\n'\n            \n            bytes_written = 0\n            \n            # Write with sudo\n            if sudo:\n                mode = '>>' if append else '>'\n                # Create temporary file\n                temp_file = f\"/tmp/file_write_{os.getpid()}.tmp\"\n                \n                # Asynchronously write to temporary file\n                def write_temp_file():\n                    with open(temp_file, 'w', encoding='utf-8') as f:\n                        f.write(content)\n                    return len(content.encode('utf-8'))\n                \n                bytes_written = await asyncio.to_thread(write_temp_file)\n                \n                # Use sudo to write temporary file content to target file\n                command = f\"sudo bash -c \\\"cat {temp_file} {mode} '{file}'\\\"\"\n                process = await asyncio.create_subprocess_shell(\n                    command,\n                    stdout=asyncio.subprocess.PIPE,\n                    stderr=asyncio.subprocess.PIPE\n                )\n                stdout, stderr = await process.communicate()\n                \n                if process.returncode != 0:\n                    return FileWriteResult(file=file, bytes_written=0)\n                \n                # Clean up temporary file\n                os.unlink(temp_file)\n            else:\n                # Ensure directory exists\n                os.makedirs(os.path.dirname(file), exist_ok=True)\n                \n                # Asynchronously write file\n                def write_file_async():\n                    mode = 'a' if append else 'w'\n                    with open(file, mode, encoding='utf-8') as f:\n                        return f.write(content)\n                \n                bytes_written = await asyncio.to_thread(write_file_async)\n            \n            return FileWriteResult(\n                file=file,\n                bytes_written=bytes_written\n            )\n        except Exception:\n            return FileWriteResult(file=file, bytes_written=0)\n\n    async def str_replace(self, file: str, old_str: str, new_str: str, \n                   sudo: bool = False) -> FileReplaceResult:\n        \"\"\"\n        Asynchronously replace string in file\n        \n        Args:\n            file: Absolute file path\n            old_str: Original string to be replaced\n            new_str: New replacement string\n            sudo: Whether to use sudo privileges\n        \"\"\"\n        # First read file content\n        file_result = await self.read_file(file, sudo=sudo)\n        content = file_result.content\n        \n        # Calculate replacement count\n        replaced_count = content.count(old_str)\n        if replaced_count == 0:\n            return FileReplaceResult(\n                file=file,\n                replaced_count=0\n            )\n        \n        # Perform replacement\n        new_content = content.replace(old_str, new_str)\n        \n        # Write back to file\n        await self.write_file(file, new_content, sudo=sudo)\n        \n        return FileReplaceResult(\n            file=file,\n            replaced_count=replaced_count\n        )\n\n    async def find_in_content(self, file: str, regex: str, \n                       sudo: bool = False) -> FileSearchResult:\n        \"\"\"\n        Asynchronously search in file content\n        \n        Args:\n            file: Absolute file path\n            regex: Regular expression pattern\n            sudo: Whether to use sudo privileges\n        \"\"\"\n        # Read file\n        file_result = await self.read_file(file, sudo=sudo)\n        content = file_result.content\n        \n        # Process line by line\n        lines = content.splitlines()\n        matches = []\n        line_numbers = []\n        \n        # Compile regular expression\n        try:\n            pattern = re.compile(regex)\n        except Exception:\n            return FileSearchResult(file=file, matches=[], line_numbers=[])\n        \n        # Find matches (use async processing for possibly large files)\n        def process_lines():\n            nonlocal matches, line_numbers\n            for i, line in enumerate(lines):\n                if pattern.search(line):\n                    matches.append(line)\n                    line_numbers.append(i)\n        \n        await asyncio.to_thread(process_lines)\n        \n        return FileSearchResult(\n            file=file,\n            matches=matches,\n            line_numbers=line_numbers\n        )\n\n    async def find_by_name(self, path: str, glob_pattern: str) -> FileFindResult:\n        \"\"\"\n        Asynchronously find files by name pattern\n        \n        Args:\n            path: Directory path to search\n            glob_pattern: File name pattern (glob syntax)\n        \"\"\"\n        # Check if path exists\n        if not os.path.exists(path):\n            return FileFindResult(path=path, files=[])\n        \n        # Asynchronously find files\n        def glob_async():\n            search_pattern = os.path.join(path, glob_pattern)\n            return glob.glob(search_pattern, recursive=True)\n        \n        files = await asyncio.to_thread(glob_async)\n        \n        return FileFindResult(\n            path=path,\n            files=files\n        )\n\n    async def upload_file(self, file_content: bytes, \n                   destination_path: str, make_executable: bool = False) -> FileUploadResponse:\n        \"\"\"\n        Asynchronously upload a binary file to the filesystem\n        \n        Args:\n            file_content: Binary content of the file\n            destination_path: Absolute path to save the file to\n            make_executable: Whether to make the file executable\n            \n        Returns:\n            FileUploadResponse with the result of the operation\n        \"\"\"\n        try:\n            # Ensure the directory exists\n            os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n            \n            # Write the file\n            def write_file_async():\n                with open(destination_path, 'wb') as f:\n                    f.write(file_content)\n                \n                # Make executable if requested\n                if make_executable:\n                    mode = os.stat(destination_path).st_mode\n                    os.chmod(destination_path, mode | 0o111)  # Add execute permission for all\n                \n                return os.path.getsize(destination_path)\n                \n            size = await asyncio.to_thread(write_file_async)\n            \n            # Check if the file is executable\n            is_executable = False\n            if os.path.exists(destination_path):\n                mode = os.stat(destination_path).st_mode\n                is_executable = bool(mode & 0o111)  # Check if any execute bit is set\n            \n            return FileUploadResponse(\n                file=destination_path,\n                size=size,\n                is_executable=is_executable\n            )\n        except Exception:\n            return FileUploadResponse(file=destination_path, size=0, is_executable=False)\n\n    async def download_file(self, file_path: str) -> bytes:\n        \"\"\"\n        Asynchronously read binary file content\n        \n        Args:\n            file_path: Absolute path of the file to download\n            \n        Returns:\n            Binary content of the file\n        \"\"\"\n        # Check if file exists\n        if not os.path.exists(file_path):\n            return b\"\"\n            \n        if not os.path.isfile(file_path):\n            return b\"\"\n            \n        try:\n            # Asynchronously read file\n            def read_file_async():\n                try:\n                    with open(file_path, 'rb') as f:\n                        return f.read()\n                except Exception:\n                    return b\"\"\n            \n            # Execute IO operation in thread pool\n            content = await asyncio.to_thread(read_file_async)\n            return content\n        except Exception:\n            return b\"\"\n\n    async def file_exists(self, path: str) -> FileExistsResult:\n        \"\"\"\n        检查文件或目录是否存在\n        \n        Args:\n            path: 要检查的文件或目录路径\n            \n        Returns:\n            FileExistsResult: 包含文件存在状态的结果\n        \"\"\"\n        try:\n            # 异步执行文件系统检查\n            def check_exists_async():\n                exists = os.path.exists(path)\n                is_file = os.path.isfile(path) if exists else None\n                is_dir = os.path.isdir(path) if exists else None\n                return exists, is_file, is_dir\n            \n            exists, is_file, is_dir = await asyncio.to_thread(check_exists_async)\n            \n            return FileExistsResult(\n                path=path,\n                exists=exists,\n                is_file=is_file,\n                is_dir=is_dir\n            )\n        except Exception:\n            return FileExistsResult(path=path, exists=False, is_file=None, is_dir=None)\n",
      "methods": [
        "<module>.FileService.read_file",
        "<module>.FileService.write_file",
        "<module>.FileService.str_replace",
        "<module>.FileService.find_in_content",
        "<module>.FileService.find_by_name",
        "<module>.FileService.upload_file",
        "<module>.FileService.download_file",
        "<module>.FileService.file_exists"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/mcp_fastmcp.py",
      "name": "FastMcpService",
      "qualname": "<module>.FastMcpService",
      "source": "class FastMcpService:\n    \"\"\"\n    FastMCP Service Manager\n    \n    Uses FastMCP client library to handle MCP server installation, lifecycle management, \n    and request proxying. Provides a simplified interface compared to manual implementation.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize FastMCP service with empty registry.\"\"\"\n        self._registry: Dict[str, tuple[Client, Language, bool]] = {}  # client, language, initialized\n        self._lock = asyncio.Lock()\n        \n    def _make_python_cmd(self, pkg: str, args: List[str] = None) -> List[str]:\n        \"\"\"\n        Build command to launch Python MCP server via uvx.\n        \n        Args:\n            pkg: PyPI package name\n            args: Additional command line arguments\n            \n        Returns:\n            Command line arguments\n        \"\"\"\n        cmd = [\"uvx\", pkg]\n        if args:\n            cmd.extend(args)\n        return cmd\n        \n    def _make_node_cmd(self, pkg: str, args: List[str] = None) -> List[str]:\n        \"\"\"\n        Build command to launch Node.js MCP server via npx.\n        \n        Args:\n            pkg: npm package name\n            args: Additional command line arguments\n            \n        Returns:\n            Command line arguments\n        \"\"\"\n        cmd = [\"npx\", pkg]\n        if args:\n            cmd.extend(args)\n        return cmd\n\n    async def install(self, request: McpInstallRequest) -> McpInstallResponse:\n        \"\"\"\n        Install and start MCP server using FastMCP client.\n        \n        Args:\n            request: Installation request with package info\n            \n        Returns:\n            Installation response with status\n        \"\"\"\n        async with self._lock:\n            pkg = request.pkg\n            lang = request.lang\n            args = request.args\n            \n            logger.info(f\"Installing MCP server: {pkg} ({lang}) with args: {args}\")\n            \n            # Check if already running\n            if pkg in self._registry:\n                client, _, _ = self._registry[pkg]\n                if client.is_connected():\n                    logger.info(f\"MCP server {pkg} already running\")\n                    return McpInstallResponse(\n                        status=\"ok\",\n                        message=f\"MCP server {pkg} is already running\"\n                    )\n                else:\n                    # Remove dead entry\n                    logger.info(f\"Removing dead MCP server entry: {pkg}\")\n                    await self._cleanup_client(client)\n                    del self._registry[pkg]\n            \n            try:\n                # Prepare environment variables\n                process_env = os.environ.copy()\n                logger.info(f\"Process environment: {process_env}\")\n\n                # Create FastMCP client with appropriate transport\n                if lang == Language.PYTHON:\n                    # 1. 优先尝试用 StdioTransport 直接启动\n                    logger.info(f\"Attempting direct launch for Python package '{pkg}' with StdioTransport.\")\n                    module_name = pkg.replace(\"-\", \"_\")\n                    direct_transport = StdioTransport(\"/opt/py313/bin/python\", [\"-m\", module_name] + (request.args or []), env=process_env)\n                    direct_client = Client(direct_transport, timeout=300.0)\n                    try:\n                        async with direct_client:\n                            await direct_client.ping()\n                        \n                        # 成功！注册客户端并立即返回\n                        logger.info(f\"Successfully started pre-installed Python server '{pkg}'.\")\n                        self._registry[pkg] = (direct_client, lang, False)\n                        return McpInstallResponse(\n                            status=\"ok\",\n                            message=f\"MCP server {pkg} started directly as pre-installed module.\"\n                        )\n                    except Exception as e:\n                        # 直接启动失败，记录警告并准备回退\n                        logger.info(f\"Direct launch for '{pkg}' failed: {e}. Falling back to uvx.\")\n                        try:\n                            await direct_client.close()  # 确保清理失败的尝试\n                        except Exception as close_exc:\n                            logger.warning(f\"Failed to cleanly close direct_client for '{pkg}': {close_exc}\")\n                        # --- 回退到 UVX (作为第二选择) ---\n                        # 2. 如果失败，则使用 UvxStdioTransport 启动\n                        # For Python packages, use UvxStdioTransport\n                        logger.info(f\"Attempting uvx launch for Python package '{pkg}' with UvxStdioTransport.\")\n                        transport = UvxStdioTransport(\n                            tool_name=pkg,\n                            env_vars=process_env,\n                            tool_args=args  # Pass arguments to the package\n                        )\n                        client = Client(transport, timeout=300.0)\n                elif lang == Language.NODE:\n                    # For Node packages, use NpxStdioTransport\n                    transport = NpxStdioTransport(\n                        package=pkg,\n                        env_vars=process_env,\n                        args=args  # Pass arguments to the package\n                    )\n                    client = Client(transport, timeout=300.0)\n                else:\n                    raise BadRequestException(f\"Unsupported language: {lang}\")\n                \n                logger.info(f\"MCP server: {pkg} using {type(transport).__name__}\")\n                \n                # Test connection by connecting and pinging\n                async with client:\n                    await client.ping()\n                    logger.info(f\"MCP server {pkg} started successfully\")\n                \n                # Store in registry (not initialized yet)\n                self._registry[pkg] = (client, lang, False)\n                \n                return McpInstallResponse(\n                    status=\"ok\",\n                    message=f\"MCP server {pkg} installed and started successfully\"\n                )\n                \n            except Exception as e:\n                logger.error(f\"Failed to start MCP server {pkg}: {e}\")\n                raise AppException(message=f\"Failed to start MCP server {pkg}: {str(e)}\")\n\n    async def uninstall(self, pkg: str) -> McpUninstallResponse:\n        \"\"\"\n        Stop and remove MCP server.\n        \n        Args:\n            pkg: Package name to uninstall\n            \n        Returns:\n            Uninstall response with status\n        \"\"\"\n        async with self._lock:\n            if pkg not in self._registry:\n                raise ResourceNotFoundException(f\"MCP server {pkg} not found\")\n            \n            client, _, _ = self._registry[pkg]\n            \n            try:\n                await self._cleanup_client(client)\n                del self._registry[pkg]\n                \n                logger.info(f\"MCP server {pkg} uninstalled successfully\")\n                return McpUninstallResponse(\n                    status=\"ok\",\n                    message=f\"MCP server {pkg} stopped and removed\"\n                )\n                \n            except Exception as e:\n                logger.error(f\"Error uninstalling MCP server {pkg}: {e}\")\n                # Remove from registry anyway\n                del self._registry[pkg]\n                return McpUninstallResponse(\n                    status=\"error\",\n                    message=f\"MCP server {pkg} removed with errors: {str(e)}\"\n                )\n\n    async def list_servers(self) -> McpListResponse:\n        \"\"\"\n        List all registered MCP servers.\n        \n        Returns:\n            List response with server information\n        \"\"\"\n        async with self._lock:\n            servers = []\n            dead_servers = []\n            \n            for pkg, (client, lang, _) in self._registry.items():\n                try:\n                    # Check if client is connected by attempting a quick ping\n                    async with client:\n                        await asyncio.wait_for(client.ping(), timeout=5.0)\n                        servers.append(McpServerInfo(\n                            pkg=pkg,\n                            lang=lang,\n                            alive=True,\n                            pid=getattr(client.transport, 'pid', None) if hasattr(client, 'transport') else None\n                        ))\n                except Exception as e:\n                    logger.warning(f\"MCP server {pkg} appears to be dead: {e}\")\n                    dead_servers.append(pkg)\n                    servers.append(McpServerInfo(\n                        pkg=pkg,\n                        lang=lang,\n                        alive=False,\n                        pid=None\n                    ))\n            \n            # Clean up dead servers\n            for pkg in dead_servers:\n                logger.info(f\"Cleaning up dead MCP server: {pkg}\")\n                client, _, _ = self._registry[pkg]\n                await self._cleanup_client(client)\n                del self._registry[pkg]\n            \n            return McpListResponse(servers=servers)\n\n    async def proxy_request(self, pkg: str, payload: bytes) -> bytes:\n        \"\"\"\n        Proxy JSON-RPC request to MCP server using FastMCP client.\n        \n        Args:\n            pkg: Package name of target server\n            payload: Raw JSON-RPC request bytes\n            \n        Returns:\n            Raw JSON-RPC response bytes\n        \"\"\"\n        # Get client without holding lock during request\n        client = None\n        async with self._lock:\n            if pkg not in self._registry:\n                raise ResourceNotFoundException(f\"MCP server {pkg} not found\")\n            \n            client, _, _ = self._registry[pkg]\n        \n        try:\n            # Parse the JSON-RPC request\n            request_data = json.loads(payload.decode('utf-8'))\n            method = request_data.get(\"method\")\n            params = request_data.get(\"params\", {})\n            request_id = request_data.get(\"id\")\n            \n            # Use FastMCP client methods for known MCP methods\n            async with client:\n                if method == \"tools/list\":\n                    result = await client.list_tools()\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"result\": {\"tools\": [tool.model_dump() for tool in result]}\n                    }\n                elif method == \"tools/call\":\n                    tool_name = params.get(\"name\")\n                    arguments = params.get(\"arguments\", {})\n                    result = await client.call_tool(tool_name, arguments)\n\n                    # The result might be a single CallToolResult object instead of a list of contents.\n                    # If so, we should iterate over its .content attribute.\n                    logger.info(f\"MCP tool call result type: {type(result)}, result: {result}\")\n                    iterable_content = result.content if hasattr(result, 'content') else result\n\n                    response = {\n                        \"jsonrpc\": \"2.0\", \n                        \"id\": request_id,\n                        \"result\": {\"content\": [content.model_dump() for content in iterable_content]}\n                    }\n                elif method == \"resources/list\":\n                    result = await client.list_resources()\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"result\": {\"resources\": [resource.model_dump() for resource in result]}\n                    }\n                elif method == \"resources/read\":\n                    uri = params.get(\"uri\")\n                    result = await client.read_resource(uri)\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"result\": {\"contents\": [content.model_dump() for content in result]}\n                    }\n                elif method == \"prompts/list\":\n                    result = await client.list_prompts()\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"result\": {\"prompts\": [prompt.model_dump() for prompt in result]}\n                    }\n                elif method == \"prompts/get\":\n                    name = params.get(\"name\")\n                    arguments = params.get(\"arguments\", {})\n                    result = await client.get_prompt(name, arguments)\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"result\": result.model_dump()\n                    }\n                elif method == \"initialize\":\n                    # Handle initialize specially - return synthetic response\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"result\": {\n                            \"protocolVersion\": \"2024-11-05\",\n                            \"capabilities\": {\n                                \"experimental\": {},\n                                \"prompts\": {\"listChanged\": False},\n                                \"tools\": {\"listChanged\": False},\n                                \"resources\": {\"listChanged\": False}\n                            },\n                            \"serverInfo\": {\n                                \"name\": pkg,\n                                \"version\": \"1.0.0\"\n                            }\n                        }\n                    }\n                else:\n                    # For unknown methods, return method not found error\n                    response = {\n                        \"jsonrpc\": \"2.0\",\n                        \"id\": request_id,\n                        \"error\": {\n                            \"code\": -32601,\n                            \"message\": f\"Method not found: {method}\"\n                        }\n                    }\n            \n            return json.dumps(response).encode('utf-8')\n            \n        except ClientError as e:\n            logger.error(f\"MCP client error for {pkg}: {e}\")\n            error_response = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": request_data.get(\"id\") if 'request_data' in locals() else None,\n                \"error\": {\n                    \"code\": -32603,\n                    \"message\": f\"Client error: {str(e)}\"\n                }\n            }\n            return json.dumps(error_response).encode('utf-8')\n        except McpError as e:\n            logger.error(f\"MCP protocol error for {pkg}: {e}\")\n            error_response = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": request_data.get(\"id\") if 'request_data' in locals() else None,\n                \"error\": {\n                    \"code\": -32603,\n                    \"message\": f\"MCP protocol error: {str(e)}\"\n                }\n            }\n            return json.dumps(error_response).encode('utf-8')\n        except json.JSONDecodeError as e:\n            logger.error(f\"Invalid JSON in request to {pkg}: {e}\")\n            error_response = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": None,\n                \"error\": {\n                    \"code\": -32700,\n                    \"message\": \"Parse error\"\n                }\n            }\n            return json.dumps(error_response).encode('utf-8')\n        except Exception as e:\n            logger.error(f\"Unexpected error proxying to {pkg}: {e}\")\n            error_response = {\n                \"jsonrpc\": \"2.0\",\n                \"id\": request_data.get(\"id\") if 'request_data' in locals() else None,\n                \"error\": {\n                    \"code\": -32603,\n                    \"message\": f\"Internal error: {str(e)}\"\n                }\n            }\n            return json.dumps(error_response).encode('utf-8')\n\n    async def health_check(self, pkg: str) -> McpHealthResponse:\n        \"\"\"\n        Check health of specific MCP server.\n        \n        Args:\n            pkg: Package name to check\n            \n        Returns:\n            Health response with status\n        \"\"\"\n        async with self._lock:\n            if pkg not in self._registry:\n                raise ResourceNotFoundException(f\"MCP server {pkg} not found\")\n            \n            client, _, _ = self._registry[pkg]\n            \n            try:\n                async with client:\n                    await asyncio.wait_for(client.ping(), timeout=5.0)\n                    return McpHealthResponse(\n                        pkg=pkg,\n                        alive=True,\n                        uptime=0.0  # FastMCP doesn't provide uptime directly\n                    )\n            except (ClientError, McpError) as e:\n                logger.warning(f\"Health check failed for {pkg}: {e}\")\n                return McpHealthResponse(\n                    pkg=pkg,\n                    alive=False,\n                    uptime=0.0\n                )\n            except Exception as e:\n                logger.warning(f\"Health check failed for {pkg}: {e}\")\n                return McpHealthResponse(\n                    pkg=pkg,\n                    alive=False,\n                    uptime=0.0\n                )\n\n    async def get_capabilities(self, pkg: str) -> dict:\n        \"\"\"\n        Get capabilities of specific MCP server.\n        \n        Args:\n            pkg: Package name to check\n            \n        Returns:\n            Server capabilities\n        \"\"\"\n        async with self._lock:\n            if pkg not in self._registry:\n                raise ResourceNotFoundException(f\"MCP server {pkg} not found\")\n            \n            client, _, _ = self._registry[pkg]\n            \n        try:\n            async with client:\n                capabilities = {\n                    \"tools\": {\"listChanged\": False, \"count\": 0},\n                    \"resources\": {\"listChanged\": False, \"count\": 0},\n                    \"prompts\": {\"listChanged\": False, \"count\": 0},\n                    \"experimental\": {}\n                }\n                \n                # Try to get tools (most common capability)\n                try:\n                    tools = await client.list_tools()\n                    capabilities[\"tools\"] = tools\n                except (ClientError, McpError) as e:\n                    logger.debug(f\"Server {pkg} does not support tools: {e}\")\n                \n                # Try to get resources (optional capability)\n                try:\n                    resources = await client.list_resources()\n                    capabilities[\"resources\"] = resources\n                except (ClientError, McpError) as e:\n                    logger.debug(f\"Server {pkg} does not support resources: {e}\")\n                \n                # Try to get prompts (optional capability)\n                try:\n                    prompts = await client.list_prompts()\n                    capabilities[\"prompts\"] = prompts\n                except (ClientError, McpError) as e:\n                    logger.debug(f\"Server {pkg} does not support prompts: {e}\")\n                \n                return capabilities\n        except Exception as e:\n            logger.error(f\"Failed to get capabilities for {pkg}: {e}\")\n            raise AppException(message=f\"Failed to get capabilities for {pkg}: {str(e)}\")\n\n    async def shutdown_all(self) -> None:\n        \"\"\"\n        Gracefully shutdown all MCP servers.\n        \"\"\"\n        async with self._lock:\n            if not self._registry:\n                return\n            \n            logger.info(f\"Shutting down {len(self._registry)} MCP servers\")\n            \n            # Stop all servers concurrently\n            tasks = []\n            for pkg, (client, _, _) in self._registry.items():\n                tasks.append(self._stop_server_safe(pkg, client))\n            \n            if tasks:\n                await asyncio.gather(*tasks, return_exceptions=True)\n            \n            # Clear registry\n            self._registry.clear()\n            logger.info(\"All MCP servers shutdown complete\")\n\n    async def _stop_server_safe(self, pkg: str, client: Client) -> None:\n        \"\"\"\n        Safely stop a single MCP server with error handling.\n        \n        Args:\n            pkg: Package name for logging\n            client: FastMCP client to stop\n        \"\"\"\n        try:\n            await self._cleanup_client(client)\n            logger.info(f\"Stopped MCP server: {pkg}\")\n        except Exception as e:\n            logger.error(f\"Error stopping MCP server {pkg}: {e}\")\n\n    async def _cleanup_client(self, client: Client) -> None:\n        \"\"\"\n        Clean up FastMCP client resources.\n        \n        Args:\n            client: Client to clean up\n        \"\"\"\n        try:\n            if hasattr(client, 'close'):\n                await client.close()\n        except Exception as e:\n            logger.debug(f\"Error during client cleanup: {e}\")\n",
      "methods": [
        "<module>.FastMcpService.__init__",
        "<module>.FastMcpService._make_python_cmd",
        "<module>.FastMcpService._make_node_cmd",
        "<module>.FastMcpService.install",
        "<module>.FastMcpService.uninstall",
        "<module>.FastMcpService.list_servers",
        "<module>.FastMcpService.proxy_request",
        "<module>.FastMcpService.health_check",
        "<module>.FastMcpService.get_capabilities",
        "<module>.FastMcpService.shutdown_all",
        "<module>.FastMcpService._stop_server_safe",
        "<module>.FastMcpService._cleanup_client"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/shell.py",
      "name": "ShellService",
      "qualname": "<module>.ShellService",
      "source": "class ShellService:\n    # Store active shell sessions\n    active_shells: Dict[str, Dict[str, Any]] = {}\n    \n    # Store shell tasks\n    shell_tasks: Dict[str, ShellTask] = {}\n\n    def _get_display_path(self, path: str) -> str:\n        \"\"\"Get the path for display, replacing user home directory with ~\"\"\"\n        home_dir = os.path.expanduser(\"~\")\n        logger.debug(f\"Home directory: {home_dir} , path: {path}\")\n        if path.startswith(home_dir):\n            return path.replace(home_dir, \"~\", 1)\n        return path\n\n    def _format_ps1(self, exec_dir: str) -> str:\n        \"\"\"Format the command prompt\"\"\"\n        username = getpass.getuser()\n        hostname = socket.gethostname()\n        display_dir = self._get_display_path(exec_dir)\n        return f\"{username}@{hostname}:{display_dir} $\"\n\n    async def _create_process(self, command: str, exec_dir: str) -> asyncio.subprocess.Process:\n        \"\"\"Create a new async subprocess\"\"\"\n        logger.debug(f\"Creating process for command: {command} in directory: {exec_dir}\")\n        return await asyncio.create_subprocess_shell(\n            command,\n            cwd=exec_dir,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.STDOUT,  # Redirect stderr to stdout\n            stdin=asyncio.subprocess.PIPE,\n            limit=1024*1024  # Set buffer size to 1MB\n        )\n\n    async def _start_output_reader(self, session_id: str, process: asyncio.subprocess.Process):\n        \"\"\"Start a coroutine to continuously read process output and store it\"\"\"\n        logger.debug(f\"Starting output reader for session: {session_id}\")\n        max_buffer_size = 10 * 1024 * 1024  # 最大10MB的输出缓冲区\n        try:\n            while True:\n                if process.stdout:\n                    try:\n                        buffer = await process.stdout.read(128)\n                        if not buffer:\n                            # Process output ended\n                            break\n                        \n                        output = buffer.decode('utf-8', errors='replace')  # 使用replace处理无效字符\n                        # Add output to shell session\n                        shell = self.active_shells.get(session_id)\n                        if shell:\n                            # 检查输出缓冲区大小\n                            current_size = len(shell[\"output\"])\n                            if current_size > max_buffer_size:\n                                # 如果超过最大大小，截断前半部分\n                                truncate_msg = \"\\n...[早期输出已被截断以节省内存]...\\n\"\n                                shell[\"output\"] = truncate_msg + shell[\"output\"][-int(max_buffer_size/2):]\n                                logger.warning(f\"Session {session_id} 输出过大，已截断到 {len(shell['output'])} 字节\")\n                            \n                            shell[\"output\"] += output\n                            # Update the output of the latest console record\n                            if shell[\"console\"]:\n                                shell[\"console\"][-1].output += output\n                    except asyncio.CancelledError:\n                        logger.info(f\"输出读取器任务被取消: {session_id}\")\n                        break\n                    except Exception as e:\n                        logger.error(f\"读取进程输出时出错: {str(e)}\", exc_info=True)\n                        break\n                else:\n                    break\n        except Exception as e:\n            logger.error(f\"输出读取器发生未处理异常: {str(e)}\", exc_info=True)\n        finally:\n            logger.debug(f\"Output reader for session {session_id} has finished\")\n\n    async def exec_command(self, session_id: str, exec_dir: Optional[str], command: str) -> ShellCommandResult:\n        \"\"\"\n        Asynchronously execute a command in the specified shell session\n        \"\"\"\n        logger.info(f\"Executing command in session {session_id}: {command}\")\n        if not exec_dir:\n            exec_dir = os.path.expanduser(\"~\")\n        # Ensure directory exists\n        if not os.path.exists(exec_dir):\n            logger.error(f\"Directory does not exist: {exec_dir}\")\n            return ShellCommandResult(\n                session_id=session_id,\n                command=command,\n                status=\"error\",\n                returncode=-1,\n                output=f\"Directory does not exist: {exec_dir}\",\n                console=[]\n            )\n        try:\n            # Create PS1 format\n            ps1 = self._format_ps1(exec_dir)\n            \n            # If it's a new session, create a new process\n            if session_id not in self.active_shells:\n                logger.debug(f\"Creating new shell session: {session_id}\")\n                process = await self._create_process(command, exec_dir)\n                self.active_shells[session_id] = {\n                    \"process\": process,\n                    \"exec_dir\": exec_dir,\n                    \"output\": \"\",\n                    \"console\": [ConsoleRecord(ps1=ps1, command=command, output=\"\")]\n                }\n                # Start the output reader coroutine\n                asyncio.create_task(self._start_output_reader(session_id, process))\n            else:\n                # Execute command in an existing session\n                logger.debug(f\"Using existing shell session: {session_id}\")\n                shell = self.active_shells[session_id]\n                old_process = shell[\"process\"]\n                \n                # If the old process is still running, terminate it first\n                if old_process.returncode is None:\n                    logger.debug(f\"Terminating previous process in session: {session_id}\")\n                    try:\n                        old_process.terminate()\n                        await asyncio.wait_for(old_process.wait(), timeout=1)\n                    except Exception:\n                        logger.warning(f\"Forcefully killing process in session: {session_id}\")\n                        old_process.kill()\n                \n                # Create a new process\n                process = await self._create_process(command, exec_dir)\n                \n                # Update session information\n                self.active_shells[session_id][\"process\"] = process\n                self.active_shells[session_id][\"exec_dir\"] = exec_dir\n                self.active_shells[session_id][\"output\"] = \"\"  # Clear previous output\n                \n                # Record command console record, but output is initially empty, will be updated later\n                shell[\"console\"].append(ConsoleRecord(ps1=ps1, command=command, output=\"\"))\n                \n                # Start the output reader coroutine\n                asyncio.create_task(self._start_output_reader(session_id, process))\n            \n            # Try to wait for the process to complete (max 5 seconds)\n            try:\n                logger.debug(f\"Waiting for process completion in session: {session_id}\")\n                wait_result = await self.wait_for_process(session_id, seconds=5)\n                if wait_result.returncode is not None and wait_result.returncode != -1:\n                    logger.debug(f\"Process completed with code: {wait_result.returncode}\")\n                    view_result = await self.view_shell(session_id)\n                    # Update the output of the latest console record\n                    if self.active_shells[session_id][\"console\"]:\n                        self.active_shells[session_id][\"console\"][-1].output = view_result.output\n                    console = []\n                    try:\n                        console = self.get_console_records(session_id)\n                    except Exception:\n                        console = []\n                    return ShellCommandResult(\n                        session_id=session_id,\n                        command=command,\n                        status=\"completed\",\n                        returncode=wait_result.returncode,\n                        output=view_result.output,\n                        console=console\n                    )\n            except Exception as e:\n                # Other exceptions, ignore and continue\n                logger.warning(f\"Exception while waiting for process: {str(e)}\")\n                pass\n            console = []\n            try:\n                console = self.get_console_records(session_id)\n            except Exception:\n                console = []\n            return ShellCommandResult(\n                session_id=session_id,\n                command=command,\n                status=\"running\",\n                returncode=None,\n                output=None,\n                console=console\n            )\n        except Exception as e:\n            logger.error(f\"Command execution failed: {str(e)}\", exc_info=True)\n            return ShellCommandResult(\n                session_id=session_id,\n                command=command,\n                status=\"error\",\n                returncode=-1,\n                output=f\"Command execution failed: {str(e)}\",\n                console=[]\n            )\n\n    async def view_shell(self, session_id: str) -> ShellViewResult:\n        \"\"\"\n        Asynchronously view the content of the specified shell session\n        \"\"\"\n        logger.debug(f\"Viewing shell content for session: {session_id}\")\n        if session_id not in self.active_shells:\n            logger.error(f\"Session ID not found: {session_id}\")\n            return ShellViewResult(\n                output=f\"Session ID does not exist: {session_id}\",\n                session_id=session_id,\n                console=[]\n            )\n        shell = self.active_shells[session_id]\n        \n        try:\n            # 检查输出大小，如果过大则进行截断\n            output = shell[\"output\"]\n            max_size = 100 * 1024  # 最大100KB\n            \n            if len(output) > max_size:\n                logger.warning(f\"Shell输出过大 ({len(output)} bytes)，将截断为最后 {max_size} 字节\")\n                output = \"...[输出太长，已截断]...\\n\" + output[-max_size:]\n            console = []\n            try:\n                console = self.get_console_records(session_id)\n            except Exception:\n                console = []\n            return ShellViewResult(\n                output=output,\n                session_id=session_id,\n                console=console\n            )\n        except Exception as e:\n            logger.exception(f\"获取shell内容时发生错误: {str(e)}\")\n            # 发生错误时返回一个基础的结果而不是抛出异常\n            return ShellViewResult(\n                output=f\"获取shell内容时发生错误: {str(e)}\",\n                session_id=session_id,\n                console=[]\n            )\n\n    def get_console_records(self, session_id: str) -> List[ConsoleRecord]:\n        \"\"\"\n        Get command console records for the specified session (this method doesn't need to be async)\n        \"\"\"\n        logger.debug(f\"Getting console records for session: {session_id}\")\n        if session_id not in self.active_shells:\n            logger.error(f\"Session ID not found: {session_id}\")\n            return []\n        return self.active_shells[session_id][\"console\"]\n\n    async def wait_for_process(self, session_id: str, seconds: Optional[int] = None) -> ShellWaitResult:\n        \"\"\"\n        Asynchronously wait for the process in the specified shell session to return\n        \"\"\"\n        logger.debug(f\"Waiting for process in session: {session_id}, timeout: {seconds}s\")\n        if session_id not in self.active_shells:\n            logger.error(f\"Session ID not found: {session_id}\")\n            return ShellWaitResult(returncode=-1)\n        shell = self.active_shells[session_id]\n        process = shell[\"process\"]\n        \n        try:\n            # Asynchronously wait for process to complete\n            if seconds is None:\n                seconds = 15\n            await asyncio.wait_for(process.wait(), timeout=seconds)\n            \n            logger.info(f\"Process completed with return code: {process.returncode}\")\n            return ShellWaitResult(\n                returncode=process.returncode if process.returncode is not None else -1\n            )\n        except asyncio.TimeoutError:\n            logger.warning(f\"Process wait timeout expired: {seconds}s\")\n            return ShellWaitResult(returncode=-1)\n        except Exception as e:\n            logger.error(f\"Failed to wait for process: {str(e)}\", exc_info=True)\n            return ShellWaitResult(returncode=-1)\n\n    async def write_to_process(self, session_id: str, input_text: str, press_enter: bool) -> ShellWriteResult:\n        \"\"\"\n        Asynchronously write input to the process in the specified shell session\n        \"\"\"\n        logger.debug(f\"Writing to process in session: {session_id}, press_enter: {press_enter}\")\n        if session_id not in self.active_shells:\n            logger.error(f\"Session ID not found: {session_id}\")\n            return ShellWriteResult(status=\"error\")\n        shell = self.active_shells[session_id]\n        process = shell[\"process\"]\n        \n        try:\n            # Check if the process is still running\n            if process.returncode is not None:\n                logger.error(\"Process has already terminated, cannot write input\")\n                return ShellWriteResult(status=\"error\")\n            if press_enter:\n                input_data = f\"{input_text}\\n\".encode()\n            else:\n                input_data = input_text.encode()\n            \n            # Add input to output and console records\n            input_str = input_data.decode('utf-8')\n            shell[\"output\"] += input_str\n            if shell[\"console\"]:\n                shell[\"console\"][-1].output += input_str\n            \n            # Asynchronously write input\n            process.stdin.write(input_data)\n            await process.stdin.drain()\n            logger.info(\"Successfully wrote input to process\")\n            return ShellWriteResult(status=\"success\")\n        except Exception as e:\n            logger.error(f\"Failed to write input: {str(e)}\", exc_info=True)\n            return ShellWriteResult(status=\"error\")\n\n    async def kill_process(self, session_id: str) -> ShellKillResult:\n        \"\"\"\n        Asynchronously terminate the process in the specified shell session\n        \"\"\"\n        logger.info(f\"Killing process in session: {session_id}\")\n        if session_id not in self.active_shells:\n            logger.error(f\"Session ID not found: {session_id}\")\n            return ShellKillResult(status=\"error\", returncode=-1)\n        shell = self.active_shells[session_id]\n        process = shell[\"process\"]\n        \n        try:\n            # Check if the process is still running\n            if process.returncode is None:\n                # Try to terminate gracefully\n                logger.debug(\"Attempting to terminate process gracefully\")\n                process.terminate()\n                try:\n                    await asyncio.wait_for(process.wait(), timeout=3)\n                except asyncio.TimeoutError:\n                    # If graceful termination fails, force kill\n                    logger.warning(\"Forcefully killing the process\")\n                    process.kill()\n                    await process.wait()\n                \n                logger.info(f\"Process terminated with return code: {process.returncode}\")\n                return ShellKillResult(\n                    status=\"terminated\",\n                    returncode=process.returncode if process.returncode is not None else -1\n                )\n            else:\n                logger.info(f\"Process was already terminated with return code: {process.returncode}\")\n                return ShellKillResult(\n                    status=\"already_terminated\",\n                    returncode=process.returncode if process.returncode is not None else -1\n                )\n        except Exception as e:\n            logger.error(f\"Failed to kill process: {str(e)}\", exc_info=True)\n            return ShellKillResult(status=\"error\", returncode=-1)\n\n    def create_session_id(self) -> str:\n        \"\"\"\n        Create a new session ID (this method doesn't need to be async)\n        \"\"\"\n        session_id = str(uuid.uuid4())\n        logger.debug(f\"Created new session ID: {session_id}\")\n        return session_id\n",
      "methods": [
        "<module>.ShellService._get_display_path",
        "<module>.ShellService._format_ps1",
        "<module>.ShellService._create_process",
        "<module>.ShellService._start_output_reader",
        "<module>.ShellService.exec_command",
        "<module>.ShellService.view_shell",
        "<module>.ShellService.get_console_records",
        "<module>.ShellService.wait_for_process",
        "<module>.ShellService.write_to_process",
        "<module>.ShellService.kill_process",
        "<module>.ShellService.create_session_id"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/supervisor.py",
      "name": "UnixStreamHTTPConnection",
      "qualname": "<module>.UnixStreamHTTPConnection",
      "source": "class UnixStreamHTTPConnection(http.client.HTTPConnection):\n    def __init__(self, host, socket_path, timeout=None):\n        http.client.HTTPConnection.__init__(self, host, timeout=timeout)\n        self.socket_path = socket_path\n\n    def connect(self):\n        self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        self.sock.connect(self.socket_path)\n",
      "methods": [
        "<module>.UnixStreamHTTPConnection.__init__",
        "<module>.UnixStreamHTTPConnection.connect"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/supervisor.py",
      "name": "UnixStreamTransport",
      "qualname": "<module>.UnixStreamTransport",
      "source": "class UnixStreamTransport(xmlrpc.client.Transport):\n    def __init__(self, socket_path):\n        xmlrpc.client.Transport.__init__(self)\n        self.socket_path = socket_path\n\n    def make_connection(self, host):\n        return UnixStreamHTTPConnection(host, self.socket_path)\n",
      "methods": [
        "<module>.UnixStreamTransport.__init__",
        "<module>.UnixStreamTransport.make_connection"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/supervisor.py",
      "name": "SupervisorService",
      "qualname": "<module>.SupervisorService",
      "source": "class SupervisorService:\n    \"\"\"\n    Supervisor service management class, used for managing service timeout and renewal functionality - Async version\n    \"\"\"\n    def __init__(self):\n        self.rpc_url = \"/tmp/supervisor.sock\"\n        self._connect_rpc()\n        \n        # Timeout management - enabled based on configuration\n        self.timeout_active = settings.SERVICE_TIMEOUT_MINUTES is not None\n        self.shutdown_task = None\n        self.shutdown_time = None\n        \n        # If timeout is configured, create scheduled task\n        if settings.SERVICE_TIMEOUT_MINUTES is not None:\n            self.shutdown_time = datetime.now() + timedelta(minutes=settings.SERVICE_TIMEOUT_MINUTES)\n            self._setup_timer(settings.SERVICE_TIMEOUT_MINUTES)\n    \n    def _connect_rpc(self):\n        \"\"\"Connect to supervisord's RPC interface\"\"\"\n        try:\n            self.server = xmlrpc.client.ServerProxy(\n                'http://localhost',\n                transport=UnixStreamTransport(self.rpc_url)\n            )\n            # Test connection\n            self.server.supervisor.getState()\n        except Exception as e:\n            raise ResourceNotFoundException(f\"Cannot connect to Supervisord: {str(e)}\")\n    \n    def _setup_timer(self, minutes):\n        \"\"\"Set up async timer\"\"\"\n        # Cancel existing scheduled task\n        if self.shutdown_task:\n            try:\n                self.shutdown_task.cancel()\n            except Exception:\n                # ignore\n                pass\n            \n        # Create scheduled task function\n        async def shutdown_after_timeout():\n            await asyncio.sleep(minutes * 60)\n            await self.shutdown()\n        \n        # Create scheduled task\n        try:\n            loop = asyncio.get_event_loop()\n            self.shutdown_task = loop.create_task(shutdown_after_timeout())\n        except Exception:\n            # If async task creation fails, fall back to thread timer\n            if hasattr(self, 'shutdown_timer') and self.shutdown_timer:\n                self.shutdown_timer.cancel()\n            \n            self.shutdown_timer = threading.Timer(\n                minutes * 60, \n                lambda: asyncio.run(self.shutdown())\n            )\n            self.shutdown_timer.daemon = True\n            self.shutdown_timer.start()\n    \n    async def _call_rpc(self, method, *args):\n        \"\"\"Execute RPC call asynchronously\"\"\"\n        try:\n            return await asyncio.to_thread(method, *args)\n        except Exception as e:\n            raise BadRequestException(f\"RPC call failed: {str(e)}\")\n    \n    async def get_all_processes(self) -> List[ProcessInfo]:\n        \"\"\"Asynchronously get all process statuses\"\"\"\n        try:\n            processes = await self._call_rpc(self.server.supervisor.getAllProcessInfo)\n            return [ProcessInfo(**process) for process in processes]\n        except Exception as e:\n            raise ResourceNotFoundException(f\"Failed to get process status: {str(e)}\")\n    \n    async def stop_all_services(self) -> SupervisorActionResult:\n        \"\"\"Asynchronously stop all services\"\"\"\n        try:\n            result = await self._call_rpc(self.server.supervisor.stopAllProcesses)\n            return SupervisorActionResult(status=\"stopped\", result=result, stop_result=None, start_result=None, shutdown_result=None)\n        except Exception as e:\n            raise BadRequestException(f\"Failed to stop all services: {str(e)}\")\n    \n    async def shutdown(self) -> SupervisorActionResult:\n        \"\"\"Asynchronously shut down the supervisord service itself, without stopping processes\"\"\"\n        try:\n            shutdown_result = await self._call_rpc(self.server.supervisor.shutdown)\n            return SupervisorActionResult(status=\"shutdown\", result=None, stop_result=None, start_result=None, shutdown_result=shutdown_result)\n        except Exception as e:\n            raise BadRequestException(f\"Failed to shut down supervisord service: {str(e)}\")\n    \n    async def restart_all_services(self) -> SupervisorActionResult:\n        \"\"\"Asynchronously restart all services\"\"\"\n        try:\n            stop_result = await self._call_rpc(self.server.supervisor.stopAllProcesses)\n            start_result = await self._call_rpc(self.server.supervisor.startAllProcesses)\n            return SupervisorActionResult(\n                status=\"restarted\",\n                result=None,\n                stop_result=stop_result,\n                start_result=start_result,\n                shutdown_result=None\n            )\n        except Exception as e:\n            raise BadRequestException(f\"Failed to restart services: {str(e)}\")\n    \n    async def activate_timeout(self, minutes=None) -> SupervisorTimeout:\n        \"\"\"\n        Asynchronously activate timeout functionality, automatically shut down all services after the set time\n        \n        Args:\n            minutes: Timeout in minutes, if None then use the configured default value\n        \"\"\"\n        # Set timeout\n        timeout_minutes = minutes or settings.SERVICE_TIMEOUT_MINUTES\n        \n        # If no timeout is specified and no default in config, throw error\n        if timeout_minutes is None:\n            raise BadRequestException(\"Timeout not specified, and system default is no timeout\")\n            \n        self.timeout_active = True\n        self.shutdown_time = datetime.now() + timedelta(minutes=timeout_minutes)\n        \n        # Set up timer\n        self._setup_timer(timeout_minutes)\n        \n        return SupervisorTimeout(\n            status=\"timeout_activated\",\n            active=True,\n            shutdown_time=self.shutdown_time.isoformat(),\n            timeout_minutes=timeout_minutes,\n            remaining_seconds=float(timeout_minutes) * 60.0 if timeout_minutes is not None else None\n        )\n    \n    async def extend_timeout(self, minutes=None) -> SupervisorTimeout:\n        \"\"\"\n        Asynchronously extend timeout\n        \n        Args:\n            minutes: Number of minutes to extend, if None then use the configured default value\n        \"\"\"\n        # Set new timeout\n        timeout_minutes = minutes or settings.SERVICE_TIMEOUT_MINUTES\n        \n        # If no timeout is specified and no default in config, throw error\n        if timeout_minutes is None:\n            raise BadRequestException(\"Timeout not specified, and system default is no timeout\")\n            \n        self.timeout_active = True\n        self.shutdown_time = datetime.now() + timedelta(minutes=timeout_minutes)\n        \n        # Set up timer\n        self._setup_timer(timeout_minutes)\n        \n        return SupervisorTimeout(\n            status=\"timeout_extended\",\n            active=True,\n            shutdown_time=self.shutdown_time.isoformat(),\n            timeout_minutes=timeout_minutes,\n            remaining_seconds=float(timeout_minutes) * 60.0 if timeout_minutes is not None else None\n        )\n    \n    async def cancel_timeout(self) -> SupervisorTimeout:\n        \"\"\"Asynchronously cancel timeout functionality\"\"\"\n        if not self.timeout_active:\n            return SupervisorTimeout(status=\"no_timeout_active\", active=False, shutdown_time=None, timeout_minutes=None, remaining_seconds=None)\n        \n        if self.shutdown_task:\n            try:\n                self.shutdown_task.cancel()\n                self.shutdown_task = None\n            except Exception:\n                pass\n        \n        # Also check thread timer (for compatibility)\n        if hasattr(self, 'shutdown_timer') and self.shutdown_timer:\n            try:\n                self.shutdown_timer.cancel()\n                self.shutdown_timer = None\n            except Exception:\n                pass\n        \n        self.timeout_active = False\n        self.shutdown_time = None\n        \n        return SupervisorTimeout(status=\"timeout_cancelled\", active=False, shutdown_time=None, timeout_minutes=None, remaining_seconds=None)\n    \n    async def get_timeout_status(self) -> SupervisorTimeout:\n        \"\"\"Asynchronously get current timeout status\"\"\"\n        if not self.timeout_active:\n            return SupervisorTimeout(status=\"no_timeout_active\", active=False, shutdown_time=None, timeout_minutes=None, remaining_seconds=None)\n        \n        remaining_seconds = 0\n        if self.shutdown_time:\n            remaining = self.shutdown_time - datetime.now()\n            remaining_seconds = max(0, remaining.total_seconds())\n        \n        return SupervisorTimeout(\n            status=\"timeout_active\",\n            active=self.timeout_active,\n            shutdown_time=self.shutdown_time.isoformat() if self.shutdown_time else None,\n            timeout_minutes=None,\n            remaining_seconds=remaining_seconds\n        )\n",
      "methods": [
        "<module>.SupervisorService.__init__",
        "<module>.SupervisorService._connect_rpc",
        "<module>.SupervisorService._setup_timer",
        "<module>.SupervisorService._call_rpc",
        "<module>.SupervisorService.get_all_processes",
        "<module>.SupervisorService.stop_all_services",
        "<module>.SupervisorService.shutdown",
        "<module>.SupervisorService.restart_all_services",
        "<module>.SupervisorService.activate_timeout",
        "<module>.SupervisorService.extend_timeout",
        "<module>.SupervisorService.cancel_timeout",
        "<module>.SupervisorService.get_timeout_status"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/browser.py",
      "name": "SessionTabs",
      "qualname": "<module>.SessionTabs",
      "source": "class SessionTabs:\n    def __init__(self, context: BrowserContext):\n        self.context = context\n        self.tabs: Dict[str, Page] = {}\n        self.active_tab_id: Optional[str] = None\n        self.lock = asyncio.Lock()\n        self.last_active_at = time.time()\n        # selector cache per tab id\n        self.elements_map: Dict[str, List[Dict[str, str]]] = {}\n        # 由 browser-use DomService 生成的 CSS 选择器映射（index -> css selector），按 tab 维度缓存\n        self.css_selector_map: Dict[str, Dict[int, str]] = {}\n        # 可选的 browser-use BrowserSession，按会话维度\n        self.browser_session: Optional[BrowserSession] = None\n",
      "methods": [
        "<module>.SessionTabs.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/services/browser.py",
      "name": "BrowserService",
      "qualname": "<module>.BrowserService",
      "source": "class BrowserService:\n    def __init__(self):\n        self._playwright = None\n        self._browser: Optional[Browser] = None\n        # 单例上下文与页面\n        self._context: Optional[BrowserContext] = None\n        self._page: Optional[Page] = None\n        self._lock = asyncio.Lock()\n        self._last_active_at = time.time()\n        # 惰性 Controller（browser-use）\n        self._controller = Controller()\n        # 单例 BrowserSession 与索引->selector 映射\n        self._browser_session: Optional[BrowserSession] = None\n        self._css_selector_map: Dict[int, str] = {}\n\n    async def _ensure_browser_session_for(self, session_id: str):\n        # 兼容旧方法签名，内部转到单例会话\n        return await self._ensure_browser_session()\n\n    async def _ensure_browser(self):\n        if self._browser:\n            return\n\n        try:\n            self._playwright = await async_playwright().start()\n            # 在 VNC/Xvfb 环境下运行需要 DISPLAY，默认绑定到 :1（见 supervisord 的 xvfb 配置）\n            if not os.environ.get(\"DISPLAY\"):\n                os.environ[\"DISPLAY\"] = \":1\"\n\n            # 等待 Xvfb 就绪，避免短时间内连接 X server 失败\n            try:\n                await self._wait_for_x_server(os.environ[\"DISPLAY\"], timeout_sec=10)\n            except Exception:\n                pass\n\n            # 兼容原先 supervisor 启动 Chrome 的常用参数；可以通过 CHROME_ARGS 追加自定义参数\n            launch_args: List[str] = [\n                \"--no-sandbox\",\n                \"--disable-setuid-sandbox\",\n                \"--disable-dev-shm-usage\",\n                \"--disable-accelerated-2d-canvas\",\n                \"--disable-gpu\",\n                \"--disable-infobars\",\n                \"--start-maximized\",\n                \"--window-size=1280,1029\",\n                \"--no-first-run\",\n                \"--no-default-browser-check\",\n                \"--disable-extensions\",\n                \"--disable-popup-blocking\",\n                \"--disable-gpu-sandbox\",\n                \"--no-xshm\",\n                \"--disable-notifications\",\n                \"--disable-component-extensions-with-background-pages\",\n                \"--disable-prompt-on-repost\",\n                \"--disable-dialogs\",\n                \"--disable-modal-dialogs\",\n                # 谨慎项：以下两项会降低安全隔离，仅在明确需要时通过 CHROME_ARGS 传入\n                # \"--disable-web-security\",\n                # \"--disable-site-isolation-trials\",\n            ]\n\n            extra = os.getenv(\"CHROME_ARGS\", \"\").strip()\n            if extra:\n                launch_args += shlex.split(extra)\n\n            # 说明：Playwright 自己管理与浏览器的调度连接，一般不需要 remote-debugging-port\n            # 若确需暴露 CDP，可通过 CHROME_ARGS 传入对应参数\n            self._browser = await self._playwright.chromium.launch(\n                headless=False,\n                args=launch_args,\n            )\n        except Exception as e:\n            logger.error(f\"Failed to launch browser: {e}\")\n\n    async def _wait_for_x_server(self, display: str, timeout_sec: int = 10) -> None:\n        \"\"\"Wait until X server socket for given DISPLAY exists, or timeout.\"\"\"\n        disp_num = display.split(\":\")[-1].split(\".\")[0] if \":\" in display else \"1\"\n        sock_path = f\"/tmp/.X11-unix/X{disp_num}\"\n        deadline = time.time() + timeout_sec\n        while time.time() < deadline:\n            if os.path.exists(sock_path):\n                return\n            await asyncio.sleep(0.2)\n\n    async def _ensure_context(self, viewport: Optional[Dict[str, int]] = None, user_agent: Optional[str] = None) -> None:\n        if self._context and self._page:\n            # 单例已存在时忽略后续 viewport/user_agent 变更，避免类型不匹配的重设\n            return\n        await self._ensure_browser()\n        if self._browser is None:\n            return\n        try:\n            context_kwargs: Dict[str, Any] = {\n                \"bypass_csp\": True,\n            }\n            if viewport:\n                context_kwargs[\"viewport\"] = viewport\n            if user_agent:\n                context_kwargs[\"user_agent\"] = user_agent\n            self._context = await self._browser.new_context(**context_kwargs)\n            self._page = await self._context.new_page()\n        except Exception:\n            self._context = None\n            self._page = None\n\n    async def _ensure_browser_session(self) -> Optional[BrowserSession]:\n        if self._browser_session is not None:\n            return self._browser_session\n        await self._ensure_browser()\n        if self._browser is None:\n            return None\n        try:\n            self._browser_session = BrowserSession(browser=self._browser)\n        except Exception:\n            self._browser_session = None\n        return self._browser_session\n\n    async def _get_page(self) -> Page:\n        await self._ensure_context()\n        if not self._page:\n            raise HTTPException(status_code=404, detail=\"page not found\")\n        return self._page\n\n    async def _wait_for_page_settled(self, page: Page, max_wait_ms: int = 4000, min_wait_ms: int = 2000) -> None:\n        \"\"\"在点击等操作后，尽量等待页面进入稳定状态，避免读取到旧的交互元素。\n\n        策略（尽力而为，均为短超时并忽略异常）：\n        - 等待 load\n        - 等待 networkidle（适配SPA可能不会真正idle）\n        - 轮询 document.readyState 至 complete\n        - 轻微延时以等待微任务队列\n        \"\"\"\n        start_time = time.time()\n        deadline = time.time() + (max_wait_ms / 1000.0)\n        def remain_ms(max_slice: int) -> int:\n            return max(0, min(max_slice, int((deadline - time.time()) * 1000)))\n        # 1) 等待 load\n        try:\n            await page.wait_for_load_state('load', timeout=remain_ms(2000))\n        except Exception:\n            pass\n        # 2) 等待 networkidle\n        try:\n            await page.wait_for_load_state('networkidle', timeout=remain_ms(1500))\n        except Exception:\n            pass\n        # 3) 轮询 readyState\n        try:\n            while time.time() < deadline:\n                state = await page.evaluate(\"() => document.readyState\")\n                if isinstance(state, str) and state.lower() == 'complete':\n                    break\n                await asyncio.sleep(0.15)\n        except Exception:\n            pass\n        # 4) 轻微延时\n        try:\n            await asyncio.sleep(0.15)\n            if time.time() - start_time < (min_wait_ms / 1000.0):\n                await asyncio.sleep((min_wait_ms / 1000.0) - (time.time() - start_time))\n        except Exception:\n            pass\n\n    async def _gc_loop(self):\n        # 单例模式下无需 GC 循环，保留空实现以兼容\n        return\n\n    async def shutdown(self):\n        # 关闭单例页面与上下文\n        try:\n            if self._page:\n                try:\n                    await self._page.close()\n                except Exception:\n                    pass\n                self._page = None\n            if self._context:\n                try:\n                    await self._context.close()\n                except Exception:\n                    pass\n                self._context = None\n        except Exception:\n            pass\n        # 关闭浏览器与 Playwright\n        if self._browser:\n            try:\n                await self._browser.close()\n            except Exception:\n                pass\n            self._browser = None\n        if self._playwright:\n            try:\n                await self._playwright.stop()\n            except Exception:\n                pass\n            self._playwright = None\n\n    @_api_guard\n    async def init_session(self, req: InitRequest) -> Response:\n        viewport = None\n        if req.viewport:\n            viewport = {\"width\": req.viewport.width, \"height\": req.viewport.height}\n        async with self._lock:\n            await self._ensure_context(viewport=viewport, user_agent=req.user_agent)\n            if not self._page:\n                return Response.error(message=\"browser not available\")\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"session initialized\", data=None)\n\n    @_api_guard\n    async def close_session(self, req: CloseRequest) -> Response:\n        async with self._lock:\n            try:\n                if self._page:\n                    try:\n                        await self._page.close()\n                    except Exception:\n                        pass\n                    self._page = None\n                if self._context:\n                    try:\n                        await self._context.close()\n                    except Exception:\n                        pass\n                    self._context = None\n                self._browser_session = None\n                self._css_selector_map = {}\n            finally:\n                self._last_active_at = time.time()\n        return Response(success=True, message=\"session closed\", data=None)\n\n    async def _close_session_internal(self, session_id: str):\n        # 兼容旧签名，转到 close_session\n        await self.close_session(CloseRequest())\n\n    @_api_guard\n    async def open_tab(self, req: OpenTabRequest) -> Response:\n        # 单例：将“打开标签”视为确保页面存在并可选导航\n        async with self._lock:\n            await self._ensure_context()\n            if not self._page:\n                return Response.error(message=\"browser not available\")\n            if req.url:\n                try:\n                    await self._page.goto(req.url, timeout=15000)\n                except Exception:\n                    pass\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"tab opened\", data=None)\n\n    @_api_guard\n    async def close_tab(self, req: CloseTabRequest) -> Response:\n        # 单例：不支持关闭唯一标签，返回成功但不执行\n        async with self._lock:\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"single tab mode; close ignored\", data=None)\n\n    @_api_guard\n    async def activate_tab(self, req: ActivateTabRequest) -> Response:\n        # 单例：始终只有一个 tab\n        async with self._lock:\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"single tab mode; activate noop\", data=None)\n\n    @_api_guard\n    async def list_tabs(self) -> Response:\n        async with self._lock:\n            url = \"\"\n            try:\n                if self._page:\n                    url = self._page.url\n            except Exception:\n                pass\n            return Response(success=True, message=\"tabs listed\", data={\"tabs\": [{\"tab_id\": \"singleton\", \"url\": url, \"is_active\": True}]})\n\n    @_api_guard\n    async def get_html(self) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            html = await page.content()\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"html fetched\", data={\"html\": html, \"interactive_elements\": interactive_elements})\n\n    async def _get_elements(self) -> str:\n        page = await self._get_page()\n        bs = await self._ensure_browser_session()\n        await self._wait_for_page_settled(page)\n        if bs is None:\n            return \"\"\n        # 通过 browser-use 的 DomService 获取可交互元素与选择器映射\n        try:\n            dom_service = DomService(page)\n            dom_state = await dom_service.get_clickable_elements()\n            # 刷新索引->选择器映射（使用 xpath），同时标准化为以 / 或 // 开头\n            new_map: Dict[int, str] = {}\n            for idx, node in (dom_state.selector_map or {}).items():\n                try:\n                    raw_xpath = getattr(node, 'xpath', None)\n                    if raw_xpath:\n                        path = str(raw_xpath).strip()\n                        if not (path.startswith('/') or path.startswith('//')):\n                            path = '/' + path\n                        new_map[int(idx)] = f\"xpath={path}\"\n                except Exception:\n                    pass\n            self._css_selector_map = new_map\n            # 使用 browser-use 的可读化字符串\n            lines_str: str = dom_state.element_tree.clickable_elements_to_string()\n            # 用于缓存存储\n            await bs.get_state_summary(cache_clickable_elements_hashes=True)\n            self._last_active_at = time.time()\n            return lines_str\n        except Exception:\n            self._last_active_at = time.time()\n            return \"\"\n\n    @_api_guard\n    async def get_elements(self) -> Response:\n        lines_str: str = await self._get_elements()\n        return Response(success=True, message=\"elements fetched\", data={\"interactive_elements\": lines_str})\n\n    @_api_guard\n    async def click(self, req: ClickRequest) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            target_details: Optional[Dict[str, Any]] = None\n            if req.x is not None and req.y is not None:\n                btn: Literal['left','middle','right'] = 'left'\n                if req.button in ('left','middle','right'):\n                    btn = req.button\n                try:\n                    target_details = await self._get_element_details_by_point(req.x, req.y)\n                except Exception:\n                    target_details = None\n                await page.mouse.click(req.x, req.y, button=btn, click_count=req.clicks or 1)\n                interactive_elements = await self._get_elements()\n                self._last_active_at = time.time()\n                return Response(success=True, message=\"clicked\", data={\"target_element\": target_details, \"interactive_elements\": interactive_elements})\n            elif req.index is not None:\n                # 直接通过 browser-use Controller 按索引点击，失败则回退\n                try:\n                    browser_session = await self._ensure_browser_session()\n                    if browser_session:\n                        try:\n                            target_details = await self._get_element_details_by_index(req.index)\n                        except Exception:\n                            target_details = None\n                        await self._controller.registry.execute_action(\n                            action_name='click_element_by_index',\n                            params={\"index\": str(req.index)},\n                            browser_session=browser_session\n                        )\n                        interactive_elements = await self._get_elements()\n                        self._last_active_at = time.time()\n                        return Response(success=True, message=\"clicked\", data={\"target_element\": target_details, \"interactive_elements\": interactive_elements})\n                except Exception:\n                    pass\n                el = await self._get_element_by_index(req.index)\n                if not el:\n                    return Response.error(message=f\"element index {req.index} not found\")\n                element = await page.query_selector(el[\"selector\"])\n                if not element:\n                    return Response.error(message=\"element not available\")\n                try:\n                    try:\n                        target_details = await self._get_element_details_by_selector(el[\"selector\"])\n                    except Exception:\n                        target_details = None\n                    await element.scroll_into_view_if_needed()\n                except Exception:\n                    pass\n                await element.click()\n                interactive_elements = await self._get_elements()\n                self._last_active_at = time.time()\n                return Response(success=True, message=\"clicked\", data={\"target_element\": target_details, \"interactive_elements\": interactive_elements})\n            else:\n                return Response.error(message=\"either (x,y) or index is required\")\n\n    @_api_guard\n    async def input(self, req: InputRequest) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            used_controller = False\n            target_details: Optional[Dict[str, Any]] = None\n            if req.x is not None and req.y is not None:\n                try:\n                    target_details = await self._get_element_details_by_point(req.x, req.y)\n                except Exception:\n                    target_details = None\n                await page.mouse.click(req.x, req.y)\n                await page.keyboard.type(req.text)\n            elif req.index is not None:\n                # 直接通过 browser-use Controller 输入文本，失败则回退\n                used_controller = False\n                try:\n                    browser_session = await self._ensure_browser_session()\n                    if browser_session:\n                        try:\n                            target_details = await self._get_element_details_by_index(req.index)\n                        except Exception:\n                            target_details = None\n                        await self._controller.registry.execute_action(\n                            action_name='input_text',\n                            params={\"index\": str(req.index), \"text\": req.text},\n                            browser_session=browser_session\n                        )\n                        used_controller = True\n                        if req.press_enter:\n                            try:\n                                await self._controller.registry.execute_action(\n                                    action_name='send_keys',\n                                    params={\"keys\": \"Enter\"},\n                                    browser_session=browser_session\n                                )\n                            except Exception:\n                                pass\n                except Exception:\n                    used_controller = False\n                if not used_controller:\n                    el = await self._get_element_by_index(req.index)\n                    if not el:\n                        return Response.error(message=f\"element index {req.index} not found\")\n                    element = await page.query_selector(el[\"selector\"])\n                    if not element:\n                        return Response.error(message=\"element not available\")\n                    try:\n                        try:\n                            target_details = await self._get_element_details_by_selector(el[\"selector\"])\n                        except Exception:\n                            target_details = None\n                        await element.fill(\"\")\n                        await element.type(req.text)\n                    except Exception:\n                        await element.click()\n                        await page.keyboard.type(req.text)\n            else:\n                return Response.error(message=\"either (x,y) or index is required\")\n            if req.press_enter and not used_controller:\n                try:\n                    await page.keyboard.press(\"Enter\")\n                except Exception:\n                    pass\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"input sent\", data={\"target_element\": target_details, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def select(self, req: SelectRequest) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            el = await self._get_element_by_index(req.index)\n            if not el:\n                return Response.error(message=f\"element index {req.index} not found\")\n            element = await page.query_selector(el[\"selector\"])\n            if not element:\n                return Response.error(message=\"element not available\")\n            target_details: Optional[Dict[str, Any]] = None\n            try:\n                target_details = await self._get_element_details_by_selector(el[\"selector\"])\n            except Exception:\n                target_details = None\n            await element.select_option(index=req.option)\n            self._last_active_at = time.time()\n            interactive_elements = await self._get_elements()\n            return Response(success=True, message=\"option selected\", data={\"target_element\": target_details, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def scroll(self, req: ScrollRequest) -> Response:\n        async with self._lock:\n            browser_session = await self._ensure_browser_session()\n            if browser_session:\n                res = await self._controller.registry.execute_action(\n                    action_name='scroll',\n                    params={\"down\": req.down, \"num_pages\": req.num_pages, \"index\": req.index},\n                    browser_session=browser_session\n                )\n                interactive_elements = await self._get_elements()\n                self._last_active_at = time.time()\n                return Response(success=True, message=\"scrolled\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n            else:\n                return Response.error(message=\"browser session not available\")\n\n    @_api_guard\n    async def key(self, req: KeyRequest) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            # 直接使用 browser-use 的 send_keys 动作，失败则回退\n            used_controller = False\n            try:\n                browser_session = await self._ensure_browser_session()\n                if browser_session:\n                    await self._controller.registry.execute_action(\n                        action_name='send_keys',\n                        params={\"keys\": req.key},\n                        browser_session=browser_session\n                    )\n                    used_controller = True\n            except Exception:\n                used_controller = False\n            if not used_controller:\n                await page.keyboard.press(req.key)\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"key pressed\", data={\"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def evaluate(self, req: EvaluateRequest) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            result = await page.evaluate(req.javascript)\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"evaluated\", data={\"result\": result, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def screenshot(self, req: ScreenshotRequest) -> Response:\n        page = await self._get_page()\n        async with self._lock:\n            options: Dict[str, Any] = {}\n            if req.full_page:\n                options[\"full_page\"] = True\n            if req.clip:\n                options[\"clip\"] = {\"x\": req.clip.x, \"y\": req.clip.y, \"width\": req.clip.width, \"height\": req.clip.height}\n            buf = await page.screenshot(**options)\n            b64 = base64.b64encode(buf).decode(\"ascii\")\n            size = await page.evaluate(\"() => ({ w: window.innerWidth, h: window.innerHeight })\")\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"screenshot taken\", data={\"image_base64\": b64, \"width\": size.get(\"w\", 0), \"height\": size.get(\"h\", 0), \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def navigate_to_url(self, req: NavigateRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            await bs.navigate(req.url, timeout_ms=25000)\n            lines_str = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"navigated\", data={\"interactive_elements\": lines_str})\n\n    @_api_guard\n    async def go_back(self, req: GoBackRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            await self._controller.registry.execute_action(\n                action_name='go_back', params={}, browser_session=bs\n            )\n            lines_str = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"went back\", data={\"interactive_elements\": lines_str})\n\n    @_api_guard\n    async def send_keys_action(self, req: SendKeysRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            res = await self._controller.registry.execute_action(\n                action_name='send_keys', params={\"keys\": req.keys}, browser_session=bs\n            )\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"keys sent\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def scroll_to_text(self, req: ScrollToTextRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            res = await self._controller.registry.execute_action(\n                action_name='scroll_to_text', params={\"text\": req.text}, browser_session=bs\n            )\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"scrolled to text\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def extract_structured_data(self) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            page = await bs.get_current_page()\n            content = ''\n            for iframe in page.frames:\n                try:\n                    await iframe.wait_for_load_state(timeout=1000)\n                except Exception:\n                    pass\n                if iframe.url != page.url and not iframe.url.startswith('data:') and not iframe.url.startswith('about:'):\n                    content += f\"\\n\\nIFRAME {iframe.url}:\\n\"\n                    try:\n                        iframe_html = await asyncio.wait_for(iframe.content(), timeout=2.0)\n                        # markdownify 在上方未导入，此处改为直接追加 HTML 以避免未使用导入\n                        content += iframe_html\n                    except Exception:\n                        pass\n            page_html_result = await asyncio.wait_for(page.content(), timeout=10.0)\n            content += page_html_result\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"structured data extracted\", data={\"html\": content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def select_dropdown_option(self, req: SelectDropdownOptionRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            res = await self._controller.registry.execute_action(\n                action_name='select_dropdown_option', params={\"index\": req.index, \"text\": req.text}, browser_session=bs\n            )\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"option selected\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def upload_file(self, req: UploadFileRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            interactive_elements = await self._get_elements()\n            res = await self._controller.registry.execute_action(\n                action_name='upload_file', params={\"index\": req.index, \"path\": req.path}, browser_session=bs\n            )\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"file uploaded\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def close_tab_by_id(self, req: CloseTabByIdRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            res = await self._controller.registry.execute_action(\n                action_name='close_tab', params={\"page_id\": req.page_id}, browser_session=bs\n            )\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"tab closed\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def switch_tab_by_id(self, req: SwitchTabByIdRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            res = await self._controller.registry.execute_action(\n                action_name='switch_tab', params={\"page_id\": req.page_id}, browser_session=bs\n            )\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"tab switched\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def wait_action(self, req: WaitRequest) -> Response:\n        async with self._lock:\n            bs = await self._ensure_browser_session()\n            if not bs:\n                return Response.error(message=\"browser session not available\")\n            res = await self._controller.registry.execute_action(\n                action_name='wait', params={\"seconds\": req.seconds}, browser_session=bs\n            )\n            interactive_elements = await self._get_elements()\n            self._last_active_at = time.time()\n            return Response(success=True, message=\"waited\", data={\"result\": res.extracted_content, \"interactive_elements\": interactive_elements})\n\n    @_api_guard\n    async def health(self) -> Response:\n        return Response(success=True, message=\"ok\", data={\n            \"playwright\": \"ready\" if self._playwright else \"not_ready\",\n            \"browser\": \"launched\" if self._browser else \"closed\",\n            \"singleton\": bool(self._page),\n        })\n\n    async def _get_session(self, session_id: str) -> SessionTabs:\n        # 单例模式，保留兼容但不使用\n        raise HTTPException(status_code=404, detail=\"single-session mode\")\n\n    async def _ensure_tab_id(self, session_id: str, tab_id: Optional[str]) -> str:\n        # 单例模式，无意义\n        return \"singleton\"\n\n    # 删除 _get_page 旧签名，统一使用无参版本\n\n    async def _get_element_by_index(self, index: int) -> Optional[Dict[str, Any]]:\n        # 使用单例缓存映射\n        if index in self._css_selector_map:\n            return {\"index\": index, \"selector\": self._css_selector_map[index], \"tag\": \"\", \"text\": \"\"}\n        return None\n\n    async def _get_element_details_from_handle(self, element) -> Optional[Dict[str, Any]]:\n        if not element:\n            return None\n        details: Optional[Dict[str, Any]] = None\n        try:\n            details = await element.evaluate(\n                r\"\"\"\n                (el) => {\n                    const rect = el.getBoundingClientRect();\n                    const attrs = {};\n                    if (el.getAttributeNames) {\n                        for (const name of el.getAttributeNames()) {\n                            attrs[name] = el.getAttribute(name);\n                        }\n                    }\n                    return {\n                        tag: (el.tagName || '').toLowerCase(),\n                        id: el.id || null,\n                        classes: (typeof el.className === 'string') ? el.className : null,\n                        name: el.getAttribute && el.getAttribute('name'),\n                        type: el.getAttribute && el.getAttribute('type'),\n                        role: el.getAttribute && el.getAttribute('role'),\n                        aria_label: el.getAttribute && (el.getAttribute('aria-label') || el.getAttribute('aria-labelledby')),\n                        text: (el.innerText || el.textContent || '').trim().slice(0, 500),\n                        href: el.getAttribute && el.getAttribute('href'),\n                        src: el.getAttribute && el.getAttribute('src'),\n                        placeholder: el.getAttribute && el.getAttribute('placeholder'),\n                        value: ('value' in el) ? el.value : null,\n                        rect: { x: rect.x, y: rect.y, width: rect.width, height: rect.height },\n                        visible: !!(el.offsetParent !== null || (rect.width && rect.height)),\n                        disabled: !!(el.disabled),\n                        attributes: attrs,\n                    };\n                }\n                \"\"\"\n            )\n        except Exception as e:\n            print(f\"Error getting element details from handle: {e}\")\n            details = None\n        try:\n            box = await element.bounding_box()\n            if details is None:\n                details = {}\n            details[\"bounding_box\"] = box\n        except Exception:\n            pass\n        return details\n\n    async def _get_element_details_by_selector(self, selector: str) -> Optional[Dict[str, Any]]:\n        page = await self._get_page()\n        sel = selector\n        candidates: List[str] = [sel]\n        # 针对 xpath= 的 selector，补充可能的变体（缺少前导/，或 html/... 开头）\n        if sel.startswith('xpath='):\n            value = sel[len('xpath='):].strip()\n            if value and not (value.startswith('/') or value.startswith('//')):\n                candidates.append(f'xpath=/{value}')\n            if value.startswith('html/'):\n                # 试试以 // 作为起点\n                candidates.append(f'xpath=//{value}')\n                rest = value[5:] if len(value) > 5 else ''\n                if rest:\n                    candidates.append(f'xpath=//{rest}')\n        element = None\n        # 先在主文档尝试\n        for cand in candidates:\n            try:\n                element = await page.query_selector(cand)\n            except Exception:\n                element = None\n            if element:\n                sel = cand\n                break\n        # 若未找到，在所有 frame 中尝试\n        if not element:\n            try:\n                for frame in page.frames:\n                    for cand in candidates:\n                        try:\n                            element = await frame.query_selector(cand)\n                        except Exception:\n                            element = None\n                        if element:\n                            sel = cand\n                            break\n                    if element:\n                        break\n            except Exception:\n                element = None\n        if not element:\n            return None\n        details = await self._get_element_details_from_handle(element)\n        if details is not None:\n            details['selector'] = sel\n        return details\n\n    async def _get_element_details_by_index(self, index: int) -> Optional[Dict[str, Any]]:\n        el = await self._get_element_by_index(index)\n        print(f\"Element: {el}\")\n        if not el:\n            return None\n        print(f\"Element selector: {el['selector']}\")\n        return await self._get_element_details_by_selector(el[\"selector\"])\n\n    async def _get_element_details_by_point(self, x: float, y: float) -> Optional[Dict[str, Any]]:\n        page = await self._get_page()\n        # 先用 elementFromPoint 获取基本信息与一个简易 CSS 路径，再尝试回查 selector 获取更完整数据\n        info = None\n        try:\n            info = await page.evaluate(\n                r\"\"\"\n                ([x, y]) => {\n                    const el = document.elementFromPoint(x, y);\n                    if (!el) return null;\n                    const rect = el.getBoundingClientRect();\n                    const attrs = {};\n                    if (el.getAttributeNames) {\n                        for (const name of el.getAttributeNames()) {\n                            attrs[name] = el.getAttribute(name);\n                        }\n                    }\n                    function cssPath(e) {\n                        if (!e || e.nodeType !== 1) return null;\n                        const parts = [];\n                        let cur = e;\n                        let depth = 0;\n                        while (cur && depth < 5) {\n                            let part = cur.nodeName.toLowerCase();\n                            if (cur.id) { part += '#' + cur.id; parts.unshift(part); break; }\n                            let cls = (typeof cur.className === 'string') ? cur.className.trim().split(/\\s+/).slice(0,3).join('.') : '';\n                            if (cls) part += '.' + cls;\n                            let sib = cur; let nth = 1;\n                            while ((sib = sib.previousElementSibling) != null) {\n                                if (sib.nodeName === cur.nodeName) nth++;\n                            }\n                            if (nth > 1) part += `:nth-of-type(${nth})`;\n                            parts.unshift(part);\n                            cur = cur.parentElement;\n                            depth++;\n                        }\n                        return parts.join(' > ');\n                    }\n                    return {\n                        tag: (el.tagName || '').toLowerCase(),\n                        id: el.id || null,\n                        classes: (typeof el.className === 'string') ? el.className : null,\n                        name: el.getAttribute && el.getAttribute('name'),\n                        type: el.getAttribute && el.getAttribute('type'),\n                        role: el.getAttribute && el.getAttribute('role'),\n                        aria_label: el.getAttribute && (el.getAttribute('aria-label') || el.getAttribute('aria-labelledby')),\n                        text: (el.innerText || el.textContent || '').trim().slice(0, 500),\n                        href: el.getAttribute && el.getAttribute('href'),\n                        src: el.getAttribute && el.getAttribute('src'),\n                        placeholder: el.getAttribute && el.getAttribute('placeholder'),\n                        value: ('value' in el) ? el.value : null,\n                        rect: { x: rect.x, y: rect.y, width: rect.width, height: rect.height },\n                        visible: !!(el.offsetParent !== null || (rect.width && rect.height)),\n                        disabled: !!(el.disabled),\n                        attributes: attrs,\n                        css_selector: cssPath(el)\n                    };\n                }\n                \"\"\",\n                [x, y]\n            )\n        except Exception:\n            info = None\n        # 如果拿到 css_selector，尽量回查以补充 selector 与 bounding_box\n        if info and isinstance(info, dict) and info.get(\"css_selector\"):\n            try:\n                details = await self._get_element_details_by_selector(info[\"css_selector\"])  # type: ignore[index]\n                if details:\n                    return details\n            except Exception:\n                pass\n        return info\n",
      "methods": [
        "<module>.BrowserService.__init__",
        "<module>.BrowserService._ensure_browser_session_for",
        "<module>.BrowserService._ensure_browser",
        "<module>.BrowserService._wait_for_x_server",
        "<module>.BrowserService._ensure_context",
        "<module>.BrowserService._ensure_browser_session",
        "<module>.BrowserService._get_page",
        "<module>.BrowserService._wait_for_page_settled",
        "<module>.BrowserService._gc_loop",
        "<module>.BrowserService.shutdown",
        "<module>.BrowserService.init_session",
        "<module>.BrowserService.close_session",
        "<module>.BrowserService._close_session_internal",
        "<module>.BrowserService.open_tab",
        "<module>.BrowserService.close_tab",
        "<module>.BrowserService.activate_tab",
        "<module>.BrowserService.list_tabs",
        "<module>.BrowserService.get_html",
        "<module>.BrowserService._get_elements",
        "<module>.BrowserService.get_elements",
        "<module>.BrowserService.click",
        "<module>.BrowserService.input",
        "<module>.BrowserService.select",
        "<module>.BrowserService.scroll",
        "<module>.BrowserService.key",
        "<module>.BrowserService.evaluate",
        "<module>.BrowserService.screenshot",
        "<module>.BrowserService.navigate_to_url",
        "<module>.BrowserService.go_back",
        "<module>.BrowserService.send_keys_action",
        "<module>.BrowserService.scroll_to_text",
        "<module>.BrowserService.extract_structured_data",
        "<module>.BrowserService.select_dropdown_option",
        "<module>.BrowserService.upload_file",
        "<module>.BrowserService.close_tab_by_id",
        "<module>.BrowserService.switch_tab_by_id",
        "<module>.BrowserService.wait_action",
        "<module>.BrowserService.health",
        "<module>.BrowserService._get_session",
        "<module>.BrowserService._ensure_tab_id",
        "<module>.BrowserService._get_element_by_index",
        "<module>.BrowserService._get_element_details_from_handle",
        "<module>.BrowserService._get_element_details_by_selector",
        "<module>.BrowserService._get_element_details_by_index",
        "<module>.BrowserService._get_element_details_by_point"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileReadRequest",
      "qualname": "<module>.FileReadRequest",
      "source": "class FileReadRequest(BaseModel):\n    \"\"\"File read request\"\"\"\n    file: str = Field(..., description=\"Absolute file path\")\n    start_line: Optional[int] = Field(None, description=\"Start line (0-based)\")\n    end_line: Optional[int] = Field(None, description=\"End line (not inclusive)\")\n    sudo: Optional[bool] = Field(False, description=\"Whether to use sudo privileges\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileWriteRequest",
      "qualname": "<module>.FileWriteRequest",
      "source": "class FileWriteRequest(BaseModel):\n    \"\"\"File write request\"\"\"\n    file: str = Field(..., description=\"Absolute file path\")\n    content: str = Field(..., description=\"Content to write\")\n    append: Optional[bool] = Field(False, description=\"Whether to use append mode\")\n    leading_newline: Optional[bool] = Field(False, description=\"Whether to add leading newline\")\n    trailing_newline: Optional[bool] = Field(False, description=\"Whether to add trailing newline\")\n    sudo: Optional[bool] = Field(False, description=\"Whether to use sudo privileges\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileReplaceRequest",
      "qualname": "<module>.FileReplaceRequest",
      "source": "class FileReplaceRequest(BaseModel):\n    \"\"\"File content replacement request\"\"\"\n    file: str = Field(..., description=\"Absolute file path\")\n    old_str: str = Field(..., description=\"Original string to replace\")\n    new_str: str = Field(..., description=\"New string to replace with\")\n    sudo: Optional[bool] = Field(False, description=\"Whether to use sudo privileges\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileSearchRequest",
      "qualname": "<module>.FileSearchRequest",
      "source": "class FileSearchRequest(BaseModel):\n    \"\"\"File content search request\"\"\"\n    file: str = Field(..., description=\"Absolute file path\")\n    regex: str = Field(..., description=\"Regular expression pattern\")\n    sudo: Optional[bool] = Field(False, description=\"Whether to use sudo privileges\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileFindRequest",
      "qualname": "<module>.FileFindRequest",
      "source": "class FileFindRequest(BaseModel):\n    \"\"\"File find request\"\"\"\n    path: str = Field(..., description=\"Directory path to search\")\n    glob: str = Field(..., description=\"Filename pattern (glob syntax)\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileUploadResponse",
      "qualname": "<module>.FileUploadResponse",
      "source": "class FileUploadResponse(BaseModel):\n    \"\"\"File upload response\"\"\"\n    file: str = Field(..., description=\"Absolute path of the uploaded file\")\n    size: int = Field(..., description=\"Size of the uploaded file in bytes\")\n    is_executable: bool = Field(False, description=\"Whether the file is executable\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileExistsRequest",
      "qualname": "<module>.FileExistsRequest",
      "source": "class FileExistsRequest(BaseModel):\n    \"\"\"File exists request\"\"\"\n    path: str = Field(..., description=\"Path to check for existence\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/file.py",
      "name": "FileDownloadRequest",
      "qualname": "<module>.FileDownloadRequest",
      "source": "class FileDownloadRequest(BaseModel):\n    \"\"\"File download request\"\"\"\n    path: str = Field(..., description=\"Absolute path of the file to download\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/shell.py",
      "name": "ShellExecRequest",
      "qualname": "<module>.ShellExecRequest",
      "source": "class ShellExecRequest(BaseModel):\n    \"\"\"Shell command execution request model\"\"\"\n    id: Optional[str] = Field(None, description=\"Unique identifier of the target shell session, if not provided, one will be automatically created\")\n    exec_dir: Optional[str] = Field(None, description=\"Working directory for command execution (must use absolute path)\")\n    command: str = Field(..., description=\"Shell command to execute\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/shell.py",
      "name": "ShellViewRequest",
      "qualname": "<module>.ShellViewRequest",
      "source": "class ShellViewRequest(BaseModel):\n    \"\"\"Shell session content view request model\"\"\"\n    id: str = Field(..., description=\"Unique identifier of the target shell session\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/shell.py",
      "name": "ShellWaitRequest",
      "qualname": "<module>.ShellWaitRequest",
      "source": "class ShellWaitRequest(BaseModel):\n    \"\"\"Shell process wait request model\"\"\"\n    id: str = Field(..., description=\"Unique identifier of the target shell session\")\n    seconds: Optional[int] = Field(None, description=\"Wait time (seconds)\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/shell.py",
      "name": "ShellWriteToProcessRequest",
      "qualname": "<module>.ShellWriteToProcessRequest",
      "source": "class ShellWriteToProcessRequest(BaseModel):\n    \"\"\"Request model for writing input to a running process\"\"\"\n    id: str = Field(..., description=\"Unique identifier of the target shell session\")\n    input: str = Field(..., description=\"Input content to write to the process\")\n    press_enter: bool = Field(..., description=\"Whether to press enter key after input\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/shell.py",
      "name": "ShellKillProcessRequest",
      "qualname": "<module>.ShellKillProcessRequest",
      "source": "class ShellKillProcessRequest(BaseModel):\n    \"\"\"Request model for terminating a running process\"\"\"\n    id: str = Field(..., description=\"Unique identifier of the target shell session\")\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/response.py",
      "name": "Response",
      "qualname": "<module>.Response",
      "source": "class Response(BaseModel):\n    \"\"\"Generic response model for API interface return results\"\"\"\n    success: bool = Field(True, description=\"Whether the operation was successful\")\n    message: Optional[str] = Field(\"Operation successful\", description=\"Operation result message\")\n    data: Optional[Any] = Field(None, description=\"Data returned from the operation\")\n\n    # Shortcut method to create error response\n    @classmethod\n    def error(cls, message: str, data: Any = None) -> \"Response\":\n        \"\"\"Create an error response instance\"\"\"\n        return cls(success=False, message=message, data=data) ",
      "methods": [
        "<module>.Response.error"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "Viewport",
      "qualname": "<module>.Viewport",
      "source": "class Viewport(BaseModel):\n    width: int = Field(1280)\n    height: int = Field(1029)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "InitRequest",
      "qualname": "<module>.InitRequest",
      "source": "class InitRequest(BaseModel):\n    viewport: Optional[Viewport] = None\n    user_agent: Optional[str] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "CloseRequest",
      "qualname": "<module>.CloseRequest",
      "source": "class CloseRequest(BaseModel):\n    pass\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "OpenTabRequest",
      "qualname": "<module>.OpenTabRequest",
      "source": "class OpenTabRequest(BaseModel):\n    url: Optional[str] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "CloseTabRequest",
      "qualname": "<module>.CloseTabRequest",
      "source": "class CloseTabRequest(BaseModel):\n    pass\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "ActivateTabRequest",
      "qualname": "<module>.ActivateTabRequest",
      "source": "class ActivateTabRequest(BaseModel):\n    pass\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "NavigateRequest",
      "qualname": "<module>.NavigateRequest",
      "source": "class NavigateRequest(BaseModel):\n    url: str\n    timeout_ms: Optional[int] = Field(default=15000)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "ClickRequest",
      "qualname": "<module>.ClickRequest",
      "source": "class ClickRequest(BaseModel):\n    index: Optional[int] = None\n    x: Optional[float] = None\n    y: Optional[float] = None\n    button: Optional[str] = Field(default=\"left\")\n    clicks: Optional[int] = Field(default=1)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "InputRequest",
      "qualname": "<module>.InputRequest",
      "source": "class InputRequest(BaseModel):\n    text: str\n    press_enter: Optional[bool] = Field(default=False)\n    index: Optional[int] = None\n    x: Optional[float] = None\n    y: Optional[float] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "SelectRequest",
      "qualname": "<module>.SelectRequest",
      "source": "class SelectRequest(BaseModel):\n    index: int\n    option: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "ScrollRequest",
      "qualname": "<module>.ScrollRequest",
      "source": "class ScrollRequest(BaseModel):\n    down: bool  # True to scroll down, False to scroll up\n    num_pages: float  # Number of pages to scroll (0.5 = half page, 1.0 = one page, etc.)\n    index: int | None = None  # Optional element index to find scroll container for\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "KeyRequest",
      "qualname": "<module>.KeyRequest",
      "source": "class KeyRequest(BaseModel):\n    key: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "EvaluateRequest",
      "qualname": "<module>.EvaluateRequest",
      "source": "class EvaluateRequest(BaseModel):\n    javascript: str\n    timeout_ms: Optional[int] = Field(default=5000)\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "Clip",
      "qualname": "<module>.Clip",
      "source": "class Clip(BaseModel):\n    x: int\n    y: int\n    width: int\n    height: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "ScreenshotRequest",
      "qualname": "<module>.ScreenshotRequest",
      "source": "class ScreenshotRequest(BaseModel):\n    full_page: Optional[bool] = Field(default=False)\n    clip: Optional[Clip] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "GoBackRequest",
      "qualname": "<module>.GoBackRequest",
      "source": "class GoBackRequest(BaseModel):\n    pass\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "SendKeysRequest",
      "qualname": "<module>.SendKeysRequest",
      "source": "class SendKeysRequest(BaseModel):\n    keys: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "ScrollToTextRequest",
      "qualname": "<module>.ScrollToTextRequest",
      "source": "class ScrollToTextRequest(BaseModel):\n    text: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "SelectDropdownOptionRequest",
      "qualname": "<module>.SelectDropdownOptionRequest",
      "source": "class SelectDropdownOptionRequest(BaseModel):\n    index: int\n    text: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "UploadFileRequest",
      "qualname": "<module>.UploadFileRequest",
      "source": "class UploadFileRequest(BaseModel):\n    index: int\n    path: str\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "CloseTabByIdRequest",
      "qualname": "<module>.CloseTabByIdRequest",
      "source": "class CloseTabByIdRequest(BaseModel):\n    page_id: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "SwitchTabByIdRequest",
      "qualname": "<module>.SwitchTabByIdRequest",
      "source": "class SwitchTabByIdRequest(BaseModel):\n    page_id: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/schemas/browser.py",
      "name": "WaitRequest",
      "qualname": "<module>.WaitRequest",
      "source": "class WaitRequest(BaseModel):\n    seconds: int\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/api/v1/supervisor.py",
      "name": "TimeoutRequest",
      "qualname": "<module>.TimeoutRequest",
      "source": "class TimeoutRequest(BaseModel):\n    minutes: Optional[int] = None\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/core/config.py",
      "name": "Settings",
      "qualname": "<module>.Settings",
      "source": "class Settings(BaseSettings):\n    ORIGINS: List[str] = [\"*\"]\n    \n    # Service timeout settings (minutes)\n    SERVICE_TIMEOUT_MINUTES: Optional[int] = None\n    \n    # Log configuration\n    LOG_LEVEL: str = \"INFO\"\n    \n    @field_validator(\"ORIGINS\", mode=\"before\")\n    def assemble_cors_origins(cls, v: Union[str, List[str]]) -> Union[List[str], str]:\n        if isinstance(v, str) and not v.startswith(\"[\"):\n            return [i.strip() for i in v.split(\",\")]\n        elif isinstance(v, (list, str)):\n            return v\n        raise ValueError(v)\n\n    class Config:\n        case_sensitive = True\n        env_file = \".env\"\n",
      "methods": [
        "<module>.Settings.assemble_cors_origins"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/core/config.py",
      "name": "Config",
      "qualname": "<module>.Settings.Config",
      "source": "    class Config:\n        case_sensitive = True\n        env_file = \".env\"\n",
      "methods": []
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/core/exceptions.py",
      "name": "AppException",
      "qualname": "<module>.AppException",
      "source": "class AppException(Exception):\n    \"\"\"Base application exception class\"\"\"\n    def __init__(\n        self, \n        message: str = \"An error occurred\", \n        status_code: int = status.HTTP_500_INTERNAL_SERVER_ERROR,\n        data: Any = None\n    ):\n        self.message = message\n        self.status_code = status_code\n        self.data = data\n        logger.error(\"AppException: %s (code: %d)\", message, status_code)\n        super().__init__(self.message)\n",
      "methods": [
        "<module>.AppException.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/core/exceptions.py",
      "name": "ResourceNotFoundException",
      "qualname": "<module>.ResourceNotFoundException",
      "source": "class ResourceNotFoundException(AppException):\n    \"\"\"Resource not found exception\"\"\"\n    def __init__(self, message: str = \"Resource not found\"):\n        super().__init__(message=message, status_code=status.HTTP_404_NOT_FOUND)\n",
      "methods": [
        "<module>.ResourceNotFoundException.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/core/exceptions.py",
      "name": "BadRequestException",
      "qualname": "<module>.BadRequestException",
      "source": "class BadRequestException(AppException):\n    \"\"\"Bad request exception\"\"\"\n    def __init__(self, message: str = \"Bad request\"):\n        super().__init__(message=message, status_code=status.HTTP_400_BAD_REQUEST)\n",
      "methods": [
        "<module>.BadRequestException.__init__"
      ]
    },
    {
      "file": "/home/yf/Workspace/coding_agent/sandbox/app/core/exceptions.py",
      "name": "UnauthorizedException",
      "qualname": "<module>.UnauthorizedException",
      "source": "class UnauthorizedException(AppException):\n    \"\"\"Unauthorized exception\"\"\"\n    def __init__(self, message: str = \"Unauthorized\"):\n        super().__init__(message=message, status_code=status.HTTP_401_UNAUTHORIZED)\n",
      "methods": [
        "<module>.UnauthorizedException.__init__"
      ]
    }
  ],
  "errors": [],
  "num_files_processed": 172,
  "num_classes": 318
}